{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///(webpack)/buildin/global.js","webpack:///./node_modules/process/browser.js","webpack:///./shells/lib/source/pouchdb.js","webpack:///./node_modules/pouchdb/lib/index-browser.es.js","webpack:///./node_modules/immediate/lib/browser.js","webpack:///./node_modules/uuid/index.js","webpack:///./node_modules/uuid/v1.js","webpack:///./node_modules/uuid/lib/rng-browser.js","webpack:///./node_modules/uuid/lib/bytesToUuid.js","webpack:///./node_modules/uuid/v4.js","webpack:///./node_modules/spark-md5/spark-md5.js","webpack:///./node_modules/vuvuzela/index.js","webpack:///./node_modules/argsarray/index.js","webpack:///./node_modules/pouchdb/node_modules/inherits/inherits_browser.js","webpack:///./node_modules/events/events.js","webpack:///./node_modules/pouchdb-adapter-memory/lib/index.es.js","webpack:///./node_modules/pouchdb-utils/lib/index-browser.es.js","webpack:///./node_modules/pouchdb-collections/lib/index.es.js","webpack:///./node_modules/pouchdb-utils/node_modules/inherits/inherits_browser.js","webpack:///./node_modules/pouchdb-errors/lib/index.es.js","webpack:///./node_modules/pouchdb-errors/node_modules/inherits/inherits_browser.js","webpack:///./node_modules/pouchdb-md5/lib/index-browser.es.js","webpack:///./node_modules/pouchdb-binary-utils/lib/index-browser.es.js","webpack:///./node_modules/pouchdb-adapter-leveldb-core/lib/index-browser.es.js","webpack:///./node_modules/levelup/lib/levelup.js","webpack:///./node_modules/node-libs-browser/node_modules/util/util.js","webpack:///./node_modules/node-libs-browser/node_modules/util/support/isBufferBrowser.js","webpack:///./node_modules/node-libs-browser/node_modules/inherits/inherits_browser.js","webpack:///./node_modules/xtend/immutable.js","webpack:///./node_modules/levelup/node_modules/deferred-leveldown/deferred-leveldown.js","webpack:///./node_modules/abstract-leveldown/index.js","webpack:///./node_modules/abstract-leveldown/abstract-leveldown.js","webpack:///./node_modules/node-libs-browser/node_modules/buffer/index.js","webpack:///./node_modules/base64-js/index.js","webpack:///./node_modules/ieee754/index.js","webpack:///./node_modules/isarray/index.js","webpack:///./node_modules/abstract-leveldown/abstract-iterator.js","webpack:///./node_modules/abstract-leveldown/abstract-chained-batch.js","webpack:///./node_modules/levelup/node_modules/inherits/inherits_browser.js","webpack:///./node_modules/levelup/node_modules/deferred-leveldown/deferred-iterator.js","webpack:///./node_modules/level-iterator-stream/index.js","webpack:///./node_modules/level-iterator-stream/node_modules/inherits/inherits_browser.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/readable-browser.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_readable.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/stream-browser.js","webpack:///util (ignored)?5fc9","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/buffer_list.js","webpack:///util (ignored)?47fa","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/destroy.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/state.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/errors-browser.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/experimentalWarning.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_duplex.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_writable.js","webpack:///./node_modules/util-deprecate/browser.js","webpack:///./node_modules/string_decoder/lib/string_decoder.js","webpack:///./node_modules/string_decoder/node_modules/safe-buffer/index.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/async_iterator.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/end-of-stream.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_transform.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_passthrough.js","webpack:///./node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/pipeline.js","webpack:///./node_modules/levelup/lib/batch.js","webpack:///./node_modules/level-errors/errors.js","webpack:///./node_modules/errno/errno.js","webpack:///./node_modules/errno/custom.js","webpack:///./node_modules/prr/prr.js","webpack:///./node_modules/levelup/lib/promisify.js","webpack:///./node_modules/levelup/lib/common.js","webpack:///./node_modules/assert/assert.js","webpack:///./node_modules/object-assign/index.js","webpack:///./node_modules/sublevel-pouchdb/lib/index.es.js","webpack:///./node_modules/ltgt/index.js","webpack:///./node_modules/level-codec/index.js","webpack:///./node_modules/level-codec/lib/encodings.js","webpack:///./node_modules/sublevel-pouchdb/node_modules/readable-stream/readable.js","webpack:///./node_modules/stream-browserify/index.js","webpack:///./node_modules/inherits/inherits_browser.js","webpack:///./node_modules/readable-stream/readable-browser.js","webpack:///./node_modules/readable-stream/lib/_stream_readable.js","webpack:///./node_modules/process-nextick-args/index.js","webpack:///./node_modules/readable-stream/lib/internal/streams/stream-browser.js","webpack:///./node_modules/readable-stream/node_modules/safe-buffer/index.js","webpack:///./node_modules/core-util-is/lib/util.js","webpack:///./node_modules/readable-stream/node_modules/inherits/inherits_browser.js","webpack:///util (ignored)","webpack:///./node_modules/readable-stream/lib/internal/streams/BufferList.js","webpack:///util (ignored)?eacd","webpack:///./node_modules/readable-stream/lib/internal/streams/destroy.js","webpack:///./node_modules/readable-stream/lib/_stream_duplex.js","webpack:///./node_modules/readable-stream/lib/_stream_writable.js","webpack:///./node_modules/timers-browserify/main.js","webpack:///./node_modules/setimmediate/setImmediate.js","webpack:///./node_modules/readable-stream/lib/_stream_transform.js","webpack:///./node_modules/readable-stream/lib/_stream_passthrough.js","webpack:///./node_modules/readable-stream/writable-browser.js","webpack:///./node_modules/readable-stream/duplex-browser.js","webpack:///./node_modules/readable-stream/transform.js","webpack:///./node_modules/readable-stream/passthrough.js","webpack:///./node_modules/sublevel-pouchdb/node_modules/readable-stream/lib/_stream_readable.js","webpack:///./node_modules/sublevel-pouchdb/node_modules/isarray/index.js","webpack:///./node_modules/sublevel-pouchdb/node_modules/inherits/inherits_browser.js","webpack:///./node_modules/sublevel-pouchdb/node_modules/readable-stream/lib/_stream_writable.js","webpack:///./node_modules/sublevel-pouchdb/node_modules/readable-stream/lib/_stream_duplex.js","webpack:///./node_modules/sublevel-pouchdb/node_modules/readable-stream/lib/_stream_transform.js","webpack:///./node_modules/sublevel-pouchdb/node_modules/readable-stream/lib/_stream_passthrough.js","webpack:///./node_modules/through2/through2.js","webpack:///./node_modules/double-ended-queue/js/deque.js","webpack:///./node_modules/buffer-from/index.js","webpack:///./node_modules/pouchdb-adapter-utils/lib/index.es.js","webpack:///./node_modules/pouchdb-merge/lib/index.es.js","webpack:///./node_modules/pouchdb-json/lib/index.es.js","webpack:///./node_modules/memdown/memdown.js","webpack:///./node_modules/memdown/node_modules/abstract-leveldown/index.js","webpack:///./node_modules/memdown/node_modules/abstract-leveldown/abstract-leveldown.js","webpack:///./node_modules/memdown/node_modules/abstract-leveldown/abstract-iterator.js","webpack:///./node_modules/memdown/node_modules/abstract-leveldown/abstract-chained-batch.js","webpack:///./node_modules/memdown/node_modules/abstract-leveldown/is-leveldown.js","webpack:///./node_modules/memdown/node_modules/ltgt/index.js","webpack:///./node_modules/functional-red-black-tree/rbtree.js","webpack:///./node_modules/memdown/immediate-browser.js","webpack:///./node_modules/memdown/node_modules/immediate/lib/index.js","webpack:///./node_modules/memdown/node_modules/immediate/lib/nextTick.js","webpack:///./node_modules/memdown/node_modules/immediate/lib/mutation.js","webpack:///./node_modules/memdown/node_modules/immediate/lib/messageChannel.js","webpack:///./node_modules/memdown/node_modules/immediate/lib/stateChange.js","webpack:///./node_modules/memdown/node_modules/immediate/lib/timeout.js","webpack:///./node_modules/pouchdb-debug/lib/index-browser.es.js","webpack:///./node_modules/debug/src/browser.js","webpack:///./node_modules/debug/src/debug.js","webpack:///./node_modules/ms/index.js"],"names":[],"mappings":";QAAA;QACA;;QAEA;QACA;;QAEA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;;QAEA;QACA;;QAEA;QACA;;QAEA;QACA;QACA;;;QAGA;QACA;;QAEA;QACA;;QAEA;QACA;QACA;QACA,0CAA0C,gCAAgC;QAC1E;QACA;;QAEA;QACA;QACA;QACA,wDAAwD,kBAAkB;QAC1E;QACA,iDAAiD,cAAc;QAC/D;;QAEA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA,yCAAyC,iCAAiC;QAC1E,gHAAgH,mBAAmB,EAAE;QACrI;QACA;;QAEA;QACA;QACA;QACA,2BAA2B,0BAA0B,EAAE;QACvD,iCAAiC,eAAe;QAChD;QACA;QACA;;QAEA;QACA,sDAAsD,+DAA+D;;QAErH;QACA;;;QAGA;QACA;;;;;;;;AClFA;;AAEA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;;AAEA;AACA;AACA,4CAA4C;;AAE5C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnBA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;;;AAIA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,uBAAuB,sBAAsB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qCAAqC;;AAErC;AACA;AACA;;AAEA,2BAA2B;AAC3B;AACA;AACA;AACA,4BAA4B,UAAU;;;;;;;;;;ACvLtC;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAC8B;AACqB;AACV;AACzC,kBAAkB,wDAAO,EAAE,6EAAa,EAAE,mEAAY;;;;;;;;ACZtD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AACR;AACE;AACI;AACK;AACL;AACM;;AAEtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,SAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;;AAEA;AACA;AACA,uCAAuC,SAAS;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA,4BAA4B;AAC5B;AACA;AACA,GAAG,OAAO;AACV;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,oCAAoC,SAAS;AAC7C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,kBAAkB;AAClB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,SAAS,gDAAY;AACrB;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA,SAAS,gDAAY;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,qBAAqB;AACxC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,mBAAmB,gDAAY;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT,OAAO;AACP;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,mCAAmC,SAAS;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;;AAEH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL,oBAAoB,iBAAiB;AACrC;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,+BAA+B;AAC/B;AACA;;AAEA;AACA;AACA;AACA,GAAG;;AAEH;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,qBAAqB,WAAW;AAChC,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,+CAAQ,UAAU,mDAAY;;AAE9B;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA,EAAE,mDAAY;AACd;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,QAAQ,gDAAS;AACjB;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,EAAE,mDAAY;AACd;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA,0BAA0B;AAC1B,GAAG;AACH;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;;AAEA,iCAAiC;AACjC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA,yBAAyB,0BAA0B;AACnD;;AAEA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,+CAAQ;;AAER;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,oCAAoC,SAAS;AAC7C;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iCAAiC,mDAAY;AAC7C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,wBAAwB,4BAA4B;AACpD;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,kBAAkB;AACrC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,YAAY;AAC7B;AACA;AACA;AACA;;AAEA;AACA,6DAA6D,WAAW;AACxE;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,YAAY;AAC7B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,gDAAG,SAAS,gDAAG;;AAElD;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA,SAAS,gDAAG;AACZ;;AAEA;AACA;AACA;AACA,WAAW,2CAAM;AACjB;;AAEA;AACA;AACA;;AAEA,WAAW,2CAAM;;AAEjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B,4CAA4C,SAAS;AACrD,sBAAsB,+BAA+B;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,SAAS;AACnD,oBAAoB,4CAA4C;AAChE;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,0CAA0C;AAC7D;AACA,GAAG;AACH;AACA,sCAAsC,SAAS;AAC/C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,SAAS;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,kBAAkB,mBAAmB;AACrC;AACA,kBAAkB,8CAA8C;AAChE;AACA,0CAA0C,SAAS;AACnD,oBAAoB,iDAAiD;AACrE;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,SAAS;AACtD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,gBAAgB,iCAAiC;AACjD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,mBAAmB,qBAAqB;AACxC;AACA;AACA;AACA;AACA;;AAEA;AACA,qBAAqB,qBAAqB;AAC1C;AACA,sBAAsB,uCAAuC;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,YAAY;AACZ;;AAEA,oCAAoC,SAAS;AAC7C;AACA;AACA;AACA;AACA;AACA,oBAAoB,+BAA+B;AACnD;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA,kBAAkB,uDAAuD;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,iBAAiB;AACvE;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;;AAEA;;AAEA;AACA;AACA,OAAO;AACP;AACA;AACA,sBAAsB,yBAAyB;AAC/C;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,qCAAqC,SAAS;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,gBAAgB;AACrC;AACA;AACA;AACA,KAAK,OAAO;AACZ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,SAAS;AACnD,oBAAoB,oCAAoC;AACxD;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,kBAAkB,6BAA6B;;AAE/C;AACA,2CAA2C,SAAS;AACpD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,wCAAwC,OAAO;AAC/C,oBAAoB,iDAAiD;AACrE;AACA;;AAEA;AACA;AACA;;AAEA,+CAAQ,YAAY,mDAAY;;AAEhC;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA,EAAE,mDAAY;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,yBAAyB,oBAAoB;AAC7C,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;;;;AAIH;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,cAAc;AACnC;AACA;AACA,uBAAuB,SAAS,YAAY,EAAE;AAC9C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oBAAoB;AAC5C;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,gDAAY;AAC9B;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,iBAAiB;AAClC;AACA;AACA,8BAA8B;AAC9B,KAAK;AACL;AACA;AACA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,uBAAuB;AACzC;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,MAAM,gDAAS;AACf;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,+CAAQ,kBAAkB,mDAAY;;AAEtC;AACA,EAAE,mDAAY;;AAEd;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,YAAY;AAC7B,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA,KAAK;AACL,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,qBAAqB,YAAY;AACjC;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA,+BAA+B,WAAW;AAC1C,KAAK;AACL;AACA;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA,iBAAiB,eAAe;AAChC,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,4BAA4B;AAC5B;;AAEA;AACA;;AAEA;AACA;AACA,uBAAuB,YAAY;AACnC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,yBAAyB,iBAAiB;AAC1C,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL,GAAG;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,8BAA8B,+BAA+B;AAC7D;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,OAAO;AACP,KAAK;AACL,sBAAsB,SAAS;AAC/B,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,4CAA4C,OAAO;AACnD;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,QAAQ;AACjC;AACA,SAAS;AACT,uBAAuB,cAAc;AACrC;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA,uBAAuB,mBAAmB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,WAAW;AACX;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,qBAAqB,kBAAkB;AACvC;AACA,0DAA0D,aAAa,EAAE;AACzE;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,kDAAkD,aAAa,EAAE;AACjE;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,SAAS;AACvC;AACA;AACA;;AAEA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,iBAAiB,qBAAqB;AACtC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,GAAG;;AAEH;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,qCAAqC,OAAO;AAC5C;AACA;AACA;;AAEA;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,UAAU;AAChC,KAAK;AACL,CAAC;;AAED;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,aAAa;AAC3C,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO,OAAO;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qBAAqB;AACrB,mBAAmB,8BAA8B;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,+CAAQ;AACR;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;;AAEH;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,SAAS,uBAAuB;;AAEnD;AACA;;AAEA;AACA;;AAEA;;AAEA,uBAAuB,mDAAY;;AAEnC;AACA,cAAc,mDAAY;AAC1B,eAAe,mDAAY;AAC3B;AACA;AACA,GAAG;;AAEH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,kCAAkC;AAClC;AACA,GAAG;AACH;AACA,GAAG;AACH,4CAA4C;AAC5C;AACA,KAAK;AACL;AACA;AACA,iDAAiD;AACjD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,mCAAmC;AACnC;AACA;;AAEA,EAAE,+CAAQ;;AAEV;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA,gDAAgD;;AAEhD;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,2CAA2C,SAAS;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,yCAAyC,SAAS;AAClD;AACA;AACA,+CAA+C;AAC/C;AACA,OAAO,OAAO;AACd;AACA;AACA;AACA,KAAK,OAAO;AACZ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA,aAAa,SAAS,GAAG,SAAS;AAClC,WAAW;AACX;;AAEA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;;AAEA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;AACA;AACA,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA,WAAW;AACX;AACA,WAAW;AACX;AACA,WAAW;AACX;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL,GAAG;;AAEH;AACA;;;;AAIA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA,KAAK,OAAO;AACZ,wCAAwC;AACxC;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,sCAAsC;AACtC;AACA;AACA;AACA,KAAK,OAAO;AACZ,sCAAsC;AACtC;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA,KAAK,OAAO;AACZ,wCAAwC;AACxC;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,sCAAsC;AACtC;AACA;AACA;AACA,KAAK,OAAO;AACZ,sCAAsC;AACtC;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG,OAAO;AACV;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD;AAClD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAe,WAAW,UAAU,MAAM;AAC1C;AACA;AACA,uBAAuB,mBAAmB;AAC1C;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA,OAAO;AACP;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;;AAEA;;AAEA,iBAAiB,mBAAmB;AACpC;AACA;;AAEA;AACA,iBAAiB;AACjB,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,yBAAyB;AACzB,yBAAyB;AACzB,aAAa;;AAEb;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,SAAS;AAChC;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO,yBAAyB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,kDAAkD;AACvD;AACA;AACA,KAAK;AACL,sBAAsB;AACtB;AACA;AACA;;AAEA;AACA;AACA,qBAAqB;AACrB;;AAEA,6CAA6C,sBAAsB;AACnE;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,sBAAsB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA,0BAA0B,YAAY;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,kDAAkD;AAClD;AACA,YAAY;AACZ;AACA;;AAEA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA,8BAA8B;AAC9B;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;;AAEH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;AACA,GAAG;;AAEH;AACA;AACA,GAAG;;AAEH;AACA;AACA,GAAG;;AAEH;AACA;AACA,GAAG;;AAEH;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;;AAEH;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA,GAAG;;AAEH;AACA;AACA,GAAG;;AAEH;AACA;AACA,GAAG;;AAEH;AACA;AACA,GAAG;;AAEH;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,iDAAiD,uBAAuB;AACxE;AACA;;AAEA;AACA,iCAAiC,uBAAuB,KAAK;AAC7D;;AAEA;AACA;AACA,2BAA2B;AAC3B,oBAAoB;AACpB,2BAA2B;AAC3B,mCAAmC;AACnC,wBAAwB;AACxB,SAAS;AACT,gCAAgC;AAChC,iBAAiB;AACjB,qBAAqB;AACrB,qBAAqB;AACrB,QAAQ;AACR,OAAO;AACP;;AAEA,2BAA2B;AAC3B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,oBAAoB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,+BAA+B,oBAAoB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,GAAG,IAAI;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,2CAA2C,SAAS;AACpD,4BAA4B,kBAAkB;AAC9C;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,kBAAkB;AAC7C,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;;AAEA;;AAEA,gBAAgB,aAAa;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,YAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG,OAAO;AACV;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,qCAAqC;AACrC;AACA,GAAG,OAAO;AACV;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,4BAA4B,QAAQ;AACpC;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA,iBAAiB;AACjB;AACA,KAAK;AACL;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,WAAW,+CAAQ;AACnB;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,WAAW,+CAAQ;AACnB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,qDAAqD;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,WAAW;AAC5C,KAAK,qCAAqC;AAC1C;AACA,KAAK,OAAO;AACZ;AACA;AACA,GAAG,OAAO;AACV;AACA;AACA,KAAK,qCAAqC;AAC1C;AACA;AACA,OAAO;AACP,KAAK,OAAO;AACZ;AACA;AACA;AACA;;AAEA;AACA,sDAAsD;AACtD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA,WAAW;AACX,SAAS;AACT,OAAO;AACP;AACA,GAAG;AACH;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,OAAO;AAChB;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wCAAwC,SAAS;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,0CAA0C,SAAS;AACnD;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,yBAAyB;AACzB,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;;AAGA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA,+DAA+D;;AAE/D;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B,4BAA4B;AAC5B;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC,wBAAwB;AACxB;AACA;;AAEA;;;AAGA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,2BAA2B;AAC3B;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA;;AAEA;AACA,oBAAoB;AACpB;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,8BAA8B;AAC9B;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH,YAAY;AACZ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,gD;AACA;AACA;AACA;;AAEA,gB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,4C;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,O;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,6CAA6C,SAAS;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,iBAAiB;AACjB,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM,gDAAS;AACf;AACA,OAAO;AACP,KAAK;AACL,GAAG;AACH;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA,cAAc;AACd;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,uCAAuC;AACvC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,yCAAyC;AACzC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,WAAW;AACX,SAAS;AACT,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA,+CAA+C,SAAS;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,6CAA6C,SAAS;AACtD;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,GAAG;AACH;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA,oDAAoD,eAAe;AACnE,wCAAwC,oBAAoB;AAC5D,kDAAkD,aAAa;AAC/D,wCAAwC,kBAAkB;AAC1D,sCAAsC,oCAAoC;AAC1E;;AAEA;AACA,8DAA8D,eAAe;;AAE7E;AACA,uCAAuC,eAAe;;AAEtD;AACA;AACA,OAAO,oBAAoB;AAC3B;AACA,0DAA0D,aAAa;AACvE;;AAEA;AACA;AACA;AACA;AACA;AACA,8DAA8D,eAAe;;AAE7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA,uCAAuC,eAAe;AACtD,kDAAkD,aAAa;AAC/D;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO,oBAAoB;AAC3B;AACA,0DAA0D,aAAa;AACvE;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;;AAEA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA,qDAAqD;AACrD;AACA,uBAAuB,iBAAiB;AACxC;AACA,uCAAuC;AACvC;AACA;AACA,mBAAmB,oBAAoB;AACvC;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,GAAG;;AAEH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,qBAAqB,uCAAuC;AAC5D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,kCAAkC;AAClC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,OAAO;AAChB;AACA;AACA,mBAAmB;AACnB,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA,KAAK,OAAO;AACZ;AACA;AACA;AACA;AACA,2BAA2B;AAC3B,4BAA4B;AAC5B;AACA;AACA,eAAe;AACf,uBAAuB;AACvB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,eAAe;AACf,uBAAuB;AACvB;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,aAAa;AACnC;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,WAAW,gDAAS;AACpB;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;;AAEA;AACA;AACA;;AAEA;AACA,iCAAiC;AACjC;AACA;AACA,+BAA+B;AAC/B;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAgB;AAChB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,4BAA4B,gDAAY;AACxC;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,iCAAiC,cAAc;AAC/C,OAAO;AACP;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;;AAEL;AACA;;AAEA,EAAE,gDAAS;AACX;AACA,GAAG;;AAEH;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,2CAA2C,eAAe;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,SAAS;AACrC,WAAW;AACX;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,iBAAiB;AAC/C,OAAO;AACP;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,4BAA4B,0BAA0B;AACtD;AACA;AACA;;AAEA,qBAAqB,gBAAgB;AACrC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA,KAAK;AACL,GAAG;;;AAGH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;;AAEA,oBAAoB,iBAAiB;AACrC,GAAG;;AAEH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,cAAc;AACjC;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,iBAAiB;AACrC,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,sBAAsB,qBAAqB;AAC3C;AACA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;;AAGA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,cAAc;AACd;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,6CAA6C;AAC7C;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA,mBAAmB;;AAEnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,QAAQ,gDAAS,cAAc,oCAAoC,EAAE;AACrE,OAAO;AACP;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;AACA;;AAEA;AACA,mCAAmC,iBAAiB;AACpD;AACA,KAAK;AACL;AACA;AACA,wBAAwB,SAAS;AACjC,OAAO;AACP;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA,+CAAQ;;AAER;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA,+CAAQ;;AAER;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA,+CAAQ;;AAER;AACA;AACA;AACA,MAAM,gDAAS;AACf;AACA,OAAO;AACP,KAAK;AACL,MAAM,gDAAS;AACf;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;;AAEA;AACA,SAAS,gDAAY;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,sCAAsC,SAAS;AAC/C;AACA;AACA;AACA;AACA;AACA,0CAA0C,UAAU;AACpD;AACA;AACA;AACA,WAAW;AACX;AACA,WAAW;AACX;AACA;AACA;AACA,OAAO,OAAO;AACd;AACA;AACA,KAAK;AACL;AACA,KAAK,OAAO;AACZ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,gCAAgC,gBAAgB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA,iDAAiD,UAAU,EAAE;AAC7D;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL,GAAG;;AAEH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,gDAAgD,UAAU,EAAE,EAAE;AAC9D;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd,KAAK;AACL;AACA,cAAc;AACd;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,oDAAoD,kBAAkB;AACtE,KAAK;AACL;AACA,oCAAoC,kBAAkB;AACtD,OAAO;AACP;AACA;AACA,YAAY,YAAY;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,kBAAkB;AAClB,SAAS,OAAO,YAAY,aAAa;AACzC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,wBAAwB,mCAAmC;AAC3D;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;;AAEL;AACA,sBAAsB,mCAAmC;AACzD;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,gCAAgC,SAAS;AACzC;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA,kDAAkD,SAAS;AAC3D;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,yBAAyB,sBAAsB;AAC/C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,mCAAmC,qBAAqB;AACxD,SAAS;AACT,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,2CAA2C,SAAS;AACpD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,8CAA8C,SAAS;AACvD;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA,wCAAwC,SAAS;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,YAAY;AACZ;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,8CAA8C;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA,SAAS;AACT,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,+CAA+C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK,OAAO;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,oCAAoC;AACpC;AACA;AACA;AACA,oDAAoD;AACpD;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,sBAAsB,mCAAmC;AACzD;AACA,KAAK;AACL;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,WAAW;AACX,SAAS;AACT;AACA,iCAAiC,mCAAmC,EAAE;AACtE;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;AACA,kBAAkB;AAClB,SAAS;AACT,OAAO;AACP,KAAK,cAAc,SAAS;AAC5B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA,WAAW;AACX,SAAS;AACT,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,6BAA6B;AAC7B;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,gDAAS;AACvB;AACA,eAAe;AACf;AACA;AACA,WAAW,OAAO;AAClB;AACA;AACA,aAAa;AACb;AACA,SAAS;AACT,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,aAAa;AACb;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA,0CAA0C,SAAS;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,gDAAgD,cAAc;AAC9D,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;;AAEvB;AACA;;AAEA;;AAEA;;AAEA,mCAAmC;AACnC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,2BAA2B;AAC3B;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;;AAEvC;AACA,qCAAqC;AACrC,SAAS;AACT,OAAO;;AAEP;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA,YAAY;AACZ;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG,IAAI;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA,mBAAmB;AACnB,mBAAmB;AACnB;AACA;AACA;AACA;AACA,IAAI;AACJ,gCAAgC;AAChC,+BAA+B;AAC/B,mCAAmC;AACnC;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,0BAA0B;AAC1B,OAAO;AACP,0BAA0B;AAC1B,OAAO;AACP,0BAA0B;AAC1B,OAAO;AACP,0BAA0B;AAC1B;;AAEA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,oBAAoB;AACpB,4BAA4B,6BAA6B;AACzD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT;AACA;AACA,OAAO;;AAEP,KAAK;AACL;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,gDAAS;AACb;AACA,KAAK;AACL;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,+BAA+B;AAC/B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,8BAA8B;AAC9B;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA,+CAAQ,cAAc,mDAAY;AAClC;AACA,EAAE,mDAAY;AACd;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,+CAAQ,OAAO,mDAAY;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qDAAqD;AACrD,qDAAqD;;AAErD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;;AAEA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEe,sEAAO,EAAC;;;;;;;;;ACphUvB,8CAAa;AACb;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA,mCAAmC;AACnC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpEA,SAAS,mBAAO,CAAC,EAAM;AACvB,SAAS,mBAAO,CAAC,EAAM;;AAEvB;AACA;AACA;;AAEA;;;;;;;ACPA,UAAU,mBAAO,CAAC,EAAW;AAC7B,kBAAkB,mBAAO,CAAC,EAAmB;;AAE7C;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,mCAAmC;AACnC;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,iBAAiB,OAAO;AACxB;AACA;;AAEA;AACA;;AAEA;;;;;;;AC5GA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,iCAAiC;;AAEjC;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA,sBAAsB,QAAQ;AAC9B;AACA;AACA;;AAEA;AACA;AACA;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA,eAAe,SAAS;AACxB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;ACtBA,UAAU,mBAAO,CAAC,EAAW;AAC7B,kBAAkB,mBAAO,CAAC,EAAmB;;AAE7C;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,SAAS;AAC7B;AACA;AACA;;AAEA;AACA;;AAEA;;;;;;;AC5BA;AACA,QAAQ,IAA2B;AACnC;AACA;AACA,KAAK,MAAM,aAcN;AACL,CAAC;;AAED;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAc;;AAEd,mBAAmB,QAAQ;AAC3B;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAc;;AAEd,mBAAmB,QAAQ;AAC3B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAoB,QAAQ;AAC5B;AACA;AACA;AACA;AACA;AACA,mBAAmB,YAAY;AAC/B;AACA;AACA;AACA;AACA;AACA,uBAAuB,QAAQ;AAC/B;AACA;AACA;;AAEA;AACA;AACA,8CAA8C,IAAI;AAClD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAoB,QAAQ;AAC5B;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,mBAAmB,YAAY;AAC/B;AACA;;AAEA;AACA;AACA;AACA,uBAAuB,QAAQ;AAC/B;AACA;AACA;;AAEA;AACA;AACA,8CAA8C,IAAI;AAClD;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,mBAAmB,OAAO;AAC1B;AACA;AACA;AACA;;AAEA;AACA;AACA,mBAAmB,cAAc;AACjC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,SAAS;AACT;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,mBAAmB,YAAY;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,mBAAmB,gBAAgB;AACnC;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,eAAe,OAAO;AACtB;AACA,gBAAgB,SAAS;AACzB;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,eAAe,OAAO;AACtB;AACA,gBAAgB,SAAS;AACzB;AACA;AACA;AACA;;AAEA;AACA;;AAEA,oBAAoB,aAAa;AACjC;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB;AACA,gBAAgB,OAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,mBAAmB,YAAY;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,gBAAgB,SAAS;AACzB;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,gBAAgB,OAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAe,OAAO;AACtB;AACA,gBAAgB,SAAS;AACzB;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAe,MAAM;AACrB,eAAe,OAAO;AACtB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,uBAAuB,QAAQ;AAC/B;AACA;AACA;;AAEA;AACA;AACA;AACA,8CAA8C,IAAI;AAClD;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,eAAe,OAAO;AACtB,eAAe,QAAQ;AACvB;AACA,gBAAgB,OAAO;AACvB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAe,OAAO;AACtB,eAAe,QAAQ;AACvB;AACA,gBAAgB,OAAO;AACvB;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAe,YAAY;AAC3B;AACA,gBAAgB,qBAAqB;AACrC;AACA;AACA;AACA;AACA;;AAEA;;AAEA,oBAAoB,aAAa;AACjC;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB;AACA,gBAAgB,OAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,mBAAmB,YAAY;AAC/B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,gBAAgB,qBAAqB;AACrC;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,gBAAgB,OAAO;AACvB;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,eAAe,OAAO;AACtB;AACA,gBAAgB,qBAAqB;AACrC;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA,eAAe,YAAY;AAC3B,eAAe,QAAQ;AACvB;AACA,gBAAgB,OAAO;AACvB;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,CAAC;;;;;;;;AC9uBY;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,WAAW;;AAEzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,KAAK;AACL,kBAAkB,SAAS;AAC3B,8BAA8B,QAAQ;AACtC;AACA,oBAAoB,iCAAiC;AACrD;AACA,kBAAkB,SAAS;AAC3B,KAAK,OAAO;AACZ;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,OAAO,EAAE;AAC3B,+BAA+B,QAAQ;AACvC;AACA;AACA;AACA;AACA,oBAAoB,8BAA8B;AAClD;AACA,kBAAkB,OAAO,EAAE;AAC3B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG,kDAAkD;AACrD;AACA;AACA,GAAG;AACH,oBAAoB;AACpB;AACA;;AAEA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA,aAAa;AACb,sBAAsB,YAAY;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5Ka;;AAEb;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,C;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEa;;AAEb;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,sBAAsB;AACvC;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA,cAAc;AACd;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA,mBAAmB,SAAS;AAC5B;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,sBAAsB;AACvC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA,iCAAiC,QAAQ;AACzC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,OAAO;AACP;AACA,sCAAsC,QAAQ;AAC9C;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,OAAO;AACxB;AACA;AACA;;AAEA;AACA,QAAQ,yBAAyB;AACjC;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,gBAAgB;AACjC;AACA;AACA;AACA;;;;;;;;AC/bA;AAAA;AAAA;AAAA;AAAA;AAAuC;AACmB;AAC5B;;AAE9B;AACA,cAAc,4DAAM;AACpB,QAAQ,8CAAO;AACf,GAAG;;AAEH,EAAE,oEAAc;AAChB;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEe,oEAAK,EAAC;;;;;;;;ACtBrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAqC;AACK;AACV;AACE;AAC6D;AACzD;AACZ;AACc;;AAExC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,oCAAoC,SAAS;AAC7C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,kBAAkB;AAClB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,SAAS,gDAAY;AACrB;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA,SAAS,gDAAY;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,qBAAqB;AACxC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,mBAAmB,gDAAY;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT,OAAO;AACP;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,mCAAmC,SAAS;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA,yBAAyB,uDAAG;AAC5B;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;;AAEH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL,oBAAoB,iBAAiB;AACrC;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,+BAA+B;AAC/B;AACA;;AAEA;AACA;AACA;AACA,GAAG;;AAEH;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,qBAAqB,WAAW;AAChC,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,+CAAQ,UAAU,mDAAY;;AAE9B;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA,EAAE,mDAAY;AACd;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,QAAQ,gDAAS;AACjB;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,EAAE,mDAAY;AACd;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA,0BAA0B;AAC1B,GAAG;AACH;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;;AAEA,iCAAiC;AACjC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA,yBAAyB,0BAA0B;AACnD;;AAEA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,WAAW,kEAAW,CAAC,0DAAW;AAClC;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,oCAAoC,SAAS;AAC7C;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,kEAAW,CAAC,yDAAU;AAChC,GAAG;AACH,UAAU,kEAAW,CAAC,yDAAU;AAChC,GAAG;AACH,UAAU,kEAAW,CAAC,0DAAW;AACjC;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iCAAiC,mDAAY;AAC7C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,wBAAwB,4BAA4B;AACpD;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,WAAW,2CAAM;AACjB;;AAEA;AACA,SAAS,6DAAS;AAClB;;AAEA,WAAW,2CAAM;;AAEib;;;;;;;;ACjwBlc;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,SAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;;AAEA;AACA;AACA,uCAAuC,SAAS;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA,4BAA4B;AAC5B;AACA;AACA,GAAG,OAAO;AACV;AACA;AACA;AACA;;AAEkD;;;;;;;ACjGlD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAgC;;AAEhC,+CAAQ;;AAER;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEkX;;;;;;;AC7FlX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+D;AACnC;;AAE5B;AACA;;AAEA;AACA,SAAS,iEAAI;AACb;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,EAAE,8EAAiB;AACnB;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,gDAAG,SAAS,gDAAG;;AAElD;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA,SAAS,gDAAG;AACZ;;AAEgC;;;;;;;;;AC3EhC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,kBAAkB;AACrC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,YAAY;AAC7B;AACA;AACA;AACA;;AAEA;AACA,6DAA6D,WAAW;AACxE;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,YAAY;AAC7B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEuU;;;;;;;;AC9GvU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8B;AACU;AACT;AACM;AACE;AACF;AACiE;AACH;AACnC;AACxB;AAC0D;AACnD;AACmD;AACO;;AAEzG;AACA;AACA;AACA;AACA;AACA,SAAS,kEAAI,eAAe,WAAW;AACvC;;AAEA;AACA;AACA,EAAE,gFAAkB;AACpB;;AAEA;AACA,SAAS,kEAAI,QAAQ,WAAW;AAChC;;AAEA;AACA;AACA;AACA;AACA;AACA,mBAAmB,wDAAG;AACtB;AACA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,wDAAG;AACvB;;AAEA;AACA;AACA;AACA;AACA,WAAW,+DAAQ;AACnB;AACA,KAAK;AACL,GAAG,4BAA4B;AAC/B;AACA,WAAW,+DAAQ;AACnB,gBAAgB,sBAAsB;AACtC,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA,qCAAqC,SAAS;AAC9C;;AAEA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;;AAEA,iBAAiB,wDAAG;AACpB;;AAEA,uBAAuB;AACvB,sCAAsC,QAAQ;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,mBAAmB,wDAAG;;AAEtB;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,UAAU,8DAAiB;AAC3B,UAAU,0DAAa;AACvB;AACA;AACA;;AAEA,uBAAuB,6DAAc;;AAErC;AACA;AACA;AACA;AACA,0BAA0B,gEAAU;AACpC;;AAEA;AACA;AACA,uBAAuB,uEAAS;AAChC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,WAAW;AACX,mBAAmB,wFAA0B;AAC7C;AACA;AACA,OAAO,OAAO;AACd;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;AACA,GAAG;AACH;;AAEA;AACA,SAAS,4DAAK;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,sBAAsB,mEAAY;AAClC;AACA;AACA,GAAG;AACH,kBAAkB,wDAAG;AACrB;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,sBAAsB,gEAAQ,CAAC,8CAAO;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,yDAAK;AAC3B;AACA,6CAA6C;AAC7C;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL;;AAEA;AACA,8CAA8C,gCAAgC;AAC9E,mDAAmD,sBAAsB;AACzE;AACA,qCAAqC,sBAAsB;AAC3D,oDAAoD,wBAAwB;AAC5E,kDAAkD,sBAAsB;AACxE,gDAAgD,sBAAsB;AACtE;AACA,2CAA2C;AAC3C;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,2DAAI;AAC1C;AACA,YAAY,+DAAQ;AACpB;AACA,aAAa;AACb,WAAW;AACX,SAAS;AACT,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACxC;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,uBAAuB,mEAAY;AACnC;AACA,WAAW,+DAAQ;AACnB;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK,OAAO;AACZ;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,8BAA8B,gDAAY;AAC1C;AACA;AACA,UAAU,+DAAQ;AAClB;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,WAAW;AACX;AACA,OAAO;AACP;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,4BAA4B,gDAAY;AACxC;AACA,MAAM,+DAAQ;AACd;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,WAAW,gDAAY;AACvB;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA,QAAQ,+DAAQ;AAChB;AACA,KAAK;AACL;;AAEA;AACA;AACA,WAAW,gDAAY;AACvB;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA,QAAQ,+DAAQ;AAChB;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,WAAW,4DAAK;;AAEhB;;AAEA;AACA,wBAAwB,mEAAW,CAAC,2DAAW;AAC/C;;AAEA;AACA;AACA;AACA;AACA;AACA,0BAA0B,mEAAW,CAAC,2DAAW;AACjD;AACA,OAAO;AACP,4BAA4B,4DAAM;AAClC;;AAEA;;AAEA;AACA;AACA,0BAA0B,mEAAW,CAAC,2DAAW;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,+BAA+B,6BAA6B;AAC5D,OAAO;AACP,KAAK;AACL,GAAG;;AAEH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,0BAA0B,wDAAG;AAC7B,0BAA0B,wDAAG;;AAE7B;AACA;AACA;;AAEA;AACA;AACA;AACA,qBAAqB,uEAAS;AAC9B;AACA;AACA,mBAAmB,sEAAQ;;AAE3B;AACA;AACA;;AAEA;AACA,KAAK;AACL;AACA;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,oBAAoB,mEAAW,CAAC,4DAAY;AAC5C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,uBAAuB,uEAAS;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,SAAS;AAC3D;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,WAAW;AACX,SAAS;AACT,OAAO;;AAEP;AACA;AACA,OAAO;AACP;;AAEA;AACA,wBAAwB,wDAAG;AAC3B;AACA,2BAA2B,iEAAW;AACtC,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,UAAU,6DAAS;AACnB;AACA;;AAEA,qBAAqB,wBAAwB;AAC7C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,kEAAI;AACvB,WAAW;AACX,qBAAqB,mEAAW,CAAC,uDAAO;AACxC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,kDAAU;AAC3B,SAAS;AACT;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA,eAAe,+DAAQ;AACvB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAQ;AAChB;AACA,SAAS;AACT,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,yEAAW;AACnB;AACA,OAAO;AACP,KAAK;AACL,GAAG;AACH;AACA;AACA,aAAa,8EAAgB;AAC7B;AACA;AACA,aAAa,4DAAK;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4BAA4B,oDAAG;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,sEAAgB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA,SAAS;AACT;AACA,SAAS;;AAET;;AAEA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA,WAAW,4DAAK;;AAEhB;AACA,4BAA4B,2DAAI;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qCAAqC,wDAAG;AACxC,iBAAiB,mEAAY;AAC7B,+BAA+B,wDAAG;;AAElC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,oCAAoC;AACrE,WAAW;AACX,SAAS;AACT,+BAA+B,oCAAoC;AACnE;AACA;AACA;AACA;AACA,wBAAwB,oDAAG;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf,aAAa;AACb;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,SAAS;AACT;;AAEA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,uEAAS;AACnB;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,sBAAsB,mEAAW,CAAC,wDAAQ;AAC1C;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,iBAAiB,mEAAW,CAAC,2DAAW;AACxC,OAAO;AACP;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM,qEAAe;AACrB;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,wDAAG;AAClC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA,qDAAqD;AACrD;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb,8BAA8B;AAC9B;AACA;AACA;AACA,wBAAwB,cAAc;AACtC;AACA,eAAe;AACf,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA,eAAe;AACf;AACA;AACA,WAAW;AACX,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,uDAAuD;AACvD;AACA;AACA;AACA,WAAW;AACX;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA,iBAAiB,mEAAW,CAAC,2DAAW;AACxC,OAAO;AACP;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA,GAAG;;AAEH;AACA;AACA,0BAA0B;AAC1B;AACA;;AAEA;;AAEA;AACA;AACA,wBAAwB,mEAAW,CAAC,4DAAY;AAChD;AACA;AACA,wBAAwB,mEAAW,CAAC,4DAAY;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,iBAAiB;;AAEjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,0BAA0B,mEAAW,CAAC,2DAAW;AACjD;AACA;AACA;AACA,wBAAwB,mEAAW,CAAC,4DAAY;AAChD;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA,wBAAwB,mEAAY;AACpC;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEe,yEAAU,EAAC;;;;;;;ACjhD1B,kEAAmB,mBAAO,CAAC,EAAQ;AACnC,eAAe,mBAAO,CAAC,GAAM;AAC7B,aAAa,mBAAO,CAAC,GAAO;AAC5B,wBAAwB,mBAAO,CAAC,GAAoB;AACpD,qBAAqB,mBAAO,CAAC,GAAuB;AACpD,YAAY,mBAAO,CAAC,GAAS;AAC7B,aAAa,mBAAO,CAAC,GAAc;AACnC,aAAa,mBAAO,CAAC,GAAQ;AAC7B,gBAAgB,mBAAO,CAAC,GAAa;AACrC,kBAAkB,mBAAO,CAAC,GAAU;AACpC,iBAAiB,mBAAO,CAAC,GAAU;;AAEnC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,mCAAmC,uBAAuB;AAC1D;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,mCAAmC;;AAEnC;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,mCAAmC;;AAEnC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,mCAAmC;;AAEnC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,mCAAmC;;AAEnC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,2BAA2B;AAC/C,0CAA0C;AAC1C;AACA;;AAEA;AACA;AACA,gDAAgD,4BAA4B;AAC5E;;AAEA;AACA;AACA,gDAAgD,4BAA4B;AAC5E;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;;;;;;AC1SA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,uBAAuB,SAAS;AAChC;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,OAAO;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;;AAGA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;AACA,GAAG;;AAEH;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,4CAA4C,KAAK;;AAEjD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,KAAK;AACL;;AAEA;;AAEA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;;AAGA;AACA;AACA,mCAAmC,OAAO;AAC1C;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;;AAGA;AACA;AACA,yDAAyD;AACzD;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;AACA;AACA,WAAW;AACX;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,mBAAmB,mBAAO,CAAC,GAAoB;;AAE/C;AACA;AACA;;;AAGA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,SAAS;AACpB;AACA,WAAW,SAAS;AACpB;AACA,mBAAmB,mBAAO,CAAC,GAAU;;AAErC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA,mBAAmB,sBAAsB;AACzC;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,kCAAkC;AAC7D,2BAA2B,mDAAmD;AAC9E;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9rBA;AACA;AACA;AACA;AACA;AACA,C;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACtBA;;AAEA;;AAEA;AACA;;AAEA,mBAAmB,sBAAsB;AACzC;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;;;;;AClBA,wBAAwB,mBAAO,CAAC,GAAoB;AACpD,eAAe,mBAAO,CAAC,GAAU;AACjC,uBAAuB,mBAAO,CAAC,GAAqB;AACpD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,6BAA6B,6BAA6B;AAC1D;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;;;;;;ACvFA,4BAA4B,mBAAO,CAAC,GAAsB;AAC1D,2BAA2B,mBAAO,CAAC,GAAqB;AACxD,+BAA+B,mBAAO,CAAC,GAA0B;;;;;;;ACFjE,mEAAY,mBAAO,CAAC,GAAO;AAC3B,uBAAuB,mBAAO,CAAC,GAAqB;AACpD,2BAA2B,mBAAO,CAAC,GAA0B;AAC7D;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA,gCAAgC,kCAAkC;AAClE;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA,iBAAiB,kBAAkB;AACnC;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;;ACtQA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEY;;AAEZ,aAAa,mBAAO,CAAC,GAAW;AAChC,cAAc,mBAAO,CAAC,GAAS;AAC/B,cAAc,mBAAO,CAAC,GAAS;;AAE/B;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,qBAAqB,mDAAmD;AACxE;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,UAAU;AAC7B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,YAAY;AAC7B;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA,uCAAuC,SAAS;AAChD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAe,iBAAiB;AAChC;AACA;AACA;;AAEA;AACA;AACA,aAAa,iBAAiB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,gDAAgD,EAAE;AAClD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA,wBAAwB,eAAe;AACvC;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,wBAAwB,QAAQ;AAChC;AACA,qBAAqB,eAAe;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,YAAY;AAC7B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,SAAS;AAC9B;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,qBAAqB,SAAS;AAC9B;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,qBAAqB,SAAS;AAC9B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,kBAAkB;AACnC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,mBAAmB,cAAc;AACjC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,uDAAuD,OAAO;AAC9D;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA,uDAAuD,OAAO;AAC9D;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,kBAAkB;AAClB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,qBAAqB,QAAQ;AAC7B;AACA;AACA,GAAG;AACH;AACA,eAAe,SAAS;AACxB;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA,mBAAmB,SAAS;AAC5B;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,eAAe,iBAAiB;AAChC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,iBAAiB,YAAY;AAC7B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,iBAAiB,gBAAgB;AACjC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,gBAAgB;AACjC;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,iBAAiB,YAAY;AAC7B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;;AC5vDY;;AAEZ;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,kCAAkC,SAAS;AAC3C;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,qBAAqB,SAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,0CAA0C,UAAU;AACpD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;;;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,QAAQ,WAAW;;AAEnB;AACA;AACA;AACA,QAAQ,WAAW;;AAEnB;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA,QAAQ,WAAW;;AAEnB;AACA;AACA,QAAQ,UAAU;;AAElB;AACA;;;;;;;ACnFA,iBAAiB;;AAEjB;AACA;AACA;;;;;;;ACJA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;;;;;;;ACvEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA,yBAAyB,sCAAsC;AAC/D;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,yBAAyB,wBAAwB;AACjD;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;;;;;;AChFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC1BA,uBAAuB,mBAAO,CAAC,GAAoB;AACnD,eAAe,mBAAO,CAAC,GAAU;;AAEjC;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA,yBAAyB,6BAA6B;AACtD;;AAEA;AACA;AACA;AACA;AACA,CAAC;;AAED;;;;;;;AC/BA,eAAe,mBAAO,CAAC,GAAU;AACjC,eAAe,mBAAO,CAAC,GAAiB;AACxC,aAAa,mBAAO,CAAC,GAAO;;AAE5B;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,KAAK;AACL,iBAAiB,yBAAyB;AAC1C;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,GAAG;AACH;;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC1BA,2BAA2B,mBAAO,CAAC,GAA2B;AAC9D;AACA;AACA,mBAAmB,mBAAO,CAAC,GAA2B;AACtD,iBAAiB,mBAAO,CAAC,GAAyB;AAClD,oBAAoB,mBAAO,CAAC,GAA4B;AACxD,sBAAsB,mBAAO,CAAC,GAA8B;AAC5D,mBAAmB,mBAAO,CAAC,GAAyC;AACpE,mBAAmB,mBAAO,CAAC,GAAoC;;;;;;;;ACR/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEb;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,SAAS,mBAAO,CAAC,EAAQ;;AAEzB;AACA;AACA;AACA;;AAEA;;;AAGA,aAAa,mBAAO,CAAC,GAA2B;AAChD;;;AAGA,aAAa,mBAAO,CAAC,GAAQ;;AAE7B;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA,gBAAgB,mBAAO,CAAC,GAAM;;AAE9B;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;;;AAGA,iBAAiB,mBAAO,CAAC,GAAgC;;AAEzD,kBAAkB,mBAAO,CAAC,GAA4B;;AAEtD,eAAe,mBAAO,CAAC,GAA0B;AACjD;;AAEA,qBAAqB,mBAAO,CAAC,GAAW;AACxC;AACA;AACA;AACA;;AAEA,gBAAgB,mBAAO,CAAC,GAAwB;AAChD,gEAAgE;;;AAGhE;AACA;;AAEA,mBAAO,CAAC,GAAU;;AAElB;;AAEA;AACA;AACA;AACA,+FAA+F;AAC/F;AACA;AACA;;AAEA,yEAAyE,mFAAmF;AAC5J;;AAEA;AACA,qBAAqB,mBAAO,CAAC,GAAkB;AAC/C,0BAA0B;AAC1B;AACA;AACA;AACA;;AAEA,yEAAyE;AACzE;;AAEA;AACA,kFAAkF;AAClF;;AAEA,0FAA0F;AAC1F;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;;AAEA,mBAAmB;AACnB;;AAEA;AACA;AACA;AACA;AACA,qBAAqB;;AAErB,+CAA+C;;AAE/C,yBAAyB;AACzB;AACA;;AAEA,2DAA2D;;AAE3D,sBAAsB;;AAEtB;AACA;AACA;;AAEA;AACA,wCAAwC,mBAAO,CAAC,GAAiB;AACjE;AACA;AACA;AACA;;AAEA;AACA,qBAAqB,mBAAO,CAAC,GAAkB;AAC/C,gEAAgE;AAChE;;AAEA;AACA,mEAAmE;;AAEnE;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;;AAGA;AACA;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA,EAAE;AACF;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA,EAAE;;;AAGF;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA,6FAA6F;AAC7F,OAAO;AACP;AACA,OAAO;AACP;AACA,OAAO;AACP;;AAEA;AACA;AACA,4FAA4F;AAC5F,SAAS;AACT;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;AACH;AACA;;;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,gDAAgD;AAChD;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,EAAE;;;AAGF;AACA,sCAAsC,mBAAO,CAAC,GAAiB;AAC/D,uDAAuD;;AAEvD;AACA;AACA,EAAE;;;AAGF;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC;AACD;;;AAGA;AACA;AACA;;AAEA;AACA;AACA,4EAA4E;AAC5E,GAAG;;;AAGH;AACA,kCAAkC;;AAElC;AACA;AACA;AACA;;AAEA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;;AAEA;AACA;AACA,6DAA6D;AAC7D;AACA;;AAEA,8BAA8B;;AAE9B;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA,iCAAiC;;AAEjC;AACA;AACA;AACA,GAAG;AACH;;;AAGA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,sBAAsB;;AAEtB,sDAAsD;;AAEtD;;AAEA,uBAAuB;AACvB;;AAEA;AACA;;AAEA;AACA,sCAAsC;;AAEtC;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA,gDAAgD;;AAEhD;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC;AACD;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,gDAAgD;AAChD;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;AACA,qBAAqB;;AAErB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;;;AAGA;AACA;AACA;AACA;AACA;AACA,GAAG;;;AAGH,0CAA0C;;AAE1C;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,GAAG;;;AAGH,yBAAyB;;AAEzB;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;;AAEJ,0CAA0C;;AAE1C;AACA;AACA;AACA,kCAAkC;;AAElC;AACA;AACA;AACA;AACA;AACA,GAAG;;;AAGH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,mBAAmB,SAAS;AAC5B;AACA;AACA,OAAO;AACP;;AAEA;AACA,GAAG;;;AAGH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAE;AACF;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA,iEAAiE;;AAEjE;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,yBAAyB;AACzB,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;;;AAGA;AACA;;AAEA;AACA,oBAAoB;AACpB;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;;;AAGA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA,0DAA0D;;AAE1D,4EAA4E;;AAE5E;;AAEA;AACA;AACA;AACA;AACA,GAAG,EAAE;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,GAAG;;;AAGH,iBAAiB,yBAAyB;AAC1C;AACA,GAAG;AACH;;;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,0CAA0C,mBAAO,CAAC,GAAmC;AACrF;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,CAAC,EAAE;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,EAAE;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mDAAmD;AACnD;AACA,mDAAmD,+DAA+D;AAClH;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,yDAAyD;;AAEzD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,gCAAgC,OAAO;AACvC;AACA;;AAEA;AACA,C;;;;;;;AC9jCA,iBAAiB,mBAAO,CAAC,EAAQ;;;;;;;ACAjC,e;;;;;;;ACAa;;AAEb,gCAAgC,gBAAgB,sBAAsB,OAAO,uDAAuD,mCAAmC,0DAA0D,sFAAsF,gEAAgE,EAAE,GAAG,EAAE,iCAAiC,2CAA2C,EAAE,EAAE,EAAE,eAAe;;AAE/d,2CAA2C,kBAAkB,kCAAkC,qEAAqE,EAAE,EAAE,OAAO,kBAAkB,EAAE,YAAY;;AAE/M,eAAe,mBAAO,CAAC,GAAQ;AAC/B;;AAEA,gBAAgB,mBAAO,CAAC,GAAM;AAC9B;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,wDAAwD;AACxD;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,wCAAwC;AACxC;;AAEA;AACA;AACA;AACA,yCAAyC;AACzC,SAAS;AACT;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,yCAAyC;AACzC,SAAS;AACT;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,GAAG;AACH;;AAEA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA,CAAC,G;;;;;;AC5LD,e;;;;;;;ACAA,+CAAa;;AAEb;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA,GAAG;AACH;;;AAGA;AACA;AACA,GAAG;;;AAGH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,E;;;;;;;;ACpFa;;AAEb,4BAA4B,mBAAO,CAAC,GAAiB;;AAErD;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;;;AAGH;AACA;;AAEA;AACA;AACA,E;;;;;;;AC1Ba;;AAEb,+CAA+C,0DAA0D,2CAA2C,iCAAiC;;AAErL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,GAAG;;AAEH;AACA;AACA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;AACA;AACA,CAAC;;;AAGD;AACA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;;AAEA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;;;;;;;;AC9HA,+CAAY;;AAEZ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;AACb;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;;AAGA;;AAEA,eAAe,mBAAO,CAAC,GAAoB;;AAE3C,eAAe,mBAAO,CAAC,GAAoB;;AAE3C,mBAAO,CAAC,GAAU;;AAElB;AACA;AACA;;AAEA,iBAAiB,iBAAiB;AAClC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,EAAE;;AAEH;AACA;AACA,wCAAwC;AACxC;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;;AAGA;AACA;AACA;AACA,CAAC,E;;;;;;;;AC1ID;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEb;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA,aAAa,mBAAO,CAAC,GAAgB;AACrC;AACA;;AAEA;;AAEA,aAAa,mBAAO,CAAC,GAA2B;AAChD;;;AAGA,aAAa,mBAAO,CAAC,GAAQ;;AAE7B;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,kBAAkB,mBAAO,CAAC,GAA4B;;AAEtD,eAAe,mBAAO,CAAC,GAA0B;AACjD;;AAEA,qBAAqB,mBAAO,CAAC,GAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,mBAAO,CAAC,GAAU;;AAElB;;AAEA;AACA,qBAAqB,mBAAO,CAAC,GAAkB;AAC/C,0BAA0B;AAC1B;AACA;AACA;AACA;;AAEA,yEAAyE;AACzE;;AAEA;AACA,kFAAkF;AAClF;AACA;;AAEA,0FAA0F;;AAE1F,2BAA2B;;AAE3B,yBAAyB;;AAEzB,sBAAsB;;AAEtB,qBAAqB;;AAErB,wBAAwB;;AAExB,yBAAyB;AACzB;AACA;;AAEA;AACA,iCAAiC;AACjC;AACA;;AAEA,2DAA2D;AAC3D;AACA;;AAEA,kBAAkB;;AAElB,uBAAuB;;AAEvB,kBAAkB;AAClB;AACA;AACA;;AAEA,mBAAmB;AACnB;AACA;;AAEA,gCAAgC;;AAEhC;AACA;AACA,IAAI;;;AAGJ,sBAAsB;;AAEtB;AACA;AACA,kCAAkC;AAClC;;AAEA,qBAAqB;AACrB;;AAEA,2BAA2B;;AAE3B,4BAA4B;;AAE5B,+CAA+C;;AAE/C,gCAAgC;AAChC;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL,GAAG;AACH,CAAC,IAAI;AACL;;;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;;AAEA;AACA,qBAAqB,mBAAO,CAAC,GAAkB,EAAE;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,mEAAmE;;AAEnE;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC;;;AAGD;AACA;AACA;;AAEA;AACA,4CAA4C;;AAE5C;AACA;AACA,CAAC;AACD;AACA;;;AAGA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,iCAAiC;AACjC;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,EAAE;AACH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,+CAA+C;;AAE/C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA,GAAG;AACH;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,wEAAwE,sDAAsD;AAC9H;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,6BAA6B;AAC7B;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD;AACpD;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA,CAAC;;;AAGD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,0EAA0E;AAC1E;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA,yEAAyE;;AAEzE;AACA;AACA;AACA,GAAG;;;AAGH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,6CAA6C;AAC7C;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;;;AAGH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;;AAGA;AACA;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA,E;;;;;;;;ACzqBA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,SAAS;AACpB,WAAW,OAAO;AAClB,aAAa,SAAS;AACtB;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa;AACb;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEa;;AAEb;;AAEA,aAAa,mBAAO,CAAC,GAAa;AAClC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,6BAA6B,sCAAsC,sCAAsC;AACzG;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,C;;;;;;ACvSA;AACA,aAAa,mBAAO,CAAC,GAAQ;AAC7B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7DA,+CAAa;;AAEb;;AAEA,2CAA2C,kBAAkB,kCAAkC,qEAAqE,EAAE,EAAE,OAAO,kBAAkB,EAAE,YAAY;;AAE/M,eAAe,mBAAO,CAAC,GAAiB;;AAExC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,oCAAoC;AACpC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;AACA;;AAEA,iEAAiE;AACjE;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL,GAAG;AACH,CAAC;;AAED;AACA;;AAEA,yFAAyF;AACzF;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,yCAAyC;AACzC;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;;AAEA,mD;;;;;;;;AC9MA;AACA;AACa;;AAEb,iCAAiC,mBAAO,CAAC,GAAiB;;AAE1D;AACA;AACA;AACA;AACA;;AAEA,uEAAuE,aAAa;AACpF;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,gCAAgC;AAChC,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qB;;;;;;;ACvGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,YAAY;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEb;;AAEA,qBAAqB,mBAAO,CAAC,GAAW;AACxC;AACA;AACA;AACA;;AAEA,aAAa,mBAAO,CAAC,GAAkB;;AAEvC,mBAAO,CAAC,GAAU;;AAElB;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;;AAEJ,0CAA0C;AAC1C;AACA;;AAEA;;AAEA;AACA;AACA;AACA,GAAG;;;AAGH;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA,EAAE;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,EAAE;AACF;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;;AAEA;AACA;AACA;AACA,C;;;;;;;ACxMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEb;;AAEA,gBAAgB,mBAAO,CAAC,GAAqB;;AAE7C,mBAAO,CAAC,GAAU;;AAElB;AACA;AACA;AACA;;AAEA;AACA;AACA,E;;;;;;;ACtCA;AACA;AACa;;AAEb;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,mBAAO,CAAC,GAAiB;AAC9C;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,+BAA+B,mBAAO,CAAC,GAAiB;AACxD;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,qBAAqB;;AAErB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,wEAAwE,aAAa;AACrF;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;;AAEA,0B;;;;;;AChGA,iBAAiB,mBAAO,CAAC,GAAc;AACvC,gBAAgB,mBAAO,CAAC,GAAa;AACrC,kBAAkB,mBAAO,CAAC,GAAU;AACpC,iBAAiB,mBAAO,CAAC,GAAU;;AAEnC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA,iBAAiB,sCAAsC;AACvD;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA,iBAAiB,wBAAwB;AACzC;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,gBAAgB;AAChB;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;;AAEA;AACA;;AAEA;;;;;;;AC9EA,kBAAkB,mBAAO,CAAC,GAAO;AACjC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,CAAC;;AAED,wBAAwB,mBAAO,CAAC,GAAU;AAC1C;;;;;;;ACxTA,UAAU,mBAAO,CAAC,GAAK;;AAEvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,MAAM,KAA4B;AAClC;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,CAAC,C;;;;;;AC9DD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;;;;;;;ACZA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;ACNA,8CAAa;;AAEb,mBAAmB,mBAAO,CAAC,GAAe;;AAE1C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,uCAAuC,SAAS;AAChD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,WAAW,mBAAO,CAAC,GAAO;AAC1B;AACA;AACA;AACA,0BAA0B;AAC1B,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,8BAA8B;AAC9B;AACA,mDAAmD;;AAEnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,gBAAgB;AAChB,gDAAgD;;AAEhD;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH,sBAAsB;;AAEtB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,QAAQ;AACjC;AACA;AACA;AACA;AACA;AACA,yBAAyB,QAAQ;AACjC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;;AAEA,yBAAyB;AACzB;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,gCAAgC,oBAAoB;;AAEpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzfA;AACA;AACA;AACA;AACA;;AAEa;AACb;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,gCAAgC;AAChC;AACA;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,QAAQ;AACzB;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH,kCAAkC;AAClC;AACA;AACA;;AAEA;AACA,EAAE;AACF;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,gBAAgB,sBAAsB;AACtC;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,kBAAkB,oBAAoB;AACtC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;;;;;;ACzFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAwB;AACI;AACI;AACiB;AACjB;;AAEhC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB,aAAa;;AAEpC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,kCAAkC;AAClC;;AAEA;AACA,iDAAiD;AACjD;;AAEA,MAAM,2CAAI;;AAEV;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,+CAAQ;;AAER;;AAEA,mBAAmB,6CAAM;AACzB;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,eAAe,sDAAkB;;AAEjC;AACA;AACA;AACA;;AAEA,uBAAuB,yDAAyD;;AAEhF;;AAEA;AACA;AACA;AACA;;AAEA,+CAAQ;;AAER;AACA;AACA;AACA;AACA,gCAAgC;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA,gBAAgB,kDAAK;;AAErB;AACA;AACA;;AAEe,4EAAa,EAAC;;;;;;;;AC9X7B;;AAEA;AACA;AACA,kBAAkB,OAAO;AACzB;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,iBAAiB;;AAEjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;AClKA,gBAAgB,mBAAO,CAAC,GAAiB;;AAEzC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;AC1GA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;AC/DA,aAAa,mBAAO,CAAC,GAAQ,EAAE;AAC/B,2BAA2B,mBAAO,CAAC,GAA2B;AAC9D;AACA;AACA,mBAAmB,mBAAO,CAAC,GAA2B;AACtD,iBAAiB,mBAAO,CAAC,GAAyB;AAClD,oBAAoB,mBAAO,CAAC,GAA4B;AACxD,sBAAsB,mBAAO,CAAC,GAA8B;;;;;;;ACP5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,SAAS,mBAAO,CAAC,EAAQ;AACzB,eAAe,mBAAO,CAAC,GAAU;;AAEjC;AACA,kBAAkB,mBAAO,CAAC,GAA6B;AACvD,kBAAkB,mBAAO,CAAC,GAA6B;AACvD,gBAAgB,mBAAO,CAAC,GAA2B;AACnD,mBAAmB,mBAAO,CAAC,GAA8B;AACzD,qBAAqB,mBAAO,CAAC,GAAgC;;AAE7D;AACA;;;;AAIA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;;;;;;;AC9HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACtBA,2BAA2B,mBAAO,CAAC,GAA2B;AAC9D;AACA;AACA,mBAAmB,mBAAO,CAAC,GAA2B;AACtD,iBAAiB,mBAAO,CAAC,GAAyB;AAClD,oBAAoB,mBAAO,CAAC,GAA4B;AACxD,sBAAsB,mBAAO,CAAC,GAA8B;;;;;;;;ACN5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEa;;AAEb;;AAEA,UAAU,mBAAO,CAAC,GAAsB;AACxC;;AAEA;;AAEA;AACA,cAAc,mBAAO,CAAC,GAAS;AAC/B;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA,SAAS,mBAAO,CAAC,EAAQ;;AAEzB;AACA;AACA;AACA;;AAEA;AACA,aAAa,mBAAO,CAAC,GAA2B;AAChD;;AAEA;;AAEA,aAAa,mBAAO,CAAC,GAAa;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,WAAW,mBAAO,CAAC,GAAc;AACjC,gBAAgB,mBAAO,CAAC,GAAU;AAClC;;AAEA;AACA,gBAAgB,mBAAO,CAAC,GAAM;AAC9B;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;;AAEA,iBAAiB,mBAAO,CAAC,GAA+B;AACxD,kBAAkB,mBAAO,CAAC,GAA4B;AACtD;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,yEAAyE,6EAA6E;AACtJ;;AAEA;AACA,qBAAqB,mBAAO,CAAC,GAAkB;;AAE/C;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,iDAAiD,0FAA0F;;AAE3I;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,wCAAwC,mBAAO,CAAC,GAAiB;AACjE;AACA;AACA;AACA;;AAEA;AACA,qBAAqB,mBAAO,CAAC,GAAkB;;AAE/C;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA,kGAAkG;AAClG,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA;AACA,4FAA4F;AAC5F,SAAS;AACT;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,gDAAgD;;AAEhD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,sCAAsC,mBAAO,CAAC,GAAiB;AAC/D;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,6DAA6D;AAC7D;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,sCAAsC;;AAEtC;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD;AACxD;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,4CAA4C;;AAE5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB;;AAEpB;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,mBAAmB,SAAS;AAC5B;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;;AAEH;AACA;AACA;;AAEA;AACA,4EAA4E;;AAE5E;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA,iBAAiB,yBAAyB;AAC1C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,mDAAmD;AACnD;AACA,mDAAmD,iEAAiE;AACpH;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA,uCAAuC;AACvC,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,gCAAgC,OAAO;AACvC;AACA;AACA;AACA,C;;;;;;;;AC1/BA,+CAAa;;AAEb;AACA;AACA;AACA;AACA,oBAAoB;AACpB,CAAC;AACD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;;;;;;;;AC3CA,iBAAiB,mBAAO,CAAC,EAAQ;;;;;;;ACAjC;AACA,aAAa,mBAAO,CAAC,GAAQ;AAC7B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;;;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC1BA,e;;;;;;;ACAa;;AAEb,iDAAiD,0CAA0C,0DAA0D,EAAE;;AAEvJ,aAAa,mBAAO,CAAC,GAAa;AAClC,WAAW,mBAAO,CAAC,GAAM;;AAEzB;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,iBAAiB;AACjB,gDAAgD;AAChD;AACA;AACA;;AAEA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,wDAAwD;AACxD;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC;;AAED;AACA;AACA,4BAA4B,sBAAsB;AAClD;AACA;AACA,C;;;;;;AC9EA,e;;;;;;;ACAa;;AAEb;;AAEA,UAAU,mBAAO,CAAC,GAAsB;AACxC;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,E;;;;;;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEa;;AAEb;;AAEA,UAAU,mBAAO,CAAC,GAAsB;AACxC;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;;AAEA;AACA,WAAW,mBAAO,CAAC,GAAc;AACjC,gBAAgB,mBAAO,CAAC,GAAU;AAClC;;AAEA,eAAe,mBAAO,CAAC,GAAoB;AAC3C,eAAe,mBAAO,CAAC,GAAoB;;AAE3C;;AAEA;AACA;AACA;AACA,iBAAiB,iBAAiB;AAClC;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA,E;;;;;;;AClIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEa;;AAEb;;AAEA,UAAU,mBAAO,CAAC,GAAsB;AACxC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA,WAAW,mBAAO,CAAC,GAAc;AACjC,gBAAgB,mBAAO,CAAC,GAAU;AAClC;;AAEA;AACA;AACA,aAAa,mBAAO,CAAC,GAAgB;AACrC;AACA;;AAEA;AACA,aAAa,mBAAO,CAAC,GAA2B;AAChD;;AAEA;;AAEA,aAAa,mBAAO,CAAC,GAAa;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,kBAAkB,mBAAO,CAAC,GAA4B;;AAEtD;;AAEA;;AAEA;AACA,qBAAqB,mBAAO,CAAC,GAAkB;;AAE/C;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,iDAAiD,0FAA0F;;AAE3I;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL,GAAG;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH,CAAC;AACD;AACA;AACA;AACA;;AAEA;AACA,qBAAqB,mBAAO,CAAC,GAAkB;;AAE/C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,iCAAiC;;AAEjC;;AAEA,2CAA2C;AAC3C;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,mDAAmD;AACnD;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA,oDAAoD;AACpD;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA,E;;;;;;;AC9qBA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA,mBAAO,CAAC,GAAc;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9DA;AACA;;AAEA;AACA;AACA;;AAEA,uBAAuB;AACvB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,0CAA0C,sBAAsB,EAAE;AAClE;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,UAAU;AACV;AACA;;AAEA,KAAK;AACL;AACA;;AAEA,KAAK;AACL;AACA;;AAEA,KAAK;AACL;AACA;;AAEA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA,CAAC;;;;;;;;;ACzLD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,YAAY;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEa;;AAEb;;AAEA,aAAa,mBAAO,CAAC,GAAkB;;AAEvC;AACA,WAAW,mBAAO,CAAC,GAAc;AACjC,gBAAgB,mBAAO,CAAC,GAAU;AAClC;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA,C;;;;;;;ACrNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEa;;AAEb;;AAEA,gBAAgB,mBAAO,CAAC,GAAqB;;AAE7C;AACA,WAAW,mBAAO,CAAC,GAAc;AACjC,gBAAgB,mBAAO,CAAC,GAAU;AAClC;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,E;;;;;;AC9CA,iBAAiB,mBAAO,CAAC,GAA2B;;;;;;;ACApD,iBAAiB,mBAAO,CAAC,GAAyB;;;;;;;ACAlD,iBAAiB,mBAAO,CAAC,GAAY;;;;;;;ACArC,iBAAiB,mBAAO,CAAC,GAAY;;;;;;;ACArC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,cAAc,mBAAO,CAAC,GAAS;AAC/B;;;AAGA;AACA,aAAa,mBAAO,CAAC,GAAQ;AAC7B;;AAEA;;AAEA,SAAS,mBAAO,CAAC,EAAQ;;AAEzB;AACA;AACA;AACA;AACA;;AAEA,aAAa,mBAAO,CAAC,GAAQ;;AAE7B;AACA,WAAW,mBAAO,CAAC,GAAc;AACjC,gBAAgB,mBAAO,CAAC,GAAU;AAClC;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,sBAAsB,mBAAO,CAAC,GAAiB;AAC/C;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;;;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,oBAAoB,mBAAO,CAAC,GAAiB;AAC7C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,mBAAm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mBAAmB,SAAS;AAC5B;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;;AAEH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA,QAAQ;AACR;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;;AAIA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,sCAAsC,gBAAgB;AACtD;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA,gCAAgC,OAAO;AACvC;AACA;AACA;;AAEA;AACA,gCAAgC,OAAO;AACvC;AACA;AACA;AACA;;;;;;;;ACr9BA;AACA;AACA;;;;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA,aAAa,mBAAO,CAAC,GAAQ;AAC7B;;AAEA;;;AAGA;AACA,WAAW,mBAAO,CAAC,GAAc;AACjC,gBAAgB,mBAAO,CAAC,GAAU;AAClC;;AAEA,aAAa,mBAAO,CAAC,GAAQ;;AAE7B;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA,eAAe,mBAAO,CAAC,GAAkB;;AAEzC;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;AAEA,iBAAiB,yBAAyB;AAC1C;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA,WAAW,mBAAO,CAAC,GAAc;AACjC,gBAAgB,mBAAO,CAAC,GAAU;AAClC;;AAEA,eAAe,mBAAO,CAAC,GAAoB;AAC3C,eAAe,mBAAO,CAAC,GAAoB;;AAE3C;;AAEA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,gCAAgC,OAAO;AACvC;AACA;AACA;;;;;;;;ACxFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,YAAY;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,aAAa,mBAAO,CAAC,GAAkB;;AAEvC;AACA,WAAW,mBAAO,CAAC,GAAc;AACjC,gBAAgB,mBAAO,CAAC,GAAU;AAClC;;AAEA;;;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;;;;;;ACjNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,gBAAgB,mBAAO,CAAC,GAAqB;;AAE7C;AACA,WAAW,mBAAO,CAAC,GAAc;AACjC,gBAAgB,mBAAO,CAAC,GAAU;AAClC;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;;;;;AC7CA,+DAAgB,mBAAO,CAAC,GAAiB;AACzC,gBAAgB,mBAAO,CAAC,GAAM;;AAE9B;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;AACA;AACA;;AAEA,mCAAmC;;AAEnC;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA,CAAC;;;AAGD;AACA,mDAAmD,sCAAsC;;AAEzF;;AAEA;AACA;;AAEA;AACA,CAAC;;;;;;;;;AC9FD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,SAAS;AAChC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,mBAAmB,SAAS;AAC5B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,gBAAgB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,gBAAgB;AAC3C;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;AACA;AACA,wCAAwC,QAAQ;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,QAAQ;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,SAAS;AAC5B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;;AAEA;AACA,mBAAmB,SAAS;AAC5B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;AClRA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;;;;;;;;ACpEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAoH;AACnB;AAC+B;AACxF;AACE;AACoE;AAC3B;AAC9B;;AAErD;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,4DAAM,EAAE,wBAAwB;AAClD;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,6BAA6B;AAC7D,OAAO;AACP,KAAK;AACL,GAAG;AACH;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,GAAG,IAAI;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW,kEAAW,CAAC,0DAAW;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,2CAA2C,SAAS;AACpD,4BAA4B,kBAAkB;AAC9C;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;;AAEA;AACA;AACA,gBAAgB,0DAAI;AACpB;AACA,eAAe,yDAAG;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,kBAAkB;AAC7C,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA,EAAE,oEAAc;;AAEhB;;AAEA,gBAAgB,aAAa;AAC7B;AACA;AACA;AACA;AACA;AACA,oBAAoB,kEAAW,CAAC,6DAAc;AAC9C,wBAAwB,6DAAc;AACtC;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW,iEAAI;AACf,GAAG;AACH,cAAc,kEAAW,CAAC,sDAAO;AACjC;AACA,YAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,uFAA0B;AACzC,GAAG;AACH,eAAe,iEAAI;AACnB,GAAG,OAAO;AACV;AACA;AACA,EAAE,6DAAS;AACX;AACA;AACA,GAAG;AACH;;AAEA;AACA,EAAE,6DAAS;AACX;AACA;AACA;AACA;AACA,MAAM,uFAA0B;AAChC;AACA;AACA,OAAO;AACP,KAAK;AACL,MAAM,iFAAoB;AAC1B;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA,qCAAqC;AACrC;AACA,GAAG,OAAO;AACV;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,MAAM,+DAAS;AACf;AACA;AACA;;AAEA;AACA,8CAA8C,gEAAU;AACxD;AACA,IAAI,+DAAS;AACb;AACA,IAAI,+DAAS;AACb;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,eAAe,2DAAK;;AAEpB;AACA;AACA;AACA;;AAEA;AACA,cAAc,kEAAW,CAAC,2DAAY;AACtC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;;AAEA;AACA,sBAAsB,gEAAU;AAChC,4BAA4B,+DAAS;;AAErC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,sBAAsB,+DAAS;AAC/B;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,wBAAwB,gEAAU;AAClC,kBAAkB,+DAAS;AAC3B;AACA,4BAA4B,kEAAW,CAAC,0DAAW;AACnD;AACA;;AAEA;AACA;;AAEA;AACA,gBAAgB,kEAAW,CAAC,2DAAY;AACxC;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA,sBAAsB,uDAAG;;AAEzB;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,0BAA0B,+DAAS;AACnC;AACA,4BAA4B,QAAQ;AACpC;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA,iBAAiB;AACjB;AACA,KAAK;AACL;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA,qBAAqB,2DAAK;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEqF;;;;;;;;AC7crF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B,4CAA4C,SAAS;AACrD,sBAAsB,+BAA+B;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,SAAS;AACnD,oBAAoB,4CAA4C;AAChE;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,0CAA0C;AAC7D;AACA,GAAG;AACH;AACA,sCAAsC,SAAS;AAC/C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,SAAS;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,kBAAkB,mBAAmB;AACrC;AACA,kBAAkB,8CAA8C;AAChE;AACA,0CAA0C,SAAS;AACnD,oBAAoB,iDAAiD;AACrE;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,SAAS;AACtD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,gBAAgB,iCAAiC;AACjD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,mBAAmB,qBAAqB;AACxC;AACA;AACA;AACA;AACA;;AAEA;AACA,qBAAqB,qBAAqB;AAC1C;AACA,sBAAsB,uCAAuC;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,YAAY;AACZ;;AAEA,oCAAoC,SAAS;AAC7C;AACA;AACA;AACA;AACA;AACA,oBAAoB,+BAA+B;AACnD;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA,kBAAkB,uDAAuD;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,iBAAiB;AACvE;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;;AAEA;;AAEA;AACA;AACA,OAAO;AACP;AACA;AACA,sBAAsB,yBAAyB;AAC/C;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,qCAAqC,SAAS;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,gBAAgB;AACrC;AACA;AACA;AACA,KAAK,OAAO;AACZ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,SAAS;AACnD,oBAAoB,oCAAoC;AACxD;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,kBAAkB,6BAA6B;;AAE/C;AACA,2CAA2C,SAAS;AACpD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,wCAAwC,OAAO;AAC/C,oBAAoB,iDAAiD;AACrE;AACA;;AAEA;AACA;AACA;;AAEiJ;;;;;;;;ACncjJ;AAAA;AAAA;AAAA;AAAA;AAAgC;;AAEhC;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,WAAW,+CAAQ;AACnB;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,WAAW,+CAAQ;AACnB;AACA;;AAE4C;;;;;;;ACvB5C,sEAAwB,mBAAO,CAAC,GAAU;AAC1C,wBAAwB,mBAAO,CAAC,GAAoB;AACpD,wBAAwB,mBAAO,CAAC,GAAoB;AACpD,wBAAwB,mBAAO,CAAC,GAAM;AACtC,gBAAgB,mBAAO,CAAC,GAA2B;AACnD;;AAEA;AACA;AACA,mBAAmB,mBAAO,CAAC,GAAa;;AAExC;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA,GAAG;AACH;;AAEA,2CAA2C;;AAE3C;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;;AAEA;;AAEA;AACA;AACA,oCAAoC,uBAAuB;AAC3D;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,6CAA6C,kCAAkC;AAC/E;;AAEA;AACA;;AAEA;AACA;AACA,GAAG;;AAEH;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;;;;;;;ACnOA,+BAA+B,mBAAO,CAAC,GAAsB;AAC7D,+BAA+B,mBAAO,CAAC,GAAqB;AAC5D,+BAA+B,mBAAO,CAAC,GAA0B;AACjE,+BAA+B,mBAAO,CAAC,GAAgB;;;;;;;ACHvD;;AAEA,2BAA2B,mBAAO,CAAC,GAAO;AAC1C,2BAA2B,mBAAO,CAAC,GAAqB;AACxD,2BAA2B,mBAAO,CAAC,GAA0B;;AAE7D;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA,gCAAgC,kCAAkC;AAClE;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,QAAQ,OAAO;AACf;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,GAAG;AACH;;AAEA;AACA;;AAEA;;AAEA,GAAG;AACH;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;;;;;;;;AC/QA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;;;;;;;;AChDA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,2BAA2B,sCAAsC;;AAEjE;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,2BAA2B,wBAAwB;;AAEnD;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,qC;;;;;;;AC/EA,wBAAwB,mBAAO,CAAC,GAAsB;;AAEtD;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;;AAEA;;;;;;;;ACZA;;AAEA;AACA;AACA,kBAAkB,OAAO;AACzB;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,iBAAiB;;AAEjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;ACjJY;;AAEZ;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,6BAA6B,MAAM;AACnC;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,6BAA6B,KAAK;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,CAAC;;AAED;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,2BAA2B,MAAM;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,MAAM;AACjC;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,8BAA8B,UAAU;AACxC;AACA;AACA;AACA;AACA;AACA,kDAAkD,iBAAiB;;AAEnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,gBAAgB,iBAAiB;AACjC;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,kBAAkB,mBAAmB;AACrC;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,CAAC;;;AAGD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,6BAA6B,MAAM;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,KAAK;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,MAAM;AACjC;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,KAAK;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,C;;;;;;ACn+BA,iBAAiB,mBAAO,CAAC,GAAW;;;;;;;;ACAvB;AACb;AACA,EAAE,mBAAO,CAAC,GAAY;AACtB,EAAE,mBAAO,CAAC,GAAe;AACzB,EAAE,mBAAO,CAAC,GAAkB;AAC5B,EAAE,mBAAO,CAAC,GAAe;AACzB,EAAE,mBAAO,CAAC,GAAW;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/FA,+CAAa;AACb;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;ACVA,8CAAa;AACb;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,E;;;;;;;;ACrBA,8CAAa;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,E;;;;;;;;ACjBA,8CAAa;;AAEb;AACA;AACA;;AAEA;AACA;;AAEA,iCAAiC;AACjC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,E;;;;;;;;ACvBa;AACb;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,E;;;;;;;ACTA;AAAA;AAAA;AAA0B;;AAE1B;AACA,kBAAkB,4CAAK;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,4CAAK;AACzB;AACA;AACA,GAAG;AACH;;AAEe,yEAAU,EAAC;;;;;;;AClB1B;AACA;AACA;AACA;AACA;;AAEA,2BAA2B,mBAAO,CAAC,GAAS;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,OAAO;AAClB;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,YAAY,OAAO;AACnB;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;;;;;;;;ACjMA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mBAAO,CAAC,GAAI;;AAE/B;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,WAAW,OAAO;AAClB,YAAY;AACZ;AACA;;AAEA;AACA;;AAEA;AACA;AACA,cAAc;AACd;;AAEA;AACA;;AAEA;AACA;AACA;AACA,WAAW,OAAO;AAClB,YAAY;AACZ;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,aAAa,SAAS;AACtB,4BAA4B;AAC5B;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA,aAAa,8BAA8B;AAC3C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,OAAO;AAClB,YAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,yCAAyC,SAAS;AAClD;AACA;AACA;AACA;AACA,yCAAyC,SAAS;AAClD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,MAAM;AACjB,YAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA;;;;;;;AChOA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,OAAO;AAClB,YAAY,MAAM;AAClB,YAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,OAAO;AAClB,YAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,OAAO;AAClB,YAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,OAAO;AAClB,YAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"pouchdb.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 77);\n","var g;\n\n// This works in non-strict mode\ng = (function() {\n\treturn this;\n})();\n\ntry {\n\t// This works if eval is allowed (see CSP)\n\tg = g || new Function(\"return this\")();\n} catch (e) {\n\t// This works if the window reference is available\n\tif (typeof window === \"object\") g = window;\n}\n\n// g can still be undefined, but nothing to do about it...\n// We return undefined, instead of nothing here, so it's\n// easier to handle this case. if(!global) { ...}\n\nmodule.exports = g;\n","// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n","/**\n * @license\n * Copyright 2019 Google LLC.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport PouchDB from 'pouchdb';\nimport PouchDbMemory from 'pouchdb-adapter-memory';\nimport PouchDbDebug from 'pouchdb-debug';\nwindow.PouchDB = {PouchDB, PouchDbMemory, PouchDbDebug};\n","import immediate from 'immediate';\nimport uuidV4 from 'uuid';\nimport Md5 from 'spark-md5';\nimport vuvuzela from 'vuvuzela';\nimport getArguments from 'argsarray';\nimport inherits from 'inherits';\nimport { EventEmitter } from 'events';\n\nfunction mangle(key) {\n  return '$' + key;\n}\nfunction unmangle(key) {\n  return key.substring(1);\n}\nfunction Map$1() {\n  this._store = {};\n}\nMap$1.prototype.get = function (key) {\n  var mangled = mangle(key);\n  return this._store[mangled];\n};\nMap$1.prototype.set = function (key, value) {\n  var mangled = mangle(key);\n  this._store[mangled] = value;\n  return true;\n};\nMap$1.prototype.has = function (key) {\n  var mangled = mangle(key);\n  return mangled in this._store;\n};\nMap$1.prototype.delete = function (key) {\n  var mangled = mangle(key);\n  var res = mangled in this._store;\n  delete this._store[mangled];\n  return res;\n};\nMap$1.prototype.forEach = function (cb) {\n  var keys = Object.keys(this._store);\n  for (var i = 0, len = keys.length; i < len; i++) {\n    var key = keys[i];\n    var value = this._store[key];\n    key = unmangle(key);\n    cb(value, key);\n  }\n};\nObject.defineProperty(Map$1.prototype, 'size', {\n  get: function () {\n    return Object.keys(this._store).length;\n  }\n});\n\nfunction Set$1(array) {\n  this._store = new Map$1();\n\n  // init with an array\n  if (array && Array.isArray(array)) {\n    for (var i = 0, len = array.length; i < len; i++) {\n      this.add(array[i]);\n    }\n  }\n}\nSet$1.prototype.add = function (key) {\n  return this._store.set(key, true);\n};\nSet$1.prototype.has = function (key) {\n  return this._store.has(key);\n};\nSet$1.prototype.forEach = function (cb) {\n  this._store.forEach(function (value, key) {\n    cb(key);\n  });\n};\nObject.defineProperty(Set$1.prototype, 'size', {\n  get: function () {\n    return this._store.size;\n  }\n});\n\n/* global Map,Set,Symbol */\n// Based on https://kangax.github.io/compat-table/es6/ we can sniff out\n// incomplete Map/Set implementations which would otherwise cause our tests to fail.\n// Notably they fail in IE11 and iOS 8.4, which this prevents.\nfunction supportsMapAndSet() {\n  if (typeof Symbol === 'undefined' || typeof Map === 'undefined' || typeof Set === 'undefined') {\n    return false;\n  }\n  var prop = Object.getOwnPropertyDescriptor(Map, Symbol.species);\n  return prop && 'get' in prop && Map[Symbol.species] === Map;\n}\n\n// based on https://github.com/montagejs/collections\n\nvar ExportedSet;\nvar ExportedMap;\n\n{\n  if (supportsMapAndSet()) { // prefer built-in Map/Set\n    ExportedSet = Set;\n    ExportedMap = Map;\n  } else { // fall back to our polyfill\n    ExportedSet = Set$1;\n    ExportedMap = Map$1;\n  }\n}\n\nfunction isBinaryObject(object) {\n  return (typeof ArrayBuffer !== 'undefined' && object instanceof ArrayBuffer) ||\n    (typeof Blob !== 'undefined' && object instanceof Blob);\n}\n\nfunction cloneArrayBuffer(buff) {\n  if (typeof buff.slice === 'function') {\n    return buff.slice(0);\n  }\n  // IE10-11 slice() polyfill\n  var target = new ArrayBuffer(buff.byteLength);\n  var targetArray = new Uint8Array(target);\n  var sourceArray = new Uint8Array(buff);\n  targetArray.set(sourceArray);\n  return target;\n}\n\nfunction cloneBinaryObject(object) {\n  if (object instanceof ArrayBuffer) {\n    return cloneArrayBuffer(object);\n  }\n  var size = object.size;\n  var type = object.type;\n  // Blob\n  if (typeof object.slice === 'function') {\n    return object.slice(0, size, type);\n  }\n  // PhantomJS slice() replacement\n  return object.webkitSlice(0, size, type);\n}\n\n// most of this is borrowed from lodash.isPlainObject:\n// https://github.com/fis-components/lodash.isplainobject/\n// blob/29c358140a74f252aeb08c9eb28bef86f2217d4a/index.js\n\nvar funcToString = Function.prototype.toString;\nvar objectCtorString = funcToString.call(Object);\n\nfunction isPlainObject(value) {\n  var proto = Object.getPrototypeOf(value);\n  /* istanbul ignore if */\n  if (proto === null) { // not sure when this happens, but I guess it can\n    return true;\n  }\n  var Ctor = proto.constructor;\n  return (typeof Ctor == 'function' &&\n    Ctor instanceof Ctor && funcToString.call(Ctor) == objectCtorString);\n}\n\nfunction clone(object) {\n  var newObject;\n  var i;\n  var len;\n\n  if (!object || typeof object !== 'object') {\n    return object;\n  }\n\n  if (Array.isArray(object)) {\n    newObject = [];\n    for (i = 0, len = object.length; i < len; i++) {\n      newObject[i] = clone(object[i]);\n    }\n    return newObject;\n  }\n\n  // special case: to avoid inconsistencies between IndexedDB\n  // and other backends, we automatically stringify Dates\n  if (object instanceof Date) {\n    return object.toISOString();\n  }\n\n  if (isBinaryObject(object)) {\n    return cloneBinaryObject(object);\n  }\n\n  if (!isPlainObject(object)) {\n    return object; // don't clone objects like Workers\n  }\n\n  newObject = {};\n  for (i in object) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(object, i)) {\n      var value = clone(object[i]);\n      if (typeof value !== 'undefined') {\n        newObject[i] = value;\n      }\n    }\n  }\n  return newObject;\n}\n\nfunction once(fun) {\n  var called = false;\n  return getArguments(function (args) {\n    /* istanbul ignore if */\n    if (called) {\n      // this is a smoke test and should never actually happen\n      throw new Error('once called more than once');\n    } else {\n      called = true;\n      fun.apply(this, args);\n    }\n  });\n}\n\nfunction toPromise(func) {\n  //create the function we will be returning\n  return getArguments(function (args) {\n    // Clone arguments\n    args = clone(args);\n    var self = this;\n    // if the last argument is a function, assume its a callback\n    var usedCB = (typeof args[args.length - 1] === 'function') ? args.pop() : false;\n    var promise = new Promise(function (fulfill, reject) {\n      var resp;\n      try {\n        var callback = once(function (err, mesg) {\n          if (err) {\n            reject(err);\n          } else {\n            fulfill(mesg);\n          }\n        });\n        // create a callback for this invocation\n        // apply the function in the orig context\n        args.push(callback);\n        resp = func.apply(self, args);\n        if (resp && typeof resp.then === 'function') {\n          fulfill(resp);\n        }\n      } catch (e) {\n        reject(e);\n      }\n    });\n    // if there is a callback, call it back\n    if (usedCB) {\n      promise.then(function (result) {\n        usedCB(null, result);\n      }, usedCB);\n    }\n    return promise;\n  });\n}\n\nfunction logApiCall(self, name, args) {\n  /* istanbul ignore if */\n  if (self.constructor.listeners('debug').length) {\n    var logArgs = ['api', self.name, name];\n    for (var i = 0; i < args.length - 1; i++) {\n      logArgs.push(args[i]);\n    }\n    self.constructor.emit('debug', logArgs);\n\n    // override the callback itself to log the response\n    var origCallback = args[args.length - 1];\n    args[args.length - 1] = function (err, res) {\n      var responseArgs = ['api', self.name, name];\n      responseArgs = responseArgs.concat(\n        err ? ['error', err] : ['success', res]\n      );\n      self.constructor.emit('debug', responseArgs);\n      origCallback(err, res);\n    };\n  }\n}\n\nfunction adapterFun(name, callback) {\n  return toPromise(getArguments(function (args) {\n    if (this._closed) {\n      return Promise.reject(new Error('database is closed'));\n    }\n    if (this._destroyed) {\n      return Promise.reject(new Error('database is destroyed'));\n    }\n    var self = this;\n    logApiCall(self, name, args);\n    if (!this.taskqueue.isReady) {\n      return new Promise(function (fulfill, reject) {\n        self.taskqueue.addTask(function (failed) {\n          if (failed) {\n            reject(failed);\n          } else {\n            fulfill(self[name].apply(self, args));\n          }\n        });\n      });\n    }\n    return callback.apply(this, args);\n  }));\n}\n\n// like underscore/lodash _.pick()\nfunction pick(obj, arr) {\n  var res = {};\n  for (var i = 0, len = arr.length; i < len; i++) {\n    var prop = arr[i];\n    if (prop in obj) {\n      res[prop] = obj[prop];\n    }\n  }\n  return res;\n}\n\n// Most browsers throttle concurrent requests at 6, so it's silly\n// to shim _bulk_get by trying to launch potentially hundreds of requests\n// and then letting the majority time out. We can handle this ourselves.\nvar MAX_NUM_CONCURRENT_REQUESTS = 6;\n\nfunction identityFunction(x) {\n  return x;\n}\n\nfunction formatResultForOpenRevsGet(result) {\n  return [{\n    ok: result\n  }];\n}\n\n// shim for P/CouchDB adapters that don't directly implement _bulk_get\nfunction bulkGet(db, opts, callback) {\n  var requests = opts.docs;\n\n  // consolidate into one request per doc if possible\n  var requestsById = new ExportedMap();\n  requests.forEach(function (request) {\n    if (requestsById.has(request.id)) {\n      requestsById.get(request.id).push(request);\n    } else {\n      requestsById.set(request.id, [request]);\n    }\n  });\n\n  var numDocs = requestsById.size;\n  var numDone = 0;\n  var perDocResults = new Array(numDocs);\n\n  function collapseResultsAndFinish() {\n    var results = [];\n    perDocResults.forEach(function (res) {\n      res.docs.forEach(function (info) {\n        results.push({\n          id: res.id,\n          docs: [info]\n        });\n      });\n    });\n    callback(null, {results: results});\n  }\n\n  function checkDone() {\n    if (++numDone === numDocs) {\n      collapseResultsAndFinish();\n    }\n  }\n\n  function gotResult(docIndex, id, docs) {\n    perDocResults[docIndex] = {id: id, docs: docs};\n    checkDone();\n  }\n\n  var allRequests = [];\n  requestsById.forEach(function (value, key) {\n    allRequests.push(key);\n  });\n\n  var i = 0;\n\n  function nextBatch() {\n\n    if (i >= allRequests.length) {\n      return;\n    }\n\n    var upTo = Math.min(i + MAX_NUM_CONCURRENT_REQUESTS, allRequests.length);\n    var batch = allRequests.slice(i, upTo);\n    processBatch(batch, i);\n    i += batch.length;\n  }\n\n  function processBatch(batch, offset) {\n    batch.forEach(function (docId, j) {\n      var docIdx = offset + j;\n      var docRequests = requestsById.get(docId);\n\n      // just use the first request as the \"template\"\n      // TODO: The _bulk_get API allows for more subtle use cases than this,\n      // but for now it is unlikely that there will be a mix of different\n      // \"atts_since\" or \"attachments\" in the same request, since it's just\n      // replicate.js that is using this for the moment.\n      // Also, atts_since is aspirational, since we don't support it yet.\n      var docOpts = pick(docRequests[0], ['atts_since', 'attachments']);\n      docOpts.open_revs = docRequests.map(function (request) {\n        // rev is optional, open_revs disallowed\n        return request.rev;\n      });\n\n      // remove falsey / undefined revisions\n      docOpts.open_revs = docOpts.open_revs.filter(identityFunction);\n\n      var formatResult = identityFunction;\n\n      if (docOpts.open_revs.length === 0) {\n        delete docOpts.open_revs;\n\n        // when fetching only the \"winning\" leaf,\n        // transform the result so it looks like an open_revs\n        // request\n        formatResult = formatResultForOpenRevsGet;\n      }\n\n      // globally-supplied options\n      ['revs', 'attachments', 'binary', 'ajax', 'latest'].forEach(function (param) {\n        if (param in opts) {\n          docOpts[param] = opts[param];\n        }\n      });\n      db.get(docId, docOpts, function (err, res) {\n        var result;\n        /* istanbul ignore if */\n        if (err) {\n          result = [{error: err}];\n        } else {\n          result = formatResult(res);\n        }\n        gotResult(docIdx, docId, result);\n        nextBatch();\n      });\n    });\n  }\n\n  nextBatch();\n\n}\n\nvar hasLocal;\n\ntry {\n  localStorage.setItem('_pouch_check_localstorage', 1);\n  hasLocal = !!localStorage.getItem('_pouch_check_localstorage');\n} catch (e) {\n  hasLocal = false;\n}\n\nfunction hasLocalStorage() {\n  return hasLocal;\n}\n\n// Custom nextTick() shim for browsers. In node, this will just be process.nextTick(). We\n\ninherits(Changes, EventEmitter);\n\n/* istanbul ignore next */\nfunction attachBrowserEvents(self) {\n  if (hasLocalStorage()) {\n    addEventListener(\"storage\", function (e) {\n      self.emit(e.key);\n    });\n  }\n}\n\nfunction Changes() {\n  EventEmitter.call(this);\n  this._listeners = {};\n\n  attachBrowserEvents(this);\n}\nChanges.prototype.addListener = function (dbName, id, db, opts) {\n  /* istanbul ignore if */\n  if (this._listeners[id]) {\n    return;\n  }\n  var self = this;\n  var inprogress = false;\n  function eventFunction() {\n    /* istanbul ignore if */\n    if (!self._listeners[id]) {\n      return;\n    }\n    if (inprogress) {\n      inprogress = 'waiting';\n      return;\n    }\n    inprogress = true;\n    var changesOpts = pick(opts, [\n      'style', 'include_docs', 'attachments', 'conflicts', 'filter',\n      'doc_ids', 'view', 'since', 'query_params', 'binary', 'return_docs'\n    ]);\n\n    /* istanbul ignore next */\n    function onError() {\n      inprogress = false;\n    }\n\n    db.changes(changesOpts).on('change', function (c) {\n      if (c.seq > opts.since && !opts.cancelled) {\n        opts.since = c.seq;\n        opts.onChange(c);\n      }\n    }).on('complete', function () {\n      if (inprogress === 'waiting') {\n        immediate(eventFunction);\n      }\n      inprogress = false;\n    }).on('error', onError);\n  }\n  this._listeners[id] = eventFunction;\n  this.on(dbName, eventFunction);\n};\n\nChanges.prototype.removeListener = function (dbName, id) {\n  /* istanbul ignore if */\n  if (!(id in this._listeners)) {\n    return;\n  }\n  EventEmitter.prototype.removeListener.call(this, dbName,\n    this._listeners[id]);\n  delete this._listeners[id];\n};\n\n\n/* istanbul ignore next */\nChanges.prototype.notifyLocalWindows = function (dbName) {\n  //do a useless change on a storage thing\n  //in order to get other windows's listeners to activate\n  if (hasLocalStorage()) {\n    localStorage[dbName] = (localStorage[dbName] === \"a\") ? \"b\" : \"a\";\n  }\n};\n\nChanges.prototype.notify = function (dbName) {\n  this.emit(dbName);\n  this.notifyLocalWindows(dbName);\n};\n\nfunction guardedConsole(method) {\n  /* istanbul ignore else */\n  if (typeof console !== 'undefined' && typeof console[method] === 'function') {\n    var args = Array.prototype.slice.call(arguments, 1);\n    console[method].apply(console, args);\n  }\n}\n\nfunction randomNumber(min, max) {\n  var maxTimeout = 600000; // Hard-coded default of 10 minutes\n  min = parseInt(min, 10) || 0;\n  max = parseInt(max, 10);\n  if (max !== max || max <= min) {\n    max = (min || 1) << 1; //doubling\n  } else {\n    max = max + 1;\n  }\n  // In order to not exceed maxTimeout, pick a random value between half of maxTimeout and maxTimeout\n  if (max > maxTimeout) {\n    min = maxTimeout >> 1; // divide by two\n    max = maxTimeout;\n  }\n  var ratio = Math.random();\n  var range = max - min;\n\n  return ~~(range * ratio + min); // ~~ coerces to an int, but fast.\n}\n\nfunction defaultBackOff(min) {\n  var max = 0;\n  if (!min) {\n    max = 2000;\n  }\n  return randomNumber(min, max);\n}\n\n// designed to give info to browser users, who are disturbed\n// when they see http errors in the console\nfunction explainError(status, str) {\n  guardedConsole('info', 'The above ' + status + ' is totally normal. ' + str);\n}\n\nvar assign;\n{\n  if (typeof Object.assign === 'function') {\n    assign = Object.assign;\n  } else {\n    // lite Object.assign polyfill based on\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign\n    assign = function (target) {\n      var to = Object(target);\n\n      for (var index = 1; index < arguments.length; index++) {\n        var nextSource = arguments[index];\n\n        if (nextSource != null) { // Skip over if undefined or null\n          for (var nextKey in nextSource) {\n            // Avoid bugs when hasOwnProperty is shadowed\n            if (Object.prototype.hasOwnProperty.call(nextSource, nextKey)) {\n              to[nextKey] = nextSource[nextKey];\n            }\n          }\n        }\n      }\n      return to;\n    };\n  }\n}\n\nvar $inject_Object_assign = assign;\n\ninherits(PouchError, Error);\n\nfunction PouchError(status, error, reason) {\n  Error.call(this, reason);\n  this.status = status;\n  this.name = error;\n  this.message = reason;\n  this.error = true;\n}\n\nPouchError.prototype.toString = function () {\n  return JSON.stringify({\n    status: this.status,\n    name: this.name,\n    message: this.message,\n    reason: this.reason\n  });\n};\n\nvar UNAUTHORIZED = new PouchError(401, 'unauthorized', \"Name or password is incorrect.\");\nvar MISSING_BULK_DOCS = new PouchError(400, 'bad_request', \"Missing JSON list of 'docs'\");\nvar MISSING_DOC = new PouchError(404, 'not_found', 'missing');\nvar REV_CONFLICT = new PouchError(409, 'conflict', 'Document update conflict');\nvar INVALID_ID = new PouchError(400, 'bad_request', '_id field must contain a string');\nvar MISSING_ID = new PouchError(412, 'missing_id', '_id is required for puts');\nvar RESERVED_ID = new PouchError(400, 'bad_request', 'Only reserved document ids may start with underscore.');\nvar NOT_OPEN = new PouchError(412, 'precondition_failed', 'Database not open');\nvar UNKNOWN_ERROR = new PouchError(500, 'unknown_error', 'Database encountered an unknown error');\nvar BAD_ARG = new PouchError(500, 'badarg', 'Some query argument is invalid');\nvar INVALID_REQUEST = new PouchError(400, 'invalid_request', 'Request was invalid');\nvar QUERY_PARSE_ERROR = new PouchError(400, 'query_parse_error', 'Some query parameter is invalid');\nvar DOC_VALIDATION = new PouchError(500, 'doc_validation', 'Bad special document member');\nvar BAD_REQUEST = new PouchError(400, 'bad_request', 'Something wrong with the request');\nvar NOT_AN_OBJECT = new PouchError(400, 'bad_request', 'Document must be a JSON object');\nvar DB_MISSING = new PouchError(404, 'not_found', 'Database not found');\nvar IDB_ERROR = new PouchError(500, 'indexed_db_went_bad', 'unknown');\nvar WSQ_ERROR = new PouchError(500, 'web_sql_went_bad', 'unknown');\nvar LDB_ERROR = new PouchError(500, 'levelDB_went_went_bad', 'unknown');\nvar FORBIDDEN = new PouchError(403, 'forbidden', 'Forbidden by design doc validate_doc_update function');\nvar INVALID_REV = new PouchError(400, 'bad_request', 'Invalid rev format');\nvar FILE_EXISTS = new PouchError(412, 'file_exists', 'The database could not be created, the file already exists.');\nvar MISSING_STUB = new PouchError(412, 'missing_stub', 'A pre-existing attachment stub wasn\\'t found');\nvar INVALID_URL = new PouchError(413, 'invalid_url', 'Provided URL is invalid');\n\nfunction createError(error, reason) {\n  function CustomPouchError(reason) {\n    // inherit error properties from our parent error manually\n    // so as to allow proper JSON parsing.\n    /* jshint ignore:start */\n    for (var p in error) {\n      if (typeof error[p] !== 'function') {\n        this[p] = error[p];\n      }\n    }\n    /* jshint ignore:end */\n    if (reason !== undefined) {\n      this.reason = reason;\n    }\n  }\n  CustomPouchError.prototype = PouchError.prototype;\n  return new CustomPouchError(reason);\n}\n\nfunction generateErrorFromResponse(err) {\n\n  if (typeof err !== 'object') {\n    var data = err;\n    err = UNKNOWN_ERROR;\n    err.data = data;\n  }\n\n  if ('error' in err && err.error === 'conflict') {\n    err.name = 'conflict';\n    err.status = 409;\n  }\n\n  if (!('name' in err)) {\n    err.name = err.error || 'unknown';\n  }\n\n  if (!('status' in err)) {\n    err.status = 500;\n  }\n\n  if (!('message' in err)) {\n    err.message = err.message || err.reason;\n  }\n\n  return err;\n}\n\nfunction tryFilter(filter, doc, req) {\n  try {\n    return !filter(doc, req);\n  } catch (err) {\n    var msg = 'Filter function threw: ' + err.toString();\n    return createError(BAD_REQUEST, msg);\n  }\n}\n\nfunction filterChange(opts) {\n  var req = {};\n  var hasFilter = opts.filter && typeof opts.filter === 'function';\n  req.query = opts.query_params;\n\n  return function filter(change) {\n    if (!change.doc) {\n      // CSG sends events on the changes feed that don't have documents,\n      // this hack makes a whole lot of existing code robust.\n      change.doc = {};\n    }\n\n    var filterReturn = hasFilter && tryFilter(opts.filter, change.doc, req);\n\n    if (typeof filterReturn === 'object') {\n      return filterReturn;\n    }\n\n    if (filterReturn) {\n      return false;\n    }\n\n    if (!opts.include_docs) {\n      delete change.doc;\n    } else if (!opts.attachments) {\n      for (var att in change.doc._attachments) {\n        /* istanbul ignore else */\n        if (change.doc._attachments.hasOwnProperty(att)) {\n          change.doc._attachments[att].stub = true;\n        }\n      }\n    }\n    return true;\n  };\n}\n\nfunction flatten(arrs) {\n  var res = [];\n  for (var i = 0, len = arrs.length; i < len; i++) {\n    res = res.concat(arrs[i]);\n  }\n  return res;\n}\n\n// shim for Function.prototype.name,\n\n// Determine id an ID is valid\n//   - invalid IDs begin with an underescore that does not begin '_design' or\n//     '_local'\n//   - any other string value is a valid id\n// Returns the specific error object for each case\nfunction invalidIdError(id) {\n  var err;\n  if (!id) {\n    err = createError(MISSING_ID);\n  } else if (typeof id !== 'string') {\n    err = createError(INVALID_ID);\n  } else if (/^_/.test(id) && !(/^_(design|local)/).test(id)) {\n    err = createError(RESERVED_ID);\n  }\n  if (err) {\n    throw err;\n  }\n}\n\n// Checks if a PouchDB object is \"remote\" or not. This is\n\nfunction isRemote(db) {\n  if (typeof db._remote === 'boolean') {\n    return db._remote;\n  }\n  /* istanbul ignore next */\n  if (typeof db.type === 'function') {\n    guardedConsole('warn',\n      'db.type() is deprecated and will be removed in ' +\n      'a future version of PouchDB');\n    return db.type() === 'http';\n  }\n  /* istanbul ignore next */\n  return false;\n}\n\nfunction listenerCount(ee, type) {\n  return 'listenerCount' in ee ? ee.listenerCount(type) :\n                                 EventEmitter.listenerCount(ee, type);\n}\n\nfunction parseDesignDocFunctionName(s) {\n  if (!s) {\n    return null;\n  }\n  var parts = s.split('/');\n  if (parts.length === 2) {\n    return parts;\n  }\n  if (parts.length === 1) {\n    return [s, s];\n  }\n  return null;\n}\n\nfunction normalizeDesignDocFunctionName(s) {\n  var normalized = parseDesignDocFunctionName(s);\n  return normalized ? normalized.join('/') : null;\n}\n\n// originally parseUri 1.2.2, now patched by us\n// (c) Steven Levithan <stevenlevithan.com>\n// MIT License\nvar keys = [\"source\", \"protocol\", \"authority\", \"userInfo\", \"user\", \"password\",\n    \"host\", \"port\", \"relative\", \"path\", \"directory\", \"file\", \"query\", \"anchor\"];\nvar qName =\"queryKey\";\nvar qParser = /(?:^|&)([^&=]*)=?([^&]*)/g;\n\n// use the \"loose\" parser\n/* eslint maxlen: 0, no-useless-escape: 0 */\nvar parser = /^(?:(?![^:@]+:[^:@\\/]*@)([^:\\/?#.]+):)?(?:\\/\\/)?((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d*))?)(((\\/(?:[^?#](?![^?#\\/]*\\.[^?#\\/.]+(?:[?#]|$)))*\\/?)?([^?#\\/]*))(?:\\?([^#]*))?(?:#(.*))?)/;\n\nfunction parseUri(str) {\n  var m = parser.exec(str);\n  var uri = {};\n  var i = 14;\n\n  while (i--) {\n    var key = keys[i];\n    var value = m[i] || \"\";\n    var encoded = ['user', 'password'].indexOf(key) !== -1;\n    uri[key] = encoded ? decodeURIComponent(value) : value;\n  }\n\n  uri[qName] = {};\n  uri[keys[12]].replace(qParser, function ($0, $1, $2) {\n    if ($1) {\n      uri[qName][$1] = $2;\n    }\n  });\n\n  return uri;\n}\n\n// Based on https://github.com/alexdavid/scope-eval v0.0.3\n// (source: https://unpkg.com/scope-eval@0.0.3/scope_eval.js)\n// This is basically just a wrapper around new Function()\n\nfunction scopeEval(source, scope) {\n  var keys = [];\n  var values = [];\n  for (var key in scope) {\n    if (scope.hasOwnProperty(key)) {\n      keys.push(key);\n      values.push(scope[key]);\n    }\n  }\n  keys.push(source);\n  return Function.apply(null, keys).apply(null, values);\n}\n\n// this is essentially the \"update sugar\" function from daleharvey/pouchdb#1388\n// the diffFun tells us what delta to apply to the doc.  it either returns\n// the doc, or false if it doesn't need to do an update after all\nfunction upsert(db, docId, diffFun) {\n  return new Promise(function (fulfill, reject) {\n    db.get(docId, function (err, doc) {\n      if (err) {\n        /* istanbul ignore next */\n        if (err.status !== 404) {\n          return reject(err);\n        }\n        doc = {};\n      }\n\n      // the user might change the _rev, so save it for posterity\n      var docRev = doc._rev;\n      var newDoc = diffFun(doc);\n\n      if (!newDoc) {\n        // if the diffFun returns falsy, we short-circuit as\n        // an optimization\n        return fulfill({updated: false, rev: docRev});\n      }\n\n      // users aren't allowed to modify these values,\n      // so reset them here\n      newDoc._id = docId;\n      newDoc._rev = docRev;\n      fulfill(tryAndPut(db, newDoc, diffFun));\n    });\n  });\n}\n\nfunction tryAndPut(db, doc, diffFun) {\n  return db.put(doc).then(function (res) {\n    return {\n      updated: true,\n      rev: res.rev\n    };\n  }, function (err) {\n    /* istanbul ignore next */\n    if (err.status !== 409) {\n      throw err;\n    }\n    return upsert(db, doc._id, diffFun);\n  });\n}\n\nvar thisAtob = function (str) {\n  return atob(str);\n};\n\nvar thisBtoa = function (str) {\n  return btoa(str);\n};\n\n// Abstracts constructing a Blob object, so it also works in older\n// browsers that don't support the native Blob constructor (e.g.\n// old QtWebKit versions, Android < 4.4).\nfunction createBlob(parts, properties) {\n  /* global BlobBuilder,MSBlobBuilder,MozBlobBuilder,WebKitBlobBuilder */\n  parts = parts || [];\n  properties = properties || {};\n  try {\n    return new Blob(parts, properties);\n  } catch (e) {\n    if (e.name !== \"TypeError\") {\n      throw e;\n    }\n    var Builder = typeof BlobBuilder !== 'undefined' ? BlobBuilder :\n                  typeof MSBlobBuilder !== 'undefined' ? MSBlobBuilder :\n                  typeof MozBlobBuilder !== 'undefined' ? MozBlobBuilder :\n                  WebKitBlobBuilder;\n    var builder = new Builder();\n    for (var i = 0; i < parts.length; i += 1) {\n      builder.append(parts[i]);\n    }\n    return builder.getBlob(properties.type);\n  }\n}\n\n// From http://stackoverflow.com/questions/14967647/ (continues on next line)\n// encode-decode-image-with-base64-breaks-image (2013-04-21)\nfunction binaryStringToArrayBuffer(bin) {\n  var length = bin.length;\n  var buf = new ArrayBuffer(length);\n  var arr = new Uint8Array(buf);\n  for (var i = 0; i < length; i++) {\n    arr[i] = bin.charCodeAt(i);\n  }\n  return buf;\n}\n\nfunction binStringToBluffer(binString, type) {\n  return createBlob([binaryStringToArrayBuffer(binString)], {type: type});\n}\n\nfunction b64ToBluffer(b64, type) {\n  return binStringToBluffer(thisAtob(b64), type);\n}\n\n//Can't find original post, but this is close\n//http://stackoverflow.com/questions/6965107/ (continues on next line)\n//converting-between-strings-and-arraybuffers\nfunction arrayBufferToBinaryString(buffer) {\n  var binary = '';\n  var bytes = new Uint8Array(buffer);\n  var length = bytes.byteLength;\n  for (var i = 0; i < length; i++) {\n    binary += String.fromCharCode(bytes[i]);\n  }\n  return binary;\n}\n\n// shim for browsers that don't support it\nfunction readAsBinaryString(blob, callback) {\n  var reader = new FileReader();\n  var hasBinaryString = typeof reader.readAsBinaryString === 'function';\n  reader.onloadend = function (e) {\n    var result = e.target.result || '';\n    if (hasBinaryString) {\n      return callback(result);\n    }\n    callback(arrayBufferToBinaryString(result));\n  };\n  if (hasBinaryString) {\n    reader.readAsBinaryString(blob);\n  } else {\n    reader.readAsArrayBuffer(blob);\n  }\n}\n\nfunction blobToBinaryString(blobOrBuffer, callback) {\n  readAsBinaryString(blobOrBuffer, function (bin) {\n    callback(bin);\n  });\n}\n\nfunction blobToBase64(blobOrBuffer, callback) {\n  blobToBinaryString(blobOrBuffer, function (base64) {\n    callback(thisBtoa(base64));\n  });\n}\n\n// simplified API. universal browser support is assumed\nfunction readAsArrayBuffer(blob, callback) {\n  var reader = new FileReader();\n  reader.onloadend = function (e) {\n    var result = e.target.result || new ArrayBuffer(0);\n    callback(result);\n  };\n  reader.readAsArrayBuffer(blob);\n}\n\n// this is not used in the browser\n\nvar setImmediateShim = global.setImmediate || global.setTimeout;\nvar MD5_CHUNK_SIZE = 32768;\n\nfunction rawToBase64(raw) {\n  return thisBtoa(raw);\n}\n\nfunction sliceBlob(blob, start, end) {\n  if (blob.webkitSlice) {\n    return blob.webkitSlice(start, end);\n  }\n  return blob.slice(start, end);\n}\n\nfunction appendBlob(buffer, blob, start, end, callback) {\n  if (start > 0 || end < blob.size) {\n    // only slice blob if we really need to\n    blob = sliceBlob(blob, start, end);\n  }\n  readAsArrayBuffer(blob, function (arrayBuffer) {\n    buffer.append(arrayBuffer);\n    callback();\n  });\n}\n\nfunction appendString(buffer, string, start, end, callback) {\n  if (start > 0 || end < string.length) {\n    // only create a substring if we really need to\n    string = string.substring(start, end);\n  }\n  buffer.appendBinary(string);\n  callback();\n}\n\nfunction binaryMd5(data, callback) {\n  var inputIsString = typeof data === 'string';\n  var len = inputIsString ? data.length : data.size;\n  var chunkSize = Math.min(MD5_CHUNK_SIZE, len);\n  var chunks = Math.ceil(len / chunkSize);\n  var currentChunk = 0;\n  var buffer = inputIsString ? new Md5() : new Md5.ArrayBuffer();\n\n  var append = inputIsString ? appendString : appendBlob;\n\n  function next() {\n    setImmediateShim(loadNextChunk);\n  }\n\n  function done() {\n    var raw = buffer.end(true);\n    var base64 = rawToBase64(raw);\n    callback(base64);\n    buffer.destroy();\n  }\n\n  function loadNextChunk() {\n    var start = currentChunk * chunkSize;\n    var end = start + chunkSize;\n    currentChunk++;\n    if (currentChunk < chunks) {\n      append(buffer, data, start, end, next);\n    } else {\n      append(buffer, data, start, end, done);\n    }\n  }\n  loadNextChunk();\n}\n\nfunction stringMd5(string) {\n  return Md5.hash(string);\n}\n\nfunction rev(doc, deterministic_revs) {\n  var clonedDoc = clone(doc);\n  if (!deterministic_revs) {\n    return uuidV4.v4().replace(/-/g, '').toLowerCase();\n  }\n\n  delete clonedDoc._rev_tree;\n  return stringMd5(JSON.stringify(clonedDoc));\n}\n\nvar uuid = uuidV4.v4;\n\n// We fetch all leafs of the revision tree, and sort them based on tree length\n// and whether they were deleted, undeleted documents with the longest revision\n// tree (most edits) win\n// The final sort algorithm is slightly documented in a sidebar here:\n// http://guide.couchdb.org/draft/conflicts.html\nfunction winningRev(metadata) {\n  var winningId;\n  var winningPos;\n  var winningDeleted;\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var tree = node.ids;\n    var branches = tree[2];\n    var pos = node.pos;\n    if (branches.length) { // non-leaf\n      for (var i = 0, len = branches.length; i < len; i++) {\n        toVisit.push({pos: pos + 1, ids: branches[i]});\n      }\n      continue;\n    }\n    var deleted = !!tree[1].deleted;\n    var id = tree[0];\n    // sort by deleted, then pos, then id\n    if (!winningId || (winningDeleted !== deleted ? winningDeleted :\n        winningPos !== pos ? winningPos < pos : winningId < id)) {\n      winningId = id;\n      winningPos = pos;\n      winningDeleted = deleted;\n    }\n  }\n\n  return winningPos + '-' + winningId;\n}\n\n// Pretty much all below can be combined into a higher order function to\n// traverse revisions\n// The return value from the callback will be passed as context to all\n// children of that node\nfunction traverseRevTree(revs, callback) {\n  var toVisit = revs.slice();\n\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var branches = tree[2];\n    var newCtx =\n      callback(branches.length === 0, pos, tree[0], node.ctx, tree[1]);\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], ctx: newCtx});\n    }\n  }\n}\n\nfunction sortByPos(a, b) {\n  return a.pos - b.pos;\n}\n\nfunction collectLeaves(revs) {\n  var leaves = [];\n  traverseRevTree(revs, function (isLeaf, pos, id, acc, opts) {\n    if (isLeaf) {\n      leaves.push({rev: pos + \"-\" + id, pos: pos, opts: opts});\n    }\n  });\n  leaves.sort(sortByPos).reverse();\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    delete leaves[i].pos;\n  }\n  return leaves;\n}\n\n// returns revs of all conflicts that is leaves such that\n// 1. are not deleted and\n// 2. are different than winning revision\nfunction collectConflicts(metadata) {\n  var win = winningRev(metadata);\n  var leaves = collectLeaves(metadata.rev_tree);\n  var conflicts = [];\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    var leaf = leaves[i];\n    if (leaf.rev !== win && !leaf.opts.deleted) {\n      conflicts.push(leaf.rev);\n    }\n  }\n  return conflicts;\n}\n\n// compact a tree by marking its non-leafs as missing,\n// and return a list of revs to delete\nfunction compactTree(metadata) {\n  var revs = [];\n  traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                               revHash, ctx, opts) {\n    if (opts.status === 'available' && !isLeaf) {\n      revs.push(pos + '-' + revHash);\n      opts.status = 'missing';\n    }\n  });\n  return revs;\n}\n\n// build up a list of all the paths to the leafs in this revision tree\nfunction rootToLeaf(revs) {\n  var paths = [];\n  var toVisit = revs.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, opts: opts});\n    if (isLeaf) {\n      paths.push({pos: (pos + 1 - history.length), ids: history});\n    }\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], history: history});\n    }\n  }\n  return paths.reverse();\n}\n\n// for a better overview of what this is doing, read:\n\nfunction sortByPos$1(a, b) {\n  return a.pos - b.pos;\n}\n\n// classic binary search\nfunction binarySearch(arr, item, comparator) {\n  var low = 0;\n  var high = arr.length;\n  var mid;\n  while (low < high) {\n    mid = (low + high) >>> 1;\n    if (comparator(arr[mid], item) < 0) {\n      low = mid + 1;\n    } else {\n      high = mid;\n    }\n  }\n  return low;\n}\n\n// assuming the arr is sorted, insert the item in the proper place\nfunction insertSorted(arr, item, comparator) {\n  var idx = binarySearch(arr, item, comparator);\n  arr.splice(idx, 0, item);\n}\n\n// Turn a path as a flat array into a tree with a single branch.\n// If any should be stemmed from the beginning of the array, that's passed\n// in as the second argument\nfunction pathToTree(path, numStemmed) {\n  var root;\n  var leaf;\n  for (var i = numStemmed, len = path.length; i < len; i++) {\n    var node = path[i];\n    var currentLeaf = [node.id, node.opts, []];\n    if (leaf) {\n      leaf[2].push(currentLeaf);\n      leaf = currentLeaf;\n    } else {\n      root = leaf = currentLeaf;\n    }\n  }\n  return root;\n}\n\n// compare the IDs of two trees\nfunction compareTree(a, b) {\n  return a[0] < b[0] ? -1 : 1;\n}\n\n// Merge two trees together\n// The roots of tree1 and tree2 must be the same revision\nfunction mergeTree(in_tree1, in_tree2) {\n  var queue = [{tree1: in_tree1, tree2: in_tree2}];\n  var conflicts = false;\n  while (queue.length > 0) {\n    var item = queue.pop();\n    var tree1 = item.tree1;\n    var tree2 = item.tree2;\n\n    if (tree1[1].status || tree2[1].status) {\n      tree1[1].status =\n        (tree1[1].status ===  'available' ||\n        tree2[1].status === 'available') ? 'available' : 'missing';\n    }\n\n    for (var i = 0; i < tree2[2].length; i++) {\n      if (!tree1[2][0]) {\n        conflicts = 'new_leaf';\n        tree1[2][0] = tree2[2][i];\n        continue;\n      }\n\n      var merged = false;\n      for (var j = 0; j < tree1[2].length; j++) {\n        if (tree1[2][j][0] === tree2[2][i][0]) {\n          queue.push({tree1: tree1[2][j], tree2: tree2[2][i]});\n          merged = true;\n        }\n      }\n      if (!merged) {\n        conflicts = 'new_branch';\n        insertSorted(tree1[2], tree2[2][i], compareTree);\n      }\n    }\n  }\n  return {conflicts: conflicts, tree: in_tree1};\n}\n\nfunction doMerge(tree, path, dontExpand) {\n  var restree = [];\n  var conflicts = false;\n  var merged = false;\n  var res;\n\n  if (!tree.length) {\n    return {tree: [path], conflicts: 'new_leaf'};\n  }\n\n  for (var i = 0, len = tree.length; i < len; i++) {\n    var branch = tree[i];\n    if (branch.pos === path.pos && branch.ids[0] === path.ids[0]) {\n      // Paths start at the same position and have the same root, so they need\n      // merged\n      res = mergeTree(branch.ids, path.ids);\n      restree.push({pos: branch.pos, ids: res.tree});\n      conflicts = conflicts || res.conflicts;\n      merged = true;\n    } else if (dontExpand !== true) {\n      // The paths start at a different position, take the earliest path and\n      // traverse up until it as at the same point from root as the path we\n      // want to merge.  If the keys match we return the longer path with the\n      // other merged After stemming we dont want to expand the trees\n\n      var t1 = branch.pos < path.pos ? branch : path;\n      var t2 = branch.pos < path.pos ? path : branch;\n      var diff = t2.pos - t1.pos;\n\n      var candidateParents = [];\n\n      var trees = [];\n      trees.push({ids: t1.ids, diff: diff, parent: null, parentIdx: null});\n      while (trees.length > 0) {\n        var item = trees.pop();\n        if (item.diff === 0) {\n          if (item.ids[0] === t2.ids[0]) {\n            candidateParents.push(item);\n          }\n          continue;\n        }\n        var elements = item.ids[2];\n        for (var j = 0, elementsLen = elements.length; j < elementsLen; j++) {\n          trees.push({\n            ids: elements[j],\n            diff: item.diff - 1,\n            parent: item.ids,\n            parentIdx: j\n          });\n        }\n      }\n\n      var el = candidateParents[0];\n\n      if (!el) {\n        restree.push(branch);\n      } else {\n        res = mergeTree(el.ids, t2.ids);\n        el.parent[2][el.parentIdx] = res.tree;\n        restree.push({pos: t1.pos, ids: t1.ids});\n        conflicts = conflicts || res.conflicts;\n        merged = true;\n      }\n    } else {\n      restree.push(branch);\n    }\n  }\n\n  // We didnt find\n  if (!merged) {\n    restree.push(path);\n  }\n\n  restree.sort(sortByPos$1);\n\n  return {\n    tree: restree,\n    conflicts: conflicts || 'internal_node'\n  };\n}\n\n// To ensure we dont grow the revision tree infinitely, we stem old revisions\nfunction stem(tree, depth) {\n  // First we break out the tree into a complete list of root to leaf paths\n  var paths = rootToLeaf(tree);\n  var stemmedRevs;\n\n  var result;\n  for (var i = 0, len = paths.length; i < len; i++) {\n    // Then for each path, we cut off the start of the path based on the\n    // `depth` to stem to, and generate a new set of flat trees\n    var path = paths[i];\n    var stemmed = path.ids;\n    var node;\n    if (stemmed.length > depth) {\n      // only do the stemming work if we actually need to stem\n      if (!stemmedRevs) {\n        stemmedRevs = {}; // avoid allocating this object unnecessarily\n      }\n      var numStemmed = stemmed.length - depth;\n      node = {\n        pos: path.pos + numStemmed,\n        ids: pathToTree(stemmed, numStemmed)\n      };\n\n      for (var s = 0; s < numStemmed; s++) {\n        var rev = (path.pos + s) + '-' + stemmed[s].id;\n        stemmedRevs[rev] = true;\n      }\n    } else { // no need to actually stem\n      node = {\n        pos: path.pos,\n        ids: pathToTree(stemmed, 0)\n      };\n    }\n\n    // Then we remerge all those flat trees together, ensuring that we dont\n    // connect trees that would go beyond the depth limit\n    if (result) {\n      result = doMerge(result, node, true).tree;\n    } else {\n      result = [node];\n    }\n  }\n\n  // this is memory-heavy per Chrome profiler, avoid unless we actually stemmed\n  if (stemmedRevs) {\n    traverseRevTree(result, function (isLeaf, pos, revHash) {\n      // some revisions may have been removed in a branch but not in another\n      delete stemmedRevs[pos + '-' + revHash];\n    });\n  }\n\n  return {\n    tree: result,\n    revs: stemmedRevs ? Object.keys(stemmedRevs) : []\n  };\n}\n\nfunction merge(tree, path, depth) {\n  var newTree = doMerge(tree, path);\n  var stemmed = stem(newTree.tree, depth);\n  return {\n    tree: stemmed.tree,\n    stemmedRevs: stemmed.revs,\n    conflicts: newTree.conflicts\n  };\n}\n\n// return true if a rev exists in the rev tree, false otherwise\nfunction revExists(revs, rev) {\n  var toVisit = revs.slice();\n  var splitRev = rev.split('-');\n  var targetPos = parseInt(splitRev[0], 10);\n  var targetId = splitRev[1];\n\n  var node;\n  while ((node = toVisit.pop())) {\n    if (node.pos === targetPos && node.ids[0] === targetId) {\n      return true;\n    }\n    var branches = node.ids[2];\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: node.pos + 1, ids: branches[i]});\n    }\n  }\n  return false;\n}\n\nfunction getTrees(node) {\n  return node.ids;\n}\n\n// check if a specific revision of a doc has been deleted\n//  - metadata: the metadata object from the doc store\n//  - rev: (optional) the revision to check. defaults to winning revision\nfunction isDeleted(metadata, rev) {\n  if (!rev) {\n    rev = winningRev(metadata);\n  }\n  var id = rev.substring(rev.indexOf('-') + 1);\n  var toVisit = metadata.rev_tree.map(getTrees);\n\n  var tree;\n  while ((tree = toVisit.pop())) {\n    if (tree[0] === id) {\n      return !!tree[1].deleted;\n    }\n    toVisit = toVisit.concat(tree[2]);\n  }\n}\n\nfunction isLocalId(id) {\n  return (/^_local/).test(id);\n}\n\n// returns the current leaf node for a given revision\nfunction latest(rev, metadata) {\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, pos: pos, opts: opts});\n\n    if (isLeaf) {\n      for (var i = 0, len = history.length; i < len; i++) {\n        var historyNode = history[i];\n        var historyRev = historyNode.pos + '-' + historyNode.id;\n\n        if (historyRev === rev) {\n          // return the rev of this leaf\n          return pos + '-' + id;\n        }\n      }\n    }\n\n    for (var j = 0, l = branches.length; j < l; j++) {\n      toVisit.push({pos: pos + 1, ids: branches[j], history: history});\n    }\n  }\n\n  /* istanbul ignore next */\n  throw new Error('Unable to resolve latest revision for id ' + metadata.id + ', rev ' + rev);\n}\n\ninherits(Changes$1, EventEmitter);\n\nfunction tryCatchInChangeListener(self, change, pending, lastSeq) {\n  // isolate try/catches to avoid V8 deoptimizations\n  try {\n    self.emit('change', change, pending, lastSeq);\n  } catch (e) {\n    guardedConsole('error', 'Error in .on(\"change\", function):', e);\n  }\n}\n\nfunction Changes$1(db, opts, callback) {\n  EventEmitter.call(this);\n  var self = this;\n  this.db = db;\n  opts = opts ? clone(opts) : {};\n  var complete = opts.complete = once(function (err, resp) {\n    if (err) {\n      if (listenerCount(self, 'error') > 0) {\n        self.emit('error', err);\n      }\n    } else {\n      self.emit('complete', resp);\n    }\n    self.removeAllListeners();\n    db.removeListener('destroyed', onDestroy);\n  });\n  if (callback) {\n    self.on('complete', function (resp) {\n      callback(null, resp);\n    });\n    self.on('error', callback);\n  }\n  function onDestroy() {\n    self.cancel();\n  }\n  db.once('destroyed', onDestroy);\n\n  opts.onChange = function (change, pending, lastSeq) {\n    /* istanbul ignore if */\n    if (self.isCancelled) {\n      return;\n    }\n    tryCatchInChangeListener(self, change, pending, lastSeq);\n  };\n\n  var promise = new Promise(function (fulfill, reject) {\n    opts.complete = function (err, res) {\n      if (err) {\n        reject(err);\n      } else {\n        fulfill(res);\n      }\n    };\n  });\n  self.once('cancel', function () {\n    db.removeListener('destroyed', onDestroy);\n    opts.complete(null, {status: 'cancelled'});\n  });\n  this.then = promise.then.bind(promise);\n  this['catch'] = promise['catch'].bind(promise);\n  this.then(function (result) {\n    complete(null, result);\n  }, complete);\n\n\n\n  if (!db.taskqueue.isReady) {\n    db.taskqueue.addTask(function (failed) {\n      if (failed) {\n        opts.complete(failed);\n      } else if (self.isCancelled) {\n        self.emit('cancel');\n      } else {\n        self.validateChanges(opts);\n      }\n    });\n  } else {\n    self.validateChanges(opts);\n  }\n}\nChanges$1.prototype.cancel = function () {\n  this.isCancelled = true;\n  if (this.db.taskqueue.isReady) {\n    this.emit('cancel');\n  }\n};\nfunction processChange(doc, metadata, opts) {\n  var changeList = [{rev: doc._rev}];\n  if (opts.style === 'all_docs') {\n    changeList = collectLeaves(metadata.rev_tree)\n    .map(function (x) { return {rev: x.rev}; });\n  }\n  var change = {\n    id: metadata.id,\n    changes: changeList,\n    doc: doc\n  };\n\n  if (isDeleted(metadata, doc._rev)) {\n    change.deleted = true;\n  }\n  if (opts.conflicts) {\n    change.doc._conflicts = collectConflicts(metadata);\n    if (!change.doc._conflicts.length) {\n      delete change.doc._conflicts;\n    }\n  }\n  return change;\n}\n\nChanges$1.prototype.validateChanges = function (opts) {\n  var callback = opts.complete;\n  var self = this;\n\n  /* istanbul ignore else */\n  if (PouchDB._changesFilterPlugin) {\n    PouchDB._changesFilterPlugin.validate(opts, function (err) {\n      if (err) {\n        return callback(err);\n      }\n      self.doChanges(opts);\n    });\n  } else {\n    self.doChanges(opts);\n  }\n};\n\nChanges$1.prototype.doChanges = function (opts) {\n  var self = this;\n  var callback = opts.complete;\n\n  opts = clone(opts);\n  if ('live' in opts && !('continuous' in opts)) {\n    opts.continuous = opts.live;\n  }\n  opts.processChange = processChange;\n\n  if (opts.since === 'latest') {\n    opts.since = 'now';\n  }\n  if (!opts.since) {\n    opts.since = 0;\n  }\n  if (opts.since === 'now') {\n    this.db.info().then(function (info) {\n      /* istanbul ignore if */\n      if (self.isCancelled) {\n        callback(null, {status: 'cancelled'});\n        return;\n      }\n      opts.since = info.update_seq;\n      self.doChanges(opts);\n    }, callback);\n    return;\n  }\n\n  /* istanbul ignore else */\n  if (PouchDB._changesFilterPlugin) {\n    PouchDB._changesFilterPlugin.normalize(opts);\n    if (PouchDB._changesFilterPlugin.shouldFilter(this, opts)) {\n      return PouchDB._changesFilterPlugin.filter(this, opts);\n    }\n  } else {\n    ['doc_ids', 'filter', 'selector', 'view'].forEach(function (key) {\n      if (key in opts) {\n        guardedConsole('warn',\n          'The \"' + key + '\" option was passed in to changes/replicate, ' +\n          'but pouchdb-changes-filter plugin is not installed, so it ' +\n          'was ignored. Please install the plugin to enable filtering.'\n        );\n      }\n    });\n  }\n\n  if (!('descending' in opts)) {\n    opts.descending = false;\n  }\n\n  // 0 and 1 should return 1 document\n  opts.limit = opts.limit === 0 ? 1 : opts.limit;\n  opts.complete = callback;\n  var newPromise = this.db._changes(opts);\n  /* istanbul ignore else */\n  if (newPromise && typeof newPromise.cancel === 'function') {\n    var cancel = self.cancel;\n    self.cancel = getArguments(function (args) {\n      newPromise.cancel();\n      cancel.apply(this, args);\n    });\n  }\n};\n\n/*\n * A generic pouch adapter\n */\n\nfunction compare(left, right) {\n  return left < right ? -1 : left > right ? 1 : 0;\n}\n\n// Wrapper for functions that call the bulkdocs api with a single doc,\n// if the first result is an error, return an error\nfunction yankError(callback, docId) {\n  return function (err, results) {\n    if (err || (results[0] && results[0].error)) {\n      err = err || results[0];\n      err.docId = docId;\n      callback(err);\n    } else {\n      callback(null, results.length ? results[0]  : results);\n    }\n  };\n}\n\n// clean docs given to us by the user\nfunction cleanDocs(docs) {\n  for (var i = 0; i < docs.length; i++) {\n    var doc = docs[i];\n    if (doc._deleted) {\n      delete doc._attachments; // ignore atts for deleted docs\n    } else if (doc._attachments) {\n      // filter out extraneous keys from _attachments\n      var atts = Object.keys(doc._attachments);\n      for (var j = 0; j < atts.length; j++) {\n        var att = atts[j];\n        doc._attachments[att] = pick(doc._attachments[att],\n          ['data', 'digest', 'content_type', 'length', 'revpos', 'stub']);\n      }\n    }\n  }\n}\n\n// compare two docs, first by _id then by _rev\nfunction compareByIdThenRev(a, b) {\n  var idCompare = compare(a._id, b._id);\n  if (idCompare !== 0) {\n    return idCompare;\n  }\n  var aStart = a._revisions ? a._revisions.start : 0;\n  var bStart = b._revisions ? b._revisions.start : 0;\n  return compare(aStart, bStart);\n}\n\n// for every node in a revision tree computes its distance from the closest\n// leaf\nfunction computeHeight(revs) {\n  var height = {};\n  var edges = [];\n  traverseRevTree(revs, function (isLeaf, pos, id, prnt) {\n    var rev$$1 = pos + \"-\" + id;\n    if (isLeaf) {\n      height[rev$$1] = 0;\n    }\n    if (prnt !== undefined) {\n      edges.push({from: prnt, to: rev$$1});\n    }\n    return rev$$1;\n  });\n\n  edges.reverse();\n  edges.forEach(function (edge) {\n    if (height[edge.from] === undefined) {\n      height[edge.from] = 1 + height[edge.to];\n    } else {\n      height[edge.from] = Math.min(height[edge.from], 1 + height[edge.to]);\n    }\n  });\n  return height;\n}\n\nfunction allDocsKeysParse(opts) {\n  var keys =  ('limit' in opts) ?\n    opts.keys.slice(opts.skip, opts.limit + opts.skip) :\n    (opts.skip > 0) ? opts.keys.slice(opts.skip) : opts.keys;\n  opts.keys = keys;\n  opts.skip = 0;\n  delete opts.limit;\n  if (opts.descending) {\n    keys.reverse();\n    opts.descending = false;\n  }\n}\n\n// all compaction is done in a queue, to avoid attaching\n// too many listeners at once\nfunction doNextCompaction(self) {\n  var task = self._compactionQueue[0];\n  var opts = task.opts;\n  var callback = task.callback;\n  self.get('_local/compaction').catch(function () {\n    return false;\n  }).then(function (doc) {\n    if (doc && doc.last_seq) {\n      opts.last_seq = doc.last_seq;\n    }\n    self._compact(opts, function (err, res) {\n      /* istanbul ignore if */\n      if (err) {\n        callback(err);\n      } else {\n        callback(null, res);\n      }\n      immediate(function () {\n        self._compactionQueue.shift();\n        if (self._compactionQueue.length) {\n          doNextCompaction(self);\n        }\n      });\n    });\n  });\n}\n\nfunction attachmentNameError(name) {\n  if (name.charAt(0) === '_') {\n    return name + ' is not a valid attachment name, attachment ' +\n      'names cannot start with \\'_\\'';\n  }\n  return false;\n}\n\ninherits(AbstractPouchDB, EventEmitter);\n\nfunction AbstractPouchDB() {\n  EventEmitter.call(this);\n\n  // re-bind prototyped methods\n  for (var p in AbstractPouchDB.prototype) {\n    if (typeof this[p] === 'function') {\n      this[p] = this[p].bind(this);\n    }\n  }\n}\n\nAbstractPouchDB.prototype.post =\n  adapterFun('post', function (doc, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof doc !== 'object' || Array.isArray(doc)) {\n    return callback(createError(NOT_AN_OBJECT));\n  }\n  this.bulkDocs({docs: [doc]}, opts, yankError(callback, doc._id));\n});\n\nAbstractPouchDB.prototype.put = adapterFun('put', function (doc, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n  if (typeof doc !== 'object' || Array.isArray(doc)) {\n    return cb(createError(NOT_AN_OBJECT));\n  }\n  invalidIdError(doc._id);\n  if (isLocalId(doc._id) && typeof this._putLocal === 'function') {\n    if (doc._deleted) {\n      return this._removeLocal(doc, cb);\n    } else {\n      return this._putLocal(doc, cb);\n    }\n  }\n  var self = this;\n  if (opts.force && doc._rev) {\n    transformForceOptionToNewEditsOption();\n    putDoc(function (err) {\n      var result = err ? null : {ok: true, id: doc._id, rev: doc._rev};\n      cb(err, result);\n    });\n  } else {\n    putDoc(cb);\n  }\n\n  function transformForceOptionToNewEditsOption() {\n    var parts = doc._rev.split('-');\n    var oldRevId = parts[1];\n    var oldRevNum = parseInt(parts[0], 10);\n\n    var newRevNum = oldRevNum + 1;\n    var newRevId = rev();\n\n    doc._revisions = {\n      start: newRevNum,\n      ids: [newRevId, oldRevId]\n    };\n    doc._rev = newRevNum + '-' + newRevId;\n    opts.new_edits = false;\n  }\n  function putDoc(next) {\n    if (typeof self._put === 'function' && opts.new_edits !== false) {\n      self._put(doc, opts, next);\n    } else {\n      self.bulkDocs({docs: [doc]}, opts, yankError(next, doc._id));\n    }\n  }\n});\n\nAbstractPouchDB.prototype.putAttachment =\n  adapterFun('putAttachment', function (docId, attachmentId, rev$$1,\n                                              blob, type) {\n  var api = this;\n  if (typeof type === 'function') {\n    type = blob;\n    blob = rev$$1;\n    rev$$1 = null;\n  }\n  // Lets fix in https://github.com/pouchdb/pouchdb/issues/3267\n  /* istanbul ignore if */\n  if (typeof type === 'undefined') {\n    type = blob;\n    blob = rev$$1;\n    rev$$1 = null;\n  }\n  if (!type) {\n    guardedConsole('warn', 'Attachment', attachmentId, 'on document', docId, 'is missing content_type');\n  }\n\n  function createAttachment(doc) {\n    var prevrevpos = '_rev' in doc ? parseInt(doc._rev, 10) : 0;\n    doc._attachments = doc._attachments || {};\n    doc._attachments[attachmentId] = {\n      content_type: type,\n      data: blob,\n      revpos: ++prevrevpos\n    };\n    return api.put(doc);\n  }\n\n  return api.get(docId).then(function (doc) {\n    if (doc._rev !== rev$$1) {\n      throw createError(REV_CONFLICT);\n    }\n\n    return createAttachment(doc);\n  }, function (err) {\n     // create new doc\n    /* istanbul ignore else */\n    if (err.reason === MISSING_DOC.message) {\n      return createAttachment({_id: docId});\n    } else {\n      throw err;\n    }\n  });\n});\n\nAbstractPouchDB.prototype.removeAttachment =\n  adapterFun('removeAttachment', function (docId, attachmentId, rev$$1,\n                                                 callback) {\n  var self = this;\n  self.get(docId, function (err, obj) {\n    /* istanbul ignore if */\n    if (err) {\n      callback(err);\n      return;\n    }\n    if (obj._rev !== rev$$1) {\n      callback(createError(REV_CONFLICT));\n      return;\n    }\n    /* istanbul ignore if */\n    if (!obj._attachments) {\n      return callback();\n    }\n    delete obj._attachments[attachmentId];\n    if (Object.keys(obj._attachments).length === 0) {\n      delete obj._attachments;\n    }\n    self.put(obj, callback);\n  });\n});\n\nAbstractPouchDB.prototype.remove =\n  adapterFun('remove', function (docOrId, optsOrRev, opts, callback) {\n  var doc;\n  if (typeof optsOrRev === 'string') {\n    // id, rev, opts, callback style\n    doc = {\n      _id: docOrId,\n      _rev: optsOrRev\n    };\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n  } else {\n    // doc, opts, callback style\n    doc = docOrId;\n    if (typeof optsOrRev === 'function') {\n      callback = optsOrRev;\n      opts = {};\n    } else {\n      callback = opts;\n      opts = optsOrRev;\n    }\n  }\n  opts = opts || {};\n  opts.was_delete = true;\n  var newDoc = {_id: doc._id, _rev: (doc._rev || opts.rev)};\n  newDoc._deleted = true;\n  if (isLocalId(newDoc._id) && typeof this._removeLocal === 'function') {\n    return this._removeLocal(doc, callback);\n  }\n  this.bulkDocs({docs: [newDoc]}, opts, yankError(callback, newDoc._id));\n});\n\nAbstractPouchDB.prototype.revsDiff =\n  adapterFun('revsDiff', function (req, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  var ids = Object.keys(req);\n\n  if (!ids.length) {\n    return callback(null, {});\n  }\n\n  var count = 0;\n  var missing = new ExportedMap();\n\n  function addToMissing(id, revId) {\n    if (!missing.has(id)) {\n      missing.set(id, {missing: []});\n    }\n    missing.get(id).missing.push(revId);\n  }\n\n  function processDoc(id, rev_tree) {\n    // Is this fast enough? Maybe we should switch to a set simulated by a map\n    var missingForId = req[id].slice(0);\n    traverseRevTree(rev_tree, function (isLeaf, pos, revHash, ctx,\n      opts) {\n        var rev$$1 = pos + '-' + revHash;\n        var idx = missingForId.indexOf(rev$$1);\n        if (idx === -1) {\n          return;\n        }\n\n        missingForId.splice(idx, 1);\n        /* istanbul ignore if */\n        if (opts.status !== 'available') {\n          addToMissing(id, rev$$1);\n        }\n      });\n\n    // Traversing the tree is synchronous, so now `missingForId` contains\n    // revisions that were not found in the tree\n    missingForId.forEach(function (rev$$1) {\n      addToMissing(id, rev$$1);\n    });\n  }\n\n  ids.map(function (id) {\n    this._getRevisionTree(id, function (err, rev_tree) {\n      if (err && err.status === 404 && err.message === 'missing') {\n        missing.set(id, {missing: req[id]});\n      } else if (err) {\n        /* istanbul ignore next */\n        return callback(err);\n      } else {\n        processDoc(id, rev_tree);\n      }\n\n      if (++count === ids.length) {\n        // convert LazyMap to object\n        var missingObj = {};\n        missing.forEach(function (value, key) {\n          missingObj[key] = value;\n        });\n        return callback(null, missingObj);\n      }\n    });\n  }, this);\n});\n\n// _bulk_get API for faster replication, as described in\n// https://github.com/apache/couchdb-chttpd/pull/33\n// At the \"abstract\" level, it will just run multiple get()s in\n// parallel, because this isn't much of a performance cost\n// for local databases (except the cost of multiple transactions, which is\n// small). The http adapter overrides this in order\n// to do a more efficient single HTTP request.\nAbstractPouchDB.prototype.bulkGet =\n  adapterFun('bulkGet', function (opts, callback) {\n  bulkGet(this, opts, callback);\n});\n\n// compact one document and fire callback\n// by compacting we mean removing all revisions which\n// are further from the leaf in revision tree than max_height\nAbstractPouchDB.prototype.compactDocument =\n  adapterFun('compactDocument', function (docId, maxHeight, callback) {\n  var self = this;\n  this._getRevisionTree(docId, function (err, revTree) {\n    /* istanbul ignore if */\n    if (err) {\n      return callback(err);\n    }\n    var height = computeHeight(revTree);\n    var candidates = [];\n    var revs = [];\n    Object.keys(height).forEach(function (rev$$1) {\n      if (height[rev$$1] > maxHeight) {\n        candidates.push(rev$$1);\n      }\n    });\n\n    traverseRevTree(revTree, function (isLeaf, pos, revHash, ctx, opts) {\n      var rev$$1 = pos + '-' + revHash;\n      if (opts.status === 'available' && candidates.indexOf(rev$$1) !== -1) {\n        revs.push(rev$$1);\n      }\n    });\n    self._doCompaction(docId, revs, callback);\n  });\n});\n\n// compact the whole database using single document\n// compaction\nAbstractPouchDB.prototype.compact =\n  adapterFun('compact', function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  var self = this;\n  opts = opts || {};\n\n  self._compactionQueue = self._compactionQueue || [];\n  self._compactionQueue.push({opts: opts, callback: callback});\n  if (self._compactionQueue.length === 1) {\n    doNextCompaction(self);\n  }\n});\nAbstractPouchDB.prototype._compact = function (opts, callback) {\n  var self = this;\n  var changesOpts = {\n    return_docs: false,\n    last_seq: opts.last_seq || 0\n  };\n  var promises = [];\n\n  function onChange(row) {\n    promises.push(self.compactDocument(row.id, 0));\n  }\n  function onComplete(resp) {\n    var lastSeq = resp.last_seq;\n    Promise.all(promises).then(function () {\n      return upsert(self, '_local/compaction', function deltaFunc(doc) {\n        if (!doc.last_seq || doc.last_seq < lastSeq) {\n          doc.last_seq = lastSeq;\n          return doc;\n        }\n        return false; // somebody else got here first, don't update\n      });\n    }).then(function () {\n      callback(null, {ok: true});\n    }).catch(callback);\n  }\n  self.changes(changesOpts)\n    .on('change', onChange)\n    .on('complete', onComplete)\n    .on('error', callback);\n};\n\n/* Begin api wrappers. Specific functionality to storage belongs in the\n   _[method] */\nAbstractPouchDB.prototype.get = adapterFun('get', function (id, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n  if (typeof id !== 'string') {\n    return cb(createError(INVALID_ID));\n  }\n  if (isLocalId(id) && typeof this._getLocal === 'function') {\n    return this._getLocal(id, cb);\n  }\n  var leaves = [], self = this;\n\n  function finishOpenRevs() {\n    var result = [];\n    var count = leaves.length;\n    /* istanbul ignore if */\n    if (!count) {\n      return cb(null, result);\n    }\n\n    // order with open_revs is unspecified\n    leaves.forEach(function (leaf) {\n      self.get(id, {\n        rev: leaf,\n        revs: opts.revs,\n        latest: opts.latest,\n        attachments: opts.attachments,\n        binary: opts.binary\n      }, function (err, doc) {\n        if (!err) {\n          // using latest=true can produce duplicates\n          var existing;\n          for (var i = 0, l = result.length; i < l; i++) {\n            if (result[i].ok && result[i].ok._rev === doc._rev) {\n              existing = true;\n              break;\n            }\n          }\n          if (!existing) {\n            result.push({ok: doc});\n          }\n        } else {\n          result.push({missing: leaf});\n        }\n        count--;\n        if (!count) {\n          cb(null, result);\n        }\n      });\n    });\n  }\n\n  if (opts.open_revs) {\n    if (opts.open_revs === \"all\") {\n      this._getRevisionTree(id, function (err, rev_tree) {\n        /* istanbul ignore if */\n        if (err) {\n          return cb(err);\n        }\n        leaves = collectLeaves(rev_tree).map(function (leaf) {\n          return leaf.rev;\n        });\n        finishOpenRevs();\n      });\n    } else {\n      if (Array.isArray(opts.open_revs)) {\n        leaves = opts.open_revs;\n        for (var i = 0; i < leaves.length; i++) {\n          var l = leaves[i];\n          // looks like it's the only thing couchdb checks\n          if (!(typeof (l) === \"string\" && /^\\d+-/.test(l))) {\n            return cb(createError(INVALID_REV));\n          }\n        }\n        finishOpenRevs();\n      } else {\n        return cb(createError(UNKNOWN_ERROR, 'function_clause'));\n      }\n    }\n    return; // open_revs does not like other options\n  }\n\n  return this._get(id, opts, function (err, result) {\n    if (err) {\n      err.docId = id;\n      return cb(err);\n    }\n\n    var doc = result.doc;\n    var metadata = result.metadata;\n    var ctx = result.ctx;\n\n    if (opts.conflicts) {\n      var conflicts = collectConflicts(metadata);\n      if (conflicts.length) {\n        doc._conflicts = conflicts;\n      }\n    }\n\n    if (isDeleted(metadata, doc._rev)) {\n      doc._deleted = true;\n    }\n\n    if (opts.revs || opts.revs_info) {\n      var splittedRev = doc._rev.split('-');\n      var revNo       = parseInt(splittedRev[0], 10);\n      var revHash     = splittedRev[1];\n\n      var paths = rootToLeaf(metadata.rev_tree);\n      var path = null;\n\n      for (var i = 0; i < paths.length; i++) {\n        var currentPath = paths[i];\n        var hashIndex = currentPath.ids.map(function (x) { return x.id; })\n          .indexOf(revHash);\n        var hashFoundAtRevPos = hashIndex === (revNo - 1);\n\n        if (hashFoundAtRevPos || (!path && hashIndex !== -1)) {\n          path = currentPath;\n        }\n      }\n\n      /* istanbul ignore if */\n      if (!path) {\n        err = new Error('invalid rev tree');\n        err.docId = id;\n        return cb(err);\n      }\n\n      var indexOfRev = path.ids.map(function (x) { return x.id; })\n        .indexOf(doc._rev.split('-')[1]) + 1;\n      var howMany = path.ids.length - indexOfRev;\n      path.ids.splice(indexOfRev, howMany);\n      path.ids.reverse();\n\n      if (opts.revs) {\n        doc._revisions = {\n          start: (path.pos + path.ids.length) - 1,\n          ids: path.ids.map(function (rev$$1) {\n            return rev$$1.id;\n          })\n        };\n      }\n      if (opts.revs_info) {\n        var pos =  path.pos + path.ids.length;\n        doc._revs_info = path.ids.map(function (rev$$1) {\n          pos--;\n          return {\n            rev: pos + '-' + rev$$1.id,\n            status: rev$$1.opts.status\n          };\n        });\n      }\n    }\n\n    if (opts.attachments && doc._attachments) {\n      var attachments = doc._attachments;\n      var count = Object.keys(attachments).length;\n      if (count === 0) {\n        return cb(null, doc);\n      }\n      Object.keys(attachments).forEach(function (key) {\n        this._getAttachment(doc._id, key, attachments[key], {\n          // Previously the revision handling was done in adapter.js\n          // getAttachment, however since idb-next doesnt we need to\n          // pass the rev through\n          rev: doc._rev,\n          binary: opts.binary,\n          ctx: ctx\n        }, function (err, data) {\n          var att = doc._attachments[key];\n          att.data = data;\n          delete att.stub;\n          delete att.length;\n          if (!--count) {\n            cb(null, doc);\n          }\n        });\n      }, self);\n    } else {\n      if (doc._attachments) {\n        for (var key in doc._attachments) {\n          /* istanbul ignore else */\n          if (doc._attachments.hasOwnProperty(key)) {\n            doc._attachments[key].stub = true;\n          }\n        }\n      }\n      cb(null, doc);\n    }\n  });\n});\n\n// TODO: I dont like this, it forces an extra read for every\n// attachment read and enforces a confusing api between\n// adapter.js and the adapter implementation\nAbstractPouchDB.prototype.getAttachment =\n  adapterFun('getAttachment', function (docId, attachmentId, opts, callback) {\n  var self = this;\n  if (opts instanceof Function) {\n    callback = opts;\n    opts = {};\n  }\n  this._get(docId, opts, function (err, res) {\n    if (err) {\n      return callback(err);\n    }\n    if (res.doc._attachments && res.doc._attachments[attachmentId]) {\n      opts.ctx = res.ctx;\n      opts.binary = true;\n      self._getAttachment(docId, attachmentId,\n                          res.doc._attachments[attachmentId], opts, callback);\n    } else {\n      return callback(createError(MISSING_DOC));\n    }\n  });\n});\n\nAbstractPouchDB.prototype.allDocs =\n  adapterFun('allDocs', function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  opts.skip = typeof opts.skip !== 'undefined' ? opts.skip : 0;\n  if (opts.start_key) {\n    opts.startkey = opts.start_key;\n  }\n  if (opts.end_key) {\n    opts.endkey = opts.end_key;\n  }\n  if ('keys' in opts) {\n    if (!Array.isArray(opts.keys)) {\n      return callback(new TypeError('options.keys must be an array'));\n    }\n    var incompatibleOpt =\n      ['startkey', 'endkey', 'key'].filter(function (incompatibleOpt) {\n      return incompatibleOpt in opts;\n    })[0];\n    if (incompatibleOpt) {\n      callback(createError(QUERY_PARSE_ERROR,\n        'Query parameter `' + incompatibleOpt +\n        '` is not compatible with multi-get'\n      ));\n      return;\n    }\n    if (!isRemote(this)) {\n      allDocsKeysParse(opts);\n      if (opts.keys.length === 0) {\n        return this._allDocs({limit: 0}, callback);\n      }\n    }\n  }\n\n  return this._allDocs(opts, callback);\n});\n\nAbstractPouchDB.prototype.changes = function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  opts = opts || {};\n\n  // By default set return_docs to false if the caller has opts.live = true,\n  // this will prevent us from collecting the set of changes indefinitely\n  // resulting in growing memory\n  opts.return_docs = ('return_docs' in opts) ? opts.return_docs : !opts.live;\n\n  return new Changes$1(this, opts, callback);\n};\n\nAbstractPouchDB.prototype.close = adapterFun('close', function (callback) {\n  this._closed = true;\n  this.emit('closed');\n  return this._close(callback);\n});\n\nAbstractPouchDB.prototype.info = adapterFun('info', function (callback) {\n  var self = this;\n  this._info(function (err, info) {\n    if (err) {\n      return callback(err);\n    }\n    // assume we know better than the adapter, unless it informs us\n    info.db_name = info.db_name || self.name;\n    info.auto_compaction = !!(self.auto_compaction && !isRemote(self));\n    info.adapter = self.adapter;\n    callback(null, info);\n  });\n});\n\nAbstractPouchDB.prototype.id = adapterFun('id', function (callback) {\n  return this._id(callback);\n});\n\n/* istanbul ignore next */\nAbstractPouchDB.prototype.type = function () {\n  return (typeof this._type === 'function') ? this._type() : this.adapter;\n};\n\nAbstractPouchDB.prototype.bulkDocs =\n  adapterFun('bulkDocs', function (req, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  opts = opts || {};\n\n  if (Array.isArray(req)) {\n    req = {\n      docs: req\n    };\n  }\n\n  if (!req || !req.docs || !Array.isArray(req.docs)) {\n    return callback(createError(MISSING_BULK_DOCS));\n  }\n\n  for (var i = 0; i < req.docs.length; ++i) {\n    if (typeof req.docs[i] !== 'object' || Array.isArray(req.docs[i])) {\n      return callback(createError(NOT_AN_OBJECT));\n    }\n  }\n\n  var attachmentError;\n  req.docs.forEach(function (doc) {\n    if (doc._attachments) {\n      Object.keys(doc._attachments).forEach(function (name) {\n        attachmentError = attachmentError || attachmentNameError(name);\n        if (!doc._attachments[name].content_type) {\n          guardedConsole('warn', 'Attachment', name, 'on document', doc._id, 'is missing content_type');\n        }\n      });\n    }\n  });\n\n  if (attachmentError) {\n    return callback(createError(BAD_REQUEST, attachmentError));\n  }\n\n  if (!('new_edits' in opts)) {\n    if ('new_edits' in req) {\n      opts.new_edits = req.new_edits;\n    } else {\n      opts.new_edits = true;\n    }\n  }\n\n  var adapter = this;\n  if (!opts.new_edits && !isRemote(adapter)) {\n    // ensure revisions of the same doc are sorted, so that\n    // the local adapter processes them correctly (#2935)\n    req.docs.sort(compareByIdThenRev);\n  }\n\n  cleanDocs(req.docs);\n\n  // in the case of conflicts, we want to return the _ids to the user\n  // however, the underlying adapter may destroy the docs array, so\n  // create a copy here\n  var ids = req.docs.map(function (doc) {\n    return doc._id;\n  });\n\n  return this._bulkDocs(req, opts, function (err, res) {\n    if (err) {\n      return callback(err);\n    }\n    if (!opts.new_edits) {\n      // this is what couch does when new_edits is false\n      res = res.filter(function (x) {\n        return x.error;\n      });\n    }\n    // add ids for error/conflict responses (not required for CouchDB)\n    if (!isRemote(adapter)) {\n      for (var i = 0, l = res.length; i < l; i++) {\n        res[i].id = res[i].id || ids[i];\n      }\n    }\n\n    callback(null, res);\n  });\n});\n\nAbstractPouchDB.prototype.registerDependentDatabase =\n  adapterFun('registerDependentDatabase', function (dependentDb,\n                                                          callback) {\n  var depDB = new this.constructor(dependentDb, this.__opts);\n\n  function diffFun(doc) {\n    doc.dependentDbs = doc.dependentDbs || {};\n    if (doc.dependentDbs[dependentDb]) {\n      return false; // no update required\n    }\n    doc.dependentDbs[dependentDb] = true;\n    return doc;\n  }\n  upsert(this, '_local/_pouch_dependentDbs', diffFun)\n    .then(function () {\n      callback(null, {db: depDB});\n    }).catch(callback);\n});\n\nAbstractPouchDB.prototype.destroy =\n  adapterFun('destroy', function (opts, callback) {\n\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  var self = this;\n  var usePrefix = 'use_prefix' in self ? self.use_prefix : true;\n\n  function destroyDb() {\n    // call destroy method of the particular adaptor\n    self._destroy(opts, function (err, resp) {\n      if (err) {\n        return callback(err);\n      }\n      self._destroyed = true;\n      self.emit('destroyed');\n      callback(null, resp || { 'ok': true });\n    });\n  }\n\n  if (isRemote(self)) {\n    // no need to check for dependent DBs if it's a remote DB\n    return destroyDb();\n  }\n\n  self.get('_local/_pouch_dependentDbs', function (err, localDoc) {\n    if (err) {\n      /* istanbul ignore if */\n      if (err.status !== 404) {\n        return callback(err);\n      } else { // no dependencies\n        return destroyDb();\n      }\n    }\n    var dependentDbs = localDoc.dependentDbs;\n    var PouchDB = self.constructor;\n    var deletedMap = Object.keys(dependentDbs).map(function (name) {\n      // use_prefix is only false in the browser\n      /* istanbul ignore next */\n      var trueName = usePrefix ?\n        name.replace(new RegExp('^' + PouchDB.prefix), '') : name;\n      return new PouchDB(trueName, self.__opts).destroy();\n    });\n    Promise.all(deletedMap).then(destroyDb, callback);\n  });\n});\n\nfunction TaskQueue() {\n  this.isReady = false;\n  this.failed = false;\n  this.queue = [];\n}\n\nTaskQueue.prototype.execute = function () {\n  var fun;\n  if (this.failed) {\n    while ((fun = this.queue.shift())) {\n      fun(this.failed);\n    }\n  } else {\n    while ((fun = this.queue.shift())) {\n      fun();\n    }\n  }\n};\n\nTaskQueue.prototype.fail = function (err) {\n  this.failed = err;\n  this.execute();\n};\n\nTaskQueue.prototype.ready = function (db) {\n  this.isReady = true;\n  this.db = db;\n  this.execute();\n};\n\nTaskQueue.prototype.addTask = function (fun) {\n  this.queue.push(fun);\n  if (this.failed) {\n    this.execute();\n  }\n};\n\nfunction parseAdapter(name, opts) {\n  var match = name.match(/([a-z-]*):\\/\\/(.*)/);\n  if (match) {\n    // the http adapter expects the fully qualified name\n    return {\n      name: /https?/.test(match[1]) ? match[1] + '://' + match[2] : match[2],\n      adapter: match[1]\n    };\n  }\n\n  var adapters = PouchDB.adapters;\n  var preferredAdapters = PouchDB.preferredAdapters;\n  var prefix = PouchDB.prefix;\n  var adapterName = opts.adapter;\n\n  if (!adapterName) { // automatically determine adapter\n    for (var i = 0; i < preferredAdapters.length; ++i) {\n      adapterName = preferredAdapters[i];\n      // check for browsers that have been upgraded from websql-only to websql+idb\n      /* istanbul ignore if */\n      if (adapterName === 'idb' && 'websql' in adapters &&\n          hasLocalStorage() && localStorage['_pouch__websqldb_' + prefix + name]) {\n        // log it, because this can be confusing during development\n        guardedConsole('log', 'PouchDB is downgrading \"' + name + '\" to WebSQL to' +\n          ' avoid data loss, because it was already opened with WebSQL.');\n        continue; // keep using websql to avoid user data loss\n      }\n      break;\n    }\n  }\n\n  var adapter = adapters[adapterName];\n\n  // if adapter is invalid, then an error will be thrown later\n  var usePrefix = (adapter && 'use_prefix' in adapter) ?\n    adapter.use_prefix : true;\n\n  return {\n    name: usePrefix ? (prefix + name) : name,\n    adapter: adapterName\n  };\n}\n\n// OK, so here's the deal. Consider this code:\n//     var db1 = new PouchDB('foo');\n//     var db2 = new PouchDB('foo');\n//     db1.destroy();\n// ^ these two both need to emit 'destroyed' events,\n// as well as the PouchDB constructor itself.\n// So we have one db object (whichever one got destroy() called on it)\n// responsible for emitting the initial event, which then gets emitted\n// by the constructor, which then broadcasts it to any other dbs\n// that may have been created with the same name.\nfunction prepareForDestruction(self) {\n\n  function onDestroyed(from_constructor) {\n    self.removeListener('closed', onClosed);\n    if (!from_constructor) {\n      self.constructor.emit('destroyed', self.name);\n    }\n  }\n\n  function onClosed() {\n    self.removeListener('destroyed', onDestroyed);\n    self.constructor.emit('unref', self);\n  }\n\n  self.once('destroyed', onDestroyed);\n  self.once('closed', onClosed);\n  self.constructor.emit('ref', self);\n}\n\ninherits(PouchDB, AbstractPouchDB);\nfunction PouchDB(name, opts) {\n  // In Node our test suite only tests this for PouchAlt unfortunately\n  /* istanbul ignore if */\n  if (!(this instanceof PouchDB)) {\n    return new PouchDB(name, opts);\n  }\n\n  var self = this;\n  opts = opts || {};\n\n  if (name && typeof name === 'object') {\n    opts = name;\n    name = opts.name;\n    delete opts.name;\n  }\n\n  if (opts.deterministic_revs === undefined) {\n    opts.deterministic_revs = true;\n  }\n\n  this.__opts = opts = clone(opts);\n\n  self.auto_compaction = opts.auto_compaction;\n  self.prefix = PouchDB.prefix;\n\n  if (typeof name !== 'string') {\n    throw new Error('Missing/invalid DB name');\n  }\n\n  var prefixedName = (opts.prefix || '') + name;\n  var backend = parseAdapter(prefixedName, opts);\n\n  opts.name = backend.name;\n  opts.adapter = opts.adapter || backend.adapter;\n\n  self.name = name;\n  self._adapter = opts.adapter;\n  PouchDB.emit('debug', ['adapter', 'Picked adapter: ', opts.adapter]);\n\n  if (!PouchDB.adapters[opts.adapter] ||\n      !PouchDB.adapters[opts.adapter].valid()) {\n    throw new Error('Invalid Adapter: ' + opts.adapter);\n  }\n\n  AbstractPouchDB.call(self);\n  self.taskqueue = new TaskQueue();\n\n  self.adapter = opts.adapter;\n\n  PouchDB.adapters[opts.adapter].call(self, opts, function (err) {\n    if (err) {\n      return self.taskqueue.fail(err);\n    }\n    prepareForDestruction(self);\n\n    self.emit('created', self);\n    PouchDB.emit('created', self.name);\n    self.taskqueue.ready(self);\n  });\n\n}\n\n// AbortController was introduced quite a while after fetch and\n// isnt required for PouchDB to function so polyfill if needed\nvar a = (typeof AbortController !== 'undefined')\n    ? AbortController\n    : function () { return {abort: function () {}}; };\n\nvar f$1 = fetch;\nvar h = Headers;\n\nPouchDB.adapters = {};\nPouchDB.preferredAdapters = [];\n\nPouchDB.prefix = '_pouch_';\n\nvar eventEmitter = new EventEmitter();\n\nfunction setUpEventEmitter(Pouch) {\n  Object.keys(EventEmitter.prototype).forEach(function (key) {\n    if (typeof EventEmitter.prototype[key] === 'function') {\n      Pouch[key] = eventEmitter[key].bind(eventEmitter);\n    }\n  });\n\n  // these are created in constructor.js, and allow us to notify each DB with\n  // the same name that it was destroyed, via the constructor object\n  var destructListeners = Pouch._destructionListeners = new ExportedMap();\n\n  Pouch.on('ref', function onConstructorRef(db) {\n    if (!destructListeners.has(db.name)) {\n      destructListeners.set(db.name, []);\n    }\n    destructListeners.get(db.name).push(db);\n  });\n\n  Pouch.on('unref', function onConstructorUnref(db) {\n    if (!destructListeners.has(db.name)) {\n      return;\n    }\n    var dbList = destructListeners.get(db.name);\n    var pos = dbList.indexOf(db);\n    if (pos < 0) {\n      /* istanbul ignore next */\n      return;\n    }\n    dbList.splice(pos, 1);\n    if (dbList.length > 1) {\n      /* istanbul ignore next */\n      destructListeners.set(db.name, dbList);\n    } else {\n      destructListeners.delete(db.name);\n    }\n  });\n\n  Pouch.on('destroyed', function onConstructorDestroyed(name) {\n    if (!destructListeners.has(name)) {\n      return;\n    }\n    var dbList = destructListeners.get(name);\n    destructListeners.delete(name);\n    dbList.forEach(function (db) {\n      db.emit('destroyed',true);\n    });\n  });\n}\n\nsetUpEventEmitter(PouchDB);\n\nPouchDB.adapter = function (id, obj, addToPreferredAdapters) {\n  /* istanbul ignore else */\n  if (obj.valid()) {\n    PouchDB.adapters[id] = obj;\n    if (addToPreferredAdapters) {\n      PouchDB.preferredAdapters.push(id);\n    }\n  }\n};\n\nPouchDB.plugin = function (obj) {\n  if (typeof obj === 'function') { // function style for plugins\n    obj(PouchDB);\n  } else if (typeof obj !== 'object' || Object.keys(obj).length === 0) {\n    throw new Error('Invalid plugin: got \"' + obj + '\", expected an object or a function');\n  } else {\n    Object.keys(obj).forEach(function (id) { // object style for plugins\n      PouchDB.prototype[id] = obj[id];\n    });\n  }\n  if (this.__defaults) {\n    PouchDB.__defaults = $inject_Object_assign({}, this.__defaults);\n  }\n  return PouchDB;\n};\n\nPouchDB.defaults = function (defaultOpts) {\n  function PouchAlt(name, opts) {\n    if (!(this instanceof PouchAlt)) {\n      return new PouchAlt(name, opts);\n    }\n\n    opts = opts || {};\n\n    if (name && typeof name === 'object') {\n      opts = name;\n      name = opts.name;\n      delete opts.name;\n    }\n\n    opts = $inject_Object_assign({}, PouchAlt.__defaults, opts);\n    PouchDB.call(this, name, opts);\n  }\n\n  inherits(PouchAlt, PouchDB);\n\n  PouchAlt.preferredAdapters = PouchDB.preferredAdapters.slice();\n  Object.keys(PouchDB).forEach(function (key) {\n    if (!(key in PouchAlt)) {\n      PouchAlt[key] = PouchDB[key];\n    }\n  });\n\n  // make default options transitive\n  // https://github.com/pouchdb/pouchdb/issues/5922\n  PouchAlt.__defaults = $inject_Object_assign({}, this.__defaults, defaultOpts);\n\n  return PouchAlt;\n};\n\nPouchDB.fetch = function (url, opts) {\n  return f$1(url, opts);\n};\n\n// managed automatically by set-version.js\nvar version = \"7.1.1\";\n\n// this would just be \"return doc[field]\", but fields\n// can be \"deep\" due to dot notation\nfunction getFieldFromDoc(doc, parsedField) {\n  var value = doc;\n  for (var i = 0, len = parsedField.length; i < len; i++) {\n    var key = parsedField[i];\n    value = value[key];\n    if (!value) {\n      break;\n    }\n  }\n  return value;\n}\n\nfunction compare$1(left, right) {\n  return left < right ? -1 : left > right ? 1 : 0;\n}\n\n// Converts a string in dot notation to an array of its components, with backslash escaping\nfunction parseField(fieldName) {\n  // fields may be deep (e.g. \"foo.bar.baz\"), so parse\n  var fields = [];\n  var current = '';\n  for (var i = 0, len = fieldName.length; i < len; i++) {\n    var ch = fieldName[i];\n    if (ch === '.') {\n      if (i > 0 && fieldName[i - 1] === '\\\\') { // escaped delimiter\n        current = current.substring(0, current.length - 1) + '.';\n      } else { // not escaped, so delimiter\n        fields.push(current);\n        current = '';\n      }\n    } else { // normal character\n      current += ch;\n    }\n  }\n  fields.push(current);\n  return fields;\n}\n\nvar combinationFields = ['$or', '$nor', '$not'];\nfunction isCombinationalField(field) {\n  return combinationFields.indexOf(field) > -1;\n}\n\nfunction getKey(obj) {\n  return Object.keys(obj)[0];\n}\n\nfunction getValue(obj) {\n  return obj[getKey(obj)];\n}\n\n\n// flatten an array of selectors joined by an $and operator\nfunction mergeAndedSelectors(selectors) {\n\n  // sort to ensure that e.g. if the user specified\n  // $and: [{$gt: 'a'}, {$gt: 'b'}], then it's collapsed into\n  // just {$gt: 'b'}\n  var res = {};\n\n  selectors.forEach(function (selector) {\n    Object.keys(selector).forEach(function (field) {\n      var matcher = selector[field];\n      if (typeof matcher !== 'object') {\n        matcher = {$eq: matcher};\n      }\n\n      if (isCombinationalField(field)) {\n        if (matcher instanceof Array) {\n          res[field] = matcher.map(function (m) {\n            return mergeAndedSelectors([m]);\n          });\n        } else {\n          res[field] = mergeAndedSelectors([matcher]);\n        }\n      } else {\n        var fieldMatchers = res[field] = res[field] || {};\n        Object.keys(matcher).forEach(function (operator) {\n          var value = matcher[operator];\n\n          if (operator === '$gt' || operator === '$gte') {\n            return mergeGtGte(operator, value, fieldMatchers);\n          } else if (operator === '$lt' || operator === '$lte') {\n            return mergeLtLte(operator, value, fieldMatchers);\n          } else if (operator === '$ne') {\n            return mergeNe(value, fieldMatchers);\n          } else if (operator === '$eq') {\n            return mergeEq(value, fieldMatchers);\n          }\n          fieldMatchers[operator] = value;\n        });\n      }\n    });\n  });\n\n  return res;\n}\n\n\n\n// collapse logically equivalent gt/gte values\nfunction mergeGtGte(operator, value, fieldMatchers) {\n  if (typeof fieldMatchers.$eq !== 'undefined') {\n    return; // do nothing\n  }\n  if (typeof fieldMatchers.$gte !== 'undefined') {\n    if (operator === '$gte') {\n      if (value > fieldMatchers.$gte) { // more specificity\n        fieldMatchers.$gte = value;\n      }\n    } else { // operator === '$gt'\n      if (value >= fieldMatchers.$gte) { // more specificity\n        delete fieldMatchers.$gte;\n        fieldMatchers.$gt = value;\n      }\n    }\n  } else if (typeof fieldMatchers.$gt !== 'undefined') {\n    if (operator === '$gte') {\n      if (value > fieldMatchers.$gt) { // more specificity\n        delete fieldMatchers.$gt;\n        fieldMatchers.$gte = value;\n      }\n    } else { // operator === '$gt'\n      if (value > fieldMatchers.$gt) { // more specificity\n        fieldMatchers.$gt = value;\n      }\n    }\n  } else {\n    fieldMatchers[operator] = value;\n  }\n}\n\n// collapse logically equivalent lt/lte values\nfunction mergeLtLte(operator, value, fieldMatchers) {\n  if (typeof fieldMatchers.$eq !== 'undefined') {\n    return; // do nothing\n  }\n  if (typeof fieldMatchers.$lte !== 'undefined') {\n    if (operator === '$lte') {\n      if (value < fieldMatchers.$lte) { // more specificity\n        fieldMatchers.$lte = value;\n      }\n    } else { // operator === '$gt'\n      if (value <= fieldMatchers.$lte) { // more specificity\n        delete fieldMatchers.$lte;\n        fieldMatchers.$lt = value;\n      }\n    }\n  } else if (typeof fieldMatchers.$lt !== 'undefined') {\n    if (operator === '$lte') {\n      if (value < fieldMatchers.$lt) { // more specificity\n        delete fieldMatchers.$lt;\n        fieldMatchers.$lte = value;\n      }\n    } else { // operator === '$gt'\n      if (value < fieldMatchers.$lt) { // more specificity\n        fieldMatchers.$lt = value;\n      }\n    }\n  } else {\n    fieldMatchers[operator] = value;\n  }\n}\n\n// combine $ne values into one array\nfunction mergeNe(value, fieldMatchers) {\n  if ('$ne' in fieldMatchers) {\n    // there are many things this could \"not\" be\n    fieldMatchers.$ne.push(value);\n  } else { // doesn't exist yet\n    fieldMatchers.$ne = [value];\n  }\n}\n\n// add $eq into the mix\nfunction mergeEq(value, fieldMatchers) {\n  // these all have less specificity than the $eq\n  // TODO: check for user errors here\n  delete fieldMatchers.$gt;\n  delete fieldMatchers.$gte;\n  delete fieldMatchers.$lt;\n  delete fieldMatchers.$lte;\n  delete fieldMatchers.$ne;\n  fieldMatchers.$eq = value;\n}\n\n//#7458: execute function mergeAndedSelectors on nested $and\nfunction mergeAndedSelectorsNested(obj) {\n    for (var prop in obj) {\n        if (Array.isArray(obj)) {\n            for (var i in obj) {\n                if (obj[i]['$and']) {\n                    obj[i] = mergeAndedSelectors(obj[i]['$and']);\n                }\n            }\n        }\n        var value = obj[prop];\n        if (typeof value === 'object') {\n            mergeAndedSelectorsNested(value); // <- recursive call\n        }\n    }\n    return obj;\n}\n\n//#7458: determine id $and is present in selector (at any level)\nfunction isAndInSelector(obj, isAnd) {\n    for (var prop in obj) {\n        if (prop === '$and') {\n            isAnd = true;\n        }\n        var value = obj[prop];\n        if (typeof value === 'object') {\n            isAnd = isAndInSelector(value, isAnd); // <- recursive call\n        }\n    }\n    return isAnd;\n}\n\n//\n// normalize the selector\n//\nfunction massageSelector(input) {\n  var result = clone(input);\n  var wasAnded = false;\n    //#7458: if $and is present in selector (at any level) merge nested $and\n    if (isAndInSelector(result, false)) {\n        result = mergeAndedSelectorsNested(result);\n        if ('$and' in result) {\n            result = mergeAndedSelectors(result['$and']);\n        }\n        wasAnded = true;\n    }\n\n  ['$or', '$nor'].forEach(function (orOrNor) {\n    if (orOrNor in result) {\n      // message each individual selector\n      // e.g. {foo: 'bar'} becomes {foo: {$eq: 'bar'}}\n      result[orOrNor].forEach(function (subSelector) {\n        var fields = Object.keys(subSelector);\n        for (var i = 0; i < fields.length; i++) {\n          var field = fields[i];\n          var matcher = subSelector[field];\n          if (typeof matcher !== 'object' || matcher === null) {\n            subSelector[field] = {$eq: matcher};\n          }\n        }\n      });\n    }\n  });\n\n  if ('$not' in result) {\n    //This feels a little like forcing, but it will work for now,\n    //I would like to come back to this and make the merging of selectors a little more generic\n    result['$not'] = mergeAndedSelectors([result['$not']]);\n  }\n\n  var fields = Object.keys(result);\n\n  for (var i = 0; i < fields.length; i++) {\n    var field = fields[i];\n    var matcher = result[field];\n\n    if (typeof matcher !== 'object' || matcher === null) {\n      matcher = {$eq: matcher};\n    } else if ('$ne' in matcher && !wasAnded) {\n      // I put these in an array, since there may be more than one\n      // but in the \"mergeAnded\" operation, I already take care of that\n      matcher.$ne = [matcher.$ne];\n    }\n    result[field] = matcher;\n  }\n\n  return result;\n}\n\nfunction pad(str, padWith, upToLength) {\n  var padding = '';\n  var targetLength = upToLength - str.length;\n  /* istanbul ignore next */\n  while (padding.length < targetLength) {\n    padding += padWith;\n  }\n  return padding;\n}\n\nfunction padLeft(str, padWith, upToLength) {\n  var padding = pad(str, padWith, upToLength);\n  return padding + str;\n}\n\nvar MIN_MAGNITUDE = -324; // verified by -Number.MIN_VALUE\nvar MAGNITUDE_DIGITS = 3; // ditto\nvar SEP = ''; // set to '_' for easier debugging \n\nfunction collate(a, b) {\n\n  if (a === b) {\n    return 0;\n  }\n\n  a = normalizeKey(a);\n  b = normalizeKey(b);\n\n  var ai = collationIndex(a);\n  var bi = collationIndex(b);\n  if ((ai - bi) !== 0) {\n    return ai - bi;\n  }\n  switch (typeof a) {\n    case 'number':\n      return a - b;\n    case 'boolean':\n      return a < b ? -1 : 1;\n    case 'string':\n      return stringCollate(a, b);\n  }\n  return Array.isArray(a) ? arrayCollate(a, b) : objectCollate(a, b);\n}\n\n// couch considers null/NaN/Infinity/-Infinity === undefined,\n// for the purposes of mapreduce indexes. also, dates get stringified.\nfunction normalizeKey(key) {\n  switch (typeof key) {\n    case 'undefined':\n      return null;\n    case 'number':\n      if (key === Infinity || key === -Infinity || isNaN(key)) {\n        return null;\n      }\n      return key;\n    case 'object':\n      var origKey = key;\n      if (Array.isArray(key)) {\n        var len = key.length;\n        key = new Array(len);\n        for (var i = 0; i < len; i++) {\n          key[i] = normalizeKey(origKey[i]);\n        }\n      /* istanbul ignore next */\n      } else if (key instanceof Date) {\n        return key.toJSON();\n      } else if (key !== null) { // generic object\n        key = {};\n        for (var k in origKey) {\n          if (origKey.hasOwnProperty(k)) {\n            var val = origKey[k];\n            if (typeof val !== 'undefined') {\n              key[k] = normalizeKey(val);\n            }\n          }\n        }\n      }\n  }\n  return key;\n}\n\nfunction indexify(key) {\n  if (key !== null) {\n    switch (typeof key) {\n      case 'boolean':\n        return key ? 1 : 0;\n      case 'number':\n        return numToIndexableString(key);\n      case 'string':\n        // We've to be sure that key does not contain \\u0000\n        // Do order-preserving replacements:\n        // 0 -> 1, 1\n        // 1 -> 1, 2\n        // 2 -> 2, 2\n        /* eslint-disable no-control-regex */\n        return key\n          .replace(/\\u0002/g, '\\u0002\\u0002')\n          .replace(/\\u0001/g, '\\u0001\\u0002')\n          .replace(/\\u0000/g, '\\u0001\\u0001');\n        /* eslint-enable no-control-regex */\n      case 'object':\n        var isArray = Array.isArray(key);\n        var arr = isArray ? key : Object.keys(key);\n        var i = -1;\n        var len = arr.length;\n        var result = '';\n        if (isArray) {\n          while (++i < len) {\n            result += toIndexableString(arr[i]);\n          }\n        } else {\n          while (++i < len) {\n            var objKey = arr[i];\n            result += toIndexableString(objKey) +\n                toIndexableString(key[objKey]);\n          }\n        }\n        return result;\n    }\n  }\n  return '';\n}\n\n// convert the given key to a string that would be appropriate\n// for lexical sorting, e.g. within a database, where the\n// sorting is the same given by the collate() function.\nfunction toIndexableString(key) {\n  var zero = '\\u0000';\n  key = normalizeKey(key);\n  return collationIndex(key) + SEP + indexify(key) + zero;\n}\n\nfunction parseNumber(str, i) {\n  var originalIdx = i;\n  var num;\n  var zero = str[i] === '1';\n  if (zero) {\n    num = 0;\n    i++;\n  } else {\n    var neg = str[i] === '0';\n    i++;\n    var numAsString = '';\n    var magAsString = str.substring(i, i + MAGNITUDE_DIGITS);\n    var magnitude = parseInt(magAsString, 10) + MIN_MAGNITUDE;\n    /* istanbul ignore next */\n    if (neg) {\n      magnitude = -magnitude;\n    }\n    i += MAGNITUDE_DIGITS;\n    while (true) {\n      var ch = str[i];\n      if (ch === '\\u0000') {\n        break;\n      } else {\n        numAsString += ch;\n      }\n      i++;\n    }\n    numAsString = numAsString.split('.');\n    if (numAsString.length === 1) {\n      num = parseInt(numAsString, 10);\n    } else {\n      /* istanbul ignore next */\n      num = parseFloat(numAsString[0] + '.' + numAsString[1]);\n    }\n    /* istanbul ignore next */\n    if (neg) {\n      num = num - 10;\n    }\n    /* istanbul ignore next */\n    if (magnitude !== 0) {\n      // parseFloat is more reliable than pow due to rounding errors\n      // e.g. Number.MAX_VALUE would return Infinity if we did\n      // num * Math.pow(10, magnitude);\n      num = parseFloat(num + 'e' + magnitude);\n    }\n  }\n  return {num: num, length : i - originalIdx};\n}\n\n// move up the stack while parsing\n// this function moved outside of parseIndexableString for performance\nfunction pop(stack, metaStack) {\n  var obj = stack.pop();\n\n  if (metaStack.length) {\n    var lastMetaElement = metaStack[metaStack.length - 1];\n    if (obj === lastMetaElement.element) {\n      // popping a meta-element, e.g. an object whose value is another object\n      metaStack.pop();\n      lastMetaElement = metaStack[metaStack.length - 1];\n    }\n    var element = lastMetaElement.element;\n    var lastElementIndex = lastMetaElement.index;\n    if (Array.isArray(element)) {\n      element.push(obj);\n    } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n      var key = stack.pop();\n      element[key] = obj;\n    } else {\n      stack.push(obj); // obj with key only\n    }\n  }\n}\n\nfunction parseIndexableString(str) {\n  var stack = [];\n  var metaStack = []; // stack for arrays and objects\n  var i = 0;\n\n  /*eslint no-constant-condition: [\"error\", { \"checkLoops\": false }]*/\n  while (true) {\n    var collationIndex = str[i++];\n    if (collationIndex === '\\u0000') {\n      if (stack.length === 1) {\n        return stack.pop();\n      } else {\n        pop(stack, metaStack);\n        continue;\n      }\n    }\n    switch (collationIndex) {\n      case '1':\n        stack.push(null);\n        break;\n      case '2':\n        stack.push(str[i] === '1');\n        i++;\n        break;\n      case '3':\n        var parsedNum = parseNumber(str, i);\n        stack.push(parsedNum.num);\n        i += parsedNum.length;\n        break;\n      case '4':\n        var parsedStr = '';\n        /*eslint no-constant-condition: [\"error\", { \"checkLoops\": false }]*/\n        while (true) {\n          var ch = str[i];\n          if (ch === '\\u0000') {\n            break;\n          }\n          parsedStr += ch;\n          i++;\n        }\n        // perform the reverse of the order-preserving replacement\n        // algorithm (see above)\n        /* eslint-disable no-control-regex */\n        parsedStr = parsedStr.replace(/\\u0001\\u0001/g, '\\u0000')\n          .replace(/\\u0001\\u0002/g, '\\u0001')\n          .replace(/\\u0002\\u0002/g, '\\u0002');\n        /* eslint-enable no-control-regex */\n        stack.push(parsedStr);\n        break;\n      case '5':\n        var arrayElement = { element: [], index: stack.length };\n        stack.push(arrayElement.element);\n        metaStack.push(arrayElement);\n        break;\n      case '6':\n        var objElement = { element: {}, index: stack.length };\n        stack.push(objElement.element);\n        metaStack.push(objElement);\n        break;\n      /* istanbul ignore next */\n      default:\n        throw new Error(\n          'bad collationIndex or unexpectedly reached end of input: ' +\n            collationIndex);\n    }\n  }\n}\n\nfunction arrayCollate(a, b) {\n  var len = Math.min(a.length, b.length);\n  for (var i = 0; i < len; i++) {\n    var sort = collate(a[i], b[i]);\n    if (sort !== 0) {\n      return sort;\n    }\n  }\n  return (a.length === b.length) ? 0 :\n    (a.length > b.length) ? 1 : -1;\n}\nfunction stringCollate(a, b) {\n  // See: https://github.com/daleharvey/pouchdb/issues/40\n  // This is incompatible with the CouchDB implementation, but its the\n  // best we can do for now\n  return (a === b) ? 0 : ((a > b) ? 1 : -1);\n}\nfunction objectCollate(a, b) {\n  var ak = Object.keys(a), bk = Object.keys(b);\n  var len = Math.min(ak.length, bk.length);\n  for (var i = 0; i < len; i++) {\n    // First sort the keys\n    var sort = collate(ak[i], bk[i]);\n    if (sort !== 0) {\n      return sort;\n    }\n    // if the keys are equal sort the values\n    sort = collate(a[ak[i]], b[bk[i]]);\n    if (sort !== 0) {\n      return sort;\n    }\n\n  }\n  return (ak.length === bk.length) ? 0 :\n    (ak.length > bk.length) ? 1 : -1;\n}\n// The collation is defined by erlangs ordered terms\n// the atoms null, true, false come first, then numbers, strings,\n// arrays, then objects\n// null/undefined/NaN/Infinity/-Infinity are all considered null\nfunction collationIndex(x) {\n  var id = ['boolean', 'number', 'string', 'object'];\n  var idx = id.indexOf(typeof x);\n  //false if -1 otherwise true, but fast!!!!1\n  if (~idx) {\n    if (x === null) {\n      return 1;\n    }\n    if (Array.isArray(x)) {\n      return 5;\n    }\n    return idx < 3 ? (idx + 2) : (idx + 3);\n  }\n  /* istanbul ignore next */\n  if (Array.isArray(x)) {\n    return 5;\n  }\n}\n\n// conversion:\n// x yyy zz...zz\n// x = 0 for negative, 1 for 0, 2 for positive\n// y = exponent (for negative numbers negated) moved so that it's >= 0\n// z = mantisse\nfunction numToIndexableString(num) {\n\n  if (num === 0) {\n    return '1';\n  }\n\n  // convert number to exponential format for easier and\n  // more succinct string sorting\n  var expFormat = num.toExponential().split(/e\\+?/);\n  var magnitude = parseInt(expFormat[1], 10);\n\n  var neg = num < 0;\n\n  var result = neg ? '0' : '2';\n\n  // first sort by magnitude\n  // it's easier if all magnitudes are positive\n  var magForComparison = ((neg ? -magnitude : magnitude) - MIN_MAGNITUDE);\n  var magString = padLeft((magForComparison).toString(), '0', MAGNITUDE_DIGITS);\n\n  result += SEP + magString;\n\n  // then sort by the factor\n  var factor = Math.abs(parseFloat(expFormat[0])); // [1..10)\n  /* istanbul ignore next */\n  if (neg) { // for negative reverse ordering\n    factor = 10 - factor;\n  }\n\n  var factorStr = factor.toFixed(20);\n\n  // strip zeros from the end\n  factorStr = factorStr.replace(/\\.?0+$/, '');\n\n  result += SEP + factorStr;\n\n  return result;\n}\n\n// create a comparator based on the sort object\nfunction createFieldSorter(sort) {\n\n  function getFieldValuesAsArray(doc) {\n    return sort.map(function (sorting) {\n      var fieldName = getKey(sorting);\n      var parsedField = parseField(fieldName);\n      var docFieldValue = getFieldFromDoc(doc, parsedField);\n      return docFieldValue;\n    });\n  }\n\n  return function (aRow, bRow) {\n    var aFieldValues = getFieldValuesAsArray(aRow.doc);\n    var bFieldValues = getFieldValuesAsArray(bRow.doc);\n    var collation = collate(aFieldValues, bFieldValues);\n    if (collation !== 0) {\n      return collation;\n    }\n    // this is what mango seems to do\n    return compare$1(aRow.doc._id, bRow.doc._id);\n  };\n}\n\nfunction filterInMemoryFields(rows, requestDef, inMemoryFields) {\n  rows = rows.filter(function (row) {\n    return rowFilter(row.doc, requestDef.selector, inMemoryFields);\n  });\n\n  if (requestDef.sort) {\n    // in-memory sort\n    var fieldSorter = createFieldSorter(requestDef.sort);\n    rows = rows.sort(fieldSorter);\n    if (typeof requestDef.sort[0] !== 'string' &&\n        getValue(requestDef.sort[0]) === 'desc') {\n      rows = rows.reverse();\n    }\n  }\n\n  if ('limit' in requestDef || 'skip' in requestDef) {\n    // have to do the limit in-memory\n    var skip = requestDef.skip || 0;\n    var limit = ('limit' in requestDef ? requestDef.limit : rows.length) + skip;\n    rows = rows.slice(skip, limit);\n  }\n  return rows;\n}\n\nfunction rowFilter(doc, selector, inMemoryFields) {\n  return inMemoryFields.every(function (field) {\n    var matcher = selector[field];\n    var parsedField = parseField(field);\n    var docFieldValue = getFieldFromDoc(doc, parsedField);\n    if (isCombinationalField(field)) {\n      return matchCominationalSelector(field, matcher, doc);\n    }\n\n    return matchSelector(matcher, doc, parsedField, docFieldValue);\n  });\n}\n\nfunction matchSelector(matcher, doc, parsedField, docFieldValue) {\n  if (!matcher) {\n    // no filtering necessary; this field is just needed for sorting\n    return true;\n  }\n\n  // is matcher an object, if so continue recursion\n  if (typeof matcher === 'object') {\n    return Object.keys(matcher).every(function (userOperator) {\n      var userValue = matcher[userOperator];\n      return match(userOperator, doc, userValue, parsedField, docFieldValue);\n    });\n  }\n\n  // no more depth, No need to recurse further\n  return matcher === docFieldValue;\n}\n\nfunction matchCominationalSelector(field, matcher, doc) {\n\n  if (field === '$or') {\n    return matcher.some(function (orMatchers) {\n      return rowFilter(doc, orMatchers, Object.keys(orMatchers));\n    });\n  }\n\n  if (field === '$not') {\n    return !rowFilter(doc, matcher, Object.keys(matcher));\n  }\n\n  //`$nor`\n  return !matcher.find(function (orMatchers) {\n    return rowFilter(doc, orMatchers, Object.keys(orMatchers));\n  });\n\n}\n\nfunction match(userOperator, doc, userValue, parsedField, docFieldValue) {\n  if (!matchers[userOperator]) {\n    throw new Error('unknown operator \"' + userOperator +\n      '\" - should be one of $eq, $lte, $lt, $gt, $gte, $exists, $ne, $in, ' +\n      '$nin, $size, $mod, $regex, $elemMatch, $type, $allMatch or $all');\n  }\n  return matchers[userOperator](doc, userValue, parsedField, docFieldValue);\n}\n\nfunction fieldExists(docFieldValue) {\n  return typeof docFieldValue !== 'undefined' && docFieldValue !== null;\n}\n\nfunction fieldIsNotUndefined(docFieldValue) {\n  return typeof docFieldValue !== 'undefined';\n}\n\nfunction modField(docFieldValue, userValue) {\n  var divisor = userValue[0];\n  var mod = userValue[1];\n  if (divisor === 0) {\n    throw new Error('Bad divisor, cannot divide by zero');\n  }\n\n  if (parseInt(divisor, 10) !== divisor ) {\n    throw new Error('Divisor is not an integer');\n  }\n\n  if (parseInt(mod, 10) !== mod ) {\n    throw new Error('Modulus is not an integer');\n  }\n\n  if (parseInt(docFieldValue, 10) !== docFieldValue) {\n    return false;\n  }\n\n  return docFieldValue % divisor === mod;\n}\n\nfunction arrayContainsValue(docFieldValue, userValue) {\n  return userValue.some(function (val) {\n    if (docFieldValue instanceof Array) {\n      return docFieldValue.indexOf(val) > -1;\n    }\n\n    return docFieldValue === val;\n  });\n}\n\nfunction arrayContainsAllValues(docFieldValue, userValue) {\n  return userValue.every(function (val) {\n    return docFieldValue.indexOf(val) > -1;\n  });\n}\n\nfunction arraySize(docFieldValue, userValue) {\n  return docFieldValue.length === userValue;\n}\n\nfunction regexMatch(docFieldValue, userValue) {\n  var re = new RegExp(userValue);\n\n  return re.test(docFieldValue);\n}\n\nfunction typeMatch(docFieldValue, userValue) {\n\n  switch (userValue) {\n    case 'null':\n      return docFieldValue === null;\n    case 'boolean':\n      return typeof (docFieldValue) === 'boolean';\n    case 'number':\n      return typeof (docFieldValue) === 'number';\n    case 'string':\n      return typeof (docFieldValue) === 'string';\n    case 'array':\n      return docFieldValue instanceof Array;\n    case 'object':\n      return ({}).toString.call(docFieldValue) === '[object Object]';\n  }\n\n  throw new Error(userValue + ' not supported as a type.' +\n                  'Please use one of object, string, array, number, boolean or null.');\n\n}\n\nvar matchers = {\n\n  '$elemMatch': function (doc, userValue, parsedField, docFieldValue) {\n    if (!Array.isArray(docFieldValue)) {\n      return false;\n    }\n\n    if (docFieldValue.length === 0) {\n      return false;\n    }\n\n    if (typeof docFieldValue[0] === 'object') {\n      return docFieldValue.some(function (val) {\n        return rowFilter(val, userValue, Object.keys(userValue));\n      });\n    }\n\n    return docFieldValue.some(function (val) {\n      return matchSelector(userValue, doc, parsedField, val);\n    });\n  },\n\n  '$allMatch': function (doc, userValue, parsedField, docFieldValue) {\n    if (!Array.isArray(docFieldValue)) {\n      return false;\n    }\n\n    /* istanbul ignore next */\n    if (docFieldValue.length === 0) {\n      return false;\n    }\n\n    if (typeof docFieldValue[0] === 'object') {\n      return docFieldValue.every(function (val) {\n        return rowFilter(val, userValue, Object.keys(userValue));\n      });\n    }\n\n    return docFieldValue.every(function (val) {\n      return matchSelector(userValue, doc, parsedField, val);\n    });\n  },\n\n  '$eq': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) === 0;\n  },\n\n  '$gte': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) >= 0;\n  },\n\n  '$gt': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) > 0;\n  },\n\n  '$lte': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) <= 0;\n  },\n\n  '$lt': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) < 0;\n  },\n\n  '$exists': function (doc, userValue, parsedField, docFieldValue) {\n    //a field that is null is still considered to exist\n    if (userValue) {\n      return fieldIsNotUndefined(docFieldValue);\n    }\n\n    return !fieldIsNotUndefined(docFieldValue);\n  },\n\n  '$mod': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && modField(docFieldValue, userValue);\n  },\n\n  '$ne': function (doc, userValue, parsedField, docFieldValue) {\n    return userValue.every(function (neValue) {\n      return collate(docFieldValue, neValue) !== 0;\n    });\n  },\n  '$in': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && arrayContainsValue(docFieldValue, userValue);\n  },\n\n  '$nin': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && !arrayContainsValue(docFieldValue, userValue);\n  },\n\n  '$size': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && arraySize(docFieldValue, userValue);\n  },\n\n  '$all': function (doc, userValue, parsedField, docFieldValue) {\n    return Array.isArray(docFieldValue) && arrayContainsAllValues(docFieldValue, userValue);\n  },\n\n  '$regex': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && regexMatch(docFieldValue, userValue);\n  },\n\n  '$type': function (doc, userValue, parsedField, docFieldValue) {\n    return typeMatch(docFieldValue, userValue);\n  }\n};\n\n// return true if the given doc matches the supplied selector\nfunction matchesSelector(doc, selector) {\n  /* istanbul ignore if */\n  if (typeof selector !== 'object') {\n    // match the CouchDB error message\n    throw new Error('Selector error: expected a JSON object');\n  }\n\n  selector = massageSelector(selector);\n  var row = {\n    'doc': doc\n  };\n\n  var rowsMatched = filterInMemoryFields([row], { 'selector': selector }, Object.keys(selector));\n  return rowsMatched && rowsMatched.length === 1;\n}\n\nfunction evalFilter(input) {\n  return scopeEval('\"use strict\";\\nreturn ' + input + ';', {});\n}\n\nfunction evalView(input) {\n  var code = [\n    'return function(doc) {',\n    '  \"use strict\";',\n    '  var emitted = false;',\n    '  var emit = function (a, b) {',\n    '    emitted = true;',\n    '  };',\n    '  var view = ' + input + ';',\n    '  view(doc);',\n    '  if (emitted) {',\n    '    return true;',\n    '  }',\n    '};'\n  ].join('\\n');\n\n  return scopeEval(code, {});\n}\n\nfunction validate(opts, callback) {\n  if (opts.selector) {\n    if (opts.filter && opts.filter !== '_selector') {\n      var filterName = typeof opts.filter === 'string' ?\n        opts.filter : 'function';\n      return callback(new Error('selector invalid for filter \"' + filterName + '\"'));\n    }\n  }\n  callback();\n}\n\nfunction normalize(opts) {\n  if (opts.view && !opts.filter) {\n    opts.filter = '_view';\n  }\n\n  if (opts.selector && !opts.filter) {\n    opts.filter = '_selector';\n  }\n\n  if (opts.filter && typeof opts.filter === 'string') {\n    if (opts.filter === '_view') {\n      opts.view = normalizeDesignDocFunctionName(opts.view);\n    } else {\n      opts.filter = normalizeDesignDocFunctionName(opts.filter);\n    }\n  }\n}\n\nfunction shouldFilter(changesHandler, opts) {\n  return opts.filter && typeof opts.filter === 'string' &&\n    !opts.doc_ids && !isRemote(changesHandler.db);\n}\n\nfunction filter(changesHandler, opts) {\n  var callback = opts.complete;\n  if (opts.filter === '_view') {\n    if (!opts.view || typeof opts.view !== 'string') {\n      var err = createError(BAD_REQUEST,\n        '`view` filter parameter not found or invalid.');\n      return callback(err);\n    }\n    // fetch a view from a design doc, make it behave like a filter\n    var viewName = parseDesignDocFunctionName(opts.view);\n    changesHandler.db.get('_design/' + viewName[0], function (err, ddoc) {\n      /* istanbul ignore if */\n      if (changesHandler.isCancelled) {\n        return callback(null, {status: 'cancelled'});\n      }\n      /* istanbul ignore next */\n      if (err) {\n        return callback(generateErrorFromResponse(err));\n      }\n      var mapFun = ddoc && ddoc.views && ddoc.views[viewName[1]] &&\n        ddoc.views[viewName[1]].map;\n      if (!mapFun) {\n        return callback(createError(MISSING_DOC,\n          (ddoc.views ? 'missing json key: ' + viewName[1] :\n            'missing json key: views')));\n      }\n      opts.filter = evalView(mapFun);\n      changesHandler.doChanges(opts);\n    });\n  } else if (opts.selector) {\n    opts.filter = function (doc) {\n      return matchesSelector(doc, opts.selector);\n    };\n    changesHandler.doChanges(opts);\n  } else {\n    // fetch a filter from a design doc\n    var filterName = parseDesignDocFunctionName(opts.filter);\n    changesHandler.db.get('_design/' + filterName[0], function (err, ddoc) {\n      /* istanbul ignore if */\n      if (changesHandler.isCancelled) {\n        return callback(null, {status: 'cancelled'});\n      }\n      /* istanbul ignore next */\n      if (err) {\n        return callback(generateErrorFromResponse(err));\n      }\n      var filterFun = ddoc && ddoc.filters && ddoc.filters[filterName[1]];\n      if (!filterFun) {\n        return callback(createError(MISSING_DOC,\n          ((ddoc && ddoc.filters) ? 'missing json key: ' + filterName[1]\n            : 'missing json key: filters')));\n      }\n      opts.filter = evalFilter(filterFun);\n      changesHandler.doChanges(opts);\n    });\n  }\n}\n\nfunction applyChangesFilterPlugin(PouchDB) {\n  PouchDB._changesFilterPlugin = {\n    validate: validate,\n    normalize: normalize,\n    shouldFilter: shouldFilter,\n    filter: filter\n  };\n}\n\n// TODO: remove from pouchdb-core (breaking)\nPouchDB.plugin(applyChangesFilterPlugin);\n\nPouchDB.version = version;\n\nfunction toObject(array) {\n  return array.reduce(function (obj, item) {\n    obj[item] = true;\n    return obj;\n  }, {});\n}\n// List of top level reserved words for doc\nvar reservedWords = toObject([\n  '_id',\n  '_rev',\n  '_attachments',\n  '_deleted',\n  '_revisions',\n  '_revs_info',\n  '_conflicts',\n  '_deleted_conflicts',\n  '_local_seq',\n  '_rev_tree',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats',\n  // Specific to Couchbase Sync Gateway\n  '_removed'\n]);\n\n// List of reserved words that should end up the document\nvar dataWords = toObject([\n  '_attachments',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats'\n]);\n\nfunction parseRevisionInfo(rev$$1) {\n  if (!/^\\d+-./.test(rev$$1)) {\n    return createError(INVALID_REV);\n  }\n  var idx = rev$$1.indexOf('-');\n  var left = rev$$1.substring(0, idx);\n  var right = rev$$1.substring(idx + 1);\n  return {\n    prefix: parseInt(left, 10),\n    id: right\n  };\n}\n\nfunction makeRevTreeFromRevisions(revisions, opts) {\n  var pos = revisions.start - revisions.ids.length + 1;\n\n  var revisionIds = revisions.ids;\n  var ids = [revisionIds[0], opts, []];\n\n  for (var i = 1, len = revisionIds.length; i < len; i++) {\n    ids = [revisionIds[i], {status: 'missing'}, [ids]];\n  }\n\n  return [{\n    pos: pos,\n    ids: ids\n  }];\n}\n\n// Preprocess documents, parse their revisions, assign an id and a\n// revision for new writes that are missing them, etc\nfunction parseDoc(doc, newEdits, dbOpts) {\n  if (!dbOpts) {\n    dbOpts = {\n      deterministic_revs: true\n    };\n  }\n\n  var nRevNum;\n  var newRevId;\n  var revInfo;\n  var opts = {status: 'available'};\n  if (doc._deleted) {\n    opts.deleted = true;\n  }\n\n  if (newEdits) {\n    if (!doc._id) {\n      doc._id = uuid();\n    }\n    newRevId = rev(doc, dbOpts.deterministic_revs);\n    if (doc._rev) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      doc._rev_tree = [{\n        pos: revInfo.prefix,\n        ids: [revInfo.id, {status: 'missing'}, [[newRevId, opts, []]]]\n      }];\n      nRevNum = revInfo.prefix + 1;\n    } else {\n      doc._rev_tree = [{\n        pos: 1,\n        ids : [newRevId, opts, []]\n      }];\n      nRevNum = 1;\n    }\n  } else {\n    if (doc._revisions) {\n      doc._rev_tree = makeRevTreeFromRevisions(doc._revisions, opts);\n      nRevNum = doc._revisions.start;\n      newRevId = doc._revisions.ids[0];\n    }\n    if (!doc._rev_tree) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      nRevNum = revInfo.prefix;\n      newRevId = revInfo.id;\n      doc._rev_tree = [{\n        pos: nRevNum,\n        ids: [newRevId, opts, []]\n      }];\n    }\n  }\n\n  invalidIdError(doc._id);\n\n  doc._rev = nRevNum + '-' + newRevId;\n\n  var result = {metadata : {}, data : {}};\n  for (var key in doc) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(doc, key)) {\n      var specialKey = key[0] === '_';\n      if (specialKey && !reservedWords[key]) {\n        var error = createError(DOC_VALIDATION, key);\n        error.message = DOC_VALIDATION.message + ': ' + key;\n        throw error;\n      } else if (specialKey && !dataWords[key]) {\n        result.metadata[key.slice(1)] = doc[key];\n      } else {\n        result.data[key] = doc[key];\n      }\n    }\n  }\n  return result;\n}\n\nfunction parseBase64(data) {\n  try {\n    return thisAtob(data);\n  } catch (e) {\n    var err = createError(BAD_ARG,\n      'Attachment is not a valid base64 string');\n    return {error: err};\n  }\n}\n\nfunction preprocessString(att, blobType, callback) {\n  var asBinary = parseBase64(att.data);\n  if (asBinary.error) {\n    return callback(asBinary.error);\n  }\n\n  att.length = asBinary.length;\n  if (blobType === 'blob') {\n    att.data = binStringToBluffer(asBinary, att.content_type);\n  } else if (blobType === 'base64') {\n    att.data = thisBtoa(asBinary);\n  } else { // binary\n    att.data = asBinary;\n  }\n  binaryMd5(asBinary, function (result) {\n    att.digest = 'md5-' + result;\n    callback();\n  });\n}\n\nfunction preprocessBlob(att, blobType, callback) {\n  binaryMd5(att.data, function (md5) {\n    att.digest = 'md5-' + md5;\n    // size is for blobs (browser), length is for buffers (node)\n    att.length = att.data.size || att.data.length || 0;\n    if (blobType === 'binary') {\n      blobToBinaryString(att.data, function (binString) {\n        att.data = binString;\n        callback();\n      });\n    } else if (blobType === 'base64') {\n      blobToBase64(att.data, function (b64) {\n        att.data = b64;\n        callback();\n      });\n    } else {\n      callback();\n    }\n  });\n}\n\nfunction preprocessAttachment(att, blobType, callback) {\n  if (att.stub) {\n    return callback();\n  }\n  if (typeof att.data === 'string') { // input is a base64 string\n    preprocessString(att, blobType, callback);\n  } else { // input is a blob\n    preprocessBlob(att, blobType, callback);\n  }\n}\n\nfunction preprocessAttachments(docInfos, blobType, callback) {\n\n  if (!docInfos.length) {\n    return callback();\n  }\n\n  var docv = 0;\n  var overallErr;\n\n  docInfos.forEach(function (docInfo) {\n    var attachments = docInfo.data && docInfo.data._attachments ?\n      Object.keys(docInfo.data._attachments) : [];\n    var recv = 0;\n\n    if (!attachments.length) {\n      return done();\n    }\n\n    function processedAttachment(err) {\n      overallErr = err;\n      recv++;\n      if (recv === attachments.length) {\n        done();\n      }\n    }\n\n    for (var key in docInfo.data._attachments) {\n      if (docInfo.data._attachments.hasOwnProperty(key)) {\n        preprocessAttachment(docInfo.data._attachments[key],\n          blobType, processedAttachment);\n      }\n    }\n  });\n\n  function done() {\n    docv++;\n    if (docInfos.length === docv) {\n      if (overallErr) {\n        callback(overallErr);\n      } else {\n        callback();\n      }\n    }\n  }\n}\n\nfunction updateDoc(revLimit, prev, docInfo, results,\n                   i, cb, writeDoc, newEdits) {\n\n  if (revExists(prev.rev_tree, docInfo.metadata.rev) && !newEdits) {\n    results[i] = docInfo;\n    return cb();\n  }\n\n  // sometimes this is pre-calculated. historically not always\n  var previousWinningRev = prev.winningRev || winningRev(prev);\n  var previouslyDeleted = 'deleted' in prev ? prev.deleted :\n    isDeleted(prev, previousWinningRev);\n  var deleted = 'deleted' in docInfo.metadata ? docInfo.metadata.deleted :\n    isDeleted(docInfo.metadata);\n  var isRoot = /^1-/.test(docInfo.metadata.rev);\n\n  if (previouslyDeleted && !deleted && newEdits && isRoot) {\n    var newDoc = docInfo.data;\n    newDoc._rev = previousWinningRev;\n    newDoc._id = docInfo.metadata.id;\n    docInfo = parseDoc(newDoc, newEdits);\n  }\n\n  var merged = merge(prev.rev_tree, docInfo.metadata.rev_tree[0], revLimit);\n\n  var inConflict = newEdits && ((\n    (previouslyDeleted && deleted && merged.conflicts !== 'new_leaf') ||\n    (!previouslyDeleted && merged.conflicts !== 'new_leaf') ||\n    (previouslyDeleted && !deleted && merged.conflicts === 'new_branch')));\n\n  if (inConflict) {\n    var err = createError(REV_CONFLICT);\n    results[i] = err;\n    return cb();\n  }\n\n  var newRev = docInfo.metadata.rev;\n  docInfo.metadata.rev_tree = merged.tree;\n  docInfo.stemmedRevs = merged.stemmedRevs || [];\n  /* istanbul ignore else */\n  if (prev.rev_map) {\n    docInfo.metadata.rev_map = prev.rev_map; // used only by leveldb\n  }\n\n  // recalculate\n  var winningRev$$1 = winningRev(docInfo.metadata);\n  var winningRevIsDeleted = isDeleted(docInfo.metadata, winningRev$$1);\n\n  // calculate the total number of documents that were added/removed,\n  // from the perspective of total_rows/doc_count\n  var delta = (previouslyDeleted === winningRevIsDeleted) ? 0 :\n    previouslyDeleted < winningRevIsDeleted ? -1 : 1;\n\n  var newRevIsDeleted;\n  if (newRev === winningRev$$1) {\n    // if the new rev is the same as the winning rev, we can reuse that value\n    newRevIsDeleted = winningRevIsDeleted;\n  } else {\n    // if they're not the same, then we need to recalculate\n    newRevIsDeleted = isDeleted(docInfo.metadata, newRev);\n  }\n\n  writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n    true, delta, i, cb);\n}\n\nfunction rootIsMissing(docInfo) {\n  return docInfo.metadata.rev_tree[0].ids[1].status === 'missing';\n}\n\nfunction processDocs(revLimit, docInfos, api, fetchedDocs, tx, results,\n                     writeDoc, opts, overallCallback) {\n\n  // Default to 1000 locally\n  revLimit = revLimit || 1000;\n\n  function insertDoc(docInfo, resultsIdx, callback) {\n    // Cant insert new deleted documents\n    var winningRev$$1 = winningRev(docInfo.metadata);\n    var deleted = isDeleted(docInfo.metadata, winningRev$$1);\n    if ('was_delete' in opts && deleted) {\n      results[resultsIdx] = createError(MISSING_DOC, 'deleted');\n      return callback();\n    }\n\n    // 4712 - detect whether a new document was inserted with a _rev\n    var inConflict = newEdits && rootIsMissing(docInfo);\n\n    if (inConflict) {\n      var err = createError(REV_CONFLICT);\n      results[resultsIdx] = err;\n      return callback();\n    }\n\n    var delta = deleted ? 0 : 1;\n\n    writeDoc(docInfo, winningRev$$1, deleted, deleted, false,\n      delta, resultsIdx, callback);\n  }\n\n  var newEdits = opts.new_edits;\n  var idsToDocs = new ExportedMap();\n\n  var docsDone = 0;\n  var docsToDo = docInfos.length;\n\n  function checkAllDocsDone() {\n    if (++docsDone === docsToDo && overallCallback) {\n      overallCallback();\n    }\n  }\n\n  docInfos.forEach(function (currentDoc, resultsIdx) {\n\n    if (currentDoc._id && isLocalId(currentDoc._id)) {\n      var fun = currentDoc._deleted ? '_removeLocal' : '_putLocal';\n      api[fun](currentDoc, {ctx: tx}, function (err, res) {\n        results[resultsIdx] = err || res;\n        checkAllDocsDone();\n      });\n      return;\n    }\n\n    var id = currentDoc.metadata.id;\n    if (idsToDocs.has(id)) {\n      docsToDo--; // duplicate\n      idsToDocs.get(id).push([currentDoc, resultsIdx]);\n    } else {\n      idsToDocs.set(id, [[currentDoc, resultsIdx]]);\n    }\n  });\n\n  // in the case of new_edits, the user can provide multiple docs\n  // with the same id. these need to be processed sequentially\n  idsToDocs.forEach(function (docs, id) {\n    var numDone = 0;\n\n    function docWritten() {\n      if (++numDone < docs.length) {\n        nextDoc();\n      } else {\n        checkAllDocsDone();\n      }\n    }\n    function nextDoc() {\n      var value = docs[numDone];\n      var currentDoc = value[0];\n      var resultsIdx = value[1];\n\n      if (fetchedDocs.has(id)) {\n        updateDoc(revLimit, fetchedDocs.get(id), currentDoc, results,\n          resultsIdx, docWritten, writeDoc, newEdits);\n      } else {\n        // Ensure stemming applies to new writes as well\n        var merged = merge([], currentDoc.metadata.rev_tree[0], revLimit);\n        currentDoc.metadata.rev_tree = merged.tree;\n        currentDoc.stemmedRevs = merged.stemmedRevs || [];\n        insertDoc(currentDoc, resultsIdx, docWritten);\n      }\n    }\n    nextDoc();\n  });\n}\n\n// IndexedDB requires a versioned database structure, so we use the\n// version here to manage migrations.\nvar ADAPTER_VERSION = 5;\n\n// The object stores created for each database\n// DOC_STORE stores the document meta data, its revision history and state\n// Keyed by document id\nvar DOC_STORE = 'document-store';\n// BY_SEQ_STORE stores a particular version of a document, keyed by its\n// sequence id\nvar BY_SEQ_STORE = 'by-sequence';\n// Where we store attachments\nvar ATTACH_STORE = 'attach-store';\n// Where we store many-to-many relations\n// between attachment digests and seqs\nvar ATTACH_AND_SEQ_STORE = 'attach-seq-store';\n\n// Where we store database-wide meta data in a single record\n// keyed by id: META_STORE\nvar META_STORE = 'meta-store';\n// Where we store local documents\nvar LOCAL_STORE = 'local-store';\n// Where we detect blob support\nvar DETECT_BLOB_SUPPORT_STORE = 'detect-blob-support';\n\nfunction safeJsonParse(str) {\n  // This try/catch guards against stack overflow errors.\n  // JSON.parse() is faster than vuvuzela.parse() but vuvuzela\n  // cannot overflow.\n  try {\n    return JSON.parse(str);\n  } catch (e) {\n    /* istanbul ignore next */\n    return vuvuzela.parse(str);\n  }\n}\n\nfunction safeJsonStringify(json) {\n  try {\n    return JSON.stringify(json);\n  } catch (e) {\n    /* istanbul ignore next */\n    return vuvuzela.stringify(json);\n  }\n}\n\nfunction idbError(callback) {\n  return function (evt) {\n    var message = 'unknown_error';\n    if (evt.target && evt.target.error) {\n      message = evt.target.error.name || evt.target.error.message;\n    }\n    callback(createError(IDB_ERROR, message, evt.type));\n  };\n}\n\n// Unfortunately, the metadata has to be stringified\n// when it is put into the database, because otherwise\n// IndexedDB can throw errors for deeply-nested objects.\n// Originally we just used JSON.parse/JSON.stringify; now\n// we use this custom vuvuzela library that avoids recursion.\n// If we could do it all over again, we'd probably use a\n// format for the revision trees other than JSON.\nfunction encodeMetadata(metadata, winningRev, deleted) {\n  return {\n    data: safeJsonStringify(metadata),\n    winningRev: winningRev,\n    deletedOrLocal: deleted ? '1' : '0',\n    seq: metadata.seq, // highest seq for this doc\n    id: metadata.id\n  };\n}\n\nfunction decodeMetadata(storedObject) {\n  if (!storedObject) {\n    return null;\n  }\n  var metadata = safeJsonParse(storedObject.data);\n  metadata.winningRev = storedObject.winningRev;\n  metadata.deleted = storedObject.deletedOrLocal === '1';\n  metadata.seq = storedObject.seq;\n  return metadata;\n}\n\n// read the doc back out from the database. we don't store the\n// _id or _rev because we already have _doc_id_rev.\nfunction decodeDoc(doc) {\n  if (!doc) {\n    return doc;\n  }\n  var idx = doc._doc_id_rev.lastIndexOf(':');\n  doc._id = doc._doc_id_rev.substring(0, idx - 1);\n  doc._rev = doc._doc_id_rev.substring(idx + 1);\n  delete doc._doc_id_rev;\n  return doc;\n}\n\n// Read a blob from the database, encoding as necessary\n// and translating from base64 if the IDB doesn't support\n// native Blobs\nfunction readBlobData(body, type, asBlob, callback) {\n  if (asBlob) {\n    if (!body) {\n      callback(createBlob([''], {type: type}));\n    } else if (typeof body !== 'string') { // we have blob support\n      callback(body);\n    } else { // no blob support\n      callback(b64ToBluffer(body, type));\n    }\n  } else { // as base64 string\n    if (!body) {\n      callback('');\n    } else if (typeof body !== 'string') { // we have blob support\n      readAsBinaryString(body, function (binary) {\n        callback(thisBtoa(binary));\n      });\n    } else { // no blob support\n      callback(body);\n    }\n  }\n}\n\nfunction fetchAttachmentsIfNecessary(doc, opts, txn, cb) {\n  var attachments = Object.keys(doc._attachments || {});\n  if (!attachments.length) {\n    return cb && cb();\n  }\n  var numDone = 0;\n\n  function checkDone() {\n    if (++numDone === attachments.length && cb) {\n      cb();\n    }\n  }\n\n  function fetchAttachment(doc, att) {\n    var attObj = doc._attachments[att];\n    var digest = attObj.digest;\n    var req = txn.objectStore(ATTACH_STORE).get(digest);\n    req.onsuccess = function (e) {\n      attObj.body = e.target.result.body;\n      checkDone();\n    };\n  }\n\n  attachments.forEach(function (att) {\n    if (opts.attachments && opts.include_docs) {\n      fetchAttachment(doc, att);\n    } else {\n      doc._attachments[att].stub = true;\n      checkDone();\n    }\n  });\n}\n\n// IDB-specific postprocessing necessary because\n// we don't know whether we stored a true Blob or\n// a base64-encoded string, and if it's a Blob it\n// needs to be read outside of the transaction context\nfunction postProcessAttachments(results, asBlob) {\n  return Promise.all(results.map(function (row) {\n    if (row.doc && row.doc._attachments) {\n      var attNames = Object.keys(row.doc._attachments);\n      return Promise.all(attNames.map(function (att) {\n        var attObj = row.doc._attachments[att];\n        if (!('body' in attObj)) { // already processed\n          return;\n        }\n        var body = attObj.body;\n        var type = attObj.content_type;\n        return new Promise(function (resolve) {\n          readBlobData(body, type, asBlob, function (data) {\n            row.doc._attachments[att] = $inject_Object_assign(\n              pick(attObj, ['digest', 'content_type']),\n              {data: data}\n            );\n            resolve();\n          });\n        });\n      }));\n    }\n  }));\n}\n\nfunction compactRevs(revs, docId, txn) {\n\n  var possiblyOrphanedDigests = [];\n  var seqStore = txn.objectStore(BY_SEQ_STORE);\n  var attStore = txn.objectStore(ATTACH_STORE);\n  var attAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n  var count = revs.length;\n\n  function checkDone() {\n    count--;\n    if (!count) { // done processing all revs\n      deleteOrphanedAttachments();\n    }\n  }\n\n  function deleteOrphanedAttachments() {\n    if (!possiblyOrphanedDigests.length) {\n      return;\n    }\n    possiblyOrphanedDigests.forEach(function (digest) {\n      var countReq = attAndSeqStore.index('digestSeq').count(\n        IDBKeyRange.bound(\n          digest + '::', digest + '::\\uffff', false, false));\n      countReq.onsuccess = function (e) {\n        var count = e.target.result;\n        if (!count) {\n          // orphaned\n          attStore.delete(digest);\n        }\n      };\n    });\n  }\n\n  revs.forEach(function (rev$$1) {\n    var index = seqStore.index('_doc_id_rev');\n    var key = docId + \"::\" + rev$$1;\n    index.getKey(key).onsuccess = function (e) {\n      var seq = e.target.result;\n      if (typeof seq !== 'number') {\n        return checkDone();\n      }\n      seqStore.delete(seq);\n\n      var cursor = attAndSeqStore.index('seq')\n        .openCursor(IDBKeyRange.only(seq));\n\n      cursor.onsuccess = function (event) {\n        var cursor = event.target.result;\n        if (cursor) {\n          var digest = cursor.value.digestSeq.split('::')[0];\n          possiblyOrphanedDigests.push(digest);\n          attAndSeqStore.delete(cursor.primaryKey);\n          cursor.continue();\n        } else { // done\n          checkDone();\n        }\n      };\n    };\n  });\n}\n\nfunction openTransactionSafely(idb, stores, mode) {\n  try {\n    return {\n      txn: idb.transaction(stores, mode)\n    };\n  } catch (err) {\n    return {\n      error: err\n    };\n  }\n}\n\nvar changesHandler = new Changes();\n\nfunction idbBulkDocs(dbOpts, req, opts, api, idb, callback) {\n  var docInfos = req.docs;\n  var txn;\n  var docStore;\n  var bySeqStore;\n  var attachStore;\n  var attachAndSeqStore;\n  var metaStore;\n  var docInfoError;\n  var metaDoc;\n\n  for (var i = 0, len = docInfos.length; i < len; i++) {\n    var doc = docInfos[i];\n    if (doc._id && isLocalId(doc._id)) {\n      continue;\n    }\n    doc = docInfos[i] = parseDoc(doc, opts.new_edits, dbOpts);\n    if (doc.error && !docInfoError) {\n      docInfoError = doc;\n    }\n  }\n\n  if (docInfoError) {\n    return callback(docInfoError);\n  }\n\n  var allDocsProcessed = false;\n  var docCountDelta = 0;\n  var results = new Array(docInfos.length);\n  var fetchedDocs = new ExportedMap();\n  var preconditionErrored = false;\n  var blobType = api._meta.blobSupport ? 'blob' : 'base64';\n\n  preprocessAttachments(docInfos, blobType, function (err) {\n    if (err) {\n      return callback(err);\n    }\n    startTransaction();\n  });\n\n  function startTransaction() {\n\n    var stores = [\n      DOC_STORE, BY_SEQ_STORE,\n      ATTACH_STORE,\n      LOCAL_STORE, ATTACH_AND_SEQ_STORE,\n      META_STORE\n    ];\n    var txnResult = openTransactionSafely(idb, stores, 'readwrite');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    txn = txnResult.txn;\n    txn.onabort = idbError(callback);\n    txn.ontimeout = idbError(callback);\n    txn.oncomplete = complete;\n    docStore = txn.objectStore(DOC_STORE);\n    bySeqStore = txn.objectStore(BY_SEQ_STORE);\n    attachStore = txn.objectStore(ATTACH_STORE);\n    attachAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n    metaStore = txn.objectStore(META_STORE);\n\n    metaStore.get(META_STORE).onsuccess = function (e) {\n      metaDoc = e.target.result;\n      updateDocCountIfReady();\n    };\n\n    verifyAttachments(function (err) {\n      if (err) {\n        preconditionErrored = true;\n        return callback(err);\n      }\n      fetchExistingDocs();\n    });\n  }\n\n  function onAllDocsProcessed() {\n    allDocsProcessed = true;\n    updateDocCountIfReady();\n  }\n\n  function idbProcessDocs() {\n    processDocs(dbOpts.revs_limit, docInfos, api, fetchedDocs,\n                txn, results, writeDoc, opts, onAllDocsProcessed);\n  }\n\n  function updateDocCountIfReady() {\n    if (!metaDoc || !allDocsProcessed) {\n      return;\n    }\n    // caching the docCount saves a lot of time in allDocs() and\n    // info(), which is why we go to all the trouble of doing this\n    metaDoc.docCount += docCountDelta;\n    metaStore.put(metaDoc);\n  }\n\n  function fetchExistingDocs() {\n\n    if (!docInfos.length) {\n      return;\n    }\n\n    var numFetched = 0;\n\n    function checkDone() {\n      if (++numFetched === docInfos.length) {\n        idbProcessDocs();\n      }\n    }\n\n    function readMetadata(event) {\n      var metadata = decodeMetadata(event.target.result);\n\n      if (metadata) {\n        fetchedDocs.set(metadata.id, metadata);\n      }\n      checkDone();\n    }\n\n    for (var i = 0, len = docInfos.length; i < len; i++) {\n      var docInfo = docInfos[i];\n      if (docInfo._id && isLocalId(docInfo._id)) {\n        checkDone(); // skip local docs\n        continue;\n      }\n      var req = docStore.get(docInfo.metadata.id);\n      req.onsuccess = readMetadata;\n    }\n  }\n\n  function complete() {\n    if (preconditionErrored) {\n      return;\n    }\n\n    changesHandler.notify(api._meta.name);\n    callback(null, results);\n  }\n\n  function verifyAttachment(digest, callback) {\n\n    var req = attachStore.get(digest);\n    req.onsuccess = function (e) {\n      if (!e.target.result) {\n        var err = createError(MISSING_STUB,\n          'unknown stub attachment with digest ' +\n          digest);\n        err.status = 412;\n        callback(err);\n      } else {\n        callback();\n      }\n    };\n  }\n\n  function verifyAttachments(finish) {\n\n\n    var digests = [];\n    docInfos.forEach(function (docInfo) {\n      if (docInfo.data && docInfo.data._attachments) {\n        Object.keys(docInfo.data._attachments).forEach(function (filename) {\n          var att = docInfo.data._attachments[filename];\n          if (att.stub) {\n            digests.push(att.digest);\n          }\n        });\n      }\n    });\n    if (!digests.length) {\n      return finish();\n    }\n    var numDone = 0;\n    var err;\n\n    function checkDone() {\n      if (++numDone === digests.length) {\n        finish(err);\n      }\n    }\n    digests.forEach(function (digest) {\n      verifyAttachment(digest, function (attErr) {\n        if (attErr && !err) {\n          err = attErr;\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n                    isUpdate, delta, resultsIdx, callback) {\n\n    docInfo.metadata.winningRev = winningRev$$1;\n    docInfo.metadata.deleted = winningRevIsDeleted;\n\n    var doc = docInfo.data;\n    doc._id = docInfo.metadata.id;\n    doc._rev = docInfo.metadata.rev;\n\n    if (newRevIsDeleted) {\n      doc._deleted = true;\n    }\n\n    var hasAttachments = doc._attachments &&\n      Object.keys(doc._attachments).length;\n    if (hasAttachments) {\n      return writeAttachments(docInfo, winningRev$$1, winningRevIsDeleted,\n        isUpdate, resultsIdx, callback);\n    }\n\n    docCountDelta += delta;\n    updateDocCountIfReady();\n\n    finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n      isUpdate, resultsIdx, callback);\n  }\n\n  function finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n                     isUpdate, resultsIdx, callback) {\n\n    var doc = docInfo.data;\n    var metadata = docInfo.metadata;\n\n    doc._doc_id_rev = metadata.id + '::' + metadata.rev;\n    delete doc._id;\n    delete doc._rev;\n\n    function afterPutDoc(e) {\n      var revsToDelete = docInfo.stemmedRevs || [];\n\n      if (isUpdate && api.auto_compaction) {\n        revsToDelete = revsToDelete.concat(compactTree(docInfo.metadata));\n      }\n\n      if (revsToDelete && revsToDelete.length) {\n        compactRevs(revsToDelete, docInfo.metadata.id, txn);\n      }\n\n      metadata.seq = e.target.result;\n      // Current _rev is calculated from _rev_tree on read\n      // delete metadata.rev;\n      var metadataToStore = encodeMetadata(metadata, winningRev$$1,\n        winningRevIsDeleted);\n      var metaDataReq = docStore.put(metadataToStore);\n      metaDataReq.onsuccess = afterPutMetadata;\n    }\n\n    function afterPutDocError(e) {\n      // ConstraintError, need to update, not put (see #1638 for details)\n      e.preventDefault(); // avoid transaction abort\n      e.stopPropagation(); // avoid transaction onerror\n      var index = bySeqStore.index('_doc_id_rev');\n      var getKeyReq = index.getKey(doc._doc_id_rev);\n      getKeyReq.onsuccess = function (e) {\n        var putReq = bySeqStore.put(doc, e.target.result);\n        putReq.onsuccess = afterPutDoc;\n      };\n    }\n\n    function afterPutMetadata() {\n      results[resultsIdx] = {\n        ok: true,\n        id: metadata.id,\n        rev: metadata.rev\n      };\n      fetchedDocs.set(docInfo.metadata.id, docInfo.metadata);\n      insertAttachmentMappings(docInfo, metadata.seq, callback);\n    }\n\n    var putReq = bySeqStore.put(doc);\n\n    putReq.onsuccess = afterPutDoc;\n    putReq.onerror = afterPutDocError;\n  }\n\n  function writeAttachments(docInfo, winningRev$$1, winningRevIsDeleted,\n                            isUpdate, resultsIdx, callback) {\n\n\n    var doc = docInfo.data;\n\n    var numDone = 0;\n    var attachments = Object.keys(doc._attachments);\n\n    function collectResults() {\n      if (numDone === attachments.length) {\n        finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n          isUpdate, resultsIdx, callback);\n      }\n    }\n\n    function attachmentSaved() {\n      numDone++;\n      collectResults();\n    }\n\n    attachments.forEach(function (key) {\n      var att = docInfo.data._attachments[key];\n      if (!att.stub) {\n        var data = att.data;\n        delete att.data;\n        att.revpos = parseInt(winningRev$$1, 10);\n        var digest = att.digest;\n        saveAttachment(digest, data, attachmentSaved);\n      } else {\n        numDone++;\n        collectResults();\n      }\n    });\n  }\n\n  // map seqs to attachment digests, which\n  // we will need later during compaction\n  function insertAttachmentMappings(docInfo, seq, callback) {\n\n    var attsAdded = 0;\n    var attsToAdd = Object.keys(docInfo.data._attachments || {});\n\n    if (!attsToAdd.length) {\n      return callback();\n    }\n\n    function checkDone() {\n      if (++attsAdded === attsToAdd.length) {\n        callback();\n      }\n    }\n\n    function add(att) {\n      var digest = docInfo.data._attachments[att].digest;\n      var req = attachAndSeqStore.put({\n        seq: seq,\n        digestSeq: digest + '::' + seq\n      });\n\n      req.onsuccess = checkDone;\n      req.onerror = function (e) {\n        // this callback is for a constaint error, which we ignore\n        // because this docid/rev has already been associated with\n        // the digest (e.g. when new_edits == false)\n        e.preventDefault(); // avoid transaction abort\n        e.stopPropagation(); // avoid transaction onerror\n        checkDone();\n      };\n    }\n    for (var i = 0; i < attsToAdd.length; i++) {\n      add(attsToAdd[i]); // do in parallel\n    }\n  }\n\n  function saveAttachment(digest, data, callback) {\n\n\n    var getKeyReq = attachStore.count(digest);\n    getKeyReq.onsuccess = function (e) {\n      var count = e.target.result;\n      if (count) {\n        return callback(); // already exists\n      }\n      var newAtt = {\n        digest: digest,\n        body: data\n      };\n      var putReq = attachStore.put(newAtt);\n      putReq.onsuccess = callback;\n    };\n  }\n}\n\n// Abstraction over IDBCursor and getAll()/getAllKeys() that allows us to batch our operations\n// while falling back to a normal IDBCursor operation on browsers that don't support getAll() or\n// getAllKeys(). This allows for a much faster implementation than just straight-up cursors, because\n// we're not processing each document one-at-a-time.\nfunction runBatchedCursor(objectStore, keyRange, descending, batchSize, onBatch) {\n\n  if (batchSize === -1) {\n    batchSize = 1000;\n  }\n\n  // Bail out of getAll()/getAllKeys() in the following cases:\n  // 1) either method is unsupported - we need both\n  // 2) batchSize is 1 (might as well use IDBCursor)\n  // 3) descending – no real way to do this via getAll()/getAllKeys()\n\n  var useGetAll = typeof objectStore.getAll === 'function' &&\n    typeof objectStore.getAllKeys === 'function' &&\n    batchSize > 1 && !descending;\n\n  var keysBatch;\n  var valuesBatch;\n  var pseudoCursor;\n\n  function onGetAll(e) {\n    valuesBatch = e.target.result;\n    if (keysBatch) {\n      onBatch(keysBatch, valuesBatch, pseudoCursor);\n    }\n  }\n\n  function onGetAllKeys(e) {\n    keysBatch = e.target.result;\n    if (valuesBatch) {\n      onBatch(keysBatch, valuesBatch, pseudoCursor);\n    }\n  }\n\n  function continuePseudoCursor() {\n    if (!keysBatch.length) { // no more results\n      return onBatch();\n    }\n    // fetch next batch, exclusive start\n    var lastKey = keysBatch[keysBatch.length - 1];\n    var newKeyRange;\n    if (keyRange && keyRange.upper) {\n      try {\n        newKeyRange = IDBKeyRange.bound(lastKey, keyRange.upper,\n          true, keyRange.upperOpen);\n      } catch (e) {\n        if (e.name === \"DataError\" && e.code === 0) {\n          return onBatch(); // we're done, startkey and endkey are equal\n        }\n      }\n    } else {\n      newKeyRange = IDBKeyRange.lowerBound(lastKey, true);\n    }\n    keyRange = newKeyRange;\n    keysBatch = null;\n    valuesBatch = null;\n    objectStore.getAll(keyRange, batchSize).onsuccess = onGetAll;\n    objectStore.getAllKeys(keyRange, batchSize).onsuccess = onGetAllKeys;\n  }\n\n  function onCursor(e) {\n    var cursor = e.target.result;\n    if (!cursor) { // done\n      return onBatch();\n    }\n    // regular IDBCursor acts like a batch where batch size is always 1\n    onBatch([cursor.key], [cursor.value], cursor);\n  }\n\n  if (useGetAll) {\n    pseudoCursor = {\"continue\": continuePseudoCursor};\n    objectStore.getAll(keyRange, batchSize).onsuccess = onGetAll;\n    objectStore.getAllKeys(keyRange, batchSize).onsuccess = onGetAllKeys;\n  } else if (descending) {\n    objectStore.openCursor(keyRange, 'prev').onsuccess = onCursor;\n  } else {\n    objectStore.openCursor(keyRange).onsuccess = onCursor;\n  }\n}\n\n// simple shim for objectStore.getAll(), falling back to IDBCursor\nfunction getAll(objectStore, keyRange, onSuccess) {\n  if (typeof objectStore.getAll === 'function') {\n    // use native getAll\n    objectStore.getAll(keyRange).onsuccess = onSuccess;\n    return;\n  }\n  // fall back to cursors\n  var values = [];\n\n  function onCursor(e) {\n    var cursor = e.target.result;\n    if (cursor) {\n      values.push(cursor.value);\n      cursor.continue();\n    } else {\n      onSuccess({\n        target: {\n          result: values\n        }\n      });\n    }\n  }\n\n  objectStore.openCursor(keyRange).onsuccess = onCursor;\n}\n\nfunction allDocsKeys(keys, docStore, onBatch) {\n  // It's not guaranted to be returned in right order  \n  var valuesBatch = new Array(keys.length);\n  var count = 0;\n  keys.forEach(function (key, index) {\n    docStore.get(key).onsuccess = function (event) {\n      if (event.target.result) {\n        valuesBatch[index] = event.target.result;\n      } else {\n        valuesBatch[index] = {key: key, error: 'not_found'};\n      }\n      count++;\n      if (count === keys.length) {\n        onBatch(keys, valuesBatch, {});\n      }\n    };\n  });\n}\n\nfunction createKeyRange(start, end, inclusiveEnd, key, descending) {\n  try {\n    if (start && end) {\n      if (descending) {\n        return IDBKeyRange.bound(end, start, !inclusiveEnd, false);\n      } else {\n        return IDBKeyRange.bound(start, end, false, !inclusiveEnd);\n      }\n    } else if (start) {\n      if (descending) {\n        return IDBKeyRange.upperBound(start);\n      } else {\n        return IDBKeyRange.lowerBound(start);\n      }\n    } else if (end) {\n      if (descending) {\n        return IDBKeyRange.lowerBound(end, !inclusiveEnd);\n      } else {\n        return IDBKeyRange.upperBound(end, !inclusiveEnd);\n      }\n    } else if (key) {\n      return IDBKeyRange.only(key);\n    }\n  } catch (e) {\n    return {error: e};\n  }\n  return null;\n}\n\nfunction idbAllDocs(opts, idb, callback) {\n  var start = 'startkey' in opts ? opts.startkey : false;\n  var end = 'endkey' in opts ? opts.endkey : false;\n  var key = 'key' in opts ? opts.key : false;\n  var keys = 'keys' in opts ? opts.keys : false; \n  var skip = opts.skip || 0;\n  var limit = typeof opts.limit === 'number' ? opts.limit : -1;\n  var inclusiveEnd = opts.inclusive_end !== false;\n\n  var keyRange ; \n  var keyRangeError;\n  if (!keys) {\n    keyRange = createKeyRange(start, end, inclusiveEnd, key, opts.descending);\n    keyRangeError = keyRange && keyRange.error;\n    if (keyRangeError && \n      !(keyRangeError.name === \"DataError\" && keyRangeError.code === 0)) {\n      // DataError with error code 0 indicates start is less than end, so\n      // can just do an empty query. Else need to throw\n      return callback(createError(IDB_ERROR,\n        keyRangeError.name, keyRangeError.message));\n    }\n  }\n\n  var stores = [DOC_STORE, BY_SEQ_STORE, META_STORE];\n\n  if (opts.attachments) {\n    stores.push(ATTACH_STORE);\n  }\n  var txnResult = openTransactionSafely(idb, stores, 'readonly');\n  if (txnResult.error) {\n    return callback(txnResult.error);\n  }\n  var txn = txnResult.txn;\n  txn.oncomplete = onTxnComplete;\n  txn.onabort = idbError(callback);\n  var docStore = txn.objectStore(DOC_STORE);\n  var seqStore = txn.objectStore(BY_SEQ_STORE);\n  var metaStore = txn.objectStore(META_STORE);\n  var docIdRevIndex = seqStore.index('_doc_id_rev');\n  var results = [];\n  var docCount;\n  var updateSeq;\n\n  metaStore.get(META_STORE).onsuccess = function (e) {\n    docCount = e.target.result.docCount;\n  };\n\n  /* istanbul ignore if */\n  if (opts.update_seq) {\n    getMaxUpdateSeq(seqStore, function (e) { \n      if (e.target.result && e.target.result.length > 0) {\n        updateSeq = e.target.result[0];\n      }\n    });\n  }\n\n  function getMaxUpdateSeq(objectStore, onSuccess) {\n    function onCursor(e) {\n      var cursor = e.target.result;\n      var maxKey = undefined;\n      if (cursor && cursor.key) {\n        maxKey = cursor.key;\n      } \n      return onSuccess({\n        target: {\n          result: [maxKey]\n        }\n      });\n    }\n    objectStore.openCursor(null, 'prev').onsuccess = onCursor;\n  }\n\n  // if the user specifies include_docs=true, then we don't\n  // want to block the main cursor while we're fetching the doc\n  function fetchDocAsynchronously(metadata, row, winningRev$$1) {\n    var key = metadata.id + \"::\" + winningRev$$1;\n    docIdRevIndex.get(key).onsuccess =  function onGetDoc(e) {\n      row.doc = decodeDoc(e.target.result) || {};\n      if (opts.conflicts) {\n        var conflicts = collectConflicts(metadata);\n        if (conflicts.length) {\n          row.doc._conflicts = conflicts;\n        }\n      }\n      fetchAttachmentsIfNecessary(row.doc, opts, txn);\n    };\n  }\n\n  function allDocsInner(winningRev$$1, metadata) {\n    var row = {\n      id: metadata.id,\n      key: metadata.id,\n      value: {\n        rev: winningRev$$1\n      }\n    };\n    var deleted = metadata.deleted;\n    if (deleted) {\n      if (keys) {\n        results.push(row);\n        // deleted docs are okay with \"keys\" requests\n        row.value.deleted = true;\n        row.doc = null;\n      }\n    } else if (skip-- <= 0) {\n      results.push(row);\n      if (opts.include_docs) {\n        fetchDocAsynchronously(metadata, row, winningRev$$1);\n      }\n    }\n  }\n\n  function processBatch(batchValues) {\n    for (var i = 0, len = batchValues.length; i < len; i++) {\n      if (results.length === limit) {\n        break;\n      }\n      var batchValue = batchValues[i];\n      if (batchValue.error && keys) {\n        // key was not found with \"keys\" requests\n        results.push(batchValue);\n        continue;\n      }\n      var metadata = decodeMetadata(batchValue);\n      var winningRev$$1 = metadata.winningRev;\n      allDocsInner(winningRev$$1, metadata);\n    }\n  }\n\n  function onBatch(batchKeys, batchValues, cursor) {\n    if (!cursor) {\n      return;\n    }\n    processBatch(batchValues);\n    if (results.length < limit) {\n      cursor.continue();\n    }\n  }\n\n  function onGetAll(e) {\n    var values = e.target.result;\n    if (opts.descending) {\n      values = values.reverse();\n    }\n    processBatch(values);\n  }\n\n  function onResultsReady() {\n    var returnVal = {\n      total_rows: docCount,\n      offset: opts.skip,\n      rows: results\n    };\n    \n    /* istanbul ignore if */\n    if (opts.update_seq && updateSeq !== undefined) {\n      returnVal.update_seq = updateSeq;\n    }\n    callback(null, returnVal);\n  }\n\n  function onTxnComplete() {\n    if (opts.attachments) {\n      postProcessAttachments(results, opts.binary).then(onResultsReady);\n    } else {\n      onResultsReady();\n    }\n  }\n\n  // don't bother doing any requests if start > end or limit === 0\n  if (keyRangeError || limit === 0) {\n    return;\n  }\n  if (keys) {\n    return allDocsKeys(opts.keys, docStore, onBatch);\n  }\n  if (limit === -1) { // just fetch everything\n    return getAll(docStore, keyRange, onGetAll);\n  }\n  // else do a cursor\n  // choose a batch size based on the skip, since we'll need to skip that many\n  runBatchedCursor(docStore, keyRange, opts.descending, limit + skip, onBatch);\n}\n\n//\n// Blobs are not supported in all versions of IndexedDB, notably\n// Chrome <37 and Android <5. In those versions, storing a blob will throw.\n//\n// Various other blob bugs exist in Chrome v37-42 (inclusive).\n// Detecting them is expensive and confusing to users, and Chrome 37-42\n// is at very low usage worldwide, so we do a hacky userAgent check instead.\n//\n// content-type bug: https://code.google.com/p/chromium/issues/detail?id=408120\n// 404 bug: https://code.google.com/p/chromium/issues/detail?id=447916\n// FileReader bug: https://code.google.com/p/chromium/issues/detail?id=447836\n//\nfunction checkBlobSupport(txn) {\n  return new Promise(function (resolve) {\n    var blob$$1 = createBlob(['']);\n    var req = txn.objectStore(DETECT_BLOB_SUPPORT_STORE).put(blob$$1, 'key');\n\n    req.onsuccess = function () {\n      var matchedChrome = navigator.userAgent.match(/Chrome\\/(\\d+)/);\n      var matchedEdge = navigator.userAgent.match(/Edge\\//);\n      // MS Edge pretends to be Chrome 42:\n      // https://msdn.microsoft.com/en-us/library/hh869301%28v=vs.85%29.aspx\n      resolve(matchedEdge || !matchedChrome ||\n        parseInt(matchedChrome[1], 10) >= 43);\n    };\n\n    req.onerror = txn.onabort = function (e) {\n      // If the transaction aborts now its due to not being able to\n      // write to the database, likely due to the disk being full\n      e.preventDefault();\n      e.stopPropagation();\n      resolve(false);\n    };\n  }).catch(function () {\n    return false; // error, so assume unsupported\n  });\n}\n\nfunction countDocs(txn, cb) {\n  var index = txn.objectStore(DOC_STORE).index('deletedOrLocal');\n  index.count(IDBKeyRange.only('0')).onsuccess = function (e) {\n    cb(e.target.result);\n  };\n}\n\n// This task queue ensures that IDB open calls are done in their own tick\n\nvar running = false;\nvar queue = [];\n\nfunction tryCode(fun, err, res, PouchDB) {\n  try {\n    fun(err, res);\n  } catch (err) {\n    // Shouldn't happen, but in some odd cases\n    // IndexedDB implementations might throw a sync\n    // error, in which case this will at least log it.\n    PouchDB.emit('error', err);\n  }\n}\n\nfunction applyNext() {\n  if (running || !queue.length) {\n    return;\n  }\n  running = true;\n  queue.shift()();\n}\n\nfunction enqueueTask(action, callback, PouchDB) {\n  queue.push(function runAction() {\n    action(function runCallback(err, res) {\n      tryCode(callback, err, res, PouchDB);\n      running = false;\n      immediate(function runNext() {\n        applyNext(PouchDB);\n      });\n    });\n  });\n  applyNext();\n}\n\nfunction changes(opts, api, dbName, idb) {\n  opts = clone(opts);\n\n  if (opts.continuous) {\n    var id = dbName + ':' + uuid();\n    changesHandler.addListener(dbName, id, api, opts);\n    changesHandler.notify(dbName);\n    return {\n      cancel: function () {\n        changesHandler.removeListener(dbName, id);\n      }\n    };\n  }\n\n  var docIds = opts.doc_ids && new ExportedSet(opts.doc_ids);\n\n  opts.since = opts.since || 0;\n  var lastSeq = opts.since;\n\n  var limit = 'limit' in opts ? opts.limit : -1;\n  if (limit === 0) {\n    limit = 1; // per CouchDB _changes spec\n  }\n\n  var results = [];\n  var numResults = 0;\n  var filter = filterChange(opts);\n  var docIdsToMetadata = new ExportedMap();\n\n  var txn;\n  var bySeqStore;\n  var docStore;\n  var docIdRevIndex;\n\n  function onBatch(batchKeys, batchValues, cursor) {\n    if (!cursor || !batchKeys.length) { // done\n      return;\n    }\n\n    var winningDocs = new Array(batchKeys.length);\n    var metadatas = new Array(batchKeys.length);\n\n    function processMetadataAndWinningDoc(metadata, winningDoc) {\n      var change = opts.processChange(winningDoc, metadata, opts);\n      lastSeq = change.seq = metadata.seq;\n\n      var filtered = filter(change);\n      if (typeof filtered === 'object') { // anything but true/false indicates error\n        return Promise.reject(filtered);\n      }\n\n      if (!filtered) {\n        return Promise.resolve();\n      }\n      numResults++;\n      if (opts.return_docs) {\n        results.push(change);\n      }\n      // process the attachment immediately\n      // for the benefit of live listeners\n      if (opts.attachments && opts.include_docs) {\n        return new Promise(function (resolve) {\n          fetchAttachmentsIfNecessary(winningDoc, opts, txn, function () {\n            postProcessAttachments([change], opts.binary).then(function () {\n              resolve(change);\n            });\n          });\n        });\n      } else {\n        return Promise.resolve(change);\n      }\n    }\n\n    function onBatchDone() {\n      var promises = [];\n      for (var i = 0, len = winningDocs.length; i < len; i++) {\n        if (numResults === limit) {\n          break;\n        }\n        var winningDoc = winningDocs[i];\n        if (!winningDoc) {\n          continue;\n        }\n        var metadata = metadatas[i];\n        promises.push(processMetadataAndWinningDoc(metadata, winningDoc));\n      }\n\n      Promise.all(promises).then(function (changes) {\n        for (var i = 0, len = changes.length; i < len; i++) {\n          if (changes[i]) {\n            opts.onChange(changes[i]);\n          }\n        }\n      }).catch(opts.complete);\n\n      if (numResults !== limit) {\n        cursor.continue();\n      }\n    }\n\n    // Fetch all metadatas/winningdocs from this batch in parallel, then process\n    // them all only once all data has been collected. This is done in parallel\n    // because it's faster than doing it one-at-a-time.\n    var numDone = 0;\n    batchValues.forEach(function (value, i) {\n      var doc = decodeDoc(value);\n      var seq = batchKeys[i];\n      fetchWinningDocAndMetadata(doc, seq, function (metadata, winningDoc) {\n        metadatas[i] = metadata;\n        winningDocs[i] = winningDoc;\n        if (++numDone === batchKeys.length) {\n          onBatchDone();\n        }\n      });\n    });\n  }\n\n  function onGetMetadata(doc, seq, metadata, cb) {\n    if (metadata.seq !== seq) {\n      // some other seq is later\n      return cb();\n    }\n\n    if (metadata.winningRev === doc._rev) {\n      // this is the winning doc\n      return cb(metadata, doc);\n    }\n\n    // fetch winning doc in separate request\n    var docIdRev = doc._id + '::' + metadata.winningRev;\n    var req = docIdRevIndex.get(docIdRev);\n    req.onsuccess = function (e) {\n      cb(metadata, decodeDoc(e.target.result));\n    };\n  }\n\n  function fetchWinningDocAndMetadata(doc, seq, cb) {\n    if (docIds && !docIds.has(doc._id)) {\n      return cb();\n    }\n\n    var metadata = docIdsToMetadata.get(doc._id);\n    if (metadata) { // cached\n      return onGetMetadata(doc, seq, metadata, cb);\n    }\n    // metadata not cached, have to go fetch it\n    docStore.get(doc._id).onsuccess = function (e) {\n      metadata = decodeMetadata(e.target.result);\n      docIdsToMetadata.set(doc._id, metadata);\n      onGetMetadata(doc, seq, metadata, cb);\n    };\n  }\n\n  function finish() {\n    opts.complete(null, {\n      results: results,\n      last_seq: lastSeq\n    });\n  }\n\n  function onTxnComplete() {\n    if (!opts.continuous && opts.attachments) {\n      // cannot guarantee that postProcessing was already done,\n      // so do it again\n      postProcessAttachments(results).then(finish);\n    } else {\n      finish();\n    }\n  }\n\n  var objectStores = [DOC_STORE, BY_SEQ_STORE];\n  if (opts.attachments) {\n    objectStores.push(ATTACH_STORE);\n  }\n  var txnResult = openTransactionSafely(idb, objectStores, 'readonly');\n  if (txnResult.error) {\n    return opts.complete(txnResult.error);\n  }\n  txn = txnResult.txn;\n  txn.onabort = idbError(opts.complete);\n  txn.oncomplete = onTxnComplete;\n\n  bySeqStore = txn.objectStore(BY_SEQ_STORE);\n  docStore = txn.objectStore(DOC_STORE);\n  docIdRevIndex = bySeqStore.index('_doc_id_rev');\n\n  var keyRange = (opts.since && !opts.descending) ?\n    IDBKeyRange.lowerBound(opts.since, true) : null;\n\n  runBatchedCursor(bySeqStore, keyRange, opts.descending, limit, onBatch);\n}\n\nvar cachedDBs = new ExportedMap();\nvar blobSupportPromise;\nvar openReqList = new ExportedMap();\n\nfunction IdbPouch(opts, callback) {\n  var api = this;\n\n  enqueueTask(function (thisCallback) {\n    init(api, opts, thisCallback);\n  }, callback, api.constructor);\n}\n\nfunction init(api, opts, callback) {\n\n  var dbName = opts.name;\n\n  var idb = null;\n  api._meta = null;\n\n  // called when creating a fresh new database\n  function createSchema(db) {\n    var docStore = db.createObjectStore(DOC_STORE, {keyPath : 'id'});\n    db.createObjectStore(BY_SEQ_STORE, {autoIncrement: true})\n      .createIndex('_doc_id_rev', '_doc_id_rev', {unique: true});\n    db.createObjectStore(ATTACH_STORE, {keyPath: 'digest'});\n    db.createObjectStore(META_STORE, {keyPath: 'id', autoIncrement: false});\n    db.createObjectStore(DETECT_BLOB_SUPPORT_STORE);\n\n    // added in v2\n    docStore.createIndex('deletedOrLocal', 'deletedOrLocal', {unique : false});\n\n    // added in v3\n    db.createObjectStore(LOCAL_STORE, {keyPath: '_id'});\n\n    // added in v4\n    var attAndSeqStore = db.createObjectStore(ATTACH_AND_SEQ_STORE,\n      {autoIncrement: true});\n    attAndSeqStore.createIndex('seq', 'seq');\n    attAndSeqStore.createIndex('digestSeq', 'digestSeq', {unique: true});\n  }\n\n  // migration to version 2\n  // unfortunately \"deletedOrLocal\" is a misnomer now that we no longer\n  // store local docs in the main doc-store, but whaddyagonnado\n  function addDeletedOrLocalIndex(txn, callback) {\n    var docStore = txn.objectStore(DOC_STORE);\n    docStore.createIndex('deletedOrLocal', 'deletedOrLocal', {unique : false});\n\n    docStore.openCursor().onsuccess = function (event) {\n      var cursor = event.target.result;\n      if (cursor) {\n        var metadata = cursor.value;\n        var deleted = isDeleted(metadata);\n        metadata.deletedOrLocal = deleted ? \"1\" : \"0\";\n        docStore.put(metadata);\n        cursor.continue();\n      } else {\n        callback();\n      }\n    };\n  }\n\n  // migration to version 3 (part 1)\n  function createLocalStoreSchema(db) {\n    db.createObjectStore(LOCAL_STORE, {keyPath: '_id'})\n      .createIndex('_doc_id_rev', '_doc_id_rev', {unique: true});\n  }\n\n  // migration to version 3 (part 2)\n  function migrateLocalStore(txn, cb) {\n    var localStore = txn.objectStore(LOCAL_STORE);\n    var docStore = txn.objectStore(DOC_STORE);\n    var seqStore = txn.objectStore(BY_SEQ_STORE);\n\n    var cursor = docStore.openCursor();\n    cursor.onsuccess = function (event) {\n      var cursor = event.target.result;\n      if (cursor) {\n        var metadata = cursor.value;\n        var docId = metadata.id;\n        var local = isLocalId(docId);\n        var rev$$1 = winningRev(metadata);\n        if (local) {\n          var docIdRev = docId + \"::\" + rev$$1;\n          // remove all seq entries\n          // associated with this docId\n          var start = docId + \"::\";\n          var end = docId + \"::~\";\n          var index = seqStore.index('_doc_id_rev');\n          var range = IDBKeyRange.bound(start, end, false, false);\n          var seqCursor = index.openCursor(range);\n          seqCursor.onsuccess = function (e) {\n            seqCursor = e.target.result;\n            if (!seqCursor) {\n              // done\n              docStore.delete(cursor.primaryKey);\n              cursor.continue();\n            } else {\n              var data = seqCursor.value;\n              if (data._doc_id_rev === docIdRev) {\n                localStore.put(data);\n              }\n              seqStore.delete(seqCursor.primaryKey);\n              seqCursor.continue();\n            }\n          };\n        } else {\n          cursor.continue();\n        }\n      } else if (cb) {\n        cb();\n      }\n    };\n  }\n\n  // migration to version 4 (part 1)\n  function addAttachAndSeqStore(db) {\n    var attAndSeqStore = db.createObjectStore(ATTACH_AND_SEQ_STORE,\n      {autoIncrement: true});\n    attAndSeqStore.createIndex('seq', 'seq');\n    attAndSeqStore.createIndex('digestSeq', 'digestSeq', {unique: true});\n  }\n\n  // migration to version 4 (part 2)\n  function migrateAttsAndSeqs(txn, callback) {\n    var seqStore = txn.objectStore(BY_SEQ_STORE);\n    var attStore = txn.objectStore(ATTACH_STORE);\n    var attAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n\n    // need to actually populate the table. this is the expensive part,\n    // so as an optimization, check first that this database even\n    // contains attachments\n    var req = attStore.count();\n    req.onsuccess = function (e) {\n      var count = e.target.result;\n      if (!count) {\n        return callback(); // done\n      }\n\n      seqStore.openCursor().onsuccess = function (e) {\n        var cursor = e.target.result;\n        if (!cursor) {\n          return callback(); // done\n        }\n        var doc = cursor.value;\n        var seq = cursor.primaryKey;\n        var atts = Object.keys(doc._attachments || {});\n        var digestMap = {};\n        for (var j = 0; j < atts.length; j++) {\n          var att = doc._attachments[atts[j]];\n          digestMap[att.digest] = true; // uniq digests, just in case\n        }\n        var digests = Object.keys(digestMap);\n        for (j = 0; j < digests.length; j++) {\n          var digest = digests[j];\n          attAndSeqStore.put({\n            seq: seq,\n            digestSeq: digest + '::' + seq\n          });\n        }\n        cursor.continue();\n      };\n    };\n  }\n\n  // migration to version 5\n  // Instead of relying on on-the-fly migration of metadata,\n  // this brings the doc-store to its modern form:\n  // - metadata.winningrev\n  // - metadata.seq\n  // - stringify the metadata when storing it\n  function migrateMetadata(txn) {\n\n    function decodeMetadataCompat(storedObject) {\n      if (!storedObject.data) {\n        // old format, when we didn't store it stringified\n        storedObject.deleted = storedObject.deletedOrLocal === '1';\n        return storedObject;\n      }\n      return decodeMetadata(storedObject);\n    }\n\n    // ensure that every metadata has a winningRev and seq,\n    // which was previously created on-the-fly but better to migrate\n    var bySeqStore = txn.objectStore(BY_SEQ_STORE);\n    var docStore = txn.objectStore(DOC_STORE);\n    var cursor = docStore.openCursor();\n    cursor.onsuccess = function (e) {\n      var cursor = e.target.result;\n      if (!cursor) {\n        return; // done\n      }\n      var metadata = decodeMetadataCompat(cursor.value);\n\n      metadata.winningRev = metadata.winningRev ||\n        winningRev(metadata);\n\n      function fetchMetadataSeq() {\n        // metadata.seq was added post-3.2.0, so if it's missing,\n        // we need to fetch it manually\n        var start = metadata.id + '::';\n        var end = metadata.id + '::\\uffff';\n        var req = bySeqStore.index('_doc_id_rev').openCursor(\n          IDBKeyRange.bound(start, end));\n\n        var metadataSeq = 0;\n        req.onsuccess = function (e) {\n          var cursor = e.target.result;\n          if (!cursor) {\n            metadata.seq = metadataSeq;\n            return onGetMetadataSeq();\n          }\n          var seq = cursor.primaryKey;\n          if (seq > metadataSeq) {\n            metadataSeq = seq;\n          }\n          cursor.continue();\n        };\n      }\n\n      function onGetMetadataSeq() {\n        var metadataToStore = encodeMetadata(metadata,\n          metadata.winningRev, metadata.deleted);\n\n        var req = docStore.put(metadataToStore);\n        req.onsuccess = function () {\n          cursor.continue();\n        };\n      }\n\n      if (metadata.seq) {\n        return onGetMetadataSeq();\n      }\n\n      fetchMetadataSeq();\n    };\n\n  }\n\n  api._remote = false;\n  api.type = function () {\n    return 'idb';\n  };\n\n  api._id = toPromise(function (callback) {\n    callback(null, api._meta.instanceId);\n  });\n\n  api._bulkDocs = function idb_bulkDocs(req, reqOpts, callback) {\n    idbBulkDocs(opts, req, reqOpts, api, idb, callback);\n  };\n\n  // First we look up the metadata in the ids database, then we fetch the\n  // current revision(s) from the by sequence store\n  api._get = function idb_get(id, opts, callback) {\n    var doc;\n    var metadata;\n    var err;\n    var txn = opts.ctx;\n    if (!txn) {\n      var txnResult = openTransactionSafely(idb,\n        [DOC_STORE, BY_SEQ_STORE, ATTACH_STORE], 'readonly');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      txn = txnResult.txn;\n    }\n\n    function finish() {\n      callback(err, {doc: doc, metadata: metadata, ctx: txn});\n    }\n\n    txn.objectStore(DOC_STORE).get(id).onsuccess = function (e) {\n      metadata = decodeMetadata(e.target.result);\n      // we can determine the result here if:\n      // 1. there is no such document\n      // 2. the document is deleted and we don't ask about specific rev\n      // When we ask with opts.rev we expect the answer to be either\n      // doc (possibly with _deleted=true) or missing error\n      if (!metadata) {\n        err = createError(MISSING_DOC, 'missing');\n        return finish();\n      }\n\n      var rev$$1;\n      if (!opts.rev) {\n        rev$$1 = metadata.winningRev;\n        var deleted = isDeleted(metadata);\n        if (deleted) {\n          err = createError(MISSING_DOC, \"deleted\");\n          return finish();\n        }\n      } else {\n        rev$$1 = opts.latest ? latest(opts.rev, metadata) : opts.rev;\n      }\n\n      var objectStore = txn.objectStore(BY_SEQ_STORE);\n      var key = metadata.id + '::' + rev$$1;\n\n      objectStore.index('_doc_id_rev').get(key).onsuccess = function (e) {\n        doc = e.target.result;\n        if (doc) {\n          doc = decodeDoc(doc);\n        }\n        if (!doc) {\n          err = createError(MISSING_DOC, 'missing');\n          return finish();\n        }\n        finish();\n      };\n    };\n  };\n\n  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n    var txn;\n    if (opts.ctx) {\n      txn = opts.ctx;\n    } else {\n      var txnResult = openTransactionSafely(idb,\n        [DOC_STORE, BY_SEQ_STORE, ATTACH_STORE], 'readonly');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      txn = txnResult.txn;\n    }\n    var digest = attachment.digest;\n    var type = attachment.content_type;\n\n    txn.objectStore(ATTACH_STORE).get(digest).onsuccess = function (e) {\n      var body = e.target.result.body;\n      readBlobData(body, type, opts.binary, function (blobData) {\n        callback(null, blobData);\n      });\n    };\n  };\n\n  api._info = function idb_info(callback) {\n    var updateSeq;\n    var docCount;\n\n    var txnResult = openTransactionSafely(idb, [META_STORE, BY_SEQ_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n    txn.objectStore(META_STORE).get(META_STORE).onsuccess = function (e) {\n      docCount = e.target.result.docCount;\n    };\n    txn.objectStore(BY_SEQ_STORE).openCursor(null, 'prev').onsuccess = function (e) {\n      var cursor = e.target.result;\n      updateSeq = cursor ? cursor.key : 0;\n    };\n\n    txn.oncomplete = function () {\n      callback(null, {\n        doc_count: docCount,\n        update_seq: updateSeq,\n        // for debugging\n        idb_attachment_format: (api._meta.blobSupport ? 'binary' : 'base64')\n      });\n    };\n  };\n\n  api._allDocs = function idb_allDocs(opts, callback) {\n    idbAllDocs(opts, idb, callback);\n  };\n\n  api._changes = function idbChanges(opts) {\n    return changes(opts, api, dbName, idb);\n  };\n\n  api._close = function (callback) {\n    // https://developer.mozilla.org/en-US/docs/IndexedDB/IDBDatabase#close\n    // \"Returns immediately and closes the connection in a separate thread...\"\n    idb.close();\n    cachedDBs.delete(dbName);\n    callback();\n  };\n\n  api._getRevisionTree = function (docId, callback) {\n    var txnResult = openTransactionSafely(idb, [DOC_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n    var req = txn.objectStore(DOC_STORE).get(docId);\n    req.onsuccess = function (event) {\n      var doc = decodeMetadata(event.target.result);\n      if (!doc) {\n        callback(createError(MISSING_DOC));\n      } else {\n        callback(null, doc.rev_tree);\n      }\n    };\n  };\n\n  // This function removes revisions of document docId\n  // which are listed in revs and sets this document\n  // revision to to rev_tree\n  api._doCompaction = function (docId, revs, callback) {\n    var stores = [\n      DOC_STORE,\n      BY_SEQ_STORE,\n      ATTACH_STORE,\n      ATTACH_AND_SEQ_STORE\n    ];\n    var txnResult = openTransactionSafely(idb, stores, 'readwrite');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n\n    var docStore = txn.objectStore(DOC_STORE);\n\n    docStore.get(docId).onsuccess = function (event) {\n      var metadata = decodeMetadata(event.target.result);\n      traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                                         revHash, ctx, opts) {\n        var rev$$1 = pos + '-' + revHash;\n        if (revs.indexOf(rev$$1) !== -1) {\n          opts.status = 'missing';\n        }\n      });\n      compactRevs(revs, docId, txn);\n      var winningRev$$1 = metadata.winningRev;\n      var deleted = metadata.deleted;\n      txn.objectStore(DOC_STORE).put(\n        encodeMetadata(metadata, winningRev$$1, deleted));\n    };\n    txn.onabort = idbError(callback);\n    txn.oncomplete = function () {\n      callback();\n    };\n  };\n\n\n  api._getLocal = function (id, callback) {\n    var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var tx = txnResult.txn;\n    var req = tx.objectStore(LOCAL_STORE).get(id);\n\n    req.onerror = idbError(callback);\n    req.onsuccess = function (e) {\n      var doc = e.target.result;\n      if (!doc) {\n        callback(createError(MISSING_DOC));\n      } else {\n        delete doc['_doc_id_rev']; // for backwards compat\n        callback(null, doc);\n      }\n    };\n  };\n\n  api._putLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    delete doc._revisions; // ignore this, trust the rev\n    var oldRev = doc._rev;\n    var id = doc._id;\n    if (!oldRev) {\n      doc._rev = '0-1';\n    } else {\n      doc._rev = '0-' + (parseInt(oldRev.split('-')[1], 10) + 1);\n    }\n\n    var tx = opts.ctx;\n    var ret;\n    if (!tx) {\n      var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readwrite');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      tx = txnResult.txn;\n      tx.onerror = idbError(callback);\n      tx.oncomplete = function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      };\n    }\n\n    var oStore = tx.objectStore(LOCAL_STORE);\n    var req;\n    if (oldRev) {\n      req = oStore.get(id);\n      req.onsuccess = function (e) {\n        var oldDoc = e.target.result;\n        if (!oldDoc || oldDoc._rev !== oldRev) {\n          callback(createError(REV_CONFLICT));\n        } else { // update\n          var req = oStore.put(doc);\n          req.onsuccess = function () {\n            ret = {ok: true, id: doc._id, rev: doc._rev};\n            if (opts.ctx) { // return immediately\n              callback(null, ret);\n            }\n          };\n        }\n      };\n    } else { // new doc\n      req = oStore.add(doc);\n      req.onerror = function (e) {\n        // constraint error, already exists\n        callback(createError(REV_CONFLICT));\n        e.preventDefault(); // avoid transaction abort\n        e.stopPropagation(); // avoid transaction onerror\n      };\n      req.onsuccess = function () {\n        ret = {ok: true, id: doc._id, rev: doc._rev};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      };\n    }\n  };\n\n  api._removeLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var tx = opts.ctx;\n    if (!tx) {\n      var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readwrite');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      tx = txnResult.txn;\n      tx.oncomplete = function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      };\n    }\n    var ret;\n    var id = doc._id;\n    var oStore = tx.objectStore(LOCAL_STORE);\n    var req = oStore.get(id);\n\n    req.onerror = idbError(callback);\n    req.onsuccess = function (e) {\n      var oldDoc = e.target.result;\n      if (!oldDoc || oldDoc._rev !== doc._rev) {\n        callback(createError(MISSING_DOC));\n      } else {\n        oStore.delete(id);\n        ret = {ok: true, id: id, rev: '0-0'};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      }\n    };\n  };\n\n  api._destroy = function (opts, callback) {\n    changesHandler.removeAllListeners(dbName);\n\n    //Close open request for \"dbName\" database to fix ie delay.\n    var openReq = openReqList.get(dbName);\n    if (openReq && openReq.result) {\n      openReq.result.close();\n      cachedDBs.delete(dbName);\n    }\n    var req = indexedDB.deleteDatabase(dbName);\n\n    req.onsuccess = function () {\n      //Remove open request from the list.\n      openReqList.delete(dbName);\n      if (hasLocalStorage() && (dbName in localStorage)) {\n        delete localStorage[dbName];\n      }\n      callback(null, { 'ok': true });\n    };\n\n    req.onerror = idbError(callback);\n  };\n\n  var cached = cachedDBs.get(dbName);\n\n  if (cached) {\n    idb = cached.idb;\n    api._meta = cached.global;\n    return immediate(function () {\n      callback(null, api);\n    });\n  }\n\n  var req = indexedDB.open(dbName, ADAPTER_VERSION);\n  openReqList.set(dbName, req);\n\n  req.onupgradeneeded = function (e) {\n    var db = e.target.result;\n    if (e.oldVersion < 1) {\n      return createSchema(db); // new db, initial schema\n    }\n    // do migrations\n\n    var txn = e.currentTarget.transaction;\n    // these migrations have to be done in this function, before\n    // control is returned to the event loop, because IndexedDB\n\n    if (e.oldVersion < 3) {\n      createLocalStoreSchema(db); // v2 -> v3\n    }\n    if (e.oldVersion < 4) {\n      addAttachAndSeqStore(db); // v3 -> v4\n    }\n\n    var migrations = [\n      addDeletedOrLocalIndex, // v1 -> v2\n      migrateLocalStore,      // v2 -> v3\n      migrateAttsAndSeqs,     // v3 -> v4\n      migrateMetadata         // v4 -> v5\n    ];\n\n    var i = e.oldVersion;\n\n    function next() {\n      var migration = migrations[i - 1];\n      i++;\n      if (migration) {\n        migration(txn, next);\n      }\n    }\n\n    next();\n  };\n\n  req.onsuccess = function (e) {\n\n    idb = e.target.result;\n\n    idb.onversionchange = function () {\n      idb.close();\n      cachedDBs.delete(dbName);\n    };\n\n    idb.onabort = function (e) {\n      guardedConsole('error', 'Database has a global failure', e.target.error);\n      idb.close();\n      cachedDBs.delete(dbName);\n    };\n\n    // Do a few setup operations (in parallel as much as possible):\n    // 1. Fetch meta doc\n    // 2. Check blob support\n    // 3. Calculate docCount\n    // 4. Generate an instanceId if necessary\n    // 5. Store docCount and instanceId on meta doc\n\n    var txn = idb.transaction([\n      META_STORE,\n      DETECT_BLOB_SUPPORT_STORE,\n      DOC_STORE\n    ], 'readwrite');\n\n    var storedMetaDoc = false;\n    var metaDoc;\n    var docCount;\n    var blobSupport;\n    var instanceId;\n\n    function completeSetup() {\n      if (typeof blobSupport === 'undefined' || !storedMetaDoc) {\n        return;\n      }\n      api._meta = {\n        name: dbName,\n        instanceId: instanceId,\n        blobSupport: blobSupport\n      };\n\n      cachedDBs.set(dbName, {\n        idb: idb,\n        global: api._meta\n      });\n      callback(null, api);\n    }\n\n    function storeMetaDocIfReady() {\n      if (typeof docCount === 'undefined' || typeof metaDoc === 'undefined') {\n        return;\n      }\n      var instanceKey = dbName + '_id';\n      if (instanceKey in metaDoc) {\n        instanceId = metaDoc[instanceKey];\n      } else {\n        metaDoc[instanceKey] = instanceId = uuid();\n      }\n      metaDoc.docCount = docCount;\n      txn.objectStore(META_STORE).put(metaDoc);\n    }\n\n    //\n    // fetch or generate the instanceId\n    //\n    txn.objectStore(META_STORE).get(META_STORE).onsuccess = function (e) {\n      metaDoc = e.target.result || { id: META_STORE };\n      storeMetaDocIfReady();\n    };\n\n    //\n    // countDocs\n    //\n    countDocs(txn, function (count) {\n      docCount = count;\n      storeMetaDocIfReady();\n    });\n\n    //\n    // check blob support\n    //\n    if (!blobSupportPromise) {\n      // make sure blob support is only checked once\n      blobSupportPromise = checkBlobSupport(txn);\n    }\n\n    blobSupportPromise.then(function (val) {\n      blobSupport = val;\n      completeSetup();\n    });\n\n    // only when the metadata put transaction has completed,\n    // consider the setup done\n    txn.oncomplete = function () {\n      storedMetaDoc = true;\n      completeSetup();\n    };\n    txn.onabort = idbError(callback);\n  };\n\n  req.onerror = function () {\n    var msg = 'Failed to open indexedDB, are you in private browsing mode?';\n    guardedConsole('error', msg);\n    callback(createError(IDB_ERROR, msg));\n  };\n}\n\nIdbPouch.valid = function () {\n  // Following #7085 buggy idb versions (typically Safari < 10.1) are\n  // considered valid.\n\n  // On Firefox SecurityError is thrown while referencing indexedDB if cookies\n  // are not allowed. `typeof indexedDB` also triggers the error.\n  try {\n    // some outdated implementations of IDB that appear on Samsung\n    // and HTC Android devices <4.4 are missing IDBKeyRange\n    return typeof indexedDB !== 'undefined' && typeof IDBKeyRange !== 'undefined';\n  } catch (e) {\n    return false;\n  }\n};\n\nfunction IDBPouch (PouchDB) {\n  PouchDB.adapter('idb', IdbPouch, true);\n}\n\n// dead simple promise pool, inspired by https://github.com/timdp/es6-promise-pool\n// but much smaller in code size. limits the number of concurrent promises that are executed\n\n\nfunction pool(promiseFactories, limit) {\n  return new Promise(function (resolve, reject) {\n    var running = 0;\n    var current = 0;\n    var done = 0;\n    var len = promiseFactories.length;\n    var err;\n\n    function runNext() {\n      running++;\n      promiseFactories[current++]().then(onSuccess, onError);\n    }\n\n    function doNext() {\n      if (++done === len) {\n        /* istanbul ignore if */\n        if (err) {\n          reject(err);\n        } else {\n          resolve();\n        }\n      } else {\n        runNextBatch();\n      }\n    }\n\n    function onSuccess() {\n      running--;\n      doNext();\n    }\n\n    /* istanbul ignore next */\n    function onError(thisErr) {\n      running--;\n      err = err || thisErr;\n      doNext();\n    }\n\n    function runNextBatch() {\n      while (running < limit && current < len) {\n        runNext();\n      }\n    }\n\n    runNextBatch();\n  });\n}\n\nvar CHANGES_BATCH_SIZE = 25;\nvar MAX_SIMULTANEOUS_REVS = 50;\nvar CHANGES_TIMEOUT_BUFFER = 5000;\nvar DEFAULT_HEARTBEAT = 10000;\n\nvar supportsBulkGetMap = {};\n\nfunction readAttachmentsAsBlobOrBuffer(row) {\n  var doc = row.doc || row.ok;\n  var atts = doc && doc._attachments;\n  if (!atts) {\n    return;\n  }\n  Object.keys(atts).forEach(function (filename) {\n    var att = atts[filename];\n    att.data = b64ToBluffer(att.data, att.content_type);\n  });\n}\n\nfunction encodeDocId(id) {\n  if (/^_design/.test(id)) {\n    return '_design/' + encodeURIComponent(id.slice(8));\n  }\n  if (/^_local/.test(id)) {\n    return '_local/' + encodeURIComponent(id.slice(7));\n  }\n  return encodeURIComponent(id);\n}\n\nfunction preprocessAttachments$1(doc) {\n  if (!doc._attachments || !Object.keys(doc._attachments)) {\n    return Promise.resolve();\n  }\n\n  return Promise.all(Object.keys(doc._attachments).map(function (key) {\n    var attachment = doc._attachments[key];\n    if (attachment.data && typeof attachment.data !== 'string') {\n      return new Promise(function (resolve) {\n        blobToBase64(attachment.data, resolve);\n      }).then(function (b64) {\n        attachment.data = b64;\n      });\n    }\n  }));\n}\n\nfunction hasUrlPrefix(opts) {\n  if (!opts.prefix) {\n    return false;\n  }\n  var protocol = parseUri(opts.prefix).protocol;\n  return protocol === 'http' || protocol === 'https';\n}\n\n// Get all the information you possibly can about the URI given by name and\n// return it as a suitable object.\nfunction getHost(name, opts) {\n  // encode db name if opts.prefix is a url (#5574)\n  if (hasUrlPrefix(opts)) {\n    var dbName = opts.name.substr(opts.prefix.length);\n    // Ensure prefix has a trailing slash\n    var prefix = opts.prefix.replace(/\\/?$/, '/');\n    name = prefix + encodeURIComponent(dbName);\n  }\n\n  var uri = parseUri(name);\n  if (uri.user || uri.password) {\n    uri.auth = {username: uri.user, password: uri.password};\n  }\n\n  // Split the path part of the URI into parts using '/' as the delimiter\n  // after removing any leading '/' and any trailing '/'\n  var parts = uri.path.replace(/(^\\/|\\/$)/g, '').split('/');\n\n  uri.db = parts.pop();\n  // Prevent double encoding of URI component\n  if (uri.db.indexOf('%') === -1) {\n    uri.db = encodeURIComponent(uri.db);\n  }\n\n  uri.path = parts.join('/');\n\n  return uri;\n}\n\n// Generate a URL with the host data given by opts and the given path\nfunction genDBUrl(opts, path) {\n  return genUrl(opts, opts.db + '/' + path);\n}\n\n// Generate a URL with the host data given by opts and the given path\nfunction genUrl(opts, path) {\n  // If the host already has a path, then we need to have a path delimiter\n  // Otherwise, the path delimiter is the empty string\n  var pathDel = !opts.path ? '' : '/';\n\n  // If the host already has a path, then we need to have a path delimiter\n  // Otherwise, the path delimiter is the empty string\n  return opts.protocol + '://' + opts.host +\n         (opts.port ? (':' + opts.port) : '') +\n         '/' + opts.path + pathDel + path;\n}\n\nfunction paramsToStr(params) {\n  return '?' + Object.keys(params).map(function (k) {\n    return k + '=' + encodeURIComponent(params[k]);\n  }).join('&');\n}\n\nfunction shouldCacheBust(opts) {\n  var ua = (typeof navigator !== 'undefined' && navigator.userAgent) ?\n      navigator.userAgent.toLowerCase() : '';\n  var isIE = ua.indexOf('msie') !== -1;\n  var isTrident = ua.indexOf('trident') !== -1;\n  var isEdge = ua.indexOf('edge') !== -1;\n  var isGET = !('method' in opts) || opts.method === 'GET';\n  return (isIE || isTrident || isEdge) && isGET;\n}\n\n// Implements the PouchDB API for dealing with CouchDB instances over HTTP\nfunction HttpPouch(opts, callback) {\n\n  // The functions that will be publicly available for HttpPouch\n  var api = this;\n\n  var host = getHost(opts.name, opts);\n  var dbUrl = genDBUrl(host, '');\n\n  opts = clone(opts);\n\n  var ourFetch = function (url, options) {\n\n    options = options || {};\n    options.headers = options.headers || new h();\n\n    options.credentials = 'include';\n\n    if (opts.auth || host.auth) {\n      var nAuth = opts.auth || host.auth;\n      var str = nAuth.username + ':' + nAuth.password;\n      var token = thisBtoa(unescape(encodeURIComponent(str)));\n      options.headers.set('Authorization', 'Basic ' + token);\n    }\n\n    var headers = opts.headers || {};\n    Object.keys(headers).forEach(function (key) {\n      options.headers.append(key, headers[key]);\n    });\n\n    /* istanbul ignore if */\n    if (shouldCacheBust(options)) {\n      url += (url.indexOf('?') === -1 ? '?' : '&') + '_nonce=' + Date.now();\n    }\n\n    var fetchFun = opts.fetch || f$1;\n    return fetchFun(url, options);\n  };\n\n  function adapterFun$$1(name, fun) {\n    return adapterFun(name, getArguments(function (args) {\n      setup().then(function () {\n        return fun.apply(this, args);\n      }).catch(function (e) {\n        var callback = args.pop();\n        callback(e);\n      });\n    })).bind(api);\n  }\n\n  function fetchJSON(url, options, callback) {\n\n    var result = {};\n\n    options = options || {};\n    options.headers = options.headers || new h();\n\n    if (!options.headers.get('Content-Type')) {\n      options.headers.set('Content-Type', 'application/json');\n    }\n    if (!options.headers.get('Accept')) {\n      options.headers.set('Accept', 'application/json');\n    }\n\n    return ourFetch(url, options).then(function (response) {\n      result.ok = response.ok;\n      result.status = response.status;\n      return response.json();\n    }).then(function (json) {\n      result.data = json;\n      if (!result.ok) {\n        result.data.status = result.status;\n        var err = generateErrorFromResponse(result.data);\n        if (callback) {\n          return callback(err);\n        } else {\n          throw err;\n        }\n      }\n\n      if (Array.isArray(result.data)) {\n        result.data = result.data.map(function (v) {\n          if (v.error || v.missing) {\n            return generateErrorFromResponse(v);\n          } else {\n            return v;\n          }\n        });\n      }\n\n      if (callback) {\n        callback(null, result.data);\n      } else {\n        return result;\n      }\n    });\n  }\n\n  var setupPromise;\n\n  function setup() {\n    if (opts.skip_setup) {\n      return Promise.resolve();\n    }\n\n    // If there is a setup in process or previous successful setup\n    // done then we will use that\n    // If previous setups have been rejected we will try again\n    if (setupPromise) {\n      return setupPromise;\n    }\n\n    setupPromise = fetchJSON(dbUrl).catch(function (err) {\n      if (err && err.status && err.status === 404) {\n        // Doesnt exist, create it\n        explainError(404, 'PouchDB is just detecting if the remote exists.');\n        return fetchJSON(dbUrl, {method: 'PUT'});\n      } else {\n        return Promise.reject(err);\n      }\n    }).catch(function (err) {\n      // If we try to create a database that already exists, skipped in\n      // istanbul since its catching a race condition.\n      /* istanbul ignore if */\n      if (err && err.status && err.status === 412) {\n        return true;\n      }\n      return Promise.reject(err);\n    });\n\n    setupPromise.catch(function () {\n      setupPromise = null;\n    });\n\n    return setupPromise;\n  }\n\n  immediate(function () {\n    callback(null, api);\n  });\n\n  api._remote = true;\n\n  /* istanbul ignore next */\n  api.type = function () {\n    return 'http';\n  };\n\n  api.id = adapterFun$$1('id', function (callback) {\n    ourFetch(genUrl(host, '')).then(function (response) {\n      return response.json();\n    }).catch(function () {\n      return {};\n    }).then(function (result) {\n      // Bad response or missing `uuid` should not prevent ID generation.\n      var uuid$$1 = (result && result.uuid) ?\n          (result.uuid + host.db) : genDBUrl(host, '');\n      callback(null, uuid$$1);\n    });\n  });\n\n  // Sends a POST request to the host calling the couchdb _compact function\n  //    version: The version of CouchDB it is running\n  api.compact = adapterFun$$1('compact', function (opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n\n    fetchJSON(genDBUrl(host, '_compact'), {method: 'POST'}).then(function () {\n      function ping() {\n        api.info(function (err, res) {\n          // CouchDB may send a \"compact_running:true\" if it's\n          // already compacting. PouchDB Server doesn't.\n          /* istanbul ignore else */\n          if (res && !res.compact_running) {\n            callback(null, {ok: true});\n          } else {\n            setTimeout(ping, opts.interval || 200);\n          }\n        });\n      }\n      // Ping the http if it's finished compaction\n      ping();\n    });\n  });\n\n  api.bulkGet = adapterFun('bulkGet', function (opts, callback) {\n    var self = this;\n\n    function doBulkGet(cb) {\n      var params = {};\n      if (opts.revs) {\n        params.revs = true;\n      }\n      if (opts.attachments) {\n        /* istanbul ignore next */\n        params.attachments = true;\n      }\n      if (opts.latest) {\n        params.latest = true;\n      }\n      fetchJSON(genDBUrl(host, '_bulk_get' + paramsToStr(params)), {\n        method: 'POST',\n        body: JSON.stringify({ docs: opts.docs})\n      }).then(function (result) {\n        if (opts.attachments && opts.binary) {\n          result.data.results.forEach(function (res) {\n            res.docs.forEach(readAttachmentsAsBlobOrBuffer);\n          });\n        }\n        cb(null, result.data);\n      }).catch(cb);\n    }\n\n    /* istanbul ignore next */\n    function doBulkGetShim() {\n      // avoid \"url too long error\" by splitting up into multiple requests\n      var batchSize = MAX_SIMULTANEOUS_REVS;\n      var numBatches = Math.ceil(opts.docs.length / batchSize);\n      var numDone = 0;\n      var results = new Array(numBatches);\n\n      function onResult(batchNum) {\n        return function (err, res) {\n          // err is impossible because shim returns a list of errs in that case\n          results[batchNum] = res.results;\n          if (++numDone === numBatches) {\n            callback(null, {results: flatten(results)});\n          }\n        };\n      }\n\n      for (var i = 0; i < numBatches; i++) {\n        var subOpts = pick(opts, ['revs', 'attachments', 'binary', 'latest']);\n        subOpts.docs = opts.docs.slice(i * batchSize,\n          Math.min(opts.docs.length, (i + 1) * batchSize));\n        bulkGet(self, subOpts, onResult(i));\n      }\n    }\n\n    // mark the whole database as either supporting or not supporting _bulk_get\n    var dbUrl = genUrl(host, '');\n    var supportsBulkGet = supportsBulkGetMap[dbUrl];\n\n    /* istanbul ignore next */\n    if (typeof supportsBulkGet !== 'boolean') {\n      // check if this database supports _bulk_get\n      doBulkGet(function (err, res) {\n        if (err) {\n          supportsBulkGetMap[dbUrl] = false;\n          explainError(\n            err.status,\n            'PouchDB is just detecting if the remote ' +\n            'supports the _bulk_get API.'\n          );\n          doBulkGetShim();\n        } else {\n          supportsBulkGetMap[dbUrl] = true;\n          callback(null, res);\n        }\n      });\n    } else if (supportsBulkGet) {\n      doBulkGet(callback);\n    } else {\n      doBulkGetShim();\n    }\n  });\n\n  // Calls GET on the host, which gets back a JSON string containing\n  //    couchdb: A welcome string\n  //    version: The version of CouchDB it is running\n  api._info = function (callback) {\n    setup().then(function () {\n      return ourFetch(genDBUrl(host, ''));\n    }).then(function (response) {\n      return response.json();\n    }).then(function (info) {\n      info.host = genDBUrl(host, '');\n      callback(null, info);\n    }).catch(callback);\n  };\n\n  api.fetch = function (path, options) {\n    return setup().then(function () {\n      var url = path.substring(0, 1) === '/' ?\n        genUrl(host, path.substring(1)) :\n        genDBUrl(host, path);\n      return ourFetch(url, options);\n    });\n  };\n\n  // Get the document with the given id from the database given by host.\n  // The id could be solely the _id in the database, or it may be a\n  // _design/ID or _local/ID path\n  api.get = adapterFun$$1('get', function (id, opts, callback) {\n    // If no options were given, set the callback to the second parameter\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n\n    // List of parameters to add to the GET request\n    var params = {};\n\n    if (opts.revs) {\n      params.revs = true;\n    }\n\n    if (opts.revs_info) {\n      params.revs_info = true;\n    }\n\n    if (opts.latest) {\n      params.latest = true;\n    }\n\n    if (opts.open_revs) {\n      if (opts.open_revs !== \"all\") {\n        opts.open_revs = JSON.stringify(opts.open_revs);\n      }\n      params.open_revs = opts.open_revs;\n    }\n\n    if (opts.rev) {\n      params.rev = opts.rev;\n    }\n\n    if (opts.conflicts) {\n      params.conflicts = opts.conflicts;\n    }\n\n    /* istanbul ignore if */\n    if (opts.update_seq) {\n      params.update_seq = opts.update_seq;\n    }\n\n    id = encodeDocId(id);\n\n    function fetchAttachments(doc) {\n      var atts = doc._attachments;\n      var filenames = atts && Object.keys(atts);\n      if (!atts || !filenames.length) {\n        return;\n      }\n      // we fetch these manually in separate XHRs, because\n      // Sync Gateway would normally send it back as multipart/mixed,\n      // which we cannot parse. Also, this is more efficient than\n      // receiving attachments as base64-encoded strings.\n      function fetchData(filename) {\n        var att = atts[filename];\n        var path = encodeDocId(doc._id) + '/' + encodeAttachmentId(filename) +\n            '?rev=' + doc._rev;\n        return ourFetch(genDBUrl(host, path)).then(function (response) {\n          if (typeof process !== 'undefined' && !process.browser) {\n            return response.buffer();\n          } else {\n            /* istanbul ignore next */\n            return response.blob();\n          }\n        }).then(function (blob) {\n          if (opts.binary) {\n            // TODO: Can we remove this?\n            if (typeof process !== 'undefined' && !process.browser) {\n              blob.type = att.content_type;\n            }\n            return blob;\n          }\n          return new Promise(function (resolve) {\n            blobToBase64(blob, resolve);\n          });\n        }).then(function (data) {\n          delete att.stub;\n          delete att.length;\n          att.data = data;\n        });\n      }\n\n      var promiseFactories = filenames.map(function (filename) {\n        return function () {\n          return fetchData(filename);\n        };\n      });\n\n      // This limits the number of parallel xhr requests to 5 any time\n      // to avoid issues with maximum browser request limits\n      return pool(promiseFactories, 5);\n    }\n\n    function fetchAllAttachments(docOrDocs) {\n      if (Array.isArray(docOrDocs)) {\n        return Promise.all(docOrDocs.map(function (doc) {\n          if (doc.ok) {\n            return fetchAttachments(doc.ok);\n          }\n        }));\n      }\n      return fetchAttachments(docOrDocs);\n    }\n\n    var url = genDBUrl(host, id + paramsToStr(params));\n    fetchJSON(url).then(function (res) {\n      return Promise.resolve().then(function () {\n        if (opts.attachments) {\n          return fetchAllAttachments(res.data);\n        }\n      }).then(function () {\n        callback(null, res.data);\n      });\n    }).catch(function (e) {\n      e.docId = id;\n      callback(e);\n    });\n  });\n\n\n  // Delete the document given by doc from the database given by host.\n  api.remove = adapterFun$$1('remove', function (docOrId, optsOrRev, opts, cb) {\n    var doc;\n    if (typeof optsOrRev === 'string') {\n      // id, rev, opts, callback style\n      doc = {\n        _id: docOrId,\n        _rev: optsOrRev\n      };\n      if (typeof opts === 'function') {\n        cb = opts;\n        opts = {};\n      }\n    } else {\n      // doc, opts, callback style\n      doc = docOrId;\n      if (typeof optsOrRev === 'function') {\n        cb = optsOrRev;\n        opts = {};\n      } else {\n        cb = opts;\n        opts = optsOrRev;\n      }\n    }\n\n    var rev$$1 = (doc._rev || opts.rev);\n    var url = genDBUrl(host, encodeDocId(doc._id)) + '?rev=' + rev$$1;\n\n    fetchJSON(url, {method: 'DELETE'}, cb).catch(cb);\n  });\n\n  function encodeAttachmentId(attachmentId) {\n    return attachmentId.split(\"/\").map(encodeURIComponent).join(\"/\");\n  }\n\n  // Get the attachment\n  api.getAttachment = adapterFun$$1('getAttachment', function (docId, attachmentId,\n                                                            opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var params = opts.rev ? ('?rev=' + opts.rev) : '';\n    var url = genDBUrl(host, encodeDocId(docId)) + '/' +\n        encodeAttachmentId(attachmentId) + params;\n    var contentType;\n    ourFetch(url, {method: 'GET'}).then(function (response) {\n      contentType = response.headers.get('content-type');\n      if (!response.ok) {\n        throw response;\n      } else {\n        if (typeof process !== 'undefined' && !process.browser) {\n          return response.buffer();\n        } else {\n          /* istanbul ignore next */\n          return response.blob();\n        }\n      }\n    }).then(function (blob) {\n      // TODO: also remove\n      if (typeof process !== 'undefined' && !process.browser) {\n        blob.type = contentType;\n      }\n      callback(null, blob);\n    }).catch(function (err) {\n      callback(err);\n    });\n  });\n\n  // Remove the attachment given by the id and rev\n  api.removeAttachment =  adapterFun$$1('removeAttachment', function (docId,\n                                                                   attachmentId,\n                                                                   rev$$1,\n                                                                   callback) {\n    var url = genDBUrl(host, encodeDocId(docId) + '/' +\n                       encodeAttachmentId(attachmentId)) + '?rev=' + rev$$1;\n    fetchJSON(url, {method: 'DELETE'}, callback).catch(callback);\n  });\n\n  // Add the attachment given by blob and its contentType property\n  // to the document with the given id, the revision given by rev, and\n  // add it to the database given by host.\n  api.putAttachment = adapterFun$$1('putAttachment', function (docId, attachmentId,\n                                                            rev$$1, blob,\n                                                            type, callback) {\n    if (typeof type === 'function') {\n      callback = type;\n      type = blob;\n      blob = rev$$1;\n      rev$$1 = null;\n    }\n    var id = encodeDocId(docId) + '/' + encodeAttachmentId(attachmentId);\n    var url = genDBUrl(host, id);\n    if (rev$$1) {\n      url += '?rev=' + rev$$1;\n    }\n\n    if (typeof blob === 'string') {\n      // input is assumed to be a base64 string\n      var binary;\n      try {\n        binary = thisAtob(blob);\n      } catch (err) {\n        return callback(createError(BAD_ARG,\n                        'Attachment is not a valid base64 string'));\n      }\n      blob = binary ? binStringToBluffer(binary, type) : '';\n    }\n\n    // Add the attachment\n    fetchJSON(url, {\n      headers: new h({'Content-Type': type}),\n      method: 'PUT',\n      body: blob\n    }, callback).catch(callback);\n  });\n\n  // Update/create multiple documents given by req in the database\n  // given by host.\n  api._bulkDocs = function (req, opts, callback) {\n    // If new_edits=false then it prevents the database from creating\n    // new revision numbers for the documents. Instead it just uses\n    // the old ones. This is used in database replication.\n    req.new_edits = opts.new_edits;\n\n    setup().then(function () {\n      return Promise.all(req.docs.map(preprocessAttachments$1));\n    }).then(function () {\n      // Update/create the documents\n      return fetchJSON(genDBUrl(host, '_bulk_docs'), {\n        method: 'POST',\n        body: JSON.stringify(req)\n      }, callback);\n    }).catch(callback);\n  };\n\n\n  // Update/create document\n  api._put = function (doc, opts, callback) {\n    setup().then(function () {\n      return preprocessAttachments$1(doc);\n    }).then(function () {\n      return fetchJSON(genDBUrl(host, encodeDocId(doc._id)), {\n        method: 'PUT',\n        body: JSON.stringify(doc)\n      });\n    }).then(function (result) {\n      callback(null, result.data);\n    }).catch(function (err) {\n      err.docId = doc && doc._id;\n      callback(err);\n    });\n  };\n\n\n  // Get a listing of the documents in the database given\n  // by host and ordered by increasing id.\n  api.allDocs = adapterFun$$1('allDocs', function (opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n\n    // List of parameters to add to the GET request\n    var params = {};\n    var body;\n    var method = 'GET';\n\n    if (opts.conflicts) {\n      params.conflicts = true;\n    }\n\n    /* istanbul ignore if */\n    if (opts.update_seq) {\n      params.update_seq = true;\n    }\n\n    if (opts.descending) {\n      params.descending = true;\n    }\n\n    if (opts.include_docs) {\n      params.include_docs = true;\n    }\n\n    // added in CouchDB 1.6.0\n    if (opts.attachments) {\n      params.attachments = true;\n    }\n\n    if (opts.key) {\n      params.key = JSON.stringify(opts.key);\n    }\n\n    if (opts.start_key) {\n      opts.startkey = opts.start_key;\n    }\n\n    if (opts.startkey) {\n      params.startkey = JSON.stringify(opts.startkey);\n    }\n\n    if (opts.end_key) {\n      opts.endkey = opts.end_key;\n    }\n\n    if (opts.endkey) {\n      params.endkey = JSON.stringify(opts.endkey);\n    }\n\n    if (typeof opts.inclusive_end !== 'undefined') {\n      params.inclusive_end = !!opts.inclusive_end;\n    }\n\n    if (typeof opts.limit !== 'undefined') {\n      params.limit = opts.limit;\n    }\n\n    if (typeof opts.skip !== 'undefined') {\n      params.skip = opts.skip;\n    }\n\n    var paramStr = paramsToStr(params);\n\n    if (typeof opts.keys !== 'undefined') {\n      method = 'POST';\n      body = {keys: opts.keys};\n    }\n\n    fetchJSON(genDBUrl(host, '_all_docs' + paramStr), {\n       method: method,\n      body: JSON.stringify(body)\n    }).then(function (result) {\n      if (opts.include_docs && opts.attachments && opts.binary) {\n        result.data.rows.forEach(readAttachmentsAsBlobOrBuffer);\n      }\n      callback(null, result.data);\n    }).catch(callback);\n  });\n\n  // Get a list of changes made to documents in the database given by host.\n  // TODO According to the README, there should be two other methods here,\n  // api.changes.addListener and api.changes.removeListener.\n  api._changes = function (opts) {\n\n    // We internally page the results of a changes request, this means\n    // if there is a large set of changes to be returned we can start\n    // processing them quicker instead of waiting on the entire\n    // set of changes to return and attempting to process them at once\n    var batchSize = 'batch_size' in opts ? opts.batch_size : CHANGES_BATCH_SIZE;\n\n    opts = clone(opts);\n\n    if (opts.continuous && !('heartbeat' in opts)) {\n      opts.heartbeat = DEFAULT_HEARTBEAT;\n    }\n\n    var requestTimeout = ('timeout' in opts) ? opts.timeout : 30 * 1000;\n\n    // ensure CHANGES_TIMEOUT_BUFFER applies\n    if ('timeout' in opts && opts.timeout &&\n      (requestTimeout - opts.timeout) < CHANGES_TIMEOUT_BUFFER) {\n        requestTimeout = opts.timeout + CHANGES_TIMEOUT_BUFFER;\n    }\n\n    /* istanbul ignore if */\n    if ('heartbeat' in opts && opts.heartbeat &&\n       (requestTimeout - opts.heartbeat) < CHANGES_TIMEOUT_BUFFER) {\n        requestTimeout = opts.heartbeat + CHANGES_TIMEOUT_BUFFER;\n    }\n\n    var params = {};\n    if ('timeout' in opts && opts.timeout) {\n      params.timeout = opts.timeout;\n    }\n\n    var limit = (typeof opts.limit !== 'undefined') ? opts.limit : false;\n    var leftToFetch = limit;\n\n    if (opts.style) {\n      params.style = opts.style;\n    }\n\n    if (opts.include_docs || opts.filter && typeof opts.filter === 'function') {\n      params.include_docs = true;\n    }\n\n    if (opts.attachments) {\n      params.attachments = true;\n    }\n\n    if (opts.continuous) {\n      params.feed = 'longpoll';\n    }\n\n    if (opts.seq_interval) {\n      params.seq_interval = opts.seq_interval;\n    }\n\n    if (opts.conflicts) {\n      params.conflicts = true;\n    }\n\n    if (opts.descending) {\n      params.descending = true;\n    }\n    \n    /* istanbul ignore if */\n    if (opts.update_seq) {\n      params.update_seq = true;\n    }\n\n    if ('heartbeat' in opts) {\n      // If the heartbeat value is false, it disables the default heartbeat\n      if (opts.heartbeat) {\n        params.heartbeat = opts.heartbeat;\n      }\n    }\n\n    if (opts.filter && typeof opts.filter === 'string') {\n      params.filter = opts.filter;\n    }\n\n    if (opts.view && typeof opts.view === 'string') {\n      params.filter = '_view';\n      params.view = opts.view;\n    }\n\n    // If opts.query_params exists, pass it through to the changes request.\n    // These parameters may be used by the filter on the source database.\n    if (opts.query_params && typeof opts.query_params === 'object') {\n      for (var param_name in opts.query_params) {\n        /* istanbul ignore else */\n        if (opts.query_params.hasOwnProperty(param_name)) {\n          params[param_name] = opts.query_params[param_name];\n        }\n      }\n    }\n\n    var method = 'GET';\n    var body;\n\n    if (opts.doc_ids) {\n      // set this automagically for the user; it's annoying that couchdb\n      // requires both a \"filter\" and a \"doc_ids\" param.\n      params.filter = '_doc_ids';\n      method = 'POST';\n      body = {doc_ids: opts.doc_ids };\n    }\n    /* istanbul ignore next */\n    else if (opts.selector) {\n      // set this automagically for the user, similar to above\n      params.filter = '_selector';\n      method = 'POST';\n      body = {selector: opts.selector };\n    }\n\n    var controller = new a();\n    var lastFetchedSeq;\n\n    // Get all the changes starting wtih the one immediately after the\n    // sequence number given by since.\n    var fetchData = function (since, callback) {\n      if (opts.aborted) {\n        return;\n      }\n      params.since = since;\n      // \"since\" can be any kind of json object in Cloudant/CouchDB 2.x\n      /* istanbul ignore next */\n      if (typeof params.since === \"object\") {\n        params.since = JSON.stringify(params.since);\n      }\n\n      if (opts.descending) {\n        if (limit) {\n          params.limit = leftToFetch;\n        }\n      } else {\n        params.limit = (!limit || leftToFetch > batchSize) ?\n          batchSize : leftToFetch;\n      }\n\n      // Set the options for the ajax call\n      var url = genDBUrl(host, '_changes' + paramsToStr(params));\n      var fetchOpts = {\n        signal: controller.signal,\n        method: method,\n        body: JSON.stringify(body)\n      };\n      lastFetchedSeq = since;\n\n      /* istanbul ignore if */\n      if (opts.aborted) {\n        return;\n      }\n\n      // Get the changes\n      setup().then(function () {\n        return fetchJSON(url, fetchOpts, callback);\n      }).catch(callback);\n    };\n\n    // If opts.since exists, get all the changes from the sequence\n    // number given by opts.since. Otherwise, get all the changes\n    // from the sequence number 0.\n    var results = {results: []};\n\n    var fetched = function (err, res) {\n      if (opts.aborted) {\n        return;\n      }\n      var raw_results_length = 0;\n      // If the result of the ajax call (res) contains changes (res.results)\n      if (res && res.results) {\n        raw_results_length = res.results.length;\n        results.last_seq = res.last_seq;\n        var pending = null;\n        var lastSeq = null;\n        // Attach 'pending' property if server supports it (CouchDB 2.0+)\n        /* istanbul ignore if */\n        if (typeof res.pending === 'number') {\n          pending = res.pending;\n        }\n        if (typeof results.last_seq === 'string' || typeof results.last_seq === 'number') {\n          lastSeq = results.last_seq;\n        }\n        // For each change\n        var req = {};\n        req.query = opts.query_params;\n        res.results = res.results.filter(function (c) {\n          leftToFetch--;\n          var ret = filterChange(opts)(c);\n          if (ret) {\n            if (opts.include_docs && opts.attachments && opts.binary) {\n              readAttachmentsAsBlobOrBuffer(c);\n            }\n            if (opts.return_docs) {\n              results.results.push(c);\n            }\n            opts.onChange(c, pending, lastSeq);\n          }\n          return ret;\n        });\n      } else if (err) {\n        // In case of an error, stop listening for changes and call\n        // opts.complete\n        opts.aborted = true;\n        opts.complete(err);\n        return;\n      }\n\n      // The changes feed may have timed out with no results\n      // if so reuse last update sequence\n      if (res && res.last_seq) {\n        lastFetchedSeq = res.last_seq;\n      }\n\n      var finished = (limit && leftToFetch <= 0) ||\n        (res && raw_results_length < batchSize) ||\n        (opts.descending);\n\n      if ((opts.continuous && !(limit && leftToFetch <= 0)) || !finished) {\n        // Queue a call to fetch again with the newest sequence number\n        immediate(function () { fetchData(lastFetchedSeq, fetched); });\n      } else {\n        // We're done, call the callback\n        opts.complete(null, results);\n      }\n    };\n\n    fetchData(opts.since || 0, fetched);\n\n    // Return a method to cancel this method from processing any more\n    return {\n      cancel: function () {\n        opts.aborted = true;\n        controller.abort();\n      }\n    };\n  };\n\n  // Given a set of document/revision IDs (given by req), tets the subset of\n  // those that do NOT correspond to revisions stored in the database.\n  // See http://wiki.apache.org/couchdb/HttpPostRevsDiff\n  api.revsDiff = adapterFun$$1('revsDiff', function (req, opts, callback) {\n    // If no options were given, set the callback to be the second parameter\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n\n    // Get the missing document/revision IDs\n    fetchJSON(genDBUrl(host, '_revs_diff'), {\n      method: 'POST',\n      body: JSON.stringify(req)\n    }, callback).catch(callback);\n  });\n\n  api._close = function (callback) {\n    callback();\n  };\n\n  api._destroy = function (options, callback) {\n    fetchJSON(genDBUrl(host, ''), {method: 'DELETE'}).then(function (json) {\n      callback(null, json);\n    }).catch(function (err) {\n      /* istanbul ignore if */\n      if (err.status === 404) {\n        callback(null, {ok: true});\n      } else {\n        callback(err);\n      }\n    });\n  };\n}\n\n// HttpPouch is a valid adapter.\nHttpPouch.valid = function () {\n  return true;\n};\n\nfunction HttpPouch$1 (PouchDB) {\n  PouchDB.adapter('http', HttpPouch, false);\n  PouchDB.adapter('https', HttpPouch, false);\n}\n\nfunction QueryParseError(message) {\n  this.status = 400;\n  this.name = 'query_parse_error';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, QueryParseError);\n  } catch (e) {}\n}\n\ninherits(QueryParseError, Error);\n\nfunction NotFoundError(message) {\n  this.status = 404;\n  this.name = 'not_found';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, NotFoundError);\n  } catch (e) {}\n}\n\ninherits(NotFoundError, Error);\n\nfunction BuiltInError(message) {\n  this.status = 500;\n  this.name = 'invalid_value';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, BuiltInError);\n  } catch (e) {}\n}\n\ninherits(BuiltInError, Error);\n\nfunction promisedCallback(promise, callback) {\n  if (callback) {\n    promise.then(function (res) {\n      immediate(function () {\n        callback(null, res);\n      });\n    }, function (reason) {\n      immediate(function () {\n        callback(reason);\n      });\n    });\n  }\n  return promise;\n}\n\nfunction callbackify(fun) {\n  return getArguments(function (args) {\n    var cb = args.pop();\n    var promise = fun.apply(this, args);\n    if (typeof cb === 'function') {\n      promisedCallback(promise, cb);\n    }\n    return promise;\n  });\n}\n\n// Promise finally util similar to Q.finally\nfunction fin(promise, finalPromiseFactory) {\n  return promise.then(function (res) {\n    return finalPromiseFactory().then(function () {\n      return res;\n    });\n  }, function (reason) {\n    return finalPromiseFactory().then(function () {\n      throw reason;\n    });\n  });\n}\n\nfunction sequentialize(queue, promiseFactory) {\n  return function () {\n    var args = arguments;\n    var that = this;\n    return queue.add(function () {\n      return promiseFactory.apply(that, args);\n    });\n  };\n}\n\n// uniq an array of strings, order not guaranteed\n// similar to underscore/lodash _.uniq\nfunction uniq(arr) {\n  var theSet = new ExportedSet(arr);\n  var result = new Array(theSet.size);\n  var index = -1;\n  theSet.forEach(function (value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\nfunction mapToKeysArray(map) {\n  var result = new Array(map.size);\n  var index = -1;\n  map.forEach(function (value, key) {\n    result[++index] = key;\n  });\n  return result;\n}\n\nfunction createBuiltInError(name) {\n  var message = 'builtin ' + name +\n    ' function requires map values to be numbers' +\n    ' or number arrays';\n  return new BuiltInError(message);\n}\n\nfunction sum(values) {\n  var result = 0;\n  for (var i = 0, len = values.length; i < len; i++) {\n    var num = values[i];\n    if (typeof num !== 'number') {\n      if (Array.isArray(num)) {\n        // lists of numbers are also allowed, sum them separately\n        result = typeof result === 'number' ? [result] : result;\n        for (var j = 0, jLen = num.length; j < jLen; j++) {\n          var jNum = num[j];\n          if (typeof jNum !== 'number') {\n            throw createBuiltInError('_sum');\n          } else if (typeof result[j] === 'undefined') {\n            result.push(jNum);\n          } else {\n            result[j] += jNum;\n          }\n        }\n      } else { // not array/number\n        throw createBuiltInError('_sum');\n      }\n    } else if (typeof result === 'number') {\n      result += num;\n    } else { // add number to array\n      result[0] += num;\n    }\n  }\n  return result;\n}\n\nvar log = guardedConsole.bind(null, 'log');\nvar isArray = Array.isArray;\nvar toJSON = JSON.parse;\n\nfunction evalFunctionWithEval(func, emit) {\n  return scopeEval(\n    \"return (\" + func.replace(/;\\s*$/, \"\") + \");\",\n    {\n      emit: emit,\n      sum: sum,\n      log: log,\n      isArray: isArray,\n      toJSON: toJSON\n    }\n  );\n}\n\n/*\n * Simple task queue to sequentialize actions. Assumes\n * callbacks will eventually fire (once).\n */\n\n\nfunction TaskQueue$1() {\n  this.promise = new Promise(function (fulfill) {fulfill(); });\n}\nTaskQueue$1.prototype.add = function (promiseFactory) {\n  this.promise = this.promise.catch(function () {\n    // just recover\n  }).then(function () {\n    return promiseFactory();\n  });\n  return this.promise;\n};\nTaskQueue$1.prototype.finish = function () {\n  return this.promise;\n};\n\nfunction stringify(input) {\n  if (!input) {\n    return 'undefined'; // backwards compat for empty reduce\n  }\n  // for backwards compat with mapreduce, functions/strings are stringified\n  // as-is. everything else is JSON-stringified.\n  switch (typeof input) {\n    case 'function':\n      // e.g. a mapreduce map\n      return input.toString();\n    case 'string':\n      // e.g. a mapreduce built-in _reduce function\n      return input.toString();\n    default:\n      // e.g. a JSON object in the case of mango queries\n      return JSON.stringify(input);\n  }\n}\n\n/* create a string signature for a view so we can cache it and uniq it */\nfunction createViewSignature(mapFun, reduceFun) {\n  // the \"undefined\" part is for backwards compatibility\n  return stringify(mapFun) + stringify(reduceFun) + 'undefined';\n}\n\nfunction createView(sourceDB, viewName, mapFun, reduceFun, temporary, localDocName) {\n  var viewSignature = createViewSignature(mapFun, reduceFun);\n\n  var cachedViews;\n  if (!temporary) {\n    // cache this to ensure we don't try to update the same view twice\n    cachedViews = sourceDB._cachedViews = sourceDB._cachedViews || {};\n    if (cachedViews[viewSignature]) {\n      return cachedViews[viewSignature];\n    }\n  }\n\n  var promiseForView = sourceDB.info().then(function (info) {\n\n    var depDbName = info.db_name + '-mrview-' +\n      (temporary ? 'temp' : stringMd5(viewSignature));\n\n    // save the view name in the source db so it can be cleaned up if necessary\n    // (e.g. when the _design doc is deleted, remove all associated view data)\n    function diffFunction(doc) {\n      doc.views = doc.views || {};\n      var fullViewName = viewName;\n      if (fullViewName.indexOf('/') === -1) {\n        fullViewName = viewName + '/' + viewName;\n      }\n      var depDbs = doc.views[fullViewName] = doc.views[fullViewName] || {};\n      /* istanbul ignore if */\n      if (depDbs[depDbName]) {\n        return; // no update necessary\n      }\n      depDbs[depDbName] = true;\n      return doc;\n    }\n    return upsert(sourceDB, '_local/' + localDocName, diffFunction).then(function () {\n      return sourceDB.registerDependentDatabase(depDbName).then(function (res) {\n        var db = res.db;\n        db.auto_compaction = true;\n        var view = {\n          name: depDbName,\n          db: db,\n          sourceDB: sourceDB,\n          adapter: sourceDB.adapter,\n          mapFun: mapFun,\n          reduceFun: reduceFun\n        };\n        return view.db.get('_local/lastSeq').catch(function (err) {\n          /* istanbul ignore if */\n          if (err.status !== 404) {\n            throw err;\n          }\n        }).then(function (lastSeqDoc) {\n          view.seq = lastSeqDoc ? lastSeqDoc.seq : 0;\n          if (cachedViews) {\n            view.db.once('destroyed', function () {\n              delete cachedViews[viewSignature];\n            });\n          }\n          return view;\n        });\n      });\n    });\n  });\n\n  if (cachedViews) {\n    cachedViews[viewSignature] = promiseForView;\n  }\n  return promiseForView;\n}\n\nvar persistentQueues = {};\nvar tempViewQueue = new TaskQueue$1();\nvar CHANGES_BATCH_SIZE$1 = 50;\n\nfunction parseViewName(name) {\n  // can be either 'ddocname/viewname' or just 'viewname'\n  // (where the ddoc name is the same)\n  return name.indexOf('/') === -1 ? [name, name] : name.split('/');\n}\n\nfunction isGenOne(changes) {\n  // only return true if the current change is 1-\n  // and there are no other leafs\n  return changes.length === 1 && /^1-/.test(changes[0].rev);\n}\n\nfunction emitError(db, e) {\n  try {\n    db.emit('error', e);\n  } catch (err) {\n    guardedConsole('error',\n      'The user\\'s map/reduce function threw an uncaught error.\\n' +\n      'You can debug this error by doing:\\n' +\n      'myDatabase.on(\\'error\\', function (err) { debugger; });\\n' +\n      'Please double-check your map/reduce function.');\n    guardedConsole('error', e);\n  }\n}\n\n/**\n * Returns an \"abstract\" mapreduce object of the form:\n *\n *   {\n *     query: queryFun,\n *     viewCleanup: viewCleanupFun\n *   }\n *\n * Arguments are:\n *\n * localDoc: string\n *   This is for the local doc that gets saved in order to track the\n *   \"dependent\" DBs and clean them up for viewCleanup. It should be\n *   unique, so that indexer plugins don't collide with each other.\n * mapper: function (mapFunDef, emit)\n *   Returns a map function based on the mapFunDef, which in the case of\n *   normal map/reduce is just the de-stringified function, but may be\n *   something else, such as an object in the case of pouchdb-find.\n * reducer: function (reduceFunDef)\n *   Ditto, but for reducing. Modules don't have to support reducing\n *   (e.g. pouchdb-find).\n * ddocValidator: function (ddoc, viewName)\n *   Throws an error if the ddoc or viewName is not valid.\n *   This could be a way to communicate to the user that the configuration for the\n *   indexer is invalid.\n */\nfunction createAbstractMapReduce(localDocName, mapper, reducer, ddocValidator) {\n\n  function tryMap(db, fun, doc) {\n    // emit an event if there was an error thrown by a map function.\n    // putting try/catches in a single function also avoids deoptimizations.\n    try {\n      fun(doc);\n    } catch (e) {\n      emitError(db, e);\n    }\n  }\n\n  function tryReduce(db, fun, keys, values, rereduce) {\n    // same as above, but returning the result or an error. there are two separate\n    // functions to avoid extra memory allocations since the tryCode() case is used\n    // for custom map functions (common) vs this function, which is only used for\n    // custom reduce functions (rare)\n    try {\n      return {output : fun(keys, values, rereduce)};\n    } catch (e) {\n      emitError(db, e);\n      return {error: e};\n    }\n  }\n\n  function sortByKeyThenValue(x, y) {\n    var keyCompare = collate(x.key, y.key);\n    return keyCompare !== 0 ? keyCompare : collate(x.value, y.value);\n  }\n\n  function sliceResults(results, limit, skip) {\n    skip = skip || 0;\n    if (typeof limit === 'number') {\n      return results.slice(skip, limit + skip);\n    } else if (skip > 0) {\n      return results.slice(skip);\n    }\n    return results;\n  }\n\n  function rowToDocId(row) {\n    var val = row.value;\n    // Users can explicitly specify a joined doc _id, or it\n    // defaults to the doc _id that emitted the key/value.\n    var docId = (val && typeof val === 'object' && val._id) || row.id;\n    return docId;\n  }\n\n  function readAttachmentsAsBlobOrBuffer(res) {\n    res.rows.forEach(function (row) {\n      var atts = row.doc && row.doc._attachments;\n      if (!atts) {\n        return;\n      }\n      Object.keys(atts).forEach(function (filename) {\n        var att = atts[filename];\n        atts[filename].data = b64ToBluffer(att.data, att.content_type);\n      });\n    });\n  }\n\n  function postprocessAttachments(opts) {\n    return function (res) {\n      if (opts.include_docs && opts.attachments && opts.binary) {\n        readAttachmentsAsBlobOrBuffer(res);\n      }\n      return res;\n    };\n  }\n\n  function addHttpParam(paramName, opts, params, asJson) {\n    // add an http param from opts to params, optionally json-encoded\n    var val = opts[paramName];\n    if (typeof val !== 'undefined') {\n      if (asJson) {\n        val = encodeURIComponent(JSON.stringify(val));\n      }\n      params.push(paramName + '=' + val);\n    }\n  }\n\n  function coerceInteger(integerCandidate) {\n    if (typeof integerCandidate !== 'undefined') {\n      var asNumber = Number(integerCandidate);\n      // prevents e.g. '1foo' or '1.1' being coerced to 1\n      if (!isNaN(asNumber) && asNumber === parseInt(integerCandidate, 10)) {\n        return asNumber;\n      } else {\n        return integerCandidate;\n      }\n    }\n  }\n\n  function coerceOptions(opts) {\n    opts.group_level = coerceInteger(opts.group_level);\n    opts.limit = coerceInteger(opts.limit);\n    opts.skip = coerceInteger(opts.skip);\n    return opts;\n  }\n\n  function checkPositiveInteger(number) {\n    if (number) {\n      if (typeof number !== 'number') {\n        return  new QueryParseError('Invalid value for integer: \"' +\n          number + '\"');\n      }\n      if (number < 0) {\n        return new QueryParseError('Invalid value for positive integer: ' +\n          '\"' + number + '\"');\n      }\n    }\n  }\n\n  function checkQueryParseError(options, fun) {\n    var startkeyName = options.descending ? 'endkey' : 'startkey';\n    var endkeyName = options.descending ? 'startkey' : 'endkey';\n\n    if (typeof options[startkeyName] !== 'undefined' &&\n      typeof options[endkeyName] !== 'undefined' &&\n      collate(options[startkeyName], options[endkeyName]) > 0) {\n      throw new QueryParseError('No rows can match your key range, ' +\n        'reverse your start_key and end_key or set {descending : true}');\n    } else if (fun.reduce && options.reduce !== false) {\n      if (options.include_docs) {\n        throw new QueryParseError('{include_docs:true} is invalid for reduce');\n      } else if (options.keys && options.keys.length > 1 &&\n        !options.group && !options.group_level) {\n        throw new QueryParseError('Multi-key fetches for reduce views must use ' +\n          '{group: true}');\n      }\n    }\n    ['group_level', 'limit', 'skip'].forEach(function (optionName) {\n      var error = checkPositiveInteger(options[optionName]);\n      if (error) {\n        throw error;\n      }\n    });\n  }\n\n  function httpQuery(db, fun, opts) {\n    // List of parameters to add to the PUT request\n    var params = [];\n    var body;\n    var method = 'GET';\n    var ok, status;\n\n    // If opts.reduce exists and is defined, then add it to the list\n    // of parameters.\n    // If reduce=false then the results are that of only the map function\n    // not the final result of map and reduce.\n    addHttpParam('reduce', opts, params);\n    addHttpParam('include_docs', opts, params);\n    addHttpParam('attachments', opts, params);\n    addHttpParam('limit', opts, params);\n    addHttpParam('descending', opts, params);\n    addHttpParam('group', opts, params);\n    addHttpParam('group_level', opts, params);\n    addHttpParam('skip', opts, params);\n    addHttpParam('stale', opts, params);\n    addHttpParam('conflicts', opts, params);\n    addHttpParam('startkey', opts, params, true);\n    addHttpParam('start_key', opts, params, true);\n    addHttpParam('endkey', opts, params, true);\n    addHttpParam('end_key', opts, params, true);\n    addHttpParam('inclusive_end', opts, params);\n    addHttpParam('key', opts, params, true);\n    addHttpParam('update_seq', opts, params);\n\n    // Format the list of parameters into a valid URI query string\n    params = params.join('&');\n    params = params === '' ? '' : '?' + params;\n\n    // If keys are supplied, issue a POST to circumvent GET query string limits\n    // see http://wiki.apache.org/couchdb/HTTP_view_API#Querying_Options\n    if (typeof opts.keys !== 'undefined') {\n      var MAX_URL_LENGTH = 2000;\n      // according to http://stackoverflow.com/a/417184/680742,\n      // the de facto URL length limit is 2000 characters\n\n      var keysAsString =\n        'keys=' + encodeURIComponent(JSON.stringify(opts.keys));\n      if (keysAsString.length + params.length + 1 <= MAX_URL_LENGTH) {\n        // If the keys are short enough, do a GET. we do this to work around\n        // Safari not understanding 304s on POSTs (see pouchdb/pouchdb#1239)\n        params += (params[0] === '?' ? '&' : '?') + keysAsString;\n      } else {\n        method = 'POST';\n        if (typeof fun === 'string') {\n          body = {keys: opts.keys};\n        } else { // fun is {map : mapfun}, so append to this\n          fun.keys = opts.keys;\n        }\n      }\n    }\n\n    // We are referencing a query defined in the design doc\n    if (typeof fun === 'string') {\n      var parts = parseViewName(fun);\n      return db.fetch('_design/' + parts[0] + '/_view/' + parts[1] + params, {\n        headers: new h({'Content-Type': 'application/json'}),\n        method: method,\n        body: JSON.stringify(body)\n      }).then(function (response) {\n        ok = response.ok;\n        status = response.status;\n        return response.json();\n      }).then(function (result) {\n        if (!ok) {\n          result.status = status;\n          throw generateErrorFromResponse(result);\n        }\n        // fail the entire request if the result contains an error\n        result.rows.forEach(function (row) {\n          /* istanbul ignore if */\n          if (row.value && row.value.error && row.value.error === \"builtin_reduce_error\") {\n            throw new Error(row.reason);\n          }\n        });\n        return result;\n      }).then(postprocessAttachments(opts));\n    }\n\n    // We are using a temporary view, terrible for performance, good for testing\n    body = body || {};\n    Object.keys(fun).forEach(function (key) {\n      if (Array.isArray(fun[key])) {\n        body[key] = fun[key];\n      } else {\n        body[key] = fun[key].toString();\n      }\n    });\n\n    return db.fetch('_temp_view' + params, {\n      headers: new h({'Content-Type': 'application/json'}),\n      method: 'POST',\n      body: JSON.stringify(body)\n    }).then(function (response) {\n        ok = response.ok;\n        status = response.status;\n      return response.json();\n    }).then(function (result) {\n      if (!ok) {\n        result.status = status;\n        throw generateErrorFromResponse(result);\n      }\n      return result;\n    }).then(postprocessAttachments(opts));\n  }\n\n  // custom adapters can define their own api._query\n  // and override the default behavior\n  /* istanbul ignore next */\n  function customQuery(db, fun, opts) {\n    return new Promise(function (resolve, reject) {\n      db._query(fun, opts, function (err, res) {\n        if (err) {\n          return reject(err);\n        }\n        resolve(res);\n      });\n    });\n  }\n\n  // custom adapters can define their own api._viewCleanup\n  // and override the default behavior\n  /* istanbul ignore next */\n  function customViewCleanup(db) {\n    return new Promise(function (resolve, reject) {\n      db._viewCleanup(function (err, res) {\n        if (err) {\n          return reject(err);\n        }\n        resolve(res);\n      });\n    });\n  }\n\n  function defaultsTo(value) {\n    return function (reason) {\n      /* istanbul ignore else */\n      if (reason.status === 404) {\n        return value;\n      } else {\n        throw reason;\n      }\n    };\n  }\n\n  // returns a promise for a list of docs to update, based on the input docId.\n  // the order doesn't matter, because post-3.2.0, bulkDocs\n  // is an atomic operation in all three adapters.\n  function getDocsToPersist(docId, view, docIdsToChangesAndEmits) {\n    var metaDocId = '_local/doc_' + docId;\n    var defaultMetaDoc = {_id: metaDocId, keys: []};\n    var docData = docIdsToChangesAndEmits.get(docId);\n    var indexableKeysToKeyValues = docData[0];\n    var changes = docData[1];\n\n    function getMetaDoc() {\n      if (isGenOne(changes)) {\n        // generation 1, so we can safely assume initial state\n        // for performance reasons (avoids unnecessary GETs)\n        return Promise.resolve(defaultMetaDoc);\n      }\n      return view.db.get(metaDocId).catch(defaultsTo(defaultMetaDoc));\n    }\n\n    function getKeyValueDocs(metaDoc) {\n      if (!metaDoc.keys.length) {\n        // no keys, no need for a lookup\n        return Promise.resolve({rows: []});\n      }\n      return view.db.allDocs({\n        keys: metaDoc.keys,\n        include_docs: true\n      });\n    }\n\n    function processKeyValueDocs(metaDoc, kvDocsRes) {\n      var kvDocs = [];\n      var oldKeys = new ExportedSet();\n\n      for (var i = 0, len = kvDocsRes.rows.length; i < len; i++) {\n        var row = kvDocsRes.rows[i];\n        var doc = row.doc;\n        if (!doc) { // deleted\n          continue;\n        }\n        kvDocs.push(doc);\n        oldKeys.add(doc._id);\n        doc._deleted = !indexableKeysToKeyValues.has(doc._id);\n        if (!doc._deleted) {\n          var keyValue = indexableKeysToKeyValues.get(doc._id);\n          if ('value' in keyValue) {\n            doc.value = keyValue.value;\n          }\n        }\n      }\n      var newKeys = mapToKeysArray(indexableKeysToKeyValues);\n      newKeys.forEach(function (key) {\n        if (!oldKeys.has(key)) {\n          // new doc\n          var kvDoc = {\n            _id: key\n          };\n          var keyValue = indexableKeysToKeyValues.get(key);\n          if ('value' in keyValue) {\n            kvDoc.value = keyValue.value;\n          }\n          kvDocs.push(kvDoc);\n        }\n      });\n      metaDoc.keys = uniq(newKeys.concat(metaDoc.keys));\n      kvDocs.push(metaDoc);\n\n      return kvDocs;\n    }\n\n    return getMetaDoc().then(function (metaDoc) {\n      return getKeyValueDocs(metaDoc).then(function (kvDocsRes) {\n        return processKeyValueDocs(metaDoc, kvDocsRes);\n      });\n    });\n  }\n\n  // updates all emitted key/value docs and metaDocs in the mrview database\n  // for the given batch of documents from the source database\n  function saveKeyValues(view, docIdsToChangesAndEmits, seq) {\n    var seqDocId = '_local/lastSeq';\n    return view.db.get(seqDocId)\n      .catch(defaultsTo({_id: seqDocId, seq: 0}))\n      .then(function (lastSeqDoc) {\n        var docIds = mapToKeysArray(docIdsToChangesAndEmits);\n        return Promise.all(docIds.map(function (docId) {\n          return getDocsToPersist(docId, view, docIdsToChangesAndEmits);\n        })).then(function (listOfDocsToPersist) {\n          var docsToPersist = flatten(listOfDocsToPersist);\n          lastSeqDoc.seq = seq;\n          docsToPersist.push(lastSeqDoc);\n          // write all docs in a single operation, update the seq once\n          return view.db.bulkDocs({docs : docsToPersist});\n        });\n      });\n  }\n\n  function getQueue(view) {\n    var viewName = typeof view === 'string' ? view : view.name;\n    var queue = persistentQueues[viewName];\n    if (!queue) {\n      queue = persistentQueues[viewName] = new TaskQueue$1();\n    }\n    return queue;\n  }\n\n  function updateView(view) {\n    return sequentialize(getQueue(view), function () {\n      return updateViewInQueue(view);\n    })();\n  }\n\n  function updateViewInQueue(view) {\n    // bind the emit function once\n    var mapResults;\n    var doc;\n\n    function emit(key, value) {\n      var output = {id: doc._id, key: normalizeKey(key)};\n      // Don't explicitly store the value unless it's defined and non-null.\n      // This saves on storage space, because often people don't use it.\n      if (typeof value !== 'undefined' && value !== null) {\n        output.value = normalizeKey(value);\n      }\n      mapResults.push(output);\n    }\n\n    var mapFun = mapper(view.mapFun, emit);\n\n    var currentSeq = view.seq || 0;\n\n    function processChange(docIdsToChangesAndEmits, seq) {\n      return function () {\n        return saveKeyValues(view, docIdsToChangesAndEmits, seq);\n      };\n    }\n\n    var queue = new TaskQueue$1();\n\n    function processNextBatch() {\n      return view.sourceDB.changes({\n        return_docs: true,\n        conflicts: true,\n        include_docs: true,\n        style: 'all_docs',\n        since: currentSeq,\n        limit: CHANGES_BATCH_SIZE$1\n      }).then(processBatch);\n    }\n\n    function processBatch(response) {\n      var results = response.results;\n      if (!results.length) {\n        return;\n      }\n      var docIdsToChangesAndEmits = createDocIdsToChangesAndEmits(results);\n      queue.add(processChange(docIdsToChangesAndEmits, currentSeq));\n      if (results.length < CHANGES_BATCH_SIZE$1) {\n        return;\n      }\n      return processNextBatch();\n    }\n\n    function createDocIdsToChangesAndEmits(results) {\n      var docIdsToChangesAndEmits = new ExportedMap();\n      for (var i = 0, len = results.length; i < len; i++) {\n        var change = results[i];\n        if (change.doc._id[0] !== '_') {\n          mapResults = [];\n          doc = change.doc;\n\n          if (!doc._deleted) {\n            tryMap(view.sourceDB, mapFun, doc);\n          }\n          mapResults.sort(sortByKeyThenValue);\n\n          var indexableKeysToKeyValues = createIndexableKeysToKeyValues(mapResults);\n          docIdsToChangesAndEmits.set(change.doc._id, [\n            indexableKeysToKeyValues,\n            change.changes\n          ]);\n        }\n        currentSeq = change.seq;\n      }\n      return docIdsToChangesAndEmits;\n    }\n\n    function createIndexableKeysToKeyValues(mapResults) {\n      var indexableKeysToKeyValues = new ExportedMap();\n      var lastKey;\n      for (var i = 0, len = mapResults.length; i < len; i++) {\n        var emittedKeyValue = mapResults[i];\n        var complexKey = [emittedKeyValue.key, emittedKeyValue.id];\n        if (i > 0 && collate(emittedKeyValue.key, lastKey) === 0) {\n          complexKey.push(i); // dup key+id, so make it unique\n        }\n        indexableKeysToKeyValues.set(toIndexableString(complexKey), emittedKeyValue);\n        lastKey = emittedKeyValue.key;\n      }\n      return indexableKeysToKeyValues;\n    }\n\n    return processNextBatch().then(function () {\n      return queue.finish();\n    }).then(function () {\n      view.seq = currentSeq;\n    });\n  }\n\n  function reduceView(view, results, options) {\n    if (options.group_level === 0) {\n      delete options.group_level;\n    }\n\n    var shouldGroup = options.group || options.group_level;\n\n    var reduceFun = reducer(view.reduceFun);\n\n    var groups = [];\n    var lvl = isNaN(options.group_level) ? Number.POSITIVE_INFINITY :\n      options.group_level;\n    results.forEach(function (e) {\n      var last = groups[groups.length - 1];\n      var groupKey = shouldGroup ? e.key : null;\n\n      // only set group_level for array keys\n      if (shouldGroup && Array.isArray(groupKey)) {\n        groupKey = groupKey.slice(0, lvl);\n      }\n\n      if (last && collate(last.groupKey, groupKey) === 0) {\n        last.keys.push([e.key, e.id]);\n        last.values.push(e.value);\n        return;\n      }\n      groups.push({\n        keys: [[e.key, e.id]],\n        values: [e.value],\n        groupKey: groupKey\n      });\n    });\n    results = [];\n    for (var i = 0, len = groups.length; i < len; i++) {\n      var e = groups[i];\n      var reduceTry = tryReduce(view.sourceDB, reduceFun, e.keys, e.values, false);\n      if (reduceTry.error && reduceTry.error instanceof BuiltInError) {\n        // CouchDB returns an error if a built-in errors out\n        throw reduceTry.error;\n      }\n      results.push({\n        // CouchDB just sets the value to null if a non-built-in errors out\n        value: reduceTry.error ? null : reduceTry.output,\n        key: e.groupKey\n      });\n    }\n    // no total_rows/offset when reducing\n    return {rows: sliceResults(results, options.limit, options.skip)};\n  }\n\n  function queryView(view, opts) {\n    return sequentialize(getQueue(view), function () {\n      return queryViewInQueue(view, opts);\n    })();\n  }\n\n  function queryViewInQueue(view, opts) {\n    var totalRows;\n    var shouldReduce = view.reduceFun && opts.reduce !== false;\n    var skip = opts.skip || 0;\n    if (typeof opts.keys !== 'undefined' && !opts.keys.length) {\n      // equivalent query\n      opts.limit = 0;\n      delete opts.keys;\n    }\n\n    function fetchFromView(viewOpts) {\n      viewOpts.include_docs = true;\n      return view.db.allDocs(viewOpts).then(function (res) {\n        totalRows = res.total_rows;\n        return res.rows.map(function (result) {\n\n          // implicit migration - in older versions of PouchDB,\n          // we explicitly stored the doc as {id: ..., key: ..., value: ...}\n          // this is tested in a migration test\n          /* istanbul ignore next */\n          if ('value' in result.doc && typeof result.doc.value === 'object' &&\n            result.doc.value !== null) {\n            var keys = Object.keys(result.doc.value).sort();\n            // this detection method is not perfect, but it's unlikely the user\n            // emitted a value which was an object with these 3 exact keys\n            var expectedKeys = ['id', 'key', 'value'];\n            if (!(keys < expectedKeys || keys > expectedKeys)) {\n              return result.doc.value;\n            }\n          }\n\n          var parsedKeyAndDocId = parseIndexableString(result.doc._id);\n          return {\n            key: parsedKeyAndDocId[0],\n            id: parsedKeyAndDocId[1],\n            value: ('value' in result.doc ? result.doc.value : null)\n          };\n        });\n      });\n    }\n\n    function onMapResultsReady(rows) {\n      var finalResults;\n      if (shouldReduce) {\n        finalResults = reduceView(view, rows, opts);\n      } else {\n        finalResults = {\n          total_rows: totalRows,\n          offset: skip,\n          rows: rows\n        };\n      }\n      /* istanbul ignore if */\n      if (opts.update_seq) {\n        finalResults.update_seq = view.seq;\n      }\n      if (opts.include_docs) {\n        var docIds = uniq(rows.map(rowToDocId));\n\n        return view.sourceDB.allDocs({\n          keys: docIds,\n          include_docs: true,\n          conflicts: opts.conflicts,\n          attachments: opts.attachments,\n          binary: opts.binary\n        }).then(function (allDocsRes) {\n          var docIdsToDocs = new ExportedMap();\n          allDocsRes.rows.forEach(function (row) {\n            docIdsToDocs.set(row.id, row.doc);\n          });\n          rows.forEach(function (row) {\n            var docId = rowToDocId(row);\n            var doc = docIdsToDocs.get(docId);\n            if (doc) {\n              row.doc = doc;\n            }\n          });\n          return finalResults;\n        });\n      } else {\n        return finalResults;\n      }\n    }\n\n    if (typeof opts.keys !== 'undefined') {\n      var keys = opts.keys;\n      var fetchPromises = keys.map(function (key) {\n        var viewOpts = {\n          startkey : toIndexableString([key]),\n          endkey   : toIndexableString([key, {}])\n        };\n        /* istanbul ignore if */\n        if (opts.update_seq) {\n          viewOpts.update_seq = true;\n        }\n        return fetchFromView(viewOpts);\n      });\n      return Promise.all(fetchPromises).then(flatten).then(onMapResultsReady);\n    } else { // normal query, no 'keys'\n      var viewOpts = {\n        descending : opts.descending\n      };\n      /* istanbul ignore if */\n      if (opts.update_seq) {\n        viewOpts.update_seq = true;\n      }\n      var startkey;\n      var endkey;\n      if ('start_key' in opts) {\n        startkey = opts.start_key;\n      }\n      if ('startkey' in opts) {\n        startkey = opts.startkey;\n      }\n      if ('end_key' in opts) {\n        endkey = opts.end_key;\n      }\n      if ('endkey' in opts) {\n        endkey = opts.endkey;\n      }\n      if (typeof startkey !== 'undefined') {\n        viewOpts.startkey = opts.descending ?\n          toIndexableString([startkey, {}]) :\n          toIndexableString([startkey]);\n      }\n      if (typeof endkey !== 'undefined') {\n        var inclusiveEnd = opts.inclusive_end !== false;\n        if (opts.descending) {\n          inclusiveEnd = !inclusiveEnd;\n        }\n\n        viewOpts.endkey = toIndexableString(\n          inclusiveEnd ? [endkey, {}] : [endkey]);\n      }\n      if (typeof opts.key !== 'undefined') {\n        var keyStart = toIndexableString([opts.key]);\n        var keyEnd = toIndexableString([opts.key, {}]);\n        if (viewOpts.descending) {\n          viewOpts.endkey = keyStart;\n          viewOpts.startkey = keyEnd;\n        } else {\n          viewOpts.startkey = keyStart;\n          viewOpts.endkey = keyEnd;\n        }\n      }\n      if (!shouldReduce) {\n        if (typeof opts.limit === 'number') {\n          viewOpts.limit = opts.limit;\n        }\n        viewOpts.skip = skip;\n      }\n      return fetchFromView(viewOpts).then(onMapResultsReady);\n    }\n  }\n\n  function httpViewCleanup(db) {\n    return db.fetch('_view_cleanup', {\n      headers: new h({'Content-Type': 'application/json'}),\n      method: 'POST'\n    }).then(function (response) {\n      return response.json();\n    });\n  }\n\n  function localViewCleanup(db) {\n    return db.get('_local/' + localDocName).then(function (metaDoc) {\n      var docsToViews = new ExportedMap();\n      Object.keys(metaDoc.views).forEach(function (fullViewName) {\n        var parts = parseViewName(fullViewName);\n        var designDocName = '_design/' + parts[0];\n        var viewName = parts[1];\n        var views = docsToViews.get(designDocName);\n        if (!views) {\n          views = new ExportedSet();\n          docsToViews.set(designDocName, views);\n        }\n        views.add(viewName);\n      });\n      var opts = {\n        keys : mapToKeysArray(docsToViews),\n        include_docs : true\n      };\n      return db.allDocs(opts).then(function (res) {\n        var viewsToStatus = {};\n        res.rows.forEach(function (row) {\n          var ddocName = row.key.substring(8); // cuts off '_design/'\n          docsToViews.get(row.key).forEach(function (viewName) {\n            var fullViewName = ddocName + '/' + viewName;\n            /* istanbul ignore if */\n            if (!metaDoc.views[fullViewName]) {\n              // new format, without slashes, to support PouchDB 2.2.0\n              // migration test in pouchdb's browser.migration.js verifies this\n              fullViewName = viewName;\n            }\n            var viewDBNames = Object.keys(metaDoc.views[fullViewName]);\n            // design doc deleted, or view function nonexistent\n            var statusIsGood = row.doc && row.doc.views &&\n              row.doc.views[viewName];\n            viewDBNames.forEach(function (viewDBName) {\n              viewsToStatus[viewDBName] =\n                viewsToStatus[viewDBName] || statusIsGood;\n            });\n          });\n        });\n        var dbsToDelete = Object.keys(viewsToStatus).filter(\n          function (viewDBName) { return !viewsToStatus[viewDBName]; });\n        var destroyPromises = dbsToDelete.map(function (viewDBName) {\n          return sequentialize(getQueue(viewDBName), function () {\n            return new db.constructor(viewDBName, db.__opts).destroy();\n          })();\n        });\n        return Promise.all(destroyPromises).then(function () {\n          return {ok: true};\n        });\n      });\n    }, defaultsTo({ok: true}));\n  }\n\n  function queryPromised(db, fun, opts) {\n    /* istanbul ignore next */\n    if (typeof db._query === 'function') {\n      return customQuery(db, fun, opts);\n    }\n    if (isRemote(db)) {\n      return httpQuery(db, fun, opts);\n    }\n\n    if (typeof fun !== 'string') {\n      // temp_view\n      checkQueryParseError(opts, fun);\n\n      tempViewQueue.add(function () {\n        var createViewPromise = createView(\n          /* sourceDB */ db,\n          /* viewName */ 'temp_view/temp_view',\n          /* mapFun */ fun.map,\n          /* reduceFun */ fun.reduce,\n          /* temporary */ true,\n          /* localDocName */ localDocName);\n        return createViewPromise.then(function (view) {\n          return fin(updateView(view).then(function () {\n            return queryView(view, opts);\n          }), function () {\n            return view.db.destroy();\n          });\n        });\n      });\n      return tempViewQueue.finish();\n    } else {\n      // persistent view\n      var fullViewName = fun;\n      var parts = parseViewName(fullViewName);\n      var designDocName = parts[0];\n      var viewName = parts[1];\n      return db.get('_design/' + designDocName).then(function (doc) {\n        var fun = doc.views && doc.views[viewName];\n\n        if (!fun) {\n          // basic validator; it's assumed that every subclass would want this\n          throw new NotFoundError('ddoc ' + doc._id + ' has no view named ' +\n            viewName);\n        }\n\n        ddocValidator(doc, viewName);\n        checkQueryParseError(opts, fun);\n\n        var createViewPromise = createView(\n          /* sourceDB */ db,\n          /* viewName */ fullViewName,\n          /* mapFun */ fun.map,\n          /* reduceFun */ fun.reduce,\n          /* temporary */ false,\n          /* localDocName */ localDocName);\n        return createViewPromise.then(function (view) {\n          if (opts.stale === 'ok' || opts.stale === 'update_after') {\n            if (opts.stale === 'update_after') {\n              immediate(function () {\n                updateView(view);\n              });\n            }\n            return queryView(view, opts);\n          } else { // stale not ok\n            return updateView(view).then(function () {\n              return queryView(view, opts);\n            });\n          }\n        });\n      });\n    }\n  }\n\n  function abstractQuery(fun, opts, callback) {\n    var db = this;\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = opts ? coerceOptions(opts) : {};\n\n    if (typeof fun === 'function') {\n      fun = {map : fun};\n    }\n\n    var promise = Promise.resolve().then(function () {\n      return queryPromised(db, fun, opts);\n    });\n    promisedCallback(promise, callback);\n    return promise;\n  }\n\n  var abstractViewCleanup = callbackify(function () {\n    var db = this;\n    /* istanbul ignore next */\n    if (typeof db._viewCleanup === 'function') {\n      return customViewCleanup(db);\n    }\n    if (isRemote(db)) {\n      return httpViewCleanup(db);\n    }\n    return localViewCleanup(db);\n  });\n\n  return {\n    query: abstractQuery,\n    viewCleanup: abstractViewCleanup\n  };\n}\n\nvar builtInReduce = {\n  _sum: function (keys, values) {\n    return sum(values);\n  },\n\n  _count: function (keys, values) {\n    return values.length;\n  },\n\n  _stats: function (keys, values) {\n    // no need to implement rereduce=true, because Pouch\n    // will never call it\n    function sumsqr(values) {\n      var _sumsqr = 0;\n      for (var i = 0, len = values.length; i < len; i++) {\n        var num = values[i];\n        _sumsqr += (num * num);\n      }\n      return _sumsqr;\n    }\n    return {\n      sum     : sum(values),\n      min     : Math.min.apply(null, values),\n      max     : Math.max.apply(null, values),\n      count   : values.length,\n      sumsqr : sumsqr(values)\n    };\n  }\n};\n\nfunction getBuiltIn(reduceFunString) {\n  if (/^_sum/.test(reduceFunString)) {\n    return builtInReduce._sum;\n  } else if (/^_count/.test(reduceFunString)) {\n    return builtInReduce._count;\n  } else if (/^_stats/.test(reduceFunString)) {\n    return builtInReduce._stats;\n  } else if (/^_/.test(reduceFunString)) {\n    throw new Error(reduceFunString + ' is not a supported reduce function.');\n  }\n}\n\nfunction mapper(mapFun, emit) {\n  // for temp_views one can use emit(doc, emit), see #38\n  if (typeof mapFun === \"function\" && mapFun.length === 2) {\n    var origMap = mapFun;\n    return function (doc) {\n      return origMap(doc, emit);\n    };\n  } else {\n    return evalFunctionWithEval(mapFun.toString(), emit);\n  }\n}\n\nfunction reducer(reduceFun) {\n  var reduceFunString = reduceFun.toString();\n  var builtIn = getBuiltIn(reduceFunString);\n  if (builtIn) {\n    return builtIn;\n  } else {\n    return evalFunctionWithEval(reduceFunString);\n  }\n}\n\nfunction ddocValidator(ddoc, viewName) {\n  var fun = ddoc.views && ddoc.views[viewName];\n  if (typeof fun.map !== 'string') {\n    throw new NotFoundError('ddoc ' + ddoc._id + ' has no string view named ' +\n      viewName + ', instead found object of type: ' + typeof fun.map);\n  }\n}\n\nvar localDocName = 'mrviews';\nvar abstract = createAbstractMapReduce(localDocName, mapper, reducer, ddocValidator);\n\nfunction query(fun, opts, callback) {\n  return abstract.query.call(this, fun, opts, callback);\n}\n\nfunction viewCleanup(callback) {\n  return abstract.viewCleanup.call(this, callback);\n}\n\nvar mapreduce = {\n  query: query,\n  viewCleanup: viewCleanup\n};\n\nfunction isGenOne$1(rev$$1) {\n  return /^1-/.test(rev$$1);\n}\n\nfunction fileHasChanged(localDoc, remoteDoc, filename) {\n  return !localDoc._attachments ||\n         !localDoc._attachments[filename] ||\n         localDoc._attachments[filename].digest !== remoteDoc._attachments[filename].digest;\n}\n\nfunction getDocAttachments(db, doc) {\n  var filenames = Object.keys(doc._attachments);\n  return Promise.all(filenames.map(function (filename) {\n    return db.getAttachment(doc._id, filename, {rev: doc._rev});\n  }));\n}\n\nfunction getDocAttachmentsFromTargetOrSource(target, src, doc) {\n  var doCheckForLocalAttachments = isRemote(src) && !isRemote(target);\n  var filenames = Object.keys(doc._attachments);\n\n  if (!doCheckForLocalAttachments) {\n    return getDocAttachments(src, doc);\n  }\n\n  return target.get(doc._id).then(function (localDoc) {\n    return Promise.all(filenames.map(function (filename) {\n      if (fileHasChanged(localDoc, doc, filename)) {\n        return src.getAttachment(doc._id, filename);\n      }\n\n      return target.getAttachment(localDoc._id, filename);\n    }));\n  }).catch(function (error) {\n    /* istanbul ignore if */\n    if (error.status !== 404) {\n      throw error;\n    }\n\n    return getDocAttachments(src, doc);\n  });\n}\n\nfunction createBulkGetOpts(diffs) {\n  var requests = [];\n  Object.keys(diffs).forEach(function (id) {\n    var missingRevs = diffs[id].missing;\n    missingRevs.forEach(function (missingRev) {\n      requests.push({\n        id: id,\n        rev: missingRev\n      });\n    });\n  });\n\n  return {\n    docs: requests,\n    revs: true,\n    latest: true\n  };\n}\n\n//\n// Fetch all the documents from the src as described in the \"diffs\",\n// which is a mapping of docs IDs to revisions. If the state ever\n// changes to \"cancelled\", then the returned promise will be rejected.\n// Else it will be resolved with a list of fetched documents.\n//\nfunction getDocs(src, target, diffs, state) {\n  diffs = clone(diffs); // we do not need to modify this\n\n  var resultDocs = [],\n      ok = true;\n\n  function getAllDocs() {\n\n    var bulkGetOpts = createBulkGetOpts(diffs);\n\n    if (!bulkGetOpts.docs.length) { // optimization: skip empty requests\n      return;\n    }\n\n    return src.bulkGet(bulkGetOpts).then(function (bulkGetResponse) {\n      /* istanbul ignore if */\n      if (state.cancelled) {\n        throw new Error('cancelled');\n      }\n      return Promise.all(bulkGetResponse.results.map(function (bulkGetInfo) {\n        return Promise.all(bulkGetInfo.docs.map(function (doc) {\n          var remoteDoc = doc.ok;\n\n          if (doc.error) {\n            // when AUTO_COMPACTION is set, docs can be returned which look\n            // like this: {\"missing\":\"1-7c3ac256b693c462af8442f992b83696\"}\n            ok = false;\n          }\n\n          if (!remoteDoc || !remoteDoc._attachments) {\n            return remoteDoc;\n          }\n\n          return getDocAttachmentsFromTargetOrSource(target, src, remoteDoc)\n                   .then(function (attachments) {\n                           var filenames = Object.keys(remoteDoc._attachments);\n                           attachments\n                             .forEach(function (attachment, i) {\n                                        var att = remoteDoc._attachments[filenames[i]];\n                                        delete att.stub;\n                                        delete att.length;\n                                        att.data = attachment;\n                                      });\n\n                                      return remoteDoc;\n                                    });\n        }));\n      }))\n\n      .then(function (results) {\n        resultDocs = resultDocs.concat(flatten(results).filter(Boolean));\n      });\n    });\n  }\n\n  function hasAttachments(doc) {\n    return doc._attachments && Object.keys(doc._attachments).length > 0;\n  }\n\n  function hasConflicts(doc) {\n    return doc._conflicts && doc._conflicts.length > 0;\n  }\n\n  function fetchRevisionOneDocs(ids) {\n    // Optimization: fetch gen-1 docs and attachments in\n    // a single request using _all_docs\n    return src.allDocs({\n      keys: ids,\n      include_docs: true,\n      conflicts: true\n    }).then(function (res) {\n      if (state.cancelled) {\n        throw new Error('cancelled');\n      }\n      res.rows.forEach(function (row) {\n        if (row.deleted || !row.doc || !isGenOne$1(row.value.rev) ||\n            hasAttachments(row.doc) || hasConflicts(row.doc)) {\n          // if any of these conditions apply, we need to fetch using get()\n          return;\n        }\n\n        // strip _conflicts array to appease CSG (#5793)\n        /* istanbul ignore if */\n        if (row.doc._conflicts) {\n          delete row.doc._conflicts;\n        }\n\n        // the doc we got back from allDocs() is sufficient\n        resultDocs.push(row.doc);\n        delete diffs[row.id];\n      });\n    });\n  }\n\n  function getRevisionOneDocs() {\n    // filter out the generation 1 docs and get them\n    // leaving the non-generation one docs to be got otherwise\n    var ids = Object.keys(diffs).filter(function (id) {\n      var missing = diffs[id].missing;\n      return missing.length === 1 && isGenOne$1(missing[0]);\n    });\n    if (ids.length > 0) {\n      return fetchRevisionOneDocs(ids);\n    }\n  }\n\n  function returnResult() {\n    return { ok:ok, docs:resultDocs };\n  }\n\n  return Promise.resolve()\n    .then(getRevisionOneDocs)\n    .then(getAllDocs)\n    .then(returnResult);\n}\n\nvar CHECKPOINT_VERSION = 1;\nvar REPLICATOR = \"pouchdb\";\n// This is an arbitrary number to limit the\n// amount of replication history we save in the checkpoint.\n// If we save too much, the checkpoing docs will become very big,\n// if we save fewer, we'll run a greater risk of having to\n// read all the changes from 0 when checkpoint PUTs fail\n// CouchDB 2.0 has a more involved history pruning,\n// but let's go for the simple version for now.\nvar CHECKPOINT_HISTORY_SIZE = 5;\nvar LOWEST_SEQ = 0;\n\nfunction updateCheckpoint(db, id, checkpoint, session, returnValue) {\n  return db.get(id).catch(function (err) {\n    if (err.status === 404) {\n      if (db.adapter === 'http' || db.adapter === 'https') {\n        explainError(\n          404, 'PouchDB is just checking if a remote checkpoint exists.'\n        );\n      }\n      return {\n        session_id: session,\n        _id: id,\n        history: [],\n        replicator: REPLICATOR,\n        version: CHECKPOINT_VERSION\n      };\n    }\n    throw err;\n  }).then(function (doc) {\n    if (returnValue.cancelled) {\n      return;\n    }\n\n    // if the checkpoint has not changed, do not update\n    if (doc.last_seq === checkpoint) {\n      return;\n    }\n\n    // Filter out current entry for this replication\n    doc.history = (doc.history || []).filter(function (item) {\n      return item.session_id !== session;\n    });\n\n    // Add the latest checkpoint to history\n    doc.history.unshift({\n      last_seq: checkpoint,\n      session_id: session\n    });\n\n    // Just take the last pieces in history, to\n    // avoid really big checkpoint docs.\n    // see comment on history size above\n    doc.history = doc.history.slice(0, CHECKPOINT_HISTORY_SIZE);\n\n    doc.version = CHECKPOINT_VERSION;\n    doc.replicator = REPLICATOR;\n\n    doc.session_id = session;\n    doc.last_seq = checkpoint;\n\n    return db.put(doc).catch(function (err) {\n      if (err.status === 409) {\n        // retry; someone is trying to write a checkpoint simultaneously\n        return updateCheckpoint(db, id, checkpoint, session, returnValue);\n      }\n      throw err;\n    });\n  });\n}\n\nfunction Checkpointer(src, target, id, returnValue, opts) {\n  this.src = src;\n  this.target = target;\n  this.id = id;\n  this.returnValue = returnValue;\n  this.opts = opts || {};\n}\n\nCheckpointer.prototype.writeCheckpoint = function (checkpoint, session) {\n  var self = this;\n  return this.updateTarget(checkpoint, session).then(function () {\n    return self.updateSource(checkpoint, session);\n  });\n};\n\nCheckpointer.prototype.updateTarget = function (checkpoint, session) {\n  if (this.opts.writeTargetCheckpoint) {\n    return updateCheckpoint(this.target, this.id, checkpoint,\n      session, this.returnValue);\n  } else {\n    return Promise.resolve(true);\n  }\n};\n\nCheckpointer.prototype.updateSource = function (checkpoint, session) {\n  if (this.opts.writeSourceCheckpoint) {\n    var self = this;\n    return updateCheckpoint(this.src, this.id, checkpoint,\n      session, this.returnValue)\n      .catch(function (err) {\n        if (isForbiddenError(err)) {\n          self.opts.writeSourceCheckpoint = false;\n          return true;\n        }\n        throw err;\n      });\n  } else {\n    return Promise.resolve(true);\n  }\n};\n\nvar comparisons = {\n  \"undefined\": function (targetDoc, sourceDoc) {\n    // This is the previous comparison function\n    if (collate(targetDoc.last_seq, sourceDoc.last_seq) === 0) {\n      return sourceDoc.last_seq;\n    }\n    /* istanbul ignore next */\n    return 0;\n  },\n  \"1\": function (targetDoc, sourceDoc) {\n    // This is the comparison function ported from CouchDB\n    return compareReplicationLogs(sourceDoc, targetDoc).last_seq;\n  }\n};\n\nCheckpointer.prototype.getCheckpoint = function () {\n  var self = this;\n\n  if (self.opts && self.opts.writeSourceCheckpoint && !self.opts.writeTargetCheckpoint) {\n    return self.src.get(self.id).then(function (sourceDoc) {\n      return sourceDoc.last_seq || LOWEST_SEQ;\n    }).catch(function (err) {\n      /* istanbul ignore if */\n      if (err.status !== 404) {\n        throw err;\n      }\n      return LOWEST_SEQ;\n    });\n  }\n\n  return self.target.get(self.id).then(function (targetDoc) {\n    if (self.opts && self.opts.writeTargetCheckpoint && !self.opts.writeSourceCheckpoint) {\n      return targetDoc.last_seq || LOWEST_SEQ;\n    }\n\n    return self.src.get(self.id).then(function (sourceDoc) {\n      // Since we can't migrate an old version doc to a new one\n      // (no session id), we just go with the lowest seq in this case\n      /* istanbul ignore if */\n      if (targetDoc.version !== sourceDoc.version) {\n        return LOWEST_SEQ;\n      }\n\n      var version;\n      if (targetDoc.version) {\n        version = targetDoc.version.toString();\n      } else {\n        version = \"undefined\";\n      }\n\n      if (version in comparisons) {\n        return comparisons[version](targetDoc, sourceDoc);\n      }\n      /* istanbul ignore next */\n      return LOWEST_SEQ;\n    }, function (err) {\n      if (err.status === 404 && targetDoc.last_seq) {\n        return self.src.put({\n          _id: self.id,\n          last_seq: LOWEST_SEQ\n        }).then(function () {\n          return LOWEST_SEQ;\n        }, function (err) {\n          if (isForbiddenError(err)) {\n            self.opts.writeSourceCheckpoint = false;\n            return targetDoc.last_seq;\n          }\n          /* istanbul ignore next */\n          return LOWEST_SEQ;\n        });\n      }\n      throw err;\n    });\n  }).catch(function (err) {\n    if (err.status !== 404) {\n      throw err;\n    }\n    return LOWEST_SEQ;\n  });\n};\n// This checkpoint comparison is ported from CouchDBs source\n// they come from here:\n// https://github.com/apache/couchdb-couch-replicator/blob/master/src/couch_replicator.erl#L863-L906\n\nfunction compareReplicationLogs(srcDoc, tgtDoc) {\n  if (srcDoc.session_id === tgtDoc.session_id) {\n    return {\n      last_seq: srcDoc.last_seq,\n      history: srcDoc.history\n    };\n  }\n\n  return compareReplicationHistory(srcDoc.history, tgtDoc.history);\n}\n\nfunction compareReplicationHistory(sourceHistory, targetHistory) {\n  // the erlang loop via function arguments is not so easy to repeat in JS\n  // therefore, doing this as recursion\n  var S = sourceHistory[0];\n  var sourceRest = sourceHistory.slice(1);\n  var T = targetHistory[0];\n  var targetRest = targetHistory.slice(1);\n\n  if (!S || targetHistory.length === 0) {\n    return {\n      last_seq: LOWEST_SEQ,\n      history: []\n    };\n  }\n\n  var sourceId = S.session_id;\n  /* istanbul ignore if */\n  if (hasSessionId(sourceId, targetHistory)) {\n    return {\n      last_seq: S.last_seq,\n      history: sourceHistory\n    };\n  }\n\n  var targetId = T.session_id;\n  if (hasSessionId(targetId, sourceRest)) {\n    return {\n      last_seq: T.last_seq,\n      history: targetRest\n    };\n  }\n\n  return compareReplicationHistory(sourceRest, targetRest);\n}\n\nfunction hasSessionId(sessionId, history) {\n  var props = history[0];\n  var rest = history.slice(1);\n\n  if (!sessionId || history.length === 0) {\n    return false;\n  }\n\n  if (sessionId === props.session_id) {\n    return true;\n  }\n\n  return hasSessionId(sessionId, rest);\n}\n\nfunction isForbiddenError(err) {\n  return typeof err.status === 'number' && Math.floor(err.status / 100) === 4;\n}\n\nvar STARTING_BACK_OFF = 0;\n\nfunction backOff(opts, returnValue, error, callback) {\n  if (opts.retry === false) {\n    returnValue.emit('error', error);\n    returnValue.removeAllListeners();\n    return;\n  }\n  /* istanbul ignore if */\n  if (typeof opts.back_off_function !== 'function') {\n    opts.back_off_function = defaultBackOff;\n  }\n  returnValue.emit('requestError', error);\n  if (returnValue.state === 'active' || returnValue.state === 'pending') {\n    returnValue.emit('paused', error);\n    returnValue.state = 'stopped';\n    var backOffSet = function backoffTimeSet() {\n      opts.current_back_off = STARTING_BACK_OFF;\n    };\n    var removeBackOffSetter = function removeBackOffTimeSet() {\n      returnValue.removeListener('active', backOffSet);\n    };\n    returnValue.once('paused', removeBackOffSetter);\n    returnValue.once('active', backOffSet);\n  }\n\n  opts.current_back_off = opts.current_back_off || STARTING_BACK_OFF;\n  opts.current_back_off = opts.back_off_function(opts.current_back_off);\n  setTimeout(callback, opts.current_back_off);\n}\n\nfunction sortObjectPropertiesByKey(queryParams) {\n  return Object.keys(queryParams).sort(collate).reduce(function (result, key) {\n    result[key] = queryParams[key];\n    return result;\n  }, {});\n}\n\n// Generate a unique id particular to this replication.\n// Not guaranteed to align perfectly with CouchDB's rep ids.\nfunction generateReplicationId(src, target, opts) {\n  var docIds = opts.doc_ids ? opts.doc_ids.sort(collate) : '';\n  var filterFun = opts.filter ? opts.filter.toString() : '';\n  var queryParams = '';\n  var filterViewName =  '';\n  var selector = '';\n\n  // possibility for checkpoints to be lost here as behaviour of\n  // JSON.stringify is not stable (see #6226)\n  /* istanbul ignore if */\n  if (opts.selector) {\n    selector = JSON.stringify(opts.selector);\n  }\n\n  if (opts.filter && opts.query_params) {\n    queryParams = JSON.stringify(sortObjectPropertiesByKey(opts.query_params));\n  }\n\n  if (opts.filter && opts.filter === '_view') {\n    filterViewName = opts.view.toString();\n  }\n\n  return Promise.all([src.id(), target.id()]).then(function (res) {\n    var queryData = res[0] + res[1] + filterFun + filterViewName +\n      queryParams + docIds + selector;\n    return new Promise(function (resolve) {\n      binaryMd5(queryData, resolve);\n    });\n  }).then(function (md5sum) {\n    // can't use straight-up md5 alphabet, because\n    // the char '/' is interpreted as being for attachments,\n    // and + is also not url-safe\n    md5sum = md5sum.replace(/\\//g, '.').replace(/\\+/g, '_');\n    return '_local/' + md5sum;\n  });\n}\n\nfunction replicate(src, target, opts, returnValue, result) {\n  var batches = [];               // list of batches to be processed\n  var currentBatch;               // the batch currently being processed\n  var pendingBatch = {\n    seq: 0,\n    changes: [],\n    docs: []\n  }; // next batch, not yet ready to be processed\n  var writingCheckpoint = false;  // true while checkpoint is being written\n  var changesCompleted = false;   // true when all changes received\n  var replicationCompleted = false; // true when replication has completed\n  var last_seq = 0;\n  var continuous = opts.continuous || opts.live || false;\n  var batch_size = opts.batch_size || 100;\n  var batches_limit = opts.batches_limit || 10;\n  var changesPending = false;     // true while src.changes is running\n  var doc_ids = opts.doc_ids;\n  var selector = opts.selector;\n  var repId;\n  var checkpointer;\n  var changedDocs = [];\n  // Like couchdb, every replication gets a unique session id\n  var session = uuid();\n\n  result = result || {\n    ok: true,\n    start_time: new Date().toISOString(),\n    docs_read: 0,\n    docs_written: 0,\n    doc_write_failures: 0,\n    errors: []\n  };\n\n  var changesOpts = {};\n  returnValue.ready(src, target);\n\n  function initCheckpointer() {\n    if (checkpointer) {\n      return Promise.resolve();\n    }\n    return generateReplicationId(src, target, opts).then(function (res) {\n      repId = res;\n\n      var checkpointOpts = {};\n      if (opts.checkpoint === false) {\n        checkpointOpts = { writeSourceCheckpoint: false, writeTargetCheckpoint: false };\n      } else if (opts.checkpoint === 'source') {\n        checkpointOpts = { writeSourceCheckpoint: true, writeTargetCheckpoint: false };\n      } else if (opts.checkpoint === 'target') {\n        checkpointOpts = { writeSourceCheckpoint: false, writeTargetCheckpoint: true };\n      } else {\n        checkpointOpts = { writeSourceCheckpoint: true, writeTargetCheckpoint: true };\n      }\n\n      checkpointer = new Checkpointer(src, target, repId, returnValue, checkpointOpts);\n    });\n  }\n\n  function writeDocs() {\n    changedDocs = [];\n\n    if (currentBatch.docs.length === 0) {\n      return;\n    }\n    var docs = currentBatch.docs;\n    var bulkOpts = {timeout: opts.timeout};\n    return target.bulkDocs({docs: docs, new_edits: false}, bulkOpts).then(function (res) {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n\n      // `res` doesn't include full documents (which live in `docs`), so we create a map of \n      // (id -> error), and check for errors while iterating over `docs`\n      var errorsById = Object.create(null);\n      res.forEach(function (res) {\n        if (res.error) {\n          errorsById[res.id] = res;\n        }\n      });\n\n      var errorsNo = Object.keys(errorsById).length;\n      result.doc_write_failures += errorsNo;\n      result.docs_written += docs.length - errorsNo;\n\n      docs.forEach(function (doc) {\n        var error = errorsById[doc._id];\n        if (error) {\n          result.errors.push(error);\n          // Normalize error name. i.e. 'Unauthorized' -> 'unauthorized' (eg Sync Gateway)\n          var errorName = (error.name || '').toLowerCase();\n          if (errorName === 'unauthorized' || errorName === 'forbidden') {\n            returnValue.emit('denied', clone(error));\n          } else {\n            throw error;\n          }\n        } else {\n          changedDocs.push(doc);\n        }\n      });\n\n    }, function (err) {\n      result.doc_write_failures += docs.length;\n      throw err;\n    });\n  }\n\n  function finishBatch() {\n    if (currentBatch.error) {\n      throw new Error('There was a problem getting docs.');\n    }\n    result.last_seq = last_seq = currentBatch.seq;\n    var outResult = clone(result);\n    if (changedDocs.length) {\n      outResult.docs = changedDocs;\n      // Attach 'pending' property if server supports it (CouchDB 2.0+)\n      /* istanbul ignore if */\n      if (typeof currentBatch.pending === 'number') {\n        outResult.pending = currentBatch.pending;\n        delete currentBatch.pending;\n      }\n      returnValue.emit('change', outResult);\n    }\n    writingCheckpoint = true;\n    return checkpointer.writeCheckpoint(currentBatch.seq,\n        session).then(function () {\n      writingCheckpoint = false;\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n      currentBatch = undefined;\n      getChanges();\n    }).catch(function (err) {\n      onCheckpointError(err);\n      throw err;\n    });\n  }\n\n  function getDiffs() {\n    var diff = {};\n    currentBatch.changes.forEach(function (change) {\n      // Couchbase Sync Gateway emits these, but we can ignore them\n      /* istanbul ignore if */\n      if (change.id === \"_user/\") {\n        return;\n      }\n      diff[change.id] = change.changes.map(function (x) {\n        return x.rev;\n      });\n    });\n    return target.revsDiff(diff).then(function (diffs) {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n      // currentBatch.diffs elements are deleted as the documents are written\n      currentBatch.diffs = diffs;\n    });\n  }\n\n  function getBatchDocs() {\n    return getDocs(src, target, currentBatch.diffs, returnValue).then(function (got) {\n      currentBatch.error = !got.ok;\n      got.docs.forEach(function (doc) {\n        delete currentBatch.diffs[doc._id];\n        result.docs_read++;\n        currentBatch.docs.push(doc);\n      });\n    });\n  }\n\n  function startNextBatch() {\n    if (returnValue.cancelled || currentBatch) {\n      return;\n    }\n    if (batches.length === 0) {\n      processPendingBatch(true);\n      return;\n    }\n    currentBatch = batches.shift();\n    getDiffs()\n      .then(getBatchDocs)\n      .then(writeDocs)\n      .then(finishBatch)\n      .then(startNextBatch)\n      .catch(function (err) {\n        abortReplication('batch processing terminated with error', err);\n      });\n  }\n\n\n  function processPendingBatch(immediate$$1) {\n    if (pendingBatch.changes.length === 0) {\n      if (batches.length === 0 && !currentBatch) {\n        if ((continuous && changesOpts.live) || changesCompleted) {\n          returnValue.state = 'pending';\n          returnValue.emit('paused');\n        }\n        if (changesCompleted) {\n          completeReplication();\n        }\n      }\n      return;\n    }\n    if (\n      immediate$$1 ||\n      changesCompleted ||\n      pendingBatch.changes.length >= batch_size\n    ) {\n      batches.push(pendingBatch);\n      pendingBatch = {\n        seq: 0,\n        changes: [],\n        docs: []\n      };\n      if (returnValue.state === 'pending' || returnValue.state === 'stopped') {\n        returnValue.state = 'active';\n        returnValue.emit('active');\n      }\n      startNextBatch();\n    }\n  }\n\n\n  function abortReplication(reason, err) {\n    if (replicationCompleted) {\n      return;\n    }\n    if (!err.message) {\n      err.message = reason;\n    }\n    result.ok = false;\n    result.status = 'aborting';\n    batches = [];\n    pendingBatch = {\n      seq: 0,\n      changes: [],\n      docs: []\n    };\n    completeReplication(err);\n  }\n\n\n  function completeReplication(fatalError) {\n    if (replicationCompleted) {\n      return;\n    }\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      result.status = 'cancelled';\n      if (writingCheckpoint) {\n        return;\n      }\n    }\n    result.status = result.status || 'complete';\n    result.end_time = new Date().toISOString();\n    result.last_seq = last_seq;\n    replicationCompleted = true;\n\n    if (fatalError) {\n      // need to extend the error because Firefox considers \".result\" read-only\n      fatalError = createError(fatalError);\n      fatalError.result = result;\n\n      // Normalize error name. i.e. 'Unauthorized' -> 'unauthorized' (eg Sync Gateway)\n      var errorName = (fatalError.name || '').toLowerCase();\n      if (errorName === 'unauthorized' || errorName === 'forbidden') {\n        returnValue.emit('error', fatalError);\n        returnValue.removeAllListeners();\n      } else {\n        backOff(opts, returnValue, fatalError, function () {\n          replicate(src, target, opts, returnValue);\n        });\n      }\n    } else {\n      returnValue.emit('complete', result);\n      returnValue.removeAllListeners();\n    }\n  }\n\n\n  function onChange(change, pending, lastSeq) {\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n    // Attach 'pending' property if server supports it (CouchDB 2.0+)\n    /* istanbul ignore if */\n    if (typeof pending === 'number') {\n      pendingBatch.pending = pending;\n    }\n\n    var filter = filterChange(opts)(change);\n    if (!filter) {\n      return;\n    }\n    pendingBatch.seq = change.seq || lastSeq;\n    pendingBatch.changes.push(change);\n    immediate(function () {\n      processPendingBatch(batches.length === 0 && changesOpts.live);\n    });\n  }\n\n\n  function onChangesComplete(changes) {\n    changesPending = false;\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n\n    // if no results were returned then we're done,\n    // else fetch more\n    if (changes.results.length > 0) {\n      changesOpts.since = changes.results[changes.results.length - 1].seq;\n      getChanges();\n      processPendingBatch(true);\n    } else {\n\n      var complete = function () {\n        if (continuous) {\n          changesOpts.live = true;\n          getChanges();\n        } else {\n          changesCompleted = true;\n        }\n        processPendingBatch(true);\n      };\n\n      // update the checkpoint so we start from the right seq next time\n      if (!currentBatch && changes.results.length === 0) {\n        writingCheckpoint = true;\n        checkpointer.writeCheckpoint(changes.last_seq,\n            session).then(function () {\n          writingCheckpoint = false;\n          result.last_seq = last_seq = changes.last_seq;\n          complete();\n        })\n        .catch(onCheckpointError);\n      } else {\n        complete();\n      }\n    }\n  }\n\n\n  function onChangesError(err) {\n    changesPending = false;\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n    abortReplication('changes rejected', err);\n  }\n\n\n  function getChanges() {\n    if (!(\n      !changesPending &&\n      !changesCompleted &&\n      batches.length < batches_limit\n      )) {\n      return;\n    }\n    changesPending = true;\n    function abortChanges() {\n      changes.cancel();\n    }\n    function removeListener() {\n      returnValue.removeListener('cancel', abortChanges);\n    }\n\n    if (returnValue._changes) { // remove old changes() and listeners\n      returnValue.removeListener('cancel', returnValue._abortChanges);\n      returnValue._changes.cancel();\n    }\n    returnValue.once('cancel', abortChanges);\n\n    var changes = src.changes(changesOpts)\n      .on('change', onChange);\n    changes.then(removeListener, removeListener);\n    changes.then(onChangesComplete)\n      .catch(onChangesError);\n\n    if (opts.retry) {\n      // save for later so we can cancel if necessary\n      returnValue._changes = changes;\n      returnValue._abortChanges = abortChanges;\n    }\n  }\n\n\n  function startChanges() {\n    initCheckpointer().then(function () {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        return;\n      }\n      return checkpointer.getCheckpoint().then(function (checkpoint) {\n        last_seq = checkpoint;\n        changesOpts = {\n          since: last_seq,\n          limit: batch_size,\n          batch_size: batch_size,\n          style: 'all_docs',\n          doc_ids: doc_ids,\n          selector: selector,\n          return_docs: true // required so we know when we're done\n        };\n        if (opts.filter) {\n          if (typeof opts.filter !== 'string') {\n            // required for the client-side filter in onChange\n            changesOpts.include_docs = true;\n          } else { // ddoc filter\n            changesOpts.filter = opts.filter;\n          }\n        }\n        if ('heartbeat' in opts) {\n          changesOpts.heartbeat = opts.heartbeat;\n        }\n        if ('timeout' in opts) {\n          changesOpts.timeout = opts.timeout;\n        }\n        if (opts.query_params) {\n          changesOpts.query_params = opts.query_params;\n        }\n        if (opts.view) {\n          changesOpts.view = opts.view;\n        }\n        getChanges();\n      });\n    }).catch(function (err) {\n      abortReplication('getCheckpoint rejected with ', err);\n    });\n  }\n\n  /* istanbul ignore next */\n  function onCheckpointError(err) {\n    writingCheckpoint = false;\n    abortReplication('writeCheckpoint completed with error', err);\n  }\n\n  /* istanbul ignore if */\n  if (returnValue.cancelled) { // cancelled immediately\n    completeReplication();\n    return;\n  }\n\n  if (!returnValue._addedListeners) {\n    returnValue.once('cancel', completeReplication);\n\n    if (typeof opts.complete === 'function') {\n      returnValue.once('error', opts.complete);\n      returnValue.once('complete', function (result) {\n        opts.complete(null, result);\n      });\n    }\n    returnValue._addedListeners = true;\n  }\n\n  if (typeof opts.since === 'undefined') {\n    startChanges();\n  } else {\n    initCheckpointer().then(function () {\n      writingCheckpoint = true;\n      return checkpointer.writeCheckpoint(opts.since, session);\n    }).then(function () {\n      writingCheckpoint = false;\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        return;\n      }\n      last_seq = opts.since;\n      startChanges();\n    }).catch(onCheckpointError);\n  }\n}\n\n// We create a basic promise so the caller can cancel the replication possibly\n// before we have actually started listening to changes etc\ninherits(Replication, EventEmitter);\nfunction Replication() {\n  EventEmitter.call(this);\n  this.cancelled = false;\n  this.state = 'pending';\n  var self = this;\n  var promise = new Promise(function (fulfill, reject) {\n    self.once('complete', fulfill);\n    self.once('error', reject);\n  });\n  self.then = function (resolve, reject) {\n    return promise.then(resolve, reject);\n  };\n  self.catch = function (reject) {\n    return promise.catch(reject);\n  };\n  // As we allow error handling via \"error\" event as well,\n  // put a stub in here so that rejecting never throws UnhandledError.\n  self.catch(function () {});\n}\n\nReplication.prototype.cancel = function () {\n  this.cancelled = true;\n  this.state = 'cancelled';\n  this.emit('cancel');\n};\n\nReplication.prototype.ready = function (src, target) {\n  var self = this;\n  if (self._readyCalled) {\n    return;\n  }\n  self._readyCalled = true;\n\n  function onDestroy() {\n    self.cancel();\n  }\n  src.once('destroyed', onDestroy);\n  target.once('destroyed', onDestroy);\n  function cleanup() {\n    src.removeListener('destroyed', onDestroy);\n    target.removeListener('destroyed', onDestroy);\n  }\n  self.once('complete', cleanup);\n};\n\nfunction toPouch(db, opts) {\n  var PouchConstructor = opts.PouchConstructor;\n  if (typeof db === 'string') {\n    return new PouchConstructor(db, opts);\n  } else {\n    return db;\n  }\n}\n\nfunction replicateWrapper(src, target, opts, callback) {\n\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof opts === 'undefined') {\n    opts = {};\n  }\n\n  if (opts.doc_ids && !Array.isArray(opts.doc_ids)) {\n    throw createError(BAD_REQUEST,\n                       \"`doc_ids` filter parameter is not a list.\");\n  }\n\n  opts.complete = callback;\n  opts = clone(opts);\n  opts.continuous = opts.continuous || opts.live;\n  opts.retry = ('retry' in opts) ? opts.retry : false;\n  /*jshint validthis:true */\n  opts.PouchConstructor = opts.PouchConstructor || this;\n  var replicateRet = new Replication(opts);\n  var srcPouch = toPouch(src, opts);\n  var targetPouch = toPouch(target, opts);\n  replicate(srcPouch, targetPouch, opts, replicateRet);\n  return replicateRet;\n}\n\ninherits(Sync, EventEmitter);\nfunction sync(src, target, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof opts === 'undefined') {\n    opts = {};\n  }\n  opts = clone(opts);\n  /*jshint validthis:true */\n  opts.PouchConstructor = opts.PouchConstructor || this;\n  src = toPouch(src, opts);\n  target = toPouch(target, opts);\n  return new Sync(src, target, opts, callback);\n}\n\nfunction Sync(src, target, opts, callback) {\n  var self = this;\n  this.canceled = false;\n\n  var optsPush = opts.push ? $inject_Object_assign({}, opts, opts.push) : opts;\n  var optsPull = opts.pull ? $inject_Object_assign({}, opts, opts.pull) : opts;\n\n  this.push = replicateWrapper(src, target, optsPush);\n  this.pull = replicateWrapper(target, src, optsPull);\n\n  this.pushPaused = true;\n  this.pullPaused = true;\n\n  function pullChange(change) {\n    self.emit('change', {\n      direction: 'pull',\n      change: change\n    });\n  }\n  function pushChange(change) {\n    self.emit('change', {\n      direction: 'push',\n      change: change\n    });\n  }\n  function pushDenied(doc) {\n    self.emit('denied', {\n      direction: 'push',\n      doc: doc\n    });\n  }\n  function pullDenied(doc) {\n    self.emit('denied', {\n      direction: 'pull',\n      doc: doc\n    });\n  }\n  function pushPaused() {\n    self.pushPaused = true;\n    /* istanbul ignore if */\n    if (self.pullPaused) {\n      self.emit('paused');\n    }\n  }\n  function pullPaused() {\n    self.pullPaused = true;\n    /* istanbul ignore if */\n    if (self.pushPaused) {\n      self.emit('paused');\n    }\n  }\n  function pushActive() {\n    self.pushPaused = false;\n    /* istanbul ignore if */\n    if (self.pullPaused) {\n      self.emit('active', {\n        direction: 'push'\n      });\n    }\n  }\n  function pullActive() {\n    self.pullPaused = false;\n    /* istanbul ignore if */\n    if (self.pushPaused) {\n      self.emit('active', {\n        direction: 'pull'\n      });\n    }\n  }\n\n  var removed = {};\n\n  function removeAll(type) { // type is 'push' or 'pull'\n    return function (event, func) {\n      var isChange = event === 'change' &&\n        (func === pullChange || func === pushChange);\n      var isDenied = event === 'denied' &&\n        (func === pullDenied || func === pushDenied);\n      var isPaused = event === 'paused' &&\n        (func === pullPaused || func === pushPaused);\n      var isActive = event === 'active' &&\n        (func === pullActive || func === pushActive);\n\n      if (isChange || isDenied || isPaused || isActive) {\n        if (!(event in removed)) {\n          removed[event] = {};\n        }\n        removed[event][type] = true;\n        if (Object.keys(removed[event]).length === 2) {\n          // both push and pull have asked to be removed\n          self.removeAllListeners(event);\n        }\n      }\n    };\n  }\n\n  if (opts.live) {\n    this.push.on('complete', self.pull.cancel.bind(self.pull));\n    this.pull.on('complete', self.push.cancel.bind(self.push));\n  }\n\n  function addOneListener(ee, event, listener) {\n    if (ee.listeners(event).indexOf(listener) == -1) {\n      ee.on(event, listener);\n    }\n  }\n\n  this.on('newListener', function (event) {\n    if (event === 'change') {\n      addOneListener(self.pull, 'change', pullChange);\n      addOneListener(self.push, 'change', pushChange);\n    } else if (event === 'denied') {\n      addOneListener(self.pull, 'denied', pullDenied);\n      addOneListener(self.push, 'denied', pushDenied);\n    } else if (event === 'active') {\n      addOneListener(self.pull, 'active', pullActive);\n      addOneListener(self.push, 'active', pushActive);\n    } else if (event === 'paused') {\n      addOneListener(self.pull, 'paused', pullPaused);\n      addOneListener(self.push, 'paused', pushPaused);\n    }\n  });\n\n  this.on('removeListener', function (event) {\n    if (event === 'change') {\n      self.pull.removeListener('change', pullChange);\n      self.push.removeListener('change', pushChange);\n    } else if (event === 'denied') {\n      self.pull.removeListener('denied', pullDenied);\n      self.push.removeListener('denied', pushDenied);\n    } else if (event === 'active') {\n      self.pull.removeListener('active', pullActive);\n      self.push.removeListener('active', pushActive);\n    } else if (event === 'paused') {\n      self.pull.removeListener('paused', pullPaused);\n      self.push.removeListener('paused', pushPaused);\n    }\n  });\n\n  this.pull.on('removeListener', removeAll('pull'));\n  this.push.on('removeListener', removeAll('push'));\n\n  var promise = Promise.all([\n    this.push,\n    this.pull\n  ]).then(function (resp) {\n    var out = {\n      push: resp[0],\n      pull: resp[1]\n    };\n    self.emit('complete', out);\n    if (callback) {\n      callback(null, out);\n    }\n    self.removeAllListeners();\n    return out;\n  }, function (err) {\n    self.cancel();\n    if (callback) {\n      // if there's a callback, then the callback can receive\n      // the error event\n      callback(err);\n    } else {\n      // if there's no callback, then we're safe to emit an error\n      // event, which would otherwise throw an unhandled error\n      // due to 'error' being a special event in EventEmitters\n      self.emit('error', err);\n    }\n    self.removeAllListeners();\n    if (callback) {\n      // no sense throwing if we're already emitting an 'error' event\n      throw err;\n    }\n  });\n\n  this.then = function (success, err) {\n    return promise.then(success, err);\n  };\n\n  this.catch = function (err) {\n    return promise.catch(err);\n  };\n}\n\nSync.prototype.cancel = function () {\n  if (!this.canceled) {\n    this.canceled = true;\n    this.push.cancel();\n    this.pull.cancel();\n  }\n};\n\nfunction replication(PouchDB) {\n  PouchDB.replicate = replicateWrapper;\n  PouchDB.sync = sync;\n\n  Object.defineProperty(PouchDB.prototype, 'replicate', {\n    get: function () {\n      var self = this;\n      if (typeof this.replicateMethods === 'undefined') {\n        this.replicateMethods = {\n          from: function (other, opts, callback) {\n            return self.constructor.replicate(other, self, opts, callback);\n          },\n          to: function (other, opts, callback) {\n            return self.constructor.replicate(self, other, opts, callback);\n          }\n        };\n      }\n      return this.replicateMethods;\n    }\n  });\n\n  PouchDB.prototype.sync = function (dbName, opts, callback) {\n    return this.constructor.sync(this, dbName, opts, callback);\n  };\n}\n\nPouchDB.plugin(IDBPouch)\n  .plugin(HttpPouch$1)\n  .plugin(mapreduce)\n  .plugin(replication);\n\n// Pull from src because pouchdb-node/pouchdb-browser themselves\n\nexport default PouchDB;\n","'use strict';\nvar Mutation = global.MutationObserver || global.WebKitMutationObserver;\n\nvar scheduleDrain;\n\n{\n  if (Mutation) {\n    var called = 0;\n    var observer = new Mutation(nextTick);\n    var element = global.document.createTextNode('');\n    observer.observe(element, {\n      characterData: true\n    });\n    scheduleDrain = function () {\n      element.data = (called = ++called % 2);\n    };\n  } else if (!global.setImmediate && typeof global.MessageChannel !== 'undefined') {\n    var channel = new global.MessageChannel();\n    channel.port1.onmessage = nextTick;\n    scheduleDrain = function () {\n      channel.port2.postMessage(0);\n    };\n  } else if ('document' in global && 'onreadystatechange' in global.document.createElement('script')) {\n    scheduleDrain = function () {\n\n      // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n      // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n      var scriptEl = global.document.createElement('script');\n      scriptEl.onreadystatechange = function () {\n        nextTick();\n\n        scriptEl.onreadystatechange = null;\n        scriptEl.parentNode.removeChild(scriptEl);\n        scriptEl = null;\n      };\n      global.document.documentElement.appendChild(scriptEl);\n    };\n  } else {\n    scheduleDrain = function () {\n      setTimeout(nextTick, 0);\n    };\n  }\n}\n\nvar draining;\nvar queue = [];\n//named nextTick for less confusing stack traces\nfunction nextTick() {\n  draining = true;\n  var i, oldQueue;\n  var len = queue.length;\n  while (len) {\n    oldQueue = queue;\n    queue = [];\n    i = -1;\n    while (++i < len) {\n      oldQueue[i]();\n    }\n    len = queue.length;\n  }\n  draining = false;\n}\n\nmodule.exports = immediate;\nfunction immediate(task) {\n  if (queue.push(task) === 1 && !draining) {\n    scheduleDrain();\n  }\n}\n","var v1 = require('./v1');\nvar v4 = require('./v4');\n\nvar uuid = v4;\nuuid.v1 = v1;\nuuid.v4 = v4;\n\nmodule.exports = uuid;\n","var rng = require('./lib/rng');\nvar bytesToUuid = require('./lib/bytesToUuid');\n\n// **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\n\nvar _nodeId;\nvar _clockseq;\n\n// Previous uuid creation time\nvar _lastMSecs = 0;\nvar _lastNSecs = 0;\n\n// See https://github.com/broofa/node-uuid for API details\nfunction v1(options, buf, offset) {\n  var i = buf && offset || 0;\n  var b = buf || [];\n\n  options = options || {};\n  var node = options.node || _nodeId;\n  var clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq;\n\n  // node and clockseq need to be initialized to random values if they're not\n  // specified.  We do this lazily to minimize issues related to insufficient\n  // system entropy.  See #189\n  if (node == null || clockseq == null) {\n    var seedBytes = rng();\n    if (node == null) {\n      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)\n      node = _nodeId = [\n        seedBytes[0] | 0x01,\n        seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]\n      ];\n    }\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n    }\n  }\n\n  // UUID timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so\n  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n  var msecs = options.msecs !== undefined ? options.msecs : new Date().getTime();\n\n  // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n  var nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1;\n\n  // Time since last uuid creation (in msecs)\n  var dt = (msecs - _lastMSecs) + (nsecs - _lastNSecs)/10000;\n\n  // Per 4.2.1.2, Bump clockseq on clock regression\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  }\n\n  // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  }\n\n  // Per 4.2.1.2 Throw error if too many uuids are requested\n  if (nsecs >= 10000) {\n    throw new Error('uuid.v1(): Can\\'t create more than 10M uuids/sec');\n  }\n\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq;\n\n  // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n  msecs += 12219292800000;\n\n  // `time_low`\n  var tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff;\n\n  // `time_mid`\n  var tmh = (msecs / 0x100000000 * 10000) & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff;\n\n  // `time_high_and_version`\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n  b[i++] = tmh >>> 16 & 0xff;\n\n  // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n  b[i++] = clockseq >>> 8 | 0x80;\n\n  // `clock_seq_low`\n  b[i++] = clockseq & 0xff;\n\n  // `node`\n  for (var n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n\n  return buf ? buf : bytesToUuid(b);\n}\n\nmodule.exports = v1;\n","// Unique ID creation requires a high quality random # generator.  In the\n// browser this is a little complicated due to unknown quality of Math.random()\n// and inconsistent support for the `crypto` API.  We do the best we can via\n// feature-detection\n\n// getRandomValues needs to be invoked in a context where \"this\" is a Crypto implementation.\nvar getRandomValues = (typeof(crypto) != 'undefined' && crypto.getRandomValues.bind(crypto)) ||\n                      (typeof(msCrypto) != 'undefined' && msCrypto.getRandomValues.bind(msCrypto));\nif (getRandomValues) {\n  // WHATWG crypto RNG - http://wiki.whatwg.org/wiki/Crypto\n  var rnds8 = new Uint8Array(16); // eslint-disable-line no-undef\n\n  module.exports = function whatwgRNG() {\n    getRandomValues(rnds8);\n    return rnds8;\n  };\n} else {\n  // Math.random()-based (RNG)\n  //\n  // If all else fails, use Math.random().  It's fast, but is of unspecified\n  // quality.\n  var rnds = new Array(16);\n\n  module.exports = function mathRNG() {\n    for (var i = 0, r; i < 16; i++) {\n      if ((i & 0x03) === 0) r = Math.random() * 0x100000000;\n      rnds[i] = r >>> ((i & 0x03) << 3) & 0xff;\n    }\n\n    return rnds;\n  };\n}\n","/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\nvar byteToHex = [];\nfor (var i = 0; i < 256; ++i) {\n  byteToHex[i] = (i + 0x100).toString(16).substr(1);\n}\n\nfunction bytesToUuid(buf, offset) {\n  var i = offset || 0;\n  var bth = byteToHex;\n  return bth[buf[i++]] + bth[buf[i++]] +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] +\n          bth[buf[i++]] + bth[buf[i++]] +\n          bth[buf[i++]] + bth[buf[i++]];\n}\n\nmodule.exports = bytesToUuid;\n","var rng = require('./lib/rng');\nvar bytesToUuid = require('./lib/bytesToUuid');\n\nfunction v4(options, buf, offset) {\n  var i = buf && offset || 0;\n\n  if (typeof(options) == 'string') {\n    buf = options === 'binary' ? new Array(16) : null;\n    options = null;\n  }\n  options = options || {};\n\n  var rnds = options.random || (options.rng || rng)();\n\n  // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n  rnds[6] = (rnds[6] & 0x0f) | 0x40;\n  rnds[8] = (rnds[8] & 0x3f) | 0x80;\n\n  // Copy bytes to buffer, if provided\n  if (buf) {\n    for (var ii = 0; ii < 16; ++ii) {\n      buf[i + ii] = rnds[ii];\n    }\n  }\n\n  return buf || bytesToUuid(rnds);\n}\n\nmodule.exports = v4;\n","(function (factory) {\n    if (typeof exports === 'object') {\n        // Node/CommonJS\n        module.exports = factory();\n    } else if (typeof define === 'function' && define.amd) {\n        // AMD\n        define(factory);\n    } else {\n        // Browser globals (with support for web workers)\n        var glob;\n\n        try {\n            glob = window;\n        } catch (e) {\n            glob = self;\n        }\n\n        glob.SparkMD5 = factory();\n    }\n}(function (undefined) {\n\n    'use strict';\n\n    /*\n     * Fastest md5 implementation around (JKM md5).\n     * Credits: Joseph Myers\n     *\n     * @see http://www.myersdaily.org/joseph/javascript/md5-text.html\n     * @see http://jsperf.com/md5-shootout/7\n     */\n\n    /* this function is much faster,\n      so if possible we use it. Some IEs\n      are the only ones I know of that\n      need the idiotic second function,\n      generated by an if clause.  */\n    var add32 = function (a, b) {\n        return (a + b) & 0xFFFFFFFF;\n    },\n        hex_chr = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'];\n\n\n    function cmn(q, a, b, x, s, t) {\n        a = add32(add32(a, q), add32(x, t));\n        return add32((a << s) | (a >>> (32 - s)), b);\n    }\n\n    function md5cycle(x, k) {\n        var a = x[0],\n            b = x[1],\n            c = x[2],\n            d = x[3];\n\n        a += (b & c | ~b & d) + k[0] - 680876936 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[1] - 389564586 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[2] + 606105819 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[3] - 1044525330 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[4] - 176418897 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[5] + 1200080426 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[6] - 1473231341 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[7] - 45705983 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[8] + 1770035416 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[9] - 1958414417 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[10] - 42063 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[11] - 1990404162 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[12] + 1804603682 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[13] - 40341101 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[14] - 1502002290 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[15] + 1236535329 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n\n        a += (b & d | c & ~d) + k[1] - 165796510 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[6] - 1069501632 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[11] + 643717713 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[0] - 373897302 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[5] - 701558691 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[10] + 38016083 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[15] - 660478335 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[4] - 405537848 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[9] + 568446438 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[14] - 1019803690 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[3] - 187363961 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[8] + 1163531501 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[13] - 1444681467 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[2] - 51403784 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[7] + 1735328473 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[12] - 1926607734 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n\n        a += (b ^ c ^ d) + k[5] - 378558 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[8] - 2022574463 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[11] + 1839030562 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[14] - 35309556 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[1] - 1530992060 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[4] + 1272893353 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[7] - 155497632 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[10] - 1094730640 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[13] + 681279174 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[0] - 358537222 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[3] - 722521979 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[6] + 76029189 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[9] - 640364487 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[12] - 421815835 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[15] + 530742520 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[2] - 995338651 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n\n        a += (c ^ (b | ~d)) + k[0] - 198630844 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[7] + 1126891415 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[14] - 1416354905 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[5] - 57434055 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[12] + 1700485571 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[3] - 1894986606 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[10] - 1051523 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[1] - 2054922799 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[8] + 1873313359 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[15] - 30611744 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[6] - 1560198380 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[13] + 1309151649 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[4] - 145523070 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[11] - 1120210379 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[2] + 718787259 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[9] - 343485551 | 0;\n        b  = (b << 21 | b >>> 11) + c | 0;\n\n        x[0] = a + x[0] | 0;\n        x[1] = b + x[1] | 0;\n        x[2] = c + x[2] | 0;\n        x[3] = d + x[3] | 0;\n    }\n\n    function md5blk(s) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = s.charCodeAt(i) + (s.charCodeAt(i + 1) << 8) + (s.charCodeAt(i + 2) << 16) + (s.charCodeAt(i + 3) << 24);\n        }\n        return md5blks;\n    }\n\n    function md5blk_array(a) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = a[i] + (a[i + 1] << 8) + (a[i + 2] << 16) + (a[i + 3] << 24);\n        }\n        return md5blks;\n    }\n\n    function md51(s) {\n        var n = s.length,\n            state = [1732584193, -271733879, -1732584194, 271733878],\n            i,\n            length,\n            tail,\n            tmp,\n            lo,\n            hi;\n\n        for (i = 64; i <= n; i += 64) {\n            md5cycle(state, md5blk(s.substring(i - 64, i)));\n        }\n        s = s.substring(i - 64);\n        length = s.length;\n        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= s.charCodeAt(i) << ((i % 4) << 3);\n        }\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Beware that the final length might not fit in 32 bits so we take care of that\n        tmp = n * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n\n        md5cycle(state, tail);\n        return state;\n    }\n\n    function md51_array(a) {\n        var n = a.length,\n            state = [1732584193, -271733879, -1732584194, 271733878],\n            i,\n            length,\n            tail,\n            tmp,\n            lo,\n            hi;\n\n        for (i = 64; i <= n; i += 64) {\n            md5cycle(state, md5blk_array(a.subarray(i - 64, i)));\n        }\n\n        // Not sure if it is a bug, however IE10 will always produce a sub array of length 1\n        // containing the last element of the parent array if the sub array specified starts\n        // beyond the length of the parent array - weird.\n        // https://connect.microsoft.com/IE/feedback/details/771452/typed-array-subarray-issue\n        a = (i - 64) < n ? a.subarray(i - 64) : new Uint8Array(0);\n\n        length = a.length;\n        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= a[i] << ((i % 4) << 3);\n        }\n\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Beware that the final length might not fit in 32 bits so we take care of that\n        tmp = n * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n\n        md5cycle(state, tail);\n\n        return state;\n    }\n\n    function rhex(n) {\n        var s = '',\n            j;\n        for (j = 0; j < 4; j += 1) {\n            s += hex_chr[(n >> (j * 8 + 4)) & 0x0F] + hex_chr[(n >> (j * 8)) & 0x0F];\n        }\n        return s;\n    }\n\n    function hex(x) {\n        var i;\n        for (i = 0; i < x.length; i += 1) {\n            x[i] = rhex(x[i]);\n        }\n        return x.join('');\n    }\n\n    // In some cases the fast add32 function cannot be used..\n    if (hex(md51('hello')) !== '5d41402abc4b2a76b9719d911017c592') {\n        add32 = function (x, y) {\n            var lsw = (x & 0xFFFF) + (y & 0xFFFF),\n                msw = (x >> 16) + (y >> 16) + (lsw >> 16);\n            return (msw << 16) | (lsw & 0xFFFF);\n        };\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * ArrayBuffer slice polyfill.\n     *\n     * @see https://github.com/ttaubert/node-arraybuffer-slice\n     */\n\n    if (typeof ArrayBuffer !== 'undefined' && !ArrayBuffer.prototype.slice) {\n        (function () {\n            function clamp(val, length) {\n                val = (val | 0) || 0;\n\n                if (val < 0) {\n                    return Math.max(val + length, 0);\n                }\n\n                return Math.min(val, length);\n            }\n\n            ArrayBuffer.prototype.slice = function (from, to) {\n                var length = this.byteLength,\n                    begin = clamp(from, length),\n                    end = length,\n                    num,\n                    target,\n                    targetArray,\n                    sourceArray;\n\n                if (to !== undefined) {\n                    end = clamp(to, length);\n                }\n\n                if (begin > end) {\n                    return new ArrayBuffer(0);\n                }\n\n                num = end - begin;\n                target = new ArrayBuffer(num);\n                targetArray = new Uint8Array(target);\n\n                sourceArray = new Uint8Array(this, begin, num);\n                targetArray.set(sourceArray);\n\n                return target;\n            };\n        })();\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * Helpers.\n     */\n\n    function toUtf8(str) {\n        if (/[\\u0080-\\uFFFF]/.test(str)) {\n            str = unescape(encodeURIComponent(str));\n        }\n\n        return str;\n    }\n\n    function utf8Str2ArrayBuffer(str, returnUInt8Array) {\n        var length = str.length,\n           buff = new ArrayBuffer(length),\n           arr = new Uint8Array(buff),\n           i;\n\n        for (i = 0; i < length; i += 1) {\n            arr[i] = str.charCodeAt(i);\n        }\n\n        return returnUInt8Array ? arr : buff;\n    }\n\n    function arrayBuffer2Utf8Str(buff) {\n        return String.fromCharCode.apply(null, new Uint8Array(buff));\n    }\n\n    function concatenateArrayBuffers(first, second, returnUInt8Array) {\n        var result = new Uint8Array(first.byteLength + second.byteLength);\n\n        result.set(new Uint8Array(first));\n        result.set(new Uint8Array(second), first.byteLength);\n\n        return returnUInt8Array ? result : result.buffer;\n    }\n\n    function hexToBinaryString(hex) {\n        var bytes = [],\n            length = hex.length,\n            x;\n\n        for (x = 0; x < length - 1; x += 2) {\n            bytes.push(parseInt(hex.substr(x, 2), 16));\n        }\n\n        return String.fromCharCode.apply(String, bytes);\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * SparkMD5 OOP implementation.\n     *\n     * Use this class to perform an incremental md5, otherwise use the\n     * static methods instead.\n     */\n\n    function SparkMD5() {\n        // call reset to init the instance\n        this.reset();\n    }\n\n    /**\n     * Appends a string.\n     * A conversion will be applied if an utf8 string is detected.\n     *\n     * @param {String} str The string to be appended\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.append = function (str) {\n        // Converts the string to utf8 bytes if necessary\n        // Then append as binary\n        this.appendBinary(toUtf8(str));\n\n        return this;\n    };\n\n    /**\n     * Appends a binary string.\n     *\n     * @param {String} contents The binary string to be appended\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.appendBinary = function (contents) {\n        this._buff += contents;\n        this._length += contents.length;\n\n        var length = this._buff.length,\n            i;\n\n        for (i = 64; i <= length; i += 64) {\n            md5cycle(this._hash, md5blk(this._buff.substring(i - 64, i)));\n        }\n\n        this._buff = this._buff.substring(i - 64);\n\n        return this;\n    };\n\n    /**\n     * Finishes the incremental computation, reseting the internal state and\n     * returning the result.\n     *\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.prototype.end = function (raw) {\n        var buff = this._buff,\n            length = buff.length,\n            i,\n            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            ret;\n\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= buff.charCodeAt(i) << ((i % 4) << 3);\n        }\n\n        this._finish(tail, length);\n        ret = hex(this._hash);\n\n        if (raw) {\n            ret = hexToBinaryString(ret);\n        }\n\n        this.reset();\n\n        return ret;\n    };\n\n    /**\n     * Resets the internal state of the computation.\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.reset = function () {\n        this._buff = '';\n        this._length = 0;\n        this._hash = [1732584193, -271733879, -1732584194, 271733878];\n\n        return this;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @return {Object} The state\n     */\n    SparkMD5.prototype.getState = function () {\n        return {\n            buff: this._buff,\n            length: this._length,\n            hash: this._hash\n        };\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @param {Object} state The state\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.setState = function (state) {\n        this._buff = state.buff;\n        this._length = state.length;\n        this._hash = state.hash;\n\n        return this;\n    };\n\n    /**\n     * Releases memory used by the incremental buffer and other additional\n     * resources. If you plan to use the instance again, use reset instead.\n     */\n    SparkMD5.prototype.destroy = function () {\n        delete this._hash;\n        delete this._buff;\n        delete this._length;\n    };\n\n    /**\n     * Finish the final calculation based on the tail.\n     *\n     * @param {Array}  tail   The tail (will be modified)\n     * @param {Number} length The length of the remaining buffer\n     */\n    SparkMD5.prototype._finish = function (tail, length) {\n        var i = length,\n            tmp,\n            lo,\n            hi;\n\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(this._hash, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Do the final computation based on the tail and length\n        // Beware that the final length may not fit in 32 bits so we take care of that\n        tmp = this._length * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n        md5cycle(this._hash, tail);\n    };\n\n    /**\n     * Performs the md5 hash on a string.\n     * A conversion will be applied if utf8 string is detected.\n     *\n     * @param {String}  str The string\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.hash = function (str, raw) {\n        // Converts the string to utf8 bytes if necessary\n        // Then compute it using the binary function\n        return SparkMD5.hashBinary(toUtf8(str), raw);\n    };\n\n    /**\n     * Performs the md5 hash on a binary string.\n     *\n     * @param {String}  content The binary string\n     * @param {Boolean} raw     True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.hashBinary = function (content, raw) {\n        var hash = md51(content),\n            ret = hex(hash);\n\n        return raw ? hexToBinaryString(ret) : ret;\n    };\n\n    // ---------------------------------------------------\n\n    /**\n     * SparkMD5 OOP implementation for array buffers.\n     *\n     * Use this class to perform an incremental md5 ONLY for array buffers.\n     */\n    SparkMD5.ArrayBuffer = function () {\n        // call reset to init the instance\n        this.reset();\n    };\n\n    /**\n     * Appends an array buffer.\n     *\n     * @param {ArrayBuffer} arr The array to be appended\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.append = function (arr) {\n        var buff = concatenateArrayBuffers(this._buff.buffer, arr, true),\n            length = buff.length,\n            i;\n\n        this._length += arr.byteLength;\n\n        for (i = 64; i <= length; i += 64) {\n            md5cycle(this._hash, md5blk_array(buff.subarray(i - 64, i)));\n        }\n\n        this._buff = (i - 64) < length ? new Uint8Array(buff.buffer.slice(i - 64)) : new Uint8Array(0);\n\n        return this;\n    };\n\n    /**\n     * Finishes the incremental computation, reseting the internal state and\n     * returning the result.\n     *\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.ArrayBuffer.prototype.end = function (raw) {\n        var buff = this._buff,\n            length = buff.length,\n            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            i,\n            ret;\n\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= buff[i] << ((i % 4) << 3);\n        }\n\n        this._finish(tail, length);\n        ret = hex(this._hash);\n\n        if (raw) {\n            ret = hexToBinaryString(ret);\n        }\n\n        this.reset();\n\n        return ret;\n    };\n\n    /**\n     * Resets the internal state of the computation.\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.reset = function () {\n        this._buff = new Uint8Array(0);\n        this._length = 0;\n        this._hash = [1732584193, -271733879, -1732584194, 271733878];\n\n        return this;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @return {Object} The state\n     */\n    SparkMD5.ArrayBuffer.prototype.getState = function () {\n        var state = SparkMD5.prototype.getState.call(this);\n\n        // Convert buffer to a string\n        state.buff = arrayBuffer2Utf8Str(state.buff);\n\n        return state;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @param {Object} state The state\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.setState = function (state) {\n        // Convert string to buffer\n        state.buff = utf8Str2ArrayBuffer(state.buff, true);\n\n        return SparkMD5.prototype.setState.call(this, state);\n    };\n\n    SparkMD5.ArrayBuffer.prototype.destroy = SparkMD5.prototype.destroy;\n\n    SparkMD5.ArrayBuffer.prototype._finish = SparkMD5.prototype._finish;\n\n    /**\n     * Performs the md5 hash on an array buffer.\n     *\n     * @param {ArrayBuffer} arr The array buffer\n     * @param {Boolean}     raw True to get the raw string, false to get the hex one\n     *\n     * @return {String} The result\n     */\n    SparkMD5.ArrayBuffer.hash = function (arr, raw) {\n        var hash = md51_array(new Uint8Array(arr)),\n            ret = hex(hash);\n\n        return raw ? hexToBinaryString(ret) : ret;\n    };\n\n    return SparkMD5;\n}));\n","'use strict';\n\n/**\n * Stringify/parse functions that don't operate\n * recursively, so they avoid call stack exceeded\n * errors.\n */\nexports.stringify = function stringify(input) {\n  var queue = [];\n  queue.push({obj: input});\n\n  var res = '';\n  var next, obj, prefix, val, i, arrayPrefix, keys, k, key, value, objPrefix;\n  while ((next = queue.pop())) {\n    obj = next.obj;\n    prefix = next.prefix || '';\n    val = next.val || '';\n    res += prefix;\n    if (val) {\n      res += val;\n    } else if (typeof obj !== 'object') {\n      res += typeof obj === 'undefined' ? null : JSON.stringify(obj);\n    } else if (obj === null) {\n      res += 'null';\n    } else if (Array.isArray(obj)) {\n      queue.push({val: ']'});\n      for (i = obj.length - 1; i >= 0; i--) {\n        arrayPrefix = i === 0 ? '' : ',';\n        queue.push({obj: obj[i], prefix: arrayPrefix});\n      }\n      queue.push({val: '['});\n    } else { // object\n      keys = [];\n      for (k in obj) {\n        if (obj.hasOwnProperty(k)) {\n          keys.push(k);\n        }\n      }\n      queue.push({val: '}'});\n      for (i = keys.length - 1; i >= 0; i--) {\n        key = keys[i];\n        value = obj[key];\n        objPrefix = (i > 0 ? ',' : '');\n        objPrefix += JSON.stringify(key) + ':';\n        queue.push({obj: value, prefix: objPrefix});\n      }\n      queue.push({val: '{'});\n    }\n  }\n  return res;\n};\n\n// Convenience function for the parse function.\n// This pop function is basically copied from\n// pouchCollate.parseIndexableString\nfunction pop(obj, stack, metaStack) {\n  var lastMetaElement = metaStack[metaStack.length - 1];\n  if (obj === lastMetaElement.element) {\n    // popping a meta-element, e.g. an object whose value is another object\n    metaStack.pop();\n    lastMetaElement = metaStack[metaStack.length - 1];\n  }\n  var element = lastMetaElement.element;\n  var lastElementIndex = lastMetaElement.index;\n  if (Array.isArray(element)) {\n    element.push(obj);\n  } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n    var key = stack.pop();\n    element[key] = obj;\n  } else {\n    stack.push(obj); // obj with key only\n  }\n}\n\nexports.parse = function (str) {\n  var stack = [];\n  var metaStack = []; // stack for arrays and objects\n  var i = 0;\n  var collationIndex,parsedNum,numChar;\n  var parsedString,lastCh,numConsecutiveSlashes,ch;\n  var arrayElement, objElement;\n  while (true) {\n    collationIndex = str[i++];\n    if (collationIndex === '}' ||\n        collationIndex === ']' ||\n        typeof collationIndex === 'undefined') {\n      if (stack.length === 1) {\n        return stack.pop();\n      } else {\n        pop(stack.pop(), stack, metaStack);\n        continue;\n      }\n    }\n    switch (collationIndex) {\n      case ' ':\n      case '\\t':\n      case '\\n':\n      case ':':\n      case ',':\n        break;\n      case 'n':\n        i += 3; // 'ull'\n        pop(null, stack, metaStack);\n        break;\n      case 't':\n        i += 3; // 'rue'\n        pop(true, stack, metaStack);\n        break;\n      case 'f':\n        i += 4; // 'alse'\n        pop(false, stack, metaStack);\n        break;\n      case '0':\n      case '1':\n      case '2':\n      case '3':\n      case '4':\n      case '5':\n      case '6':\n      case '7':\n      case '8':\n      case '9':\n      case '-':\n        parsedNum = '';\n        i--;\n        while (true) {\n          numChar = str[i++];\n          if (/[\\d\\.\\-e\\+]/.test(numChar)) {\n            parsedNum += numChar;\n          } else {\n            i--;\n            break;\n          }\n        }\n        pop(parseFloat(parsedNum), stack, metaStack);\n        break;\n      case '\"':\n        parsedString = '';\n        lastCh = void 0;\n        numConsecutiveSlashes = 0;\n        while (true) {\n          ch = str[i++];\n          if (ch !== '\"' || (lastCh === '\\\\' &&\n              numConsecutiveSlashes % 2 === 1)) {\n            parsedString += ch;\n            lastCh = ch;\n            if (lastCh === '\\\\') {\n              numConsecutiveSlashes++;\n            } else {\n              numConsecutiveSlashes = 0;\n            }\n          } else {\n            break;\n          }\n        }\n        pop(JSON.parse('\"' + parsedString + '\"'), stack, metaStack);\n        break;\n      case '[':\n        arrayElement = { element: [], index: stack.length };\n        stack.push(arrayElement.element);\n        metaStack.push(arrayElement);\n        break;\n      case '{':\n        objElement = { element: {}, index: stack.length };\n        stack.push(objElement.element);\n        metaStack.push(objElement);\n        break;\n      default:\n        throw new Error(\n          'unexpectedly reached end of input: ' + collationIndex);\n    }\n  }\n};\n","'use strict';\n\nmodule.exports = argsArray;\n\nfunction argsArray(fun) {\n  return function () {\n    var len = arguments.length;\n    if (len) {\n      var args = [];\n      var i = -1;\n      while (++i < len) {\n        args[i] = arguments[i];\n      }\n      return fun.call(this, args);\n    } else {\n      return fun.call(this, []);\n    }\n  };\n}","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\nvar R = typeof Reflect === 'object' ? Reflect : null\nvar ReflectApply = R && typeof R.apply === 'function'\n  ? R.apply\n  : function ReflectApply(target, receiver, args) {\n    return Function.prototype.apply.call(target, receiver, args);\n  }\n\nvar ReflectOwnKeys\nif (R && typeof R.ownKeys === 'function') {\n  ReflectOwnKeys = R.ownKeys\n} else if (Object.getOwnPropertySymbols) {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target)\n      .concat(Object.getOwnPropertySymbols(target));\n  };\n} else {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target);\n  };\n}\n\nfunction ProcessEmitWarning(warning) {\n  if (console && console.warn) console.warn(warning);\n}\n\nvar NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {\n  return value !== value;\n}\n\nfunction EventEmitter() {\n  EventEmitter.init.call(this);\n}\nmodule.exports = EventEmitter;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._eventsCount = 0;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nvar defaultMaxListeners = 10;\n\nObject.defineProperty(EventEmitter, 'defaultMaxListeners', {\n  enumerable: true,\n  get: function() {\n    return defaultMaxListeners;\n  },\n  set: function(arg) {\n    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {\n      throw new RangeError('The value of \"defaultMaxListeners\" is out of range. It must be a non-negative number. Received ' + arg + '.');\n    }\n    defaultMaxListeners = arg;\n  }\n});\n\nEventEmitter.init = function() {\n\n  if (this._events === undefined ||\n      this._events === Object.getPrototypeOf(this)._events) {\n    this._events = Object.create(null);\n    this._eventsCount = 0;\n  }\n\n  this._maxListeners = this._maxListeners || undefined;\n};\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {\n  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {\n    throw new RangeError('The value of \"n\" is out of range. It must be a non-negative number. Received ' + n + '.');\n  }\n  this._maxListeners = n;\n  return this;\n};\n\nfunction $getMaxListeners(that) {\n  if (that._maxListeners === undefined)\n    return EventEmitter.defaultMaxListeners;\n  return that._maxListeners;\n}\n\nEventEmitter.prototype.getMaxListeners = function getMaxListeners() {\n  return $getMaxListeners(this);\n};\n\nEventEmitter.prototype.emit = function emit(type) {\n  var args = [];\n  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);\n  var doError = (type === 'error');\n\n  var events = this._events;\n  if (events !== undefined)\n    doError = (doError && events.error === undefined);\n  else if (!doError)\n    return false;\n\n  // If there is no 'error' event listener then throw.\n  if (doError) {\n    var er;\n    if (args.length > 0)\n      er = args[0];\n    if (er instanceof Error) {\n      // Note: The comments on the `throw` lines are intentional, they show\n      // up in Node's output if this results in an unhandled exception.\n      throw er; // Unhandled 'error' event\n    }\n    // At least give some kind of context to the user\n    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));\n    err.context = er;\n    throw err; // Unhandled 'error' event\n  }\n\n  var handler = events[type];\n\n  if (handler === undefined)\n    return false;\n\n  if (typeof handler === 'function') {\n    ReflectApply(handler, this, args);\n  } else {\n    var len = handler.length;\n    var listeners = arrayClone(handler, len);\n    for (var i = 0; i < len; ++i)\n      ReflectApply(listeners[i], this, args);\n  }\n\n  return true;\n};\n\nfunction _addListener(target, type, listener, prepend) {\n  var m;\n  var events;\n  var existing;\n\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n\n  events = target._events;\n  if (events === undefined) {\n    events = target._events = Object.create(null);\n    target._eventsCount = 0;\n  } else {\n    // To avoid recursion in the case that type === \"newListener\"! Before\n    // adding it to the listeners, first emit \"newListener\".\n    if (events.newListener !== undefined) {\n      target.emit('newListener', type,\n                  listener.listener ? listener.listener : listener);\n\n      // Re-assign `events` because a newListener handler could have caused the\n      // this._events to be assigned to a new object\n      events = target._events;\n    }\n    existing = events[type];\n  }\n\n  if (existing === undefined) {\n    // Optimize the case of one listener. Don't need the extra array object.\n    existing = events[type] = listener;\n    ++target._eventsCount;\n  } else {\n    if (typeof existing === 'function') {\n      // Adding the second element, need to change to array.\n      existing = events[type] =\n        prepend ? [listener, existing] : [existing, listener];\n      // If we've already got an array, just append.\n    } else if (prepend) {\n      existing.unshift(listener);\n    } else {\n      existing.push(listener);\n    }\n\n    // Check for listener leak\n    m = $getMaxListeners(target);\n    if (m > 0 && existing.length > m && !existing.warned) {\n      existing.warned = true;\n      // No error code for this since it is a Warning\n      // eslint-disable-next-line no-restricted-syntax\n      var w = new Error('Possible EventEmitter memory leak detected. ' +\n                          existing.length + ' ' + String(type) + ' listeners ' +\n                          'added. Use emitter.setMaxListeners() to ' +\n                          'increase limit');\n      w.name = 'MaxListenersExceededWarning';\n      w.emitter = target;\n      w.type = type;\n      w.count = existing.length;\n      ProcessEmitWarning(w);\n    }\n  }\n\n  return target;\n}\n\nEventEmitter.prototype.addListener = function addListener(type, listener) {\n  return _addListener(this, type, listener, false);\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.prependListener =\n    function prependListener(type, listener) {\n      return _addListener(this, type, listener, true);\n    };\n\nfunction onceWrapper() {\n  var args = [];\n  for (var i = 0; i < arguments.length; i++) args.push(arguments[i]);\n  if (!this.fired) {\n    this.target.removeListener(this.type, this.wrapFn);\n    this.fired = true;\n    ReflectApply(this.listener, this.target, args);\n  }\n}\n\nfunction _onceWrap(target, type, listener) {\n  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };\n  var wrapped = onceWrapper.bind(state);\n  wrapped.listener = listener;\n  state.wrapFn = wrapped;\n  return wrapped;\n}\n\nEventEmitter.prototype.once = function once(type, listener) {\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n  this.on(type, _onceWrap(this, type, listener));\n  return this;\n};\n\nEventEmitter.prototype.prependOnceListener =\n    function prependOnceListener(type, listener) {\n      if (typeof listener !== 'function') {\n        throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n      }\n      this.prependListener(type, _onceWrap(this, type, listener));\n      return this;\n    };\n\n// Emits a 'removeListener' event if and only if the listener was removed.\nEventEmitter.prototype.removeListener =\n    function removeListener(type, listener) {\n      var list, events, position, i, originalListener;\n\n      if (typeof listener !== 'function') {\n        throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n      }\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      list = events[type];\n      if (list === undefined)\n        return this;\n\n      if (list === listener || list.listener === listener) {\n        if (--this._eventsCount === 0)\n          this._events = Object.create(null);\n        else {\n          delete events[type];\n          if (events.removeListener)\n            this.emit('removeListener', type, list.listener || listener);\n        }\n      } else if (typeof list !== 'function') {\n        position = -1;\n\n        for (i = list.length - 1; i >= 0; i--) {\n          if (list[i] === listener || list[i].listener === listener) {\n            originalListener = list[i].listener;\n            position = i;\n            break;\n          }\n        }\n\n        if (position < 0)\n          return this;\n\n        if (position === 0)\n          list.shift();\n        else {\n          spliceOne(list, position);\n        }\n\n        if (list.length === 1)\n          events[type] = list[0];\n\n        if (events.removeListener !== undefined)\n          this.emit('removeListener', type, originalListener || listener);\n      }\n\n      return this;\n    };\n\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\nEventEmitter.prototype.removeAllListeners =\n    function removeAllListeners(type) {\n      var listeners, events, i;\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      // not listening for removeListener, no need to emit\n      if (events.removeListener === undefined) {\n        if (arguments.length === 0) {\n          this._events = Object.create(null);\n          this._eventsCount = 0;\n        } else if (events[type] !== undefined) {\n          if (--this._eventsCount === 0)\n            this._events = Object.create(null);\n          else\n            delete events[type];\n        }\n        return this;\n      }\n\n      // emit removeListener for all listeners on all events\n      if (arguments.length === 0) {\n        var keys = Object.keys(events);\n        var key;\n        for (i = 0; i < keys.length; ++i) {\n          key = keys[i];\n          if (key === 'removeListener') continue;\n          this.removeAllListeners(key);\n        }\n        this.removeAllListeners('removeListener');\n        this._events = Object.create(null);\n        this._eventsCount = 0;\n        return this;\n      }\n\n      listeners = events[type];\n\n      if (typeof listeners === 'function') {\n        this.removeListener(type, listeners);\n      } else if (listeners !== undefined) {\n        // LIFO order\n        for (i = listeners.length - 1; i >= 0; i--) {\n          this.removeListener(type, listeners[i]);\n        }\n      }\n\n      return this;\n    };\n\nfunction _listeners(target, type, unwrap) {\n  var events = target._events;\n\n  if (events === undefined)\n    return [];\n\n  var evlistener = events[type];\n  if (evlistener === undefined)\n    return [];\n\n  if (typeof evlistener === 'function')\n    return unwrap ? [evlistener.listener || evlistener] : [evlistener];\n\n  return unwrap ?\n    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);\n}\n\nEventEmitter.prototype.listeners = function listeners(type) {\n  return _listeners(this, type, true);\n};\n\nEventEmitter.prototype.rawListeners = function rawListeners(type) {\n  return _listeners(this, type, false);\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  if (typeof emitter.listenerCount === 'function') {\n    return emitter.listenerCount(type);\n  } else {\n    return listenerCount.call(emitter, type);\n  }\n};\n\nEventEmitter.prototype.listenerCount = listenerCount;\nfunction listenerCount(type) {\n  var events = this._events;\n\n  if (events !== undefined) {\n    var evlistener = events[type];\n\n    if (typeof evlistener === 'function') {\n      return 1;\n    } else if (evlistener !== undefined) {\n      return evlistener.length;\n    }\n  }\n\n  return 0;\n}\n\nEventEmitter.prototype.eventNames = function eventNames() {\n  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];\n};\n\nfunction arrayClone(arr, n) {\n  var copy = new Array(n);\n  for (var i = 0; i < n; ++i)\n    copy[i] = arr[i];\n  return copy;\n}\n\nfunction spliceOne(list, index) {\n  for (; index + 1 < list.length; index++)\n    list[index] = list[index + 1];\n  list.pop();\n}\n\nfunction unwrapListeners(arr) {\n  var ret = new Array(arr.length);\n  for (var i = 0; i < ret.length; ++i) {\n    ret[i] = arr[i].listener || arr[i];\n  }\n  return ret;\n}\n","import { assign } from 'pouchdb-utils';\nimport CoreLevelPouch from 'pouchdb-adapter-leveldb-core';\nimport memdown from 'memdown';\n\nfunction MemDownPouch(opts, callback) {\n  var _opts = assign({\n    db: memdown\n  }, opts);\n\n  CoreLevelPouch.call(this, _opts, callback);\n}\n\n// overrides for normal LevelDB behavior on Node\nMemDownPouch.valid = function () {\n  return true;\n};\nMemDownPouch.use_prefix = false;\n\nfunction index (PouchDB) {\n  PouchDB.adapter('memory', MemDownPouch, true);\n}\n\nexport default index;\n","import getArguments from 'argsarray';\nimport { Map } from 'pouchdb-collections';\nimport inherits from 'inherits';\nimport immediate from 'immediate';\nimport { createError, BAD_REQUEST, INVALID_ID, MISSING_ID, RESERVED_ID } from 'pouchdb-errors';\nimport { EventEmitter } from 'events';\nimport uuidV4 from 'uuid';\nimport { stringMd5 } from 'pouchdb-md5';\n\nfunction isBinaryObject(object) {\n  return (typeof ArrayBuffer !== 'undefined' && object instanceof ArrayBuffer) ||\n    (typeof Blob !== 'undefined' && object instanceof Blob);\n}\n\nfunction cloneArrayBuffer(buff) {\n  if (typeof buff.slice === 'function') {\n    return buff.slice(0);\n  }\n  // IE10-11 slice() polyfill\n  var target = new ArrayBuffer(buff.byteLength);\n  var targetArray = new Uint8Array(target);\n  var sourceArray = new Uint8Array(buff);\n  targetArray.set(sourceArray);\n  return target;\n}\n\nfunction cloneBinaryObject(object) {\n  if (object instanceof ArrayBuffer) {\n    return cloneArrayBuffer(object);\n  }\n  var size = object.size;\n  var type = object.type;\n  // Blob\n  if (typeof object.slice === 'function') {\n    return object.slice(0, size, type);\n  }\n  // PhantomJS slice() replacement\n  return object.webkitSlice(0, size, type);\n}\n\n// most of this is borrowed from lodash.isPlainObject:\n// https://github.com/fis-components/lodash.isplainobject/\n// blob/29c358140a74f252aeb08c9eb28bef86f2217d4a/index.js\n\nvar funcToString = Function.prototype.toString;\nvar objectCtorString = funcToString.call(Object);\n\nfunction isPlainObject(value) {\n  var proto = Object.getPrototypeOf(value);\n  /* istanbul ignore if */\n  if (proto === null) { // not sure when this happens, but I guess it can\n    return true;\n  }\n  var Ctor = proto.constructor;\n  return (typeof Ctor == 'function' &&\n    Ctor instanceof Ctor && funcToString.call(Ctor) == objectCtorString);\n}\n\nfunction clone(object) {\n  var newObject;\n  var i;\n  var len;\n\n  if (!object || typeof object !== 'object') {\n    return object;\n  }\n\n  if (Array.isArray(object)) {\n    newObject = [];\n    for (i = 0, len = object.length; i < len; i++) {\n      newObject[i] = clone(object[i]);\n    }\n    return newObject;\n  }\n\n  // special case: to avoid inconsistencies between IndexedDB\n  // and other backends, we automatically stringify Dates\n  if (object instanceof Date) {\n    return object.toISOString();\n  }\n\n  if (isBinaryObject(object)) {\n    return cloneBinaryObject(object);\n  }\n\n  if (!isPlainObject(object)) {\n    return object; // don't clone objects like Workers\n  }\n\n  newObject = {};\n  for (i in object) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(object, i)) {\n      var value = clone(object[i]);\n      if (typeof value !== 'undefined') {\n        newObject[i] = value;\n      }\n    }\n  }\n  return newObject;\n}\n\nfunction once(fun) {\n  var called = false;\n  return getArguments(function (args) {\n    /* istanbul ignore if */\n    if (called) {\n      // this is a smoke test and should never actually happen\n      throw new Error('once called more than once');\n    } else {\n      called = true;\n      fun.apply(this, args);\n    }\n  });\n}\n\nfunction toPromise(func) {\n  //create the function we will be returning\n  return getArguments(function (args) {\n    // Clone arguments\n    args = clone(args);\n    var self = this;\n    // if the last argument is a function, assume its a callback\n    var usedCB = (typeof args[args.length - 1] === 'function') ? args.pop() : false;\n    var promise = new Promise(function (fulfill, reject) {\n      var resp;\n      try {\n        var callback = once(function (err, mesg) {\n          if (err) {\n            reject(err);\n          } else {\n            fulfill(mesg);\n          }\n        });\n        // create a callback for this invocation\n        // apply the function in the orig context\n        args.push(callback);\n        resp = func.apply(self, args);\n        if (resp && typeof resp.then === 'function') {\n          fulfill(resp);\n        }\n      } catch (e) {\n        reject(e);\n      }\n    });\n    // if there is a callback, call it back\n    if (usedCB) {\n      promise.then(function (result) {\n        usedCB(null, result);\n      }, usedCB);\n    }\n    return promise;\n  });\n}\n\nfunction logApiCall(self, name, args) {\n  /* istanbul ignore if */\n  if (self.constructor.listeners('debug').length) {\n    var logArgs = ['api', self.name, name];\n    for (var i = 0; i < args.length - 1; i++) {\n      logArgs.push(args[i]);\n    }\n    self.constructor.emit('debug', logArgs);\n\n    // override the callback itself to log the response\n    var origCallback = args[args.length - 1];\n    args[args.length - 1] = function (err, res) {\n      var responseArgs = ['api', self.name, name];\n      responseArgs = responseArgs.concat(\n        err ? ['error', err] : ['success', res]\n      );\n      self.constructor.emit('debug', responseArgs);\n      origCallback(err, res);\n    };\n  }\n}\n\nfunction adapterFun(name, callback) {\n  return toPromise(getArguments(function (args) {\n    if (this._closed) {\n      return Promise.reject(new Error('database is closed'));\n    }\n    if (this._destroyed) {\n      return Promise.reject(new Error('database is destroyed'));\n    }\n    var self = this;\n    logApiCall(self, name, args);\n    if (!this.taskqueue.isReady) {\n      return new Promise(function (fulfill, reject) {\n        self.taskqueue.addTask(function (failed) {\n          if (failed) {\n            reject(failed);\n          } else {\n            fulfill(self[name].apply(self, args));\n          }\n        });\n      });\n    }\n    return callback.apply(this, args);\n  }));\n}\n\n// like underscore/lodash _.pick()\nfunction pick(obj, arr) {\n  var res = {};\n  for (var i = 0, len = arr.length; i < len; i++) {\n    var prop = arr[i];\n    if (prop in obj) {\n      res[prop] = obj[prop];\n    }\n  }\n  return res;\n}\n\n// Most browsers throttle concurrent requests at 6, so it's silly\n// to shim _bulk_get by trying to launch potentially hundreds of requests\n// and then letting the majority time out. We can handle this ourselves.\nvar MAX_NUM_CONCURRENT_REQUESTS = 6;\n\nfunction identityFunction(x) {\n  return x;\n}\n\nfunction formatResultForOpenRevsGet(result) {\n  return [{\n    ok: result\n  }];\n}\n\n// shim for P/CouchDB adapters that don't directly implement _bulk_get\nfunction bulkGet(db, opts, callback) {\n  var requests = opts.docs;\n\n  // consolidate into one request per doc if possible\n  var requestsById = new Map();\n  requests.forEach(function (request) {\n    if (requestsById.has(request.id)) {\n      requestsById.get(request.id).push(request);\n    } else {\n      requestsById.set(request.id, [request]);\n    }\n  });\n\n  var numDocs = requestsById.size;\n  var numDone = 0;\n  var perDocResults = new Array(numDocs);\n\n  function collapseResultsAndFinish() {\n    var results = [];\n    perDocResults.forEach(function (res) {\n      res.docs.forEach(function (info) {\n        results.push({\n          id: res.id,\n          docs: [info]\n        });\n      });\n    });\n    callback(null, {results: results});\n  }\n\n  function checkDone() {\n    if (++numDone === numDocs) {\n      collapseResultsAndFinish();\n    }\n  }\n\n  function gotResult(docIndex, id, docs) {\n    perDocResults[docIndex] = {id: id, docs: docs};\n    checkDone();\n  }\n\n  var allRequests = [];\n  requestsById.forEach(function (value, key) {\n    allRequests.push(key);\n  });\n\n  var i = 0;\n\n  function nextBatch() {\n\n    if (i >= allRequests.length) {\n      return;\n    }\n\n    var upTo = Math.min(i + MAX_NUM_CONCURRENT_REQUESTS, allRequests.length);\n    var batch = allRequests.slice(i, upTo);\n    processBatch(batch, i);\n    i += batch.length;\n  }\n\n  function processBatch(batch, offset) {\n    batch.forEach(function (docId, j) {\n      var docIdx = offset + j;\n      var docRequests = requestsById.get(docId);\n\n      // just use the first request as the \"template\"\n      // TODO: The _bulk_get API allows for more subtle use cases than this,\n      // but for now it is unlikely that there will be a mix of different\n      // \"atts_since\" or \"attachments\" in the same request, since it's just\n      // replicate.js that is using this for the moment.\n      // Also, atts_since is aspirational, since we don't support it yet.\n      var docOpts = pick(docRequests[0], ['atts_since', 'attachments']);\n      docOpts.open_revs = docRequests.map(function (request) {\n        // rev is optional, open_revs disallowed\n        return request.rev;\n      });\n\n      // remove falsey / undefined revisions\n      docOpts.open_revs = docOpts.open_revs.filter(identityFunction);\n\n      var formatResult = identityFunction;\n\n      if (docOpts.open_revs.length === 0) {\n        delete docOpts.open_revs;\n\n        // when fetching only the \"winning\" leaf,\n        // transform the result so it looks like an open_revs\n        // request\n        formatResult = formatResultForOpenRevsGet;\n      }\n\n      // globally-supplied options\n      ['revs', 'attachments', 'binary', 'ajax', 'latest'].forEach(function (param) {\n        if (param in opts) {\n          docOpts[param] = opts[param];\n        }\n      });\n      db.get(docId, docOpts, function (err, res) {\n        var result;\n        /* istanbul ignore if */\n        if (err) {\n          result = [{error: err}];\n        } else {\n          result = formatResult(res);\n        }\n        gotResult(docIdx, docId, result);\n        nextBatch();\n      });\n    });\n  }\n\n  nextBatch();\n\n}\n\nvar hasLocal;\n\ntry {\n  localStorage.setItem('_pouch_check_localstorage', 1);\n  hasLocal = !!localStorage.getItem('_pouch_check_localstorage');\n} catch (e) {\n  hasLocal = false;\n}\n\nfunction hasLocalStorage() {\n  return hasLocal;\n}\n\n// Custom nextTick() shim for browsers. In node, this will just be process.nextTick(). We\n\ninherits(Changes, EventEmitter);\n\n/* istanbul ignore next */\nfunction attachBrowserEvents(self) {\n  if (hasLocalStorage()) {\n    addEventListener(\"storage\", function (e) {\n      self.emit(e.key);\n    });\n  }\n}\n\nfunction Changes() {\n  EventEmitter.call(this);\n  this._listeners = {};\n\n  attachBrowserEvents(this);\n}\nChanges.prototype.addListener = function (dbName, id, db, opts) {\n  /* istanbul ignore if */\n  if (this._listeners[id]) {\n    return;\n  }\n  var self = this;\n  var inprogress = false;\n  function eventFunction() {\n    /* istanbul ignore if */\n    if (!self._listeners[id]) {\n      return;\n    }\n    if (inprogress) {\n      inprogress = 'waiting';\n      return;\n    }\n    inprogress = true;\n    var changesOpts = pick(opts, [\n      'style', 'include_docs', 'attachments', 'conflicts', 'filter',\n      'doc_ids', 'view', 'since', 'query_params', 'binary', 'return_docs'\n    ]);\n\n    /* istanbul ignore next */\n    function onError() {\n      inprogress = false;\n    }\n\n    db.changes(changesOpts).on('change', function (c) {\n      if (c.seq > opts.since && !opts.cancelled) {\n        opts.since = c.seq;\n        opts.onChange(c);\n      }\n    }).on('complete', function () {\n      if (inprogress === 'waiting') {\n        immediate(eventFunction);\n      }\n      inprogress = false;\n    }).on('error', onError);\n  }\n  this._listeners[id] = eventFunction;\n  this.on(dbName, eventFunction);\n};\n\nChanges.prototype.removeListener = function (dbName, id) {\n  /* istanbul ignore if */\n  if (!(id in this._listeners)) {\n    return;\n  }\n  EventEmitter.prototype.removeListener.call(this, dbName,\n    this._listeners[id]);\n  delete this._listeners[id];\n};\n\n\n/* istanbul ignore next */\nChanges.prototype.notifyLocalWindows = function (dbName) {\n  //do a useless change on a storage thing\n  //in order to get other windows's listeners to activate\n  if (hasLocalStorage()) {\n    localStorage[dbName] = (localStorage[dbName] === \"a\") ? \"b\" : \"a\";\n  }\n};\n\nChanges.prototype.notify = function (dbName) {\n  this.emit(dbName);\n  this.notifyLocalWindows(dbName);\n};\n\nfunction guardedConsole(method) {\n  /* istanbul ignore else */\n  if (typeof console !== 'undefined' && typeof console[method] === 'function') {\n    var args = Array.prototype.slice.call(arguments, 1);\n    console[method].apply(console, args);\n  }\n}\n\nfunction randomNumber(min, max) {\n  var maxTimeout = 600000; // Hard-coded default of 10 minutes\n  min = parseInt(min, 10) || 0;\n  max = parseInt(max, 10);\n  if (max !== max || max <= min) {\n    max = (min || 1) << 1; //doubling\n  } else {\n    max = max + 1;\n  }\n  // In order to not exceed maxTimeout, pick a random value between half of maxTimeout and maxTimeout\n  if (max > maxTimeout) {\n    min = maxTimeout >> 1; // divide by two\n    max = maxTimeout;\n  }\n  var ratio = Math.random();\n  var range = max - min;\n\n  return ~~(range * ratio + min); // ~~ coerces to an int, but fast.\n}\n\nfunction defaultBackOff(min) {\n  var max = 0;\n  if (!min) {\n    max = 2000;\n  }\n  return randomNumber(min, max);\n}\n\n// designed to give info to browser users, who are disturbed\n// when they see http errors in the console\nfunction explainError(status, str) {\n  guardedConsole('info', 'The above ' + status + ' is totally normal. ' + str);\n}\n\nvar assign;\n{\n  if (typeof Object.assign === 'function') {\n    assign = Object.assign;\n  } else {\n    // lite Object.assign polyfill based on\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign\n    assign = function (target) {\n      var to = Object(target);\n\n      for (var index = 1; index < arguments.length; index++) {\n        var nextSource = arguments[index];\n\n        if (nextSource != null) { // Skip over if undefined or null\n          for (var nextKey in nextSource) {\n            // Avoid bugs when hasOwnProperty is shadowed\n            if (Object.prototype.hasOwnProperty.call(nextSource, nextKey)) {\n              to[nextKey] = nextSource[nextKey];\n            }\n          }\n        }\n      }\n      return to;\n    };\n  }\n}\n\nvar assign$1 = assign;\n\nfunction tryFilter(filter, doc, req) {\n  try {\n    return !filter(doc, req);\n  } catch (err) {\n    var msg = 'Filter function threw: ' + err.toString();\n    return createError(BAD_REQUEST, msg);\n  }\n}\n\nfunction filterChange(opts) {\n  var req = {};\n  var hasFilter = opts.filter && typeof opts.filter === 'function';\n  req.query = opts.query_params;\n\n  return function filter(change) {\n    if (!change.doc) {\n      // CSG sends events on the changes feed that don't have documents,\n      // this hack makes a whole lot of existing code robust.\n      change.doc = {};\n    }\n\n    var filterReturn = hasFilter && tryFilter(opts.filter, change.doc, req);\n\n    if (typeof filterReturn === 'object') {\n      return filterReturn;\n    }\n\n    if (filterReturn) {\n      return false;\n    }\n\n    if (!opts.include_docs) {\n      delete change.doc;\n    } else if (!opts.attachments) {\n      for (var att in change.doc._attachments) {\n        /* istanbul ignore else */\n        if (change.doc._attachments.hasOwnProperty(att)) {\n          change.doc._attachments[att].stub = true;\n        }\n      }\n    }\n    return true;\n  };\n}\n\nfunction flatten(arrs) {\n  var res = [];\n  for (var i = 0, len = arrs.length; i < len; i++) {\n    res = res.concat(arrs[i]);\n  }\n  return res;\n}\n\n// shim for Function.prototype.name,\n// for browsers that don't support it like IE\n\n/* istanbul ignore next */\nfunction f() {}\n\nvar hasName = f.name;\nvar res;\n\n// We dont run coverage in IE\n/* istanbul ignore else */\nif (hasName) {\n  res = function (fun) {\n    return fun.name;\n  };\n} else {\n  res = function (fun) {\n    var match = fun.toString().match(/^\\s*function\\s*(?:(\\S+)\\s*)?\\(/);\n    if (match && match[1]) {\n      return match[1];\n    }\n    else {\n      return '';\n    }\n  };\n}\n\nvar res$1 = res;\n\n// Determine id an ID is valid\n//   - invalid IDs begin with an underescore that does not begin '_design' or\n//     '_local'\n//   - any other string value is a valid id\n// Returns the specific error object for each case\nfunction invalidIdError(id) {\n  var err;\n  if (!id) {\n    err = createError(MISSING_ID);\n  } else if (typeof id !== 'string') {\n    err = createError(INVALID_ID);\n  } else if (/^_/.test(id) && !(/^_(design|local)/).test(id)) {\n    err = createError(RESERVED_ID);\n  }\n  if (err) {\n    throw err;\n  }\n}\n\n// Checks if a PouchDB object is \"remote\" or not. This is\n\nfunction isRemote(db) {\n  if (typeof db._remote === 'boolean') {\n    return db._remote;\n  }\n  /* istanbul ignore next */\n  if (typeof db.type === 'function') {\n    guardedConsole('warn',\n      'db.type() is deprecated and will be removed in ' +\n      'a future version of PouchDB');\n    return db.type() === 'http';\n  }\n  /* istanbul ignore next */\n  return false;\n}\n\nfunction listenerCount(ee, type) {\n  return 'listenerCount' in ee ? ee.listenerCount(type) :\n                                 EventEmitter.listenerCount(ee, type);\n}\n\nfunction parseDesignDocFunctionName(s) {\n  if (!s) {\n    return null;\n  }\n  var parts = s.split('/');\n  if (parts.length === 2) {\n    return parts;\n  }\n  if (parts.length === 1) {\n    return [s, s];\n  }\n  return null;\n}\n\nfunction normalizeDesignDocFunctionName(s) {\n  var normalized = parseDesignDocFunctionName(s);\n  return normalized ? normalized.join('/') : null;\n}\n\n// originally parseUri 1.2.2, now patched by us\n// (c) Steven Levithan <stevenlevithan.com>\n// MIT License\nvar keys = [\"source\", \"protocol\", \"authority\", \"userInfo\", \"user\", \"password\",\n    \"host\", \"port\", \"relative\", \"path\", \"directory\", \"file\", \"query\", \"anchor\"];\nvar qName =\"queryKey\";\nvar qParser = /(?:^|&)([^&=]*)=?([^&]*)/g;\n\n// use the \"loose\" parser\n/* eslint maxlen: 0, no-useless-escape: 0 */\nvar parser = /^(?:(?![^:@]+:[^:@\\/]*@)([^:\\/?#.]+):)?(?:\\/\\/)?((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d*))?)(((\\/(?:[^?#](?![^?#\\/]*\\.[^?#\\/.]+(?:[?#]|$)))*\\/?)?([^?#\\/]*))(?:\\?([^#]*))?(?:#(.*))?)/;\n\nfunction parseUri(str) {\n  var m = parser.exec(str);\n  var uri = {};\n  var i = 14;\n\n  while (i--) {\n    var key = keys[i];\n    var value = m[i] || \"\";\n    var encoded = ['user', 'password'].indexOf(key) !== -1;\n    uri[key] = encoded ? decodeURIComponent(value) : value;\n  }\n\n  uri[qName] = {};\n  uri[keys[12]].replace(qParser, function ($0, $1, $2) {\n    if ($1) {\n      uri[qName][$1] = $2;\n    }\n  });\n\n  return uri;\n}\n\n// Based on https://github.com/alexdavid/scope-eval v0.0.3\n// (source: https://unpkg.com/scope-eval@0.0.3/scope_eval.js)\n// This is basically just a wrapper around new Function()\n\nfunction scopeEval(source, scope) {\n  var keys = [];\n  var values = [];\n  for (var key in scope) {\n    if (scope.hasOwnProperty(key)) {\n      keys.push(key);\n      values.push(scope[key]);\n    }\n  }\n  keys.push(source);\n  return Function.apply(null, keys).apply(null, values);\n}\n\n// this is essentially the \"update sugar\" function from daleharvey/pouchdb#1388\n// the diffFun tells us what delta to apply to the doc.  it either returns\n// the doc, or false if it doesn't need to do an update after all\nfunction upsert(db, docId, diffFun) {\n  return new Promise(function (fulfill, reject) {\n    db.get(docId, function (err, doc) {\n      if (err) {\n        /* istanbul ignore next */\n        if (err.status !== 404) {\n          return reject(err);\n        }\n        doc = {};\n      }\n\n      // the user might change the _rev, so save it for posterity\n      var docRev = doc._rev;\n      var newDoc = diffFun(doc);\n\n      if (!newDoc) {\n        // if the diffFun returns falsy, we short-circuit as\n        // an optimization\n        return fulfill({updated: false, rev: docRev});\n      }\n\n      // users aren't allowed to modify these values,\n      // so reset them here\n      newDoc._id = docId;\n      newDoc._rev = docRev;\n      fulfill(tryAndPut(db, newDoc, diffFun));\n    });\n  });\n}\n\nfunction tryAndPut(db, doc, diffFun) {\n  return db.put(doc).then(function (res) {\n    return {\n      updated: true,\n      rev: res.rev\n    };\n  }, function (err) {\n    /* istanbul ignore next */\n    if (err.status !== 409) {\n      throw err;\n    }\n    return upsert(db, doc._id, diffFun);\n  });\n}\n\nfunction rev(doc, deterministic_revs) {\n  var clonedDoc = clone(doc);\n  if (!deterministic_revs) {\n    return uuidV4.v4().replace(/-/g, '').toLowerCase();\n  }\n\n  delete clonedDoc._rev_tree;\n  return stringMd5(JSON.stringify(clonedDoc));\n}\n\nvar uuid = uuidV4.v4;\n\nexport { adapterFun, assign$1 as assign, bulkGet as bulkGetShim, Changes as changesHandler, clone, defaultBackOff, explainError, filterChange, flatten, res$1 as functionName, guardedConsole, hasLocalStorage, invalidIdError, isRemote, listenerCount, immediate as nextTick, normalizeDesignDocFunctionName as normalizeDdocFunctionName, once, parseDesignDocFunctionName as parseDdocFunctionName, parseUri, pick, rev, scopeEval, toPromise, upsert, uuid };\n","function mangle(key) {\n  return '$' + key;\n}\nfunction unmangle(key) {\n  return key.substring(1);\n}\nfunction Map$1() {\n  this._store = {};\n}\nMap$1.prototype.get = function (key) {\n  var mangled = mangle(key);\n  return this._store[mangled];\n};\nMap$1.prototype.set = function (key, value) {\n  var mangled = mangle(key);\n  this._store[mangled] = value;\n  return true;\n};\nMap$1.prototype.has = function (key) {\n  var mangled = mangle(key);\n  return mangled in this._store;\n};\nMap$1.prototype.delete = function (key) {\n  var mangled = mangle(key);\n  var res = mangled in this._store;\n  delete this._store[mangled];\n  return res;\n};\nMap$1.prototype.forEach = function (cb) {\n  var keys = Object.keys(this._store);\n  for (var i = 0, len = keys.length; i < len; i++) {\n    var key = keys[i];\n    var value = this._store[key];\n    key = unmangle(key);\n    cb(value, key);\n  }\n};\nObject.defineProperty(Map$1.prototype, 'size', {\n  get: function () {\n    return Object.keys(this._store).length;\n  }\n});\n\nfunction Set$1(array) {\n  this._store = new Map$1();\n\n  // init with an array\n  if (array && Array.isArray(array)) {\n    for (var i = 0, len = array.length; i < len; i++) {\n      this.add(array[i]);\n    }\n  }\n}\nSet$1.prototype.add = function (key) {\n  return this._store.set(key, true);\n};\nSet$1.prototype.has = function (key) {\n  return this._store.has(key);\n};\nSet$1.prototype.forEach = function (cb) {\n  this._store.forEach(function (value, key) {\n    cb(key);\n  });\n};\nObject.defineProperty(Set$1.prototype, 'size', {\n  get: function () {\n    return this._store.size;\n  }\n});\n\n/* global Map,Set,Symbol */\n// Based on https://kangax.github.io/compat-table/es6/ we can sniff out\n// incomplete Map/Set implementations which would otherwise cause our tests to fail.\n// Notably they fail in IE11 and iOS 8.4, which this prevents.\nfunction supportsMapAndSet() {\n  if (typeof Symbol === 'undefined' || typeof Map === 'undefined' || typeof Set === 'undefined') {\n    return false;\n  }\n  var prop = Object.getOwnPropertyDescriptor(Map, Symbol.species);\n  return prop && 'get' in prop && Map[Symbol.species] === Map;\n}\n\n// based on https://github.com/montagejs/collections\n\nvar ExportedSet;\nvar ExportedMap;\n\n{\n  if (supportsMapAndSet()) { // prefer built-in Map/Set\n    ExportedSet = Set;\n    ExportedMap = Map;\n  } else { // fall back to our polyfill\n    ExportedSet = Set$1;\n    ExportedMap = Map$1;\n  }\n}\n\nexport { ExportedSet as Set, ExportedMap as Map };\n","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n","import inherits from 'inherits';\n\ninherits(PouchError, Error);\n\nfunction PouchError(status, error, reason) {\n  Error.call(this, reason);\n  this.status = status;\n  this.name = error;\n  this.message = reason;\n  this.error = true;\n}\n\nPouchError.prototype.toString = function () {\n  return JSON.stringify({\n    status: this.status,\n    name: this.name,\n    message: this.message,\n    reason: this.reason\n  });\n};\n\nvar UNAUTHORIZED = new PouchError(401, 'unauthorized', \"Name or password is incorrect.\");\nvar MISSING_BULK_DOCS = new PouchError(400, 'bad_request', \"Missing JSON list of 'docs'\");\nvar MISSING_DOC = new PouchError(404, 'not_found', 'missing');\nvar REV_CONFLICT = new PouchError(409, 'conflict', 'Document update conflict');\nvar INVALID_ID = new PouchError(400, 'bad_request', '_id field must contain a string');\nvar MISSING_ID = new PouchError(412, 'missing_id', '_id is required for puts');\nvar RESERVED_ID = new PouchError(400, 'bad_request', 'Only reserved document ids may start with underscore.');\nvar NOT_OPEN = new PouchError(412, 'precondition_failed', 'Database not open');\nvar UNKNOWN_ERROR = new PouchError(500, 'unknown_error', 'Database encountered an unknown error');\nvar BAD_ARG = new PouchError(500, 'badarg', 'Some query argument is invalid');\nvar INVALID_REQUEST = new PouchError(400, 'invalid_request', 'Request was invalid');\nvar QUERY_PARSE_ERROR = new PouchError(400, 'query_parse_error', 'Some query parameter is invalid');\nvar DOC_VALIDATION = new PouchError(500, 'doc_validation', 'Bad special document member');\nvar BAD_REQUEST = new PouchError(400, 'bad_request', 'Something wrong with the request');\nvar NOT_AN_OBJECT = new PouchError(400, 'bad_request', 'Document must be a JSON object');\nvar DB_MISSING = new PouchError(404, 'not_found', 'Database not found');\nvar IDB_ERROR = new PouchError(500, 'indexed_db_went_bad', 'unknown');\nvar WSQ_ERROR = new PouchError(500, 'web_sql_went_bad', 'unknown');\nvar LDB_ERROR = new PouchError(500, 'levelDB_went_went_bad', 'unknown');\nvar FORBIDDEN = new PouchError(403, 'forbidden', 'Forbidden by design doc validate_doc_update function');\nvar INVALID_REV = new PouchError(400, 'bad_request', 'Invalid rev format');\nvar FILE_EXISTS = new PouchError(412, 'file_exists', 'The database could not be created, the file already exists.');\nvar MISSING_STUB = new PouchError(412, 'missing_stub', 'A pre-existing attachment stub wasn\\'t found');\nvar INVALID_URL = new PouchError(413, 'invalid_url', 'Provided URL is invalid');\n\nfunction createError(error, reason) {\n  function CustomPouchError(reason) {\n    // inherit error properties from our parent error manually\n    // so as to allow proper JSON parsing.\n    /* jshint ignore:start */\n    for (var p in error) {\n      if (typeof error[p] !== 'function') {\n        this[p] = error[p];\n      }\n    }\n    /* jshint ignore:end */\n    if (reason !== undefined) {\n      this.reason = reason;\n    }\n  }\n  CustomPouchError.prototype = PouchError.prototype;\n  return new CustomPouchError(reason);\n}\n\nfunction generateErrorFromResponse(err) {\n\n  if (typeof err !== 'object') {\n    var data = err;\n    err = UNKNOWN_ERROR;\n    err.data = data;\n  }\n\n  if ('error' in err && err.error === 'conflict') {\n    err.name = 'conflict';\n    err.status = 409;\n  }\n\n  if (!('name' in err)) {\n    err.name = err.error || 'unknown';\n  }\n\n  if (!('status' in err)) {\n    err.status = 500;\n  }\n\n  if (!('message' in err)) {\n    err.message = err.message || err.reason;\n  }\n\n  return err;\n}\n\nexport { UNAUTHORIZED, MISSING_BULK_DOCS, MISSING_DOC, REV_CONFLICT, INVALID_ID, MISSING_ID, RESERVED_ID, NOT_OPEN, UNKNOWN_ERROR, BAD_ARG, INVALID_REQUEST, QUERY_PARSE_ERROR, DOC_VALIDATION, BAD_REQUEST, NOT_AN_OBJECT, DB_MISSING, WSQ_ERROR, LDB_ERROR, FORBIDDEN, INVALID_REV, FILE_EXISTS, MISSING_STUB, IDB_ERROR, INVALID_URL, createError, generateErrorFromResponse };\n","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n","import { btoa, readAsArrayBuffer } from 'pouchdb-binary-utils';\nimport Md5 from 'spark-md5';\n\nvar setImmediateShim = global.setImmediate || global.setTimeout;\nvar MD5_CHUNK_SIZE = 32768;\n\nfunction rawToBase64(raw) {\n  return btoa(raw);\n}\n\nfunction sliceBlob(blob, start, end) {\n  if (blob.webkitSlice) {\n    return blob.webkitSlice(start, end);\n  }\n  return blob.slice(start, end);\n}\n\nfunction appendBlob(buffer, blob, start, end, callback) {\n  if (start > 0 || end < blob.size) {\n    // only slice blob if we really need to\n    blob = sliceBlob(blob, start, end);\n  }\n  readAsArrayBuffer(blob, function (arrayBuffer) {\n    buffer.append(arrayBuffer);\n    callback();\n  });\n}\n\nfunction appendString(buffer, string, start, end, callback) {\n  if (start > 0 || end < string.length) {\n    // only create a substring if we really need to\n    string = string.substring(start, end);\n  }\n  buffer.appendBinary(string);\n  callback();\n}\n\nfunction binaryMd5(data, callback) {\n  var inputIsString = typeof data === 'string';\n  var len = inputIsString ? data.length : data.size;\n  var chunkSize = Math.min(MD5_CHUNK_SIZE, len);\n  var chunks = Math.ceil(len / chunkSize);\n  var currentChunk = 0;\n  var buffer = inputIsString ? new Md5() : new Md5.ArrayBuffer();\n\n  var append = inputIsString ? appendString : appendBlob;\n\n  function next() {\n    setImmediateShim(loadNextChunk);\n  }\n\n  function done() {\n    var raw = buffer.end(true);\n    var base64 = rawToBase64(raw);\n    callback(base64);\n    buffer.destroy();\n  }\n\n  function loadNextChunk() {\n    var start = currentChunk * chunkSize;\n    var end = start + chunkSize;\n    currentChunk++;\n    if (currentChunk < chunks) {\n      append(buffer, data, start, end, next);\n    } else {\n      append(buffer, data, start, end, done);\n    }\n  }\n  loadNextChunk();\n}\n\nfunction stringMd5(string) {\n  return Md5.hash(string);\n}\n\nexport { binaryMd5, stringMd5 };\n","var thisAtob = function (str) {\n  return atob(str);\n};\n\nvar thisBtoa = function (str) {\n  return btoa(str);\n};\n\n// Abstracts constructing a Blob object, so it also works in older\n// browsers that don't support the native Blob constructor (e.g.\n// old QtWebKit versions, Android < 4.4).\nfunction createBlob(parts, properties) {\n  /* global BlobBuilder,MSBlobBuilder,MozBlobBuilder,WebKitBlobBuilder */\n  parts = parts || [];\n  properties = properties || {};\n  try {\n    return new Blob(parts, properties);\n  } catch (e) {\n    if (e.name !== \"TypeError\") {\n      throw e;\n    }\n    var Builder = typeof BlobBuilder !== 'undefined' ? BlobBuilder :\n                  typeof MSBlobBuilder !== 'undefined' ? MSBlobBuilder :\n                  typeof MozBlobBuilder !== 'undefined' ? MozBlobBuilder :\n                  WebKitBlobBuilder;\n    var builder = new Builder();\n    for (var i = 0; i < parts.length; i += 1) {\n      builder.append(parts[i]);\n    }\n    return builder.getBlob(properties.type);\n  }\n}\n\n// From http://stackoverflow.com/questions/14967647/ (continues on next line)\n// encode-decode-image-with-base64-breaks-image (2013-04-21)\nfunction binaryStringToArrayBuffer(bin) {\n  var length = bin.length;\n  var buf = new ArrayBuffer(length);\n  var arr = new Uint8Array(buf);\n  for (var i = 0; i < length; i++) {\n    arr[i] = bin.charCodeAt(i);\n  }\n  return buf;\n}\n\nfunction binStringToBluffer(binString, type) {\n  return createBlob([binaryStringToArrayBuffer(binString)], {type: type});\n}\n\nfunction b64ToBluffer(b64, type) {\n  return binStringToBluffer(thisAtob(b64), type);\n}\n\n//Can't find original post, but this is close\n//http://stackoverflow.com/questions/6965107/ (continues on next line)\n//converting-between-strings-and-arraybuffers\nfunction arrayBufferToBinaryString(buffer) {\n  var binary = '';\n  var bytes = new Uint8Array(buffer);\n  var length = bytes.byteLength;\n  for (var i = 0; i < length; i++) {\n    binary += String.fromCharCode(bytes[i]);\n  }\n  return binary;\n}\n\n// shim for browsers that don't support it\nfunction readAsBinaryString(blob, callback) {\n  var reader = new FileReader();\n  var hasBinaryString = typeof reader.readAsBinaryString === 'function';\n  reader.onloadend = function (e) {\n    var result = e.target.result || '';\n    if (hasBinaryString) {\n      return callback(result);\n    }\n    callback(arrayBufferToBinaryString(result));\n  };\n  if (hasBinaryString) {\n    reader.readAsBinaryString(blob);\n  } else {\n    reader.readAsArrayBuffer(blob);\n  }\n}\n\nfunction blobToBinaryString(blobOrBuffer, callback) {\n  readAsBinaryString(blobOrBuffer, function (bin) {\n    callback(bin);\n  });\n}\n\nfunction blobToBase64(blobOrBuffer, callback) {\n  blobToBinaryString(blobOrBuffer, function (base64) {\n    callback(thisBtoa(base64));\n  });\n}\n\n// simplified API. universal browser support is assumed\nfunction readAsArrayBuffer(blob, callback) {\n  var reader = new FileReader();\n  reader.onloadend = function (e) {\n    var result = e.target.result || new ArrayBuffer(0);\n    callback(result);\n  };\n  reader.readAsArrayBuffer(blob);\n}\n\n// this is not used in the browser\nfunction typedBuffer() {\n}\n\nexport { thisAtob as atob, thisBtoa as btoa, b64ToBluffer as base64StringToBlobOrBuffer, binaryStringToArrayBuffer, binStringToBluffer as binaryStringToBlobOrBuffer, createBlob as blob, blobToBase64 as blobOrBufferToBase64, blobToBinaryString as blobOrBufferToBinaryString, readAsArrayBuffer, readAsBinaryString, typedBuffer };\n","import levelup from 'levelup';\nimport sublevel from 'sublevel-pouchdb';\nimport { obj } from 'through2';\nimport getArguments from 'argsarray';\nimport Deque from 'double-ended-queue';\nimport bufferFrom from 'buffer-from';\nimport { allDocsKeysQuery, isDeleted, isLocalId, parseDoc, processDocs } from 'pouchdb-adapter-utils';\nimport { winningRev, traverseRevTree, compactTree, collectConflicts, latest } from 'pouchdb-merge';\nimport { safeJsonParse, safeJsonStringify } from 'pouchdb-json';\nimport { binaryMd5 } from 'pouchdb-md5';\nimport { blob, readAsBinaryString, atob, binaryStringToBlobOrBuffer } from 'pouchdb-binary-utils';\nimport { Map, Set } from 'pouchdb-collections';\nimport { nextTick, clone, changesHandler, filterChange, functionName, uuid } from 'pouchdb-utils';\nimport { MISSING_DOC, REV_CONFLICT, NOT_OPEN, BAD_ARG, MISSING_STUB, createError } from 'pouchdb-errors';\n\nfunction readAsBlobOrBuffer(storedObject, type) {\n  // In the browser, we've stored a binary string. This now comes back as a\n  // browserified Node-style Buffer (implemented as a typed array),\n  // but we want a Blob instead.\n  var byteArray = new Uint8Array(storedObject);\n  return blob([byteArray], {type: type});\n}\n\n// In the browser, we store a binary string\nfunction prepareAttachmentForStorage(attData, cb) {\n  readAsBinaryString(attData, cb);\n}\n\nfunction createEmptyBlobOrBuffer(type) {\n  return blob([''], {type: type});\n}\n\nfunction getCacheFor(transaction, store) {\n  var prefix = store.prefix()[0];\n  var cache = transaction._cache;\n  var subCache = cache.get(prefix);\n  if (!subCache) {\n    subCache = new Map();\n    cache.set(prefix, subCache);\n  }\n  return subCache;\n}\n\nfunction LevelTransaction() {\n  this._batch = [];\n  this._cache = new Map();\n}\n\nLevelTransaction.prototype.get = function (store, key, callback) {\n  var cache = getCacheFor(this, store);\n  var exists = cache.get(key);\n  if (exists) {\n    return nextTick(function () {\n      callback(null, exists);\n    });\n  } else if (exists === null) { // deleted marker\n    /* istanbul ignore next */\n    return nextTick(function () {\n      callback({name: 'NotFoundError'});\n    });\n  }\n  store.get(key, function (err, res) {\n    if (err) {\n      /* istanbul ignore else */\n      if (err.name === 'NotFoundError') {\n        cache.set(key, null);\n      }\n      return callback(err);\n    }\n    cache.set(key, res);\n    callback(null, res);\n  });\n};\n\nLevelTransaction.prototype.batch = function (batch) {\n  for (var i = 0, len = batch.length; i < len; i++) {\n    var operation = batch[i];\n\n    var cache = getCacheFor(this, operation.prefix);\n\n    if (operation.type === 'put') {\n      cache.set(operation.key, operation.value);\n    } else {\n      cache.set(operation.key, null);\n    }\n  }\n  this._batch = this._batch.concat(batch);\n};\n\nLevelTransaction.prototype.execute = function (db, callback) {\n\n  var keys = new Set();\n  var uniqBatches = [];\n\n  // remove duplicates; last one wins\n  for (var i = this._batch.length - 1; i >= 0; i--) {\n    var operation = this._batch[i];\n    var lookupKey = operation.prefix.prefix()[0] + '\\xff' + operation.key;\n    if (keys.has(lookupKey)) {\n      continue;\n    }\n    keys.add(lookupKey);\n    uniqBatches.push(operation);\n  }\n\n  db.batch(uniqBatches, callback);\n};\n\nvar DOC_STORE = 'document-store';\nvar BY_SEQ_STORE = 'by-sequence';\nvar ATTACHMENT_STORE = 'attach-store';\nvar BINARY_STORE = 'attach-binary-store';\nvar LOCAL_STORE = 'local-store';\nvar META_STORE = 'meta-store';\n\n// leveldb barks if we try to open a db multiple times\n// so we cache opened connections here for initstore()\nvar dbStores = new Map();\n\n// store the value of update_seq in the by-sequence store the key name will\n// never conflict, since the keys in the by-sequence store are integers\nvar UPDATE_SEQ_KEY = '_local_last_update_seq';\nvar DOC_COUNT_KEY = '_local_doc_count';\nvar UUID_KEY = '_local_uuid';\n\nvar MD5_PREFIX = 'md5-';\n\nvar safeJsonEncoding = {\n  encode: safeJsonStringify,\n  decode: safeJsonParse,\n  buffer: false,\n  type: 'cheap-json'\n};\n\nvar levelChanges = new changesHandler();\n\n// winningRev and deleted are performance-killers, but\n// in newer versions of PouchDB, they are cached on the metadata\nfunction getWinningRev(metadata) {\n  return 'winningRev' in metadata ?\n    metadata.winningRev : winningRev(metadata);\n}\n\nfunction getIsDeleted(metadata, winningRev$$1) {\n  return 'deleted' in metadata ?\n    metadata.deleted : isDeleted(metadata, winningRev$$1);\n}\n\nfunction fetchAttachment(att, stores, opts) {\n  var type = att.content_type;\n  return new Promise(function (resolve, reject) {\n    stores.binaryStore.get(att.digest, function (err, buffer) {\n      var data;\n      if (err) {\n        /* istanbul ignore if */\n        if (err.name !== 'NotFoundError') {\n          return reject(err);\n        } else {\n          // empty\n          if (!opts.binary) {\n            data = '';\n          } else {\n            data = binaryStringToBlobOrBuffer('', type);\n          }\n        }\n      } else { // non-empty\n        if (opts.binary) {\n          data = readAsBlobOrBuffer(buffer, type);\n        } else {\n          data = buffer.toString('base64');\n        }\n      }\n      delete att.stub;\n      delete att.length;\n      att.data = data;\n      resolve();\n    });\n  });\n}\n\nfunction fetchAttachments(results, stores, opts) {\n  var atts = [];\n  results.forEach(function (row) {\n    if (!(row.doc && row.doc._attachments)) {\n      return;\n    }\n    var attNames = Object.keys(row.doc._attachments);\n    attNames.forEach(function (attName) {\n      var att = row.doc._attachments[attName];\n      if (!('data' in att)) {\n        atts.push(att);\n      }\n    });\n  });\n\n  return Promise.all(atts.map(function (att) {\n    return fetchAttachment(att, stores, opts);\n  }));\n}\n\nfunction LevelPouch(opts, callback) {\n  opts = clone(opts);\n  var api = this;\n  var instanceId;\n  var stores = {};\n  var revLimit = opts.revs_limit;\n  var db;\n  var name = opts.name;\n  // TODO: this is undocumented and unused probably\n  /* istanbul ignore else */\n  if (typeof opts.createIfMissing === 'undefined') {\n    opts.createIfMissing = true;\n  }\n\n  var leveldown = opts.db;\n\n  var dbStore;\n  var leveldownName = functionName(leveldown);\n  if (dbStores.has(leveldownName)) {\n    dbStore = dbStores.get(leveldownName);\n  } else {\n    dbStore = new Map();\n    dbStores.set(leveldownName, dbStore);\n  }\n  if (dbStore.has(name)) {\n    db = dbStore.get(name);\n    afterDBCreated();\n  } else {\n    dbStore.set(name, sublevel(levelup(leveldown(name), opts, function (err) {\n      /* istanbul ignore if */\n      if (err) {\n        dbStore.delete(name);\n        return callback(err);\n      }\n      db = dbStore.get(name);\n      db._docCount  = -1;\n      db._queue = new Deque();\n      /* istanbul ignore else */\n      if (typeof opts.migrate === 'object') { // migration for leveldown\n        opts.migrate.doMigrationOne(name, db, afterDBCreated);\n      } else {\n        afterDBCreated();\n      }\n    })));\n  }\n\n  function afterDBCreated() {\n    stores.docStore = db.sublevel(DOC_STORE, {valueEncoding: safeJsonEncoding});\n    stores.bySeqStore = db.sublevel(BY_SEQ_STORE, {valueEncoding: 'json'});\n    stores.attachmentStore =\n      db.sublevel(ATTACHMENT_STORE, {valueEncoding: 'json'});\n    stores.binaryStore = db.sublevel(BINARY_STORE, {valueEncoding: 'binary'});\n    stores.localStore = db.sublevel(LOCAL_STORE, {valueEncoding: 'json'});\n    stores.metaStore = db.sublevel(META_STORE, {valueEncoding: 'json'});\n    /* istanbul ignore else */\n    if (typeof opts.migrate === 'object') { // migration for leveldown\n      opts.migrate.doMigrationTwo(db, stores, afterLastMigration);\n    } else {\n      afterLastMigration();\n    }\n  }\n\n  function afterLastMigration() {\n    stores.metaStore.get(UPDATE_SEQ_KEY, function (err, value) {\n      if (typeof db._updateSeq === 'undefined') {\n        db._updateSeq = value || 0;\n      }\n      stores.metaStore.get(DOC_COUNT_KEY, function (err, value) {\n        db._docCount = !err ? value : 0;\n        stores.metaStore.get(UUID_KEY, function (err, value) {\n          instanceId = !err ? value : uuid();\n          stores.metaStore.put(UUID_KEY, instanceId, function () {\n            nextTick(function () {\n              callback(null, api);\n            });\n          });\n        });\n      });\n    });\n  }\n\n  function countDocs(callback) {\n    /* istanbul ignore if */\n    if (db.isClosed()) {\n      return callback(new Error('database is closed'));\n    }\n    return callback(null, db._docCount); // use cached value\n  }\n\n  api._remote = false;\n  /* istanbul ignore next */\n  api.type = function () {\n    return 'leveldb';\n  };\n\n  api._id = function (callback) {\n    callback(null, instanceId);\n  };\n\n  api._info = function (callback) {\n    var res = {\n      doc_count: db._docCount,\n      update_seq: db._updateSeq,\n      backend_adapter: functionName(leveldown)\n    };\n    return nextTick(function () {\n      callback(null, res);\n    });\n  };\n\n  function tryCode(fun, args) {\n    try {\n      fun.apply(null, args);\n    } catch (err) {\n      args[args.length - 1](err);\n    }\n  }\n\n  function executeNext() {\n    var firstTask = db._queue.peekFront();\n\n    if (firstTask.type === 'read') {\n      runReadOperation(firstTask);\n    } else { // write, only do one at a time\n      runWriteOperation(firstTask);\n    }\n  }\n\n  function runReadOperation(firstTask) {\n    // do multiple reads at once simultaneously, because it's safe\n\n    var readTasks = [firstTask];\n    var i = 1;\n    var nextTask = db._queue.get(i);\n    while (typeof nextTask !== 'undefined' && nextTask.type === 'read') {\n      readTasks.push(nextTask);\n      i++;\n      nextTask = db._queue.get(i);\n    }\n\n    var numDone = 0;\n\n    readTasks.forEach(function (readTask) {\n      var args = readTask.args;\n      var callback = args[args.length - 1];\n      args[args.length - 1] = getArguments(function (cbArgs) {\n        callback.apply(null, cbArgs);\n        if (++numDone === readTasks.length) {\n          nextTick(function () {\n            // all read tasks have finished\n            readTasks.forEach(function () {\n              db._queue.shift();\n            });\n            if (db._queue.length) {\n              executeNext();\n            }\n          });\n        }\n      });\n      tryCode(readTask.fun, args);\n    });\n  }\n\n  function runWriteOperation(firstTask) {\n    var args = firstTask.args;\n    var callback = args[args.length - 1];\n    args[args.length - 1] = getArguments(function (cbArgs) {\n      callback.apply(null, cbArgs);\n      nextTick(function () {\n        db._queue.shift();\n        if (db._queue.length) {\n          executeNext();\n        }\n      });\n    });\n    tryCode(firstTask.fun, args);\n  }\n\n  // all read/write operations to the database are done in a queue,\n  // similar to how websql/idb works. this avoids problems such\n  // as e.g. compaction needing to have a lock on the database while\n  // it updates stuff. in the future we can revisit this.\n  function writeLock(fun) {\n    return getArguments(function (args) {\n      db._queue.push({\n        fun: fun,\n        args: args,\n        type: 'write'\n      });\n\n      if (db._queue.length === 1) {\n        nextTick(executeNext);\n      }\n    });\n  }\n\n  // same as the writelock, but multiple can run at once\n  function readLock(fun) {\n    return getArguments(function (args) {\n      db._queue.push({\n        fun: fun,\n        args: args,\n        type: 'read'\n      });\n\n      if (db._queue.length === 1) {\n        nextTick(executeNext);\n      }\n    });\n  }\n\n  function formatSeq(n) {\n    return ('0000000000000000' + n).slice(-16);\n  }\n\n  function parseSeq(s) {\n    return parseInt(s, 10);\n  }\n\n  api._get = readLock(function (id, opts, callback) {\n    opts = clone(opts);\n\n    stores.docStore.get(id, function (err, metadata) {\n\n      if (err || !metadata) {\n        return callback(createError(MISSING_DOC, 'missing'));\n      }\n\n      var rev;\n      if (!opts.rev) {\n        rev = getWinningRev(metadata);\n        var deleted = getIsDeleted(metadata, rev);\n        if (deleted) {\n          return callback(createError(MISSING_DOC, \"deleted\"));\n        }\n      } else {\n        rev = opts.latest ? latest(opts.rev, metadata) : opts.rev;\n      }\n\n      var seq = metadata.rev_map[rev];\n\n      stores.bySeqStore.get(formatSeq(seq), function (err, doc) {\n        if (!doc) {\n          return callback(createError(MISSING_DOC));\n        }\n        /* istanbul ignore if */\n        if ('_id' in doc && doc._id !== metadata.id) {\n          // this failing implies something very wrong\n          return callback(new Error('wrong doc returned'));\n        }\n        doc._id = metadata.id;\n        if ('_rev' in doc) {\n          /* istanbul ignore if */\n          if (doc._rev !== rev) {\n            // this failing implies something very wrong\n            return callback(new Error('wrong doc returned'));\n          }\n        } else {\n          // we didn't always store this\n          doc._rev = rev;\n        }\n        return callback(null, {doc: doc, metadata: metadata});\n      });\n    });\n  });\n\n  // not technically part of the spec, but if putAttachment has its own\n  // method...\n  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n    var digest = attachment.digest;\n    var type = attachment.content_type;\n\n    stores.binaryStore.get(digest, function (err, attach) {\n      if (err) {\n        /* istanbul ignore if */\n        if (err.name !== 'NotFoundError') {\n          return callback(err);\n        }\n        // Empty attachment\n        return callback(null, opts.binary ? createEmptyBlobOrBuffer(type) : '');\n      }\n\n      if (opts.binary) {\n        callback(null, readAsBlobOrBuffer(attach, type));\n      } else {\n        callback(null, attach.toString('base64'));\n      }\n    });\n  };\n\n  api._bulkDocs = writeLock(function (req, opts, callback) {\n    var newEdits = opts.new_edits;\n    var results = new Array(req.docs.length);\n    var fetchedDocs = new Map();\n    var stemmedRevs = new Map();\n\n    var txn = new LevelTransaction();\n    var docCountDelta = 0;\n    var newUpdateSeq = db._updateSeq;\n\n    // parse the docs and give each a sequence number\n    var userDocs = req.docs;\n    var docInfos = userDocs.map(function (doc) {\n      if (doc._id && isLocalId(doc._id)) {\n        return doc;\n      }\n      var newDoc = parseDoc(doc, newEdits, api.__opts);\n\n      if (newDoc.metadata && !newDoc.metadata.rev_map) {\n        newDoc.metadata.rev_map = {};\n      }\n\n      return newDoc;\n    });\n    var infoErrors = docInfos.filter(function (doc) {\n      return doc.error;\n    });\n\n    if (infoErrors.length) {\n      return callback(infoErrors[0]);\n    }\n\n    // verify any stub attachments as a precondition test\n\n    function verifyAttachment(digest, callback) {\n      txn.get(stores.attachmentStore, digest, function (levelErr) {\n        if (levelErr) {\n          var err = createError(MISSING_STUB,\n                                'unknown stub attachment with digest ' +\n                                digest);\n          callback(err);\n        } else {\n          callback();\n        }\n      });\n    }\n\n    function verifyAttachments(finish) {\n      var digests = [];\n      userDocs.forEach(function (doc) {\n        if (doc && doc._attachments) {\n          Object.keys(doc._attachments).forEach(function (filename) {\n            var att = doc._attachments[filename];\n            if (att.stub) {\n              digests.push(att.digest);\n            }\n          });\n        }\n      });\n      if (!digests.length) {\n        return finish();\n      }\n      var numDone = 0;\n      var err;\n\n      digests.forEach(function (digest) {\n        verifyAttachment(digest, function (attErr) {\n          if (attErr && !err) {\n            err = attErr;\n          }\n\n          if (++numDone === digests.length) {\n            finish(err);\n          }\n        });\n      });\n    }\n\n    function fetchExistingDocs(finish) {\n      var numDone = 0;\n      var overallErr;\n      function checkDone() {\n        if (++numDone === userDocs.length) {\n          return finish(overallErr);\n        }\n      }\n\n      userDocs.forEach(function (doc) {\n        if (doc._id && isLocalId(doc._id)) {\n          // skip local docs\n          return checkDone();\n        }\n        txn.get(stores.docStore, doc._id, function (err, info) {\n          if (err) {\n            /* istanbul ignore if */\n            if (err.name !== 'NotFoundError') {\n              overallErr = err;\n            }\n          } else {\n            fetchedDocs.set(doc._id, info);\n          }\n          checkDone();\n        });\n      });\n    }\n\n    function compact(revsMap, callback) {\n      var promise = Promise.resolve();\n      revsMap.forEach(function (revs, docId) {\n        // TODO: parallelize, for now need to be sequential to\n        // pass orphaned attachment tests\n        promise = promise.then(function () {\n          return new Promise(function (resolve, reject) {\n            api._doCompactionNoLock(docId, revs, {ctx: txn}, function (err) {\n              /* istanbul ignore if */\n              if (err) {\n                return reject(err);\n              }\n              resolve();\n            });\n          });\n        });\n      });\n\n      promise.then(function () {\n        callback();\n      }, callback);\n    }\n\n    function autoCompact(callback) {\n      var revsMap = new Map();\n      fetchedDocs.forEach(function (metadata, docId) {\n        revsMap.set(docId, compactTree(metadata));\n      });\n      compact(revsMap, callback);\n    }\n\n    function finish() {\n      compact(stemmedRevs, function (error) {\n        /* istanbul ignore if */\n        if (error) {\n          complete(error);\n        }\n        if (api.auto_compaction) {\n          return autoCompact(complete);\n        }\n        complete();\n      });\n    }\n\n    function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n                      isUpdate, delta, resultsIdx, callback2) {\n      docCountDelta += delta;\n\n      var err = null;\n      var recv = 0;\n\n      docInfo.metadata.winningRev = winningRev$$1;\n      docInfo.metadata.deleted = winningRevIsDeleted;\n\n      docInfo.data._id = docInfo.metadata.id;\n      docInfo.data._rev = docInfo.metadata.rev;\n\n      if (newRevIsDeleted) {\n        docInfo.data._deleted = true;\n      }\n\n      if (docInfo.stemmedRevs.length) {\n        stemmedRevs.set(docInfo.metadata.id, docInfo.stemmedRevs);\n      }\n\n      var attachments = docInfo.data._attachments ?\n        Object.keys(docInfo.data._attachments) :\n        [];\n\n      function attachmentSaved(attachmentErr) {\n        recv++;\n        if (!err) {\n          /* istanbul ignore if */\n          if (attachmentErr) {\n            err = attachmentErr;\n            callback2(err);\n          } else if (recv === attachments.length) {\n            finish();\n          }\n        }\n      }\n\n      function onMD5Load(doc, key, data, attachmentSaved) {\n        return function (result) {\n          saveAttachment(doc, MD5_PREFIX + result, key, data, attachmentSaved);\n        };\n      }\n\n      function doMD5(doc, key, attachmentSaved) {\n        return function (data) {\n          binaryMd5(data, onMD5Load(doc, key, data, attachmentSaved));\n        };\n      }\n\n      for (var i = 0; i < attachments.length; i++) {\n        var key = attachments[i];\n        var att = docInfo.data._attachments[key];\n\n        if (att.stub) {\n          // still need to update the refs mapping\n          var id = docInfo.data._id;\n          var rev = docInfo.data._rev;\n          saveAttachmentRefs(id, rev, att.digest, attachmentSaved);\n          continue;\n        }\n        var data;\n        if (typeof att.data === 'string') {\n          // input is assumed to be a base64 string\n          try {\n            data = atob(att.data);\n          } catch (e) {\n            callback(createError(BAD_ARG,\n                     'Attachment is not a valid base64 string'));\n            return;\n          }\n          doMD5(docInfo, key, attachmentSaved)(data);\n        } else {\n          prepareAttachmentForStorage(att.data,\n            doMD5(docInfo, key, attachmentSaved));\n        }\n      }\n\n      function finish() {\n        var seq = docInfo.metadata.rev_map[docInfo.metadata.rev];\n        /* istanbul ignore if */\n        if (seq) {\n          // check that there aren't any existing revisions with the same\n          // revision id, else we shouldn't do anything\n          return callback2();\n        }\n        seq = ++newUpdateSeq;\n        docInfo.metadata.rev_map[docInfo.metadata.rev] =\n          docInfo.metadata.seq = seq;\n        var seqKey = formatSeq(seq);\n        var batch = [{\n          key: seqKey,\n          value: docInfo.data,\n          prefix: stores.bySeqStore,\n          type: 'put'\n        }, {\n          key: docInfo.metadata.id,\n          value: docInfo.metadata,\n          prefix: stores.docStore,\n          type: 'put'\n        }];\n        txn.batch(batch);\n        results[resultsIdx] = {\n          ok: true,\n          id: docInfo.metadata.id,\n          rev: docInfo.metadata.rev\n        };\n        fetchedDocs.set(docInfo.metadata.id, docInfo.metadata);\n        callback2();\n      }\n\n      if (!attachments.length) {\n        finish();\n      }\n    }\n\n    // attachments are queued per-digest, otherwise the refs could be\n    // overwritten by concurrent writes in the same bulkDocs session\n    var attachmentQueues = {};\n\n    function saveAttachmentRefs(id, rev, digest, callback) {\n\n      function fetchAtt() {\n        return new Promise(function (resolve, reject) {\n          txn.get(stores.attachmentStore, digest, function (err, oldAtt) {\n            /* istanbul ignore if */\n            if (err && err.name !== 'NotFoundError') {\n              return reject(err);\n            }\n            resolve(oldAtt);\n          });\n        });\n      }\n\n      function saveAtt(oldAtt) {\n        var ref = [id, rev].join('@');\n        var newAtt = {};\n\n        if (oldAtt) {\n          if (oldAtt.refs) {\n            // only update references if this attachment already has them\n            // since we cannot migrate old style attachments here without\n            // doing a full db scan for references\n            newAtt.refs = oldAtt.refs;\n            newAtt.refs[ref] = true;\n          }\n        } else {\n          newAtt.refs = {};\n          newAtt.refs[ref] = true;\n        }\n\n        return new Promise(function (resolve) {\n          txn.batch([{\n            type: 'put',\n            prefix: stores.attachmentStore,\n            key: digest,\n            value: newAtt\n          }]);\n          resolve(!oldAtt);\n        });\n      }\n\n      // put attachments in a per-digest queue, to avoid two docs with the same\n      // attachment overwriting each other\n      var queue = attachmentQueues[digest] || Promise.resolve();\n      attachmentQueues[digest] = queue.then(function () {\n        return fetchAtt().then(saveAtt).then(function (isNewAttachment) {\n          callback(null, isNewAttachment);\n        }, callback);\n      });\n    }\n\n    function saveAttachment(docInfo, digest, key, data, callback) {\n      var att = docInfo.data._attachments[key];\n      delete att.data;\n      att.digest = digest;\n      att.length = data.length;\n      var id = docInfo.metadata.id;\n      var rev = docInfo.metadata.rev;\n      att.revpos = parseInt(rev, 10);\n\n      saveAttachmentRefs(id, rev, digest, function (err, isNewAttachment) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        // do not try to store empty attachments\n        if (data.length === 0) {\n          return callback(err);\n        }\n        if (!isNewAttachment) {\n          // small optimization - don't bother writing it again\n          return callback(err);\n        }\n        txn.batch([{\n          type: 'put',\n          prefix: stores.binaryStore,\n          key: digest,\n          value: bufferFrom(data, 'binary')\n        }]);\n        callback();\n      });\n    }\n\n    function complete(err) {\n      /* istanbul ignore if */\n      if (err) {\n        return nextTick(function () {\n          callback(err);\n        });\n      }\n      txn.batch([\n        {\n          prefix: stores.metaStore,\n          type: 'put',\n          key: UPDATE_SEQ_KEY,\n          value: newUpdateSeq\n        },\n        {\n          prefix: stores.metaStore,\n          type: 'put',\n          key: DOC_COUNT_KEY,\n          value: db._docCount + docCountDelta\n        }\n      ]);\n      txn.execute(db, function (err) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        db._docCount += docCountDelta;\n        db._updateSeq = newUpdateSeq;\n        levelChanges.notify(name);\n        nextTick(function () {\n          callback(null, results);\n        });\n      });\n    }\n\n    if (!docInfos.length) {\n      return callback(null, []);\n    }\n\n    verifyAttachments(function (err) {\n      if (err) {\n        return callback(err);\n      }\n      fetchExistingDocs(function (err) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        processDocs(revLimit, docInfos, api, fetchedDocs, txn, results,\n                    writeDoc, opts, finish);\n      });\n    });\n  });\n  api._allDocs = function (opts, callback) {\n    if ('keys' in opts) {\n      return allDocsKeysQuery(this, opts);\n    }\n    return readLock(function (opts, callback) {\n      opts = clone(opts);\n      countDocs(function (err, docCount) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        var readstreamOpts = {};\n        var skip = opts.skip || 0;\n        if (opts.startkey) {\n          readstreamOpts.gte = opts.startkey;\n        }\n        if (opts.endkey) {\n          readstreamOpts.lte = opts.endkey;\n        }\n        if (opts.key) {\n          readstreamOpts.gte = readstreamOpts.lte = opts.key;\n        }\n        if (opts.descending) {\n          readstreamOpts.reverse = true;\n          // switch start and ends\n          var tmp = readstreamOpts.lte;\n          readstreamOpts.lte = readstreamOpts.gte;\n          readstreamOpts.gte = tmp;\n        }\n        var limit;\n        if (typeof opts.limit === 'number') {\n          limit = opts.limit;\n        }\n        if (limit === 0 ||\n            ('gte' in readstreamOpts && 'lte' in readstreamOpts &&\n            readstreamOpts.gte > readstreamOpts.lte)) {\n          // should return 0 results when start is greater than end.\n          // normally level would \"fix\" this for us by reversing the order,\n          // so short-circuit instead\n          var returnVal = {\n            total_rows: docCount,\n            offset: opts.skip,\n            rows: []\n          };\n          /* istanbul ignore if */\n          if (opts.update_seq) {\n            returnVal.update_seq = db._updateSeq;\n          }\n          return callback(null, returnVal);\n        }\n        var results = [];\n        var docstream = stores.docStore.readStream(readstreamOpts);\n\n        var throughStream = obj(function (entry, _, next) {\n          var metadata = entry.value;\n          // winningRev and deleted are performance-killers, but\n          // in newer versions of PouchDB, they are cached on the metadata\n          var winningRev$$1 = getWinningRev(metadata);\n          var deleted = getIsDeleted(metadata, winningRev$$1);\n          if (!deleted) {\n            if (skip-- > 0) {\n              next();\n              return;\n            } else if (typeof limit === 'number' && limit-- <= 0) {\n              docstream.unpipe();\n              docstream.destroy();\n              next();\n              return;\n            }\n          } else if (opts.deleted !== 'ok') {\n            next();\n            return;\n          }\n          function allDocsInner(data) {\n            var doc = {\n              id: metadata.id,\n              key: metadata.id,\n              value: {\n                rev: winningRev$$1\n              }\n            };\n            if (opts.include_docs) {\n              doc.doc = data;\n              doc.doc._rev = doc.value.rev;\n              if (opts.conflicts) {\n                var conflicts = collectConflicts(metadata);\n                if (conflicts.length) {\n                  doc.doc._conflicts = conflicts;\n                }\n              }\n              for (var att in doc.doc._attachments) {\n                if (doc.doc._attachments.hasOwnProperty(att)) {\n                  doc.doc._attachments[att].stub = true;\n                }\n              }\n            }\n            if (opts.inclusive_end === false && metadata.id === opts.endkey) {\n              return next();\n            } else if (deleted) {\n              if (opts.deleted === 'ok') {\n                doc.value.deleted = true;\n                doc.doc = null;\n              } else {\n                /* istanbul ignore next */\n                return next();\n              }\n            }\n            results.push(doc);\n            next();\n          }\n          if (opts.include_docs) {\n            var seq = metadata.rev_map[winningRev$$1];\n            stores.bySeqStore.get(formatSeq(seq), function (err, data) {\n              allDocsInner(data);\n            });\n          }\n          else {\n            allDocsInner();\n          }\n        }, function (next) {\n          Promise.resolve().then(function () {\n            if (opts.include_docs && opts.attachments) {\n              return fetchAttachments(results, stores, opts);\n            }\n          }).then(function () {\n            var returnVal = {\n              total_rows: docCount,\n              offset: opts.skip,\n              rows: results\n            };\n\n            /* istanbul ignore if */\n            if (opts.update_seq) {\n              returnVal.update_seq = db._updateSeq;\n            }\n            callback(null, returnVal);\n          }, callback);\n          next();\n        }).on('unpipe', function () {\n          throughStream.end();\n        });\n\n        docstream.on('error', callback);\n\n        docstream.pipe(throughStream);\n      });\n    })(opts, callback);\n  };\n\n  api._changes = function (opts) {\n    opts = clone(opts);\n\n    if (opts.continuous) {\n      var id = name + ':' + uuid();\n      levelChanges.addListener(name, id, api, opts);\n      levelChanges.notify(name);\n      return {\n        cancel: function () {\n          levelChanges.removeListener(name, id);\n        }\n      };\n    }\n\n    var descending = opts.descending;\n    var results = [];\n    var lastSeq = opts.since || 0;\n    var called = 0;\n    var streamOpts = {\n      reverse: descending\n    };\n    var limit;\n    if ('limit' in opts && opts.limit > 0) {\n      limit = opts.limit;\n    }\n    if (!streamOpts.reverse) {\n      streamOpts.start = formatSeq(opts.since || 0);\n    }\n\n    var docIds = opts.doc_ids && new Set(opts.doc_ids);\n    var filter = filterChange(opts);\n    var docIdsToMetadata = new Map();\n\n    function complete() {\n      opts.done = true;\n      if (opts.return_docs && opts.limit) {\n        /* istanbul ignore if */\n        if (opts.limit < results.length) {\n          results.length = opts.limit;\n        }\n      }\n      changeStream.unpipe(throughStream);\n      changeStream.destroy();\n      if (!opts.continuous && !opts.cancelled) {\n        if (opts.include_docs && opts.attachments && opts.return_docs) {\n          fetchAttachments(results, stores, opts).then(function () {\n            opts.complete(null, {results: results, last_seq: lastSeq});\n          });\n        } else {\n          opts.complete(null, {results: results, last_seq: lastSeq});\n        }\n      }\n    }\n    var changeStream = stores.bySeqStore.readStream(streamOpts);\n    var throughStream = obj(function (data, _, next) {\n      if (limit && called >= limit) {\n        complete();\n        return next();\n      }\n      if (opts.cancelled || opts.done) {\n        return next();\n      }\n\n      var seq = parseSeq(data.key);\n      var doc = data.value;\n\n      if (seq === opts.since && !descending) {\n        // couchdb ignores `since` if descending=true\n        return next();\n      }\n\n      if (docIds && !docIds.has(doc._id)) {\n        return next();\n      }\n\n      var metadata;\n\n      function onGetMetadata(metadata) {\n        var winningRev$$1 = getWinningRev(metadata);\n\n        function onGetWinningDoc(winningDoc) {\n\n          var change = opts.processChange(winningDoc, metadata, opts);\n          change.seq = metadata.seq;\n\n          var filtered = filter(change);\n          if (typeof filtered === 'object') {\n            return opts.complete(filtered);\n          }\n\n          if (filtered) {\n            called++;\n\n            if (opts.attachments && opts.include_docs) {\n              // fetch attachment immediately for the benefit\n              // of live listeners\n              fetchAttachments([change], stores, opts).then(function () {\n                opts.onChange(change);\n              });\n            } else {\n              opts.onChange(change);\n            }\n\n            if (opts.return_docs) {\n              results.push(change);\n            }\n          }\n          next();\n        }\n\n        if (metadata.seq !== seq) {\n          // some other seq is later\n          return next();\n        }\n\n        lastSeq = seq;\n\n        if (winningRev$$1 === doc._rev) {\n          return onGetWinningDoc(doc);\n        }\n\n        // fetch the winner\n\n        var winningSeq = metadata.rev_map[winningRev$$1];\n\n        stores.bySeqStore.get(formatSeq(winningSeq), function (err, doc) {\n          onGetWinningDoc(doc);\n        });\n      }\n\n      metadata = docIdsToMetadata.get(doc._id);\n      if (metadata) { // cached\n        return onGetMetadata(metadata);\n      }\n      // metadata not cached, have to go fetch it\n      stores.docStore.get(doc._id, function (err, metadata) {\n        /* istanbul ignore if */\n        if (opts.cancelled || opts.done || db.isClosed() ||\n          isLocalId(metadata.id)) {\n          return next();\n        }\n        docIdsToMetadata.set(doc._id, metadata);\n        onGetMetadata(metadata);\n      });\n    }, function (next) {\n      if (opts.cancelled) {\n        return next();\n      }\n      if (opts.return_docs && opts.limit) {\n        /* istanbul ignore if */\n        if (opts.limit < results.length) {\n          results.length = opts.limit;\n        }\n      }\n\n      next();\n    }).on('unpipe', function () {\n      throughStream.end();\n      complete();\n    });\n    changeStream.pipe(throughStream);\n    return {\n      cancel: function () {\n        opts.cancelled = true;\n        complete();\n      }\n    };\n  };\n\n  api._close = function (callback) {\n    /* istanbul ignore if */\n    if (db.isClosed()) {\n      return callback(createError(NOT_OPEN));\n    }\n    db.close(function (err) {\n      /* istanbul ignore if */\n      if (err) {\n        callback(err);\n      } else {\n        dbStore.delete(name);\n        callback();\n      }\n    });\n  };\n\n  api._getRevisionTree = function (docId, callback) {\n    stores.docStore.get(docId, function (err, metadata) {\n      if (err) {\n        callback(createError(MISSING_DOC));\n      } else {\n        callback(null, metadata.rev_tree);\n      }\n    });\n  };\n\n  api._doCompaction = writeLock(function (docId, revs, opts, callback) {\n    api._doCompactionNoLock(docId, revs, opts, callback);\n  });\n\n  // the NoLock version is for use by bulkDocs\n  api._doCompactionNoLock = function (docId, revs, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n\n    if (!revs.length) {\n      return callback();\n    }\n    var txn = opts.ctx || new LevelTransaction();\n\n    txn.get(stores.docStore, docId, function (err, metadata) {\n      /* istanbul ignore if */\n      if (err) {\n        return callback(err);\n      }\n      var seqs = revs.map(function (rev) {\n        var seq = metadata.rev_map[rev];\n        delete metadata.rev_map[rev];\n        return seq;\n      });\n      traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                                         revHash, ctx, opts) {\n        var rev = pos + '-' + revHash;\n        if (revs.indexOf(rev) !== -1) {\n          opts.status = 'missing';\n        }\n      });\n\n      var batch = [];\n      batch.push({\n        key: metadata.id,\n        value: metadata,\n        type: 'put',\n        prefix: stores.docStore\n      });\n\n      var digestMap = {};\n      var numDone = 0;\n      var overallErr;\n      function checkDone(err) {\n        /* istanbul ignore if */\n        if (err) {\n          overallErr = err;\n        }\n        if (++numDone === revs.length) { // done\n          /* istanbul ignore if */\n          if (overallErr) {\n            return callback(overallErr);\n          }\n          deleteOrphanedAttachments();\n        }\n      }\n\n      function finish(err) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        txn.batch(batch);\n        if (opts.ctx) {\n          // don't execute immediately\n          return callback();\n        }\n        txn.execute(db, callback);\n      }\n\n      function deleteOrphanedAttachments() {\n        var possiblyOrphanedAttachments = Object.keys(digestMap);\n        if (!possiblyOrphanedAttachments.length) {\n          return finish();\n        }\n        var numDone = 0;\n        var overallErr;\n        function checkDone(err) {\n          /* istanbul ignore if */\n          if (err) {\n            overallErr = err;\n          }\n          if (++numDone === possiblyOrphanedAttachments.length) {\n            finish(overallErr);\n          }\n        }\n        var refsToDelete = new Map();\n        revs.forEach(function (rev) {\n          refsToDelete.set(docId + '@' + rev, true);\n        });\n        possiblyOrphanedAttachments.forEach(function (digest) {\n          txn.get(stores.attachmentStore, digest, function (err, attData) {\n            /* istanbul ignore if */\n            if (err) {\n              if (err.name === 'NotFoundError') {\n                return checkDone();\n              } else {\n                return checkDone(err);\n              }\n            }\n            var refs = Object.keys(attData.refs || {}).filter(function (ref) {\n              return !refsToDelete.has(ref);\n            });\n            var newRefs = {};\n            refs.forEach(function (ref) {\n              newRefs[ref] = true;\n            });\n            if (refs.length) { // not orphaned\n              batch.push({\n                key: digest,\n                type: 'put',\n                value: {refs: newRefs},\n                prefix: stores.attachmentStore\n              });\n            } else { // orphaned, can safely delete\n              batch = batch.concat([{\n                key: digest,\n                type: 'del',\n                prefix: stores.attachmentStore\n              }, {\n                key: digest,\n                type: 'del',\n                prefix: stores.binaryStore\n              }]);\n            }\n            checkDone();\n          });\n        });\n      }\n\n      seqs.forEach(function (seq) {\n        batch.push({\n          key: formatSeq(seq),\n          type: 'del',\n          prefix: stores.bySeqStore\n        });\n        txn.get(stores.bySeqStore, formatSeq(seq), function (err, doc) {\n          /* istanbul ignore if */\n          if (err) {\n            if (err.name === 'NotFoundError') {\n              return checkDone();\n            } else {\n              return checkDone(err);\n            }\n          }\n          var atts = Object.keys(doc._attachments || {});\n          atts.forEach(function (attName) {\n            var digest = doc._attachments[attName].digest;\n            digestMap[digest] = true;\n          });\n          checkDone();\n        });\n      });\n    });\n  };\n\n  api._getLocal = function (id, callback) {\n    stores.localStore.get(id, function (err, doc) {\n      if (err) {\n        callback(createError(MISSING_DOC));\n      } else {\n        callback(null, doc);\n      }\n    });\n  };\n\n  api._putLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    if (opts.ctx) {\n      api._putLocalNoLock(doc, opts, callback);\n    } else {\n      api._putLocalWithLock(doc, opts, callback);\n    }\n  };\n\n  api._putLocalWithLock = writeLock(function (doc, opts, callback) {\n    api._putLocalNoLock(doc, opts, callback);\n  });\n\n  // the NoLock version is for use by bulkDocs\n  api._putLocalNoLock = function (doc, opts, callback) {\n    delete doc._revisions; // ignore this, trust the rev\n    var oldRev = doc._rev;\n    var id = doc._id;\n\n    var txn = opts.ctx || new LevelTransaction();\n\n    txn.get(stores.localStore, id, function (err, resp) {\n      if (err && oldRev) {\n        return callback(createError(REV_CONFLICT));\n      }\n      if (resp && resp._rev !== oldRev) {\n        return callback(createError(REV_CONFLICT));\n      }\n      doc._rev =\n          oldRev ? '0-' + (parseInt(oldRev.split('-')[1], 10) + 1) : '0-1';\n      var batch = [\n        {\n          type: 'put',\n          prefix: stores.localStore,\n          key: id,\n          value: doc\n        }\n      ];\n\n      txn.batch(batch);\n      var ret = {ok: true, id: doc._id, rev: doc._rev};\n\n      if (opts.ctx) {\n        // don't execute immediately\n        return callback(null, ret);\n      }\n      txn.execute(db, function (err) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        callback(null, ret);\n      });\n    });\n  };\n\n  api._removeLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    if (opts.ctx) {\n      api._removeLocalNoLock(doc, opts, callback);\n    } else {\n      api._removeLocalWithLock(doc, opts, callback);\n    }\n  };\n\n  api._removeLocalWithLock = writeLock(function (doc, opts, callback) {\n    api._removeLocalNoLock(doc, opts, callback);\n  });\n\n  // the NoLock version is for use by bulkDocs\n  api._removeLocalNoLock = function (doc, opts, callback) {\n    var txn = opts.ctx || new LevelTransaction();\n    txn.get(stores.localStore, doc._id, function (err, resp) {\n      if (err) {\n        /* istanbul ignore if */\n        if (err.name !== 'NotFoundError') {\n          return callback(err);\n        } else {\n          return callback(createError(MISSING_DOC));\n        }\n      }\n      if (resp._rev !== doc._rev) {\n        return callback(createError(REV_CONFLICT));\n      }\n      txn.batch([{\n        prefix: stores.localStore,\n        type: 'del',\n        key: doc._id\n      }]);\n      var ret = {ok: true, id: doc._id, rev: '0-0'};\n      if (opts.ctx) {\n        // don't execute immediately\n        return callback(null, ret);\n      }\n      txn.execute(db, function (err) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        callback(null, ret);\n      });\n    });\n  };\n\n  // close and delete open leveldb stores\n  api._destroy = function (opts, callback) {\n    var dbStore;\n    var leveldownName = functionName(leveldown);\n    /* istanbul ignore else */\n    if (dbStores.has(leveldownName)) {\n      dbStore = dbStores.get(leveldownName);\n    } else {\n      return callDestroy(name, callback);\n    }\n\n    /* istanbul ignore else */\n    if (dbStore.has(name)) {\n      levelChanges.removeAllListeners(name);\n\n      dbStore.get(name).close(function () {\n        dbStore.delete(name);\n        callDestroy(name, callback);\n      });\n    } else {\n      callDestroy(name, callback);\n    }\n  };\n  function callDestroy(name, cb) {\n    // May not exist if leveldown is backed by memory adapter\n    /* istanbul ignore else */\n    if ('destroy' in leveldown) {\n      leveldown.destroy(name, cb);\n    } else {\n      cb(null);\n    }\n  }\n}\n\nexport default LevelPouch;\n","var EventEmitter = require('events').EventEmitter\nvar inherits = require('util').inherits\nvar extend = require('xtend')\nvar DeferredLevelDOWN = require('deferred-leveldown')\nvar IteratorStream = require('level-iterator-stream')\nvar Batch = require('./batch')\nvar errors = require('level-errors')\nvar assert = require('assert')\nvar promisify = require('./promisify')\nvar getCallback = require('./common').getCallback\nvar getOptions = require('./common').getOptions\n\nvar WriteError = errors.WriteError\nvar ReadError = errors.ReadError\nvar NotFoundError = errors.NotFoundError\nvar OpenError = errors.OpenError\nvar InitializationError = errors.InitializationError\n\n// Possible AbstractLevelDOWN#status values:\n//  - 'new'     - newly created, not opened or closed\n//  - 'opening' - waiting for the database to be opened, post open()\n//  - 'open'    - successfully opened the database, available for use\n//  - 'closing' - waiting for the database to be closed, post close()\n//  - 'closed'  - database has been successfully closed, should not be\n//                 used except for another open() operation\n\nfunction LevelUP (db, options, callback) {\n  if (!(this instanceof LevelUP)) {\n    return new LevelUP(db, options, callback)\n  }\n\n  var error\n\n  EventEmitter.call(this)\n  this.setMaxListeners(Infinity)\n\n  if (typeof options === 'function') {\n    callback = options\n    options = {}\n  }\n\n  options = options || {}\n\n  if (!db || typeof db !== 'object') {\n    error = new InitializationError('First argument must be an abstract-leveldown compliant store')\n    if (typeof callback === 'function') {\n      return process.nextTick(callback, error)\n    }\n    throw error\n  }\n\n  assert.strictEqual(typeof db.status, 'string', '.status required, old abstract-leveldown')\n\n  this.options = getOptions(options)\n  this._db = db\n  this.db = new DeferredLevelDOWN(db)\n  this.open(callback)\n}\n\nLevelUP.prototype.emit = EventEmitter.prototype.emit\nLevelUP.prototype.once = EventEmitter.prototype.once\ninherits(LevelUP, EventEmitter)\n\nLevelUP.prototype.open = function (callback) {\n  var self = this\n  var promise\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  if (this.isOpen()) {\n    process.nextTick(callback, null, self)\n    return promise\n  }\n\n  if (this._isOpening()) {\n    this.once('open', function () { callback(null, self) })\n    return promise\n  }\n\n  this.emit('opening')\n\n  this.db.open(this.options, function (err) {\n    if (err) {\n      return callback(new OpenError(err))\n    }\n    self.db = self._db\n    callback(null, self)\n    self.emit('open')\n    self.emit('ready')\n  })\n\n  return promise\n}\n\nLevelUP.prototype.close = function (callback) {\n  var self = this\n  var promise\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  if (this.isOpen()) {\n    this.db.close(function () {\n      self.emit('closed')\n      callback.apply(null, arguments)\n    })\n    this.emit('closing')\n    this.db = new DeferredLevelDOWN(this._db)\n  } else if (this.isClosed()) {\n    process.nextTick(callback)\n  } else if (this.db.status === 'closing') {\n    this.once('closed', callback)\n  } else if (this._isOpening()) {\n    this.once('open', function () {\n      self.close(callback)\n    })\n  }\n\n  return promise\n}\n\nLevelUP.prototype.isOpen = function () {\n  return this.db.status === 'open'\n}\n\nLevelUP.prototype._isOpening = function () {\n  return this.db.status === 'opening'\n}\n\nLevelUP.prototype.isClosed = function () {\n  return (/^clos|new/).test(this.db.status)\n}\n\nLevelUP.prototype.get = function (key, options, callback) {\n  if (key === null || key === undefined) {\n    throw new ReadError('get() requires a key argument')\n  }\n\n  var promise\n\n  callback = getCallback(options, callback)\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  if (maybeError(this, callback)) { return promise }\n\n  options = getOptions(options)\n\n  this.db.get(key, options, function (err, value) {\n    if (err) {\n      if ((/notfound/i).test(err) || err.notFound) {\n        err = new NotFoundError('Key not found in database [' + key + ']', err)\n      } else {\n        err = new ReadError(err)\n      }\n      return callback(err)\n    }\n    callback(null, value)\n  })\n\n  return promise\n}\n\nLevelUP.prototype.put = function (key, value, options, callback) {\n  if (key === null || key === undefined) {\n    throw new WriteError('put() requires a key argument')\n  }\n\n  var self = this\n  var promise\n\n  callback = getCallback(options, callback)\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  if (maybeError(this, callback)) { return promise }\n\n  options = getOptions(options)\n\n  this.db.put(key, value, options, function (err) {\n    if (err) {\n      return callback(new WriteError(err))\n    }\n    self.emit('put', key, value)\n    callback()\n  })\n\n  return promise\n}\n\nLevelUP.prototype.del = function (key, options, callback) {\n  if (key === null || key === undefined) {\n    throw new WriteError('del() requires a key argument')\n  }\n\n  var self = this\n  var promise\n\n  callback = getCallback(options, callback)\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  if (maybeError(this, callback)) { return promise }\n\n  options = getOptions(options)\n\n  this.db.del(key, options, function (err) {\n    if (err) {\n      return callback(new WriteError(err))\n    }\n    self.emit('del', key)\n    callback()\n  })\n\n  return promise\n}\n\nLevelUP.prototype.batch = function (arr, options, callback) {\n  if (!arguments.length) {\n    return new Batch(this)\n  }\n\n  if (!Array.isArray(arr)) {\n    throw new WriteError('batch() requires an array argument')\n  }\n\n  var self = this\n  var promise\n\n  callback = getCallback(options, callback)\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  if (maybeError(this, callback)) { return promise }\n\n  options = getOptions(options)\n\n  this.db.batch(arr, options, function (err) {\n    if (err) {\n      return callback(new WriteError(err))\n    }\n    self.emit('batch', arr)\n    callback()\n  })\n\n  return promise\n}\n\nLevelUP.prototype.iterator = function (options) {\n  return this.db.iterator(options)\n}\n\nLevelUP.prototype.readStream =\nLevelUP.prototype.createReadStream = function (options) {\n  options = extend({ keys: true, values: true }, options)\n  if (typeof options.limit !== 'number') { options.limit = -1 }\n  return new IteratorStream(this.db.iterator(options), options)\n}\n\nLevelUP.prototype.keyStream =\nLevelUP.prototype.createKeyStream = function (options) {\n  return this.createReadStream(extend(options, { keys: true, values: false }))\n}\n\nLevelUP.prototype.valueStream =\nLevelUP.prototype.createValueStream = function (options) {\n  return this.createReadStream(extend(options, { keys: false, values: true }))\n}\n\nLevelUP.prototype.toString = function () {\n  return 'LevelUP'\n}\n\nfunction maybeError (db, callback) {\n  if (!db._isOpening() && !db.isOpen()) {\n    process.nextTick(callback, new ReadError('Database is not open'))\n    return true\n  }\n}\n\nLevelUP.errors = errors\nmodule.exports = LevelUP.default = LevelUP\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar getOwnPropertyDescriptors = Object.getOwnPropertyDescriptors ||\n  function getOwnPropertyDescriptors(obj) {\n    var keys = Object.keys(obj);\n    var descriptors = {};\n    for (var i = 0; i < keys.length; i++) {\n      descriptors[keys[i]] = Object.getOwnPropertyDescriptor(obj, keys[i]);\n    }\n    return descriptors;\n  };\n\nvar formatRegExp = /%[sdj%]/g;\nexports.format = function(f) {\n  if (!isString(f)) {\n    var objects = [];\n    for (var i = 0; i < arguments.length; i++) {\n      objects.push(inspect(arguments[i]));\n    }\n    return objects.join(' ');\n  }\n\n  var i = 1;\n  var args = arguments;\n  var len = args.length;\n  var str = String(f).replace(formatRegExp, function(x) {\n    if (x === '%%') return '%';\n    if (i >= len) return x;\n    switch (x) {\n      case '%s': return String(args[i++]);\n      case '%d': return Number(args[i++]);\n      case '%j':\n        try {\n          return JSON.stringify(args[i++]);\n        } catch (_) {\n          return '[Circular]';\n        }\n      default:\n        return x;\n    }\n  });\n  for (var x = args[i]; i < len; x = args[++i]) {\n    if (isNull(x) || !isObject(x)) {\n      str += ' ' + x;\n    } else {\n      str += ' ' + inspect(x);\n    }\n  }\n  return str;\n};\n\n\n// Mark that a method should not be used.\n// Returns a modified function which warns once by default.\n// If --no-deprecation is set, then it is a no-op.\nexports.deprecate = function(fn, msg) {\n  if (typeof process !== 'undefined' && process.noDeprecation === true) {\n    return fn;\n  }\n\n  // Allow for deprecating things in the process of starting up.\n  if (typeof process === 'undefined') {\n    return function() {\n      return exports.deprecate(fn, msg).apply(this, arguments);\n    };\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (process.throwDeprecation) {\n        throw new Error(msg);\n      } else if (process.traceDeprecation) {\n        console.trace(msg);\n      } else {\n        console.error(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n};\n\n\nvar debugs = {};\nvar debugEnviron;\nexports.debuglog = function(set) {\n  if (isUndefined(debugEnviron))\n    debugEnviron = process.env.NODE_DEBUG || '';\n  set = set.toUpperCase();\n  if (!debugs[set]) {\n    if (new RegExp('\\\\b' + set + '\\\\b', 'i').test(debugEnviron)) {\n      var pid = process.pid;\n      debugs[set] = function() {\n        var msg = exports.format.apply(exports, arguments);\n        console.error('%s %d: %s', set, pid, msg);\n      };\n    } else {\n      debugs[set] = function() {};\n    }\n  }\n  return debugs[set];\n};\n\n\n/**\n * Echos the value of a value. Trys to print the value out\n * in the best way possible given the different types.\n *\n * @param {Object} obj The object to print out.\n * @param {Object} opts Optional options object that alters the output.\n */\n/* legacy: obj, showHidden, depth, colors*/\nfunction inspect(obj, opts) {\n  // default options\n  var ctx = {\n    seen: [],\n    stylize: stylizeNoColor\n  };\n  // legacy...\n  if (arguments.length >= 3) ctx.depth = arguments[2];\n  if (arguments.length >= 4) ctx.colors = arguments[3];\n  if (isBoolean(opts)) {\n    // legacy...\n    ctx.showHidden = opts;\n  } else if (opts) {\n    // got an \"options\" object\n    exports._extend(ctx, opts);\n  }\n  // set default options\n  if (isUndefined(ctx.showHidden)) ctx.showHidden = false;\n  if (isUndefined(ctx.depth)) ctx.depth = 2;\n  if (isUndefined(ctx.colors)) ctx.colors = false;\n  if (isUndefined(ctx.customInspect)) ctx.customInspect = true;\n  if (ctx.colors) ctx.stylize = stylizeWithColor;\n  return formatValue(ctx, obj, ctx.depth);\n}\nexports.inspect = inspect;\n\n\n// http://en.wikipedia.org/wiki/ANSI_escape_code#graphics\ninspect.colors = {\n  'bold' : [1, 22],\n  'italic' : [3, 23],\n  'underline' : [4, 24],\n  'inverse' : [7, 27],\n  'white' : [37, 39],\n  'grey' : [90, 39],\n  'black' : [30, 39],\n  'blue' : [34, 39],\n  'cyan' : [36, 39],\n  'green' : [32, 39],\n  'magenta' : [35, 39],\n  'red' : [31, 39],\n  'yellow' : [33, 39]\n};\n\n// Don't use 'blue' not visible on cmd.exe\ninspect.styles = {\n  'special': 'cyan',\n  'number': 'yellow',\n  'boolean': 'yellow',\n  'undefined': 'grey',\n  'null': 'bold',\n  'string': 'green',\n  'date': 'magenta',\n  // \"name\": intentionally not styling\n  'regexp': 'red'\n};\n\n\nfunction stylizeWithColor(str, styleType) {\n  var style = inspect.styles[styleType];\n\n  if (style) {\n    return '\\u001b[' + inspect.colors[style][0] + 'm' + str +\n           '\\u001b[' + inspect.colors[style][1] + 'm';\n  } else {\n    return str;\n  }\n}\n\n\nfunction stylizeNoColor(str, styleType) {\n  return str;\n}\n\n\nfunction arrayToHash(array) {\n  var hash = {};\n\n  array.forEach(function(val, idx) {\n    hash[val] = true;\n  });\n\n  return hash;\n}\n\n\nfunction formatValue(ctx, value, recurseTimes) {\n  // Provide a hook for user-specified inspect functions.\n  // Check that value is an object with an inspect function on it\n  if (ctx.customInspect &&\n      value &&\n      isFunction(value.inspect) &&\n      // Filter out the util module, it's inspect function is special\n      value.inspect !== exports.inspect &&\n      // Also filter out any prototype objects using the circular check.\n      !(value.constructor && value.constructor.prototype === value)) {\n    var ret = value.inspect(recurseTimes, ctx);\n    if (!isString(ret)) {\n      ret = formatValue(ctx, ret, recurseTimes);\n    }\n    return ret;\n  }\n\n  // Primitive types cannot have properties\n  var primitive = formatPrimitive(ctx, value);\n  if (primitive) {\n    return primitive;\n  }\n\n  // Look up the keys of the object.\n  var keys = Object.keys(value);\n  var visibleKeys = arrayToHash(keys);\n\n  if (ctx.showHidden) {\n    keys = Object.getOwnPropertyNames(value);\n  }\n\n  // IE doesn't make error fields non-enumerable\n  // http://msdn.microsoft.com/en-us/library/ie/dww52sbt(v=vs.94).aspx\n  if (isError(value)\n      && (keys.indexOf('message') >= 0 || keys.indexOf('description') >= 0)) {\n    return formatError(value);\n  }\n\n  // Some type of object without properties can be shortcutted.\n  if (keys.length === 0) {\n    if (isFunction(value)) {\n      var name = value.name ? ': ' + value.name : '';\n      return ctx.stylize('[Function' + name + ']', 'special');\n    }\n    if (isRegExp(value)) {\n      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');\n    }\n    if (isDate(value)) {\n      return ctx.stylize(Date.prototype.toString.call(value), 'date');\n    }\n    if (isError(value)) {\n      return formatError(value);\n    }\n  }\n\n  var base = '', array = false, braces = ['{', '}'];\n\n  // Make Array say that they are Array\n  if (isArray(value)) {\n    array = true;\n    braces = ['[', ']'];\n  }\n\n  // Make functions say that they are functions\n  if (isFunction(value)) {\n    var n = value.name ? ': ' + value.name : '';\n    base = ' [Function' + n + ']';\n  }\n\n  // Make RegExps say that they are RegExps\n  if (isRegExp(value)) {\n    base = ' ' + RegExp.prototype.toString.call(value);\n  }\n\n  // Make dates with properties first say the date\n  if (isDate(value)) {\n    base = ' ' + Date.prototype.toUTCString.call(value);\n  }\n\n  // Make error with message first say the error\n  if (isError(value)) {\n    base = ' ' + formatError(value);\n  }\n\n  if (keys.length === 0 && (!array || value.length == 0)) {\n    return braces[0] + base + braces[1];\n  }\n\n  if (recurseTimes < 0) {\n    if (isRegExp(value)) {\n      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');\n    } else {\n      return ctx.stylize('[Object]', 'special');\n    }\n  }\n\n  ctx.seen.push(value);\n\n  var output;\n  if (array) {\n    output = formatArray(ctx, value, recurseTimes, visibleKeys, keys);\n  } else {\n    output = keys.map(function(key) {\n      return formatProperty(ctx, value, recurseTimes, visibleKeys, key, array);\n    });\n  }\n\n  ctx.seen.pop();\n\n  return reduceToSingleString(output, base, braces);\n}\n\n\nfunction formatPrimitive(ctx, value) {\n  if (isUndefined(value))\n    return ctx.stylize('undefined', 'undefined');\n  if (isString(value)) {\n    var simple = '\\'' + JSON.stringify(value).replace(/^\"|\"$/g, '')\n                                             .replace(/'/g, \"\\\\'\")\n                                             .replace(/\\\\\"/g, '\"') + '\\'';\n    return ctx.stylize(simple, 'string');\n  }\n  if (isNumber(value))\n    return ctx.stylize('' + value, 'number');\n  if (isBoolean(value))\n    return ctx.stylize('' + value, 'boolean');\n  // For some reason typeof null is \"object\", so special case here.\n  if (isNull(value))\n    return ctx.stylize('null', 'null');\n}\n\n\nfunction formatError(value) {\n  return '[' + Error.prototype.toString.call(value) + ']';\n}\n\n\nfunction formatArray(ctx, value, recurseTimes, visibleKeys, keys) {\n  var output = [];\n  for (var i = 0, l = value.length; i < l; ++i) {\n    if (hasOwnProperty(value, String(i))) {\n      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,\n          String(i), true));\n    } else {\n      output.push('');\n    }\n  }\n  keys.forEach(function(key) {\n    if (!key.match(/^\\d+$/)) {\n      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,\n          key, true));\n    }\n  });\n  return output;\n}\n\n\nfunction formatProperty(ctx, value, recurseTimes, visibleKeys, key, array) {\n  var name, str, desc;\n  desc = Object.getOwnPropertyDescriptor(value, key) || { value: value[key] };\n  if (desc.get) {\n    if (desc.set) {\n      str = ctx.stylize('[Getter/Setter]', 'special');\n    } else {\n      str = ctx.stylize('[Getter]', 'special');\n    }\n  } else {\n    if (desc.set) {\n      str = ctx.stylize('[Setter]', 'special');\n    }\n  }\n  if (!hasOwnProperty(visibleKeys, key)) {\n    name = '[' + key + ']';\n  }\n  if (!str) {\n    if (ctx.seen.indexOf(desc.value) < 0) {\n      if (isNull(recurseTimes)) {\n        str = formatValue(ctx, desc.value, null);\n      } else {\n        str = formatValue(ctx, desc.value, recurseTimes - 1);\n      }\n      if (str.indexOf('\\n') > -1) {\n        if (array) {\n          str = str.split('\\n').map(function(line) {\n            return '  ' + line;\n          }).join('\\n').substr(2);\n        } else {\n          str = '\\n' + str.split('\\n').map(function(line) {\n            return '   ' + line;\n          }).join('\\n');\n        }\n      }\n    } else {\n      str = ctx.stylize('[Circular]', 'special');\n    }\n  }\n  if (isUndefined(name)) {\n    if (array && key.match(/^\\d+$/)) {\n      return str;\n    }\n    name = JSON.stringify('' + key);\n    if (name.match(/^\"([a-zA-Z_][a-zA-Z_0-9]*)\"$/)) {\n      name = name.substr(1, name.length - 2);\n      name = ctx.stylize(name, 'name');\n    } else {\n      name = name.replace(/'/g, \"\\\\'\")\n                 .replace(/\\\\\"/g, '\"')\n                 .replace(/(^\"|\"$)/g, \"'\");\n      name = ctx.stylize(name, 'string');\n    }\n  }\n\n  return name + ': ' + str;\n}\n\n\nfunction reduceToSingleString(output, base, braces) {\n  var numLinesEst = 0;\n  var length = output.reduce(function(prev, cur) {\n    numLinesEst++;\n    if (cur.indexOf('\\n') >= 0) numLinesEst++;\n    return prev + cur.replace(/\\u001b\\[\\d\\d?m/g, '').length + 1;\n  }, 0);\n\n  if (length > 60) {\n    return braces[0] +\n           (base === '' ? '' : base + '\\n ') +\n           ' ' +\n           output.join(',\\n  ') +\n           ' ' +\n           braces[1];\n  }\n\n  return braces[0] + base + ' ' + output.join(', ') + ' ' + braces[1];\n}\n\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\nfunction isArray(ar) {\n  return Array.isArray(ar);\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return isObject(re) && objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return isObject(d) && objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return isObject(e) &&\n      (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = require('./support/isBuffer');\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n\n\nfunction pad(n) {\n  return n < 10 ? '0' + n.toString(10) : n.toString(10);\n}\n\n\nvar months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',\n              'Oct', 'Nov', 'Dec'];\n\n// 26 Feb 16:19:34\nfunction timestamp() {\n  var d = new Date();\n  var time = [pad(d.getHours()),\n              pad(d.getMinutes()),\n              pad(d.getSeconds())].join(':');\n  return [d.getDate(), months[d.getMonth()], time].join(' ');\n}\n\n\n// log is just a thin wrapper to console.log that prepends a timestamp\nexports.log = function() {\n  console.log('%s - %s', timestamp(), exports.format.apply(exports, arguments));\n};\n\n\n/**\n * Inherit the prototype methods from one constructor into another.\n *\n * The Function.prototype.inherits from lang.js rewritten as a standalone\n * function (not on Function.prototype). NOTE: If this file is to be loaded\n * during bootstrapping this function needs to be rewritten using some native\n * functions as prototype setup using normal JavaScript does not work as\n * expected during bootstrapping (see mirror.js in r114903).\n *\n * @param {function} ctor Constructor function which needs to inherit the\n *     prototype.\n * @param {function} superCtor Constructor function to inherit prototype from.\n */\nexports.inherits = require('inherits');\n\nexports._extend = function(origin, add) {\n  // Don't do anything if add isn't an object\n  if (!add || !isObject(add)) return origin;\n\n  var keys = Object.keys(add);\n  var i = keys.length;\n  while (i--) {\n    origin[keys[i]] = add[keys[i]];\n  }\n  return origin;\n};\n\nfunction hasOwnProperty(obj, prop) {\n  return Object.prototype.hasOwnProperty.call(obj, prop);\n}\n\nvar kCustomPromisifiedSymbol = typeof Symbol !== 'undefined' ? Symbol('util.promisify.custom') : undefined;\n\nexports.promisify = function promisify(original) {\n  if (typeof original !== 'function')\n    throw new TypeError('The \"original\" argument must be of type Function');\n\n  if (kCustomPromisifiedSymbol && original[kCustomPromisifiedSymbol]) {\n    var fn = original[kCustomPromisifiedSymbol];\n    if (typeof fn !== 'function') {\n      throw new TypeError('The \"util.promisify.custom\" argument must be of type Function');\n    }\n    Object.defineProperty(fn, kCustomPromisifiedSymbol, {\n      value: fn, enumerable: false, writable: false, configurable: true\n    });\n    return fn;\n  }\n\n  function fn() {\n    var promiseResolve, promiseReject;\n    var promise = new Promise(function (resolve, reject) {\n      promiseResolve = resolve;\n      promiseReject = reject;\n    });\n\n    var args = [];\n    for (var i = 0; i < arguments.length; i++) {\n      args.push(arguments[i]);\n    }\n    args.push(function (err, value) {\n      if (err) {\n        promiseReject(err);\n      } else {\n        promiseResolve(value);\n      }\n    });\n\n    try {\n      original.apply(this, args);\n    } catch (err) {\n      promiseReject(err);\n    }\n\n    return promise;\n  }\n\n  Object.setPrototypeOf(fn, Object.getPrototypeOf(original));\n\n  if (kCustomPromisifiedSymbol) Object.defineProperty(fn, kCustomPromisifiedSymbol, {\n    value: fn, enumerable: false, writable: false, configurable: true\n  });\n  return Object.defineProperties(\n    fn,\n    getOwnPropertyDescriptors(original)\n  );\n}\n\nexports.promisify.custom = kCustomPromisifiedSymbol\n\nfunction callbackifyOnRejected(reason, cb) {\n  // `!reason` guard inspired by bluebird (Ref: https://goo.gl/t5IS6M).\n  // Because `null` is a special error value in callbacks which means \"no error\n  // occurred\", we error-wrap so the callback consumer can distinguish between\n  // \"the promise rejected with null\" or \"the promise fulfilled with undefined\".\n  if (!reason) {\n    var newReason = new Error('Promise was rejected with a falsy value');\n    newReason.reason = reason;\n    reason = newReason;\n  }\n  return cb(reason);\n}\n\nfunction callbackify(original) {\n  if (typeof original !== 'function') {\n    throw new TypeError('The \"original\" argument must be of type Function');\n  }\n\n  // We DO NOT return the promise as it gives the user a false sense that\n  // the promise is actually somehow related to the callback's execution\n  // and that the callback throwing will reject the promise.\n  function callbackified() {\n    var args = [];\n    for (var i = 0; i < arguments.length; i++) {\n      args.push(arguments[i]);\n    }\n\n    var maybeCb = args.pop();\n    if (typeof maybeCb !== 'function') {\n      throw new TypeError('The last argument must be of type Function');\n    }\n    var self = this;\n    var cb = function() {\n      return maybeCb.apply(self, arguments);\n    };\n    // In true node style we process the callback on `nextTick` with all the\n    // implications (stack, `uncaughtException`, `async_hooks`)\n    original.apply(this, args)\n      .then(function(ret) { process.nextTick(cb, null, ret) },\n            function(rej) { process.nextTick(callbackifyOnRejected, rej, cb) });\n  }\n\n  Object.setPrototypeOf(callbackified, Object.getPrototypeOf(original));\n  Object.defineProperties(callbackified,\n                          getOwnPropertyDescriptors(original));\n  return callbackified;\n}\nexports.callbackify = callbackify;\n","module.exports = function isBuffer(arg) {\n  return arg && typeof arg === 'object'\n    && typeof arg.copy === 'function'\n    && typeof arg.fill === 'function'\n    && typeof arg.readUInt8 === 'function';\n}","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n","module.exports = extend\n\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\nfunction extend() {\n    var target = {}\n\n    for (var i = 0; i < arguments.length; i++) {\n        var source = arguments[i]\n\n        for (var key in source) {\n            if (hasOwnProperty.call(source, key)) {\n                target[key] = source[key]\n            }\n        }\n    }\n\n    return target\n}\n","var AbstractLevelDOWN = require('abstract-leveldown').AbstractLevelDOWN\nvar inherits = require('inherits')\nvar DeferredIterator = require('./deferred-iterator')\nvar deferrables = 'put get del batch'.split(' ')\n\nfunction DeferredLevelDOWN (db) {\n  AbstractLevelDOWN.call(this, '')\n  this._db = db\n  this._operations = []\n  this._iterators = []\n  closed(this)\n}\n\ninherits(DeferredLevelDOWN, AbstractLevelDOWN)\n\nDeferredLevelDOWN.prototype._open = function (options, callback) {\n  var self = this\n\n  this._db.open(options, function (err) {\n    if (err) return callback(err)\n\n    self._operations.forEach(function (op) {\n      self._db[op.method].apply(self._db, op.args)\n    })\n    self._operations = []\n    self._iterators.forEach(function (it) {\n      it.setDb(self._db)\n    })\n    self._iterators = []\n    open(self)\n    callback()\n  })\n}\n\nDeferredLevelDOWN.prototype._close = function (callback) {\n  var self = this\n\n  this._db.close(function (err) {\n    if (err) return callback(err)\n    closed(self)\n    callback()\n  })\n}\n\nfunction open (self) {\n  deferrables.concat('iterator').forEach(function (m) {\n    self['_' + m] = function () {\n      return this._db[m].apply(this._db, arguments)\n    }\n  })\n  if (self._db.approximateSize) {\n    self.approximateSize = function () {\n      return this._db.approximateSize.apply(this._db, arguments)\n    }\n  }\n}\n\nfunction closed (self) {\n  deferrables.forEach(function (m) {\n    self['_' + m] = function () {\n      this._operations.push({ method: m, args: arguments })\n    }\n  })\n  if (typeof self._db.approximateSize === 'function') {\n    self.approximateSize = function () {\n      this._operations.push({\n        method: 'approximateSize',\n        args: arguments\n      })\n    }\n  }\n  self._iterator = function (options) {\n    var it = new DeferredIterator(options)\n    this._iterators.push(it)\n    return it\n  }\n}\n\nDeferredLevelDOWN.prototype._serializeKey = function (key) {\n  return key\n}\n\nDeferredLevelDOWN.prototype._serializeValue = function (value) {\n  return value\n}\n\nmodule.exports = DeferredLevelDOWN\nmodule.exports.DeferredIterator = DeferredIterator\n","exports.AbstractLevelDOWN = require('./abstract-leveldown')\nexports.AbstractIterator = require('./abstract-iterator')\nexports.AbstractChainedBatch = require('./abstract-chained-batch')\n","var xtend = require('xtend')\nvar AbstractIterator = require('./abstract-iterator')\nvar AbstractChainedBatch = require('./abstract-chained-batch')\nvar hasOwnProperty = Object.prototype.hasOwnProperty\nvar rangeOptions = 'start end gt gte lt lte'.split(' ')\n\nfunction AbstractLevelDOWN () {\n  this.status = 'new'\n}\n\nAbstractLevelDOWN.prototype.open = function (options, callback) {\n  var self = this\n  var oldStatus = this.status\n\n  if (typeof options === 'function') callback = options\n\n  if (typeof callback !== 'function') {\n    throw new Error('open() requires a callback argument')\n  }\n\n  if (typeof options !== 'object' || options === null) options = {}\n\n  options.createIfMissing = options.createIfMissing !== false\n  options.errorIfExists = !!options.errorIfExists\n\n  this.status = 'opening'\n  this._open(options, function (err) {\n    if (err) {\n      self.status = oldStatus\n      return callback(err)\n    }\n    self.status = 'open'\n    callback()\n  })\n}\n\nAbstractLevelDOWN.prototype._open = function (options, callback) {\n  process.nextTick(callback)\n}\n\nAbstractLevelDOWN.prototype.close = function (callback) {\n  var self = this\n  var oldStatus = this.status\n\n  if (typeof callback !== 'function') {\n    throw new Error('close() requires a callback argument')\n  }\n\n  this.status = 'closing'\n  this._close(function (err) {\n    if (err) {\n      self.status = oldStatus\n      return callback(err)\n    }\n    self.status = 'closed'\n    callback()\n  })\n}\n\nAbstractLevelDOWN.prototype._close = function (callback) {\n  process.nextTick(callback)\n}\n\nAbstractLevelDOWN.prototype.get = function (key, options, callback) {\n  if (typeof options === 'function') callback = options\n\n  if (typeof callback !== 'function') {\n    throw new Error('get() requires a callback argument')\n  }\n\n  var err = this._checkKey(key)\n  if (err) return process.nextTick(callback, err)\n\n  key = this._serializeKey(key)\n\n  if (typeof options !== 'object' || options === null) options = {}\n\n  options.asBuffer = options.asBuffer !== false\n\n  this._get(key, options, callback)\n}\n\nAbstractLevelDOWN.prototype._get = function (key, options, callback) {\n  process.nextTick(function () { callback(new Error('NotFound')) })\n}\n\nAbstractLevelDOWN.prototype.put = function (key, value, options, callback) {\n  if (typeof options === 'function') callback = options\n\n  if (typeof callback !== 'function') {\n    throw new Error('put() requires a callback argument')\n  }\n\n  var err = this._checkKey(key) || this._checkValue(value)\n  if (err) return process.nextTick(callback, err)\n\n  key = this._serializeKey(key)\n  value = this._serializeValue(value)\n\n  if (typeof options !== 'object' || options === null) options = {}\n\n  this._put(key, value, options, callback)\n}\n\nAbstractLevelDOWN.prototype._put = function (key, value, options, callback) {\n  process.nextTick(callback)\n}\n\nAbstractLevelDOWN.prototype.del = function (key, options, callback) {\n  if (typeof options === 'function') callback = options\n\n  if (typeof callback !== 'function') {\n    throw new Error('del() requires a callback argument')\n  }\n\n  var err = this._checkKey(key)\n  if (err) return process.nextTick(callback, err)\n\n  key = this._serializeKey(key)\n\n  if (typeof options !== 'object' || options === null) options = {}\n\n  this._del(key, options, callback)\n}\n\nAbstractLevelDOWN.prototype._del = function (key, options, callback) {\n  process.nextTick(callback)\n}\n\nAbstractLevelDOWN.prototype.batch = function (array, options, callback) {\n  if (!arguments.length) return this._chainedBatch()\n\n  if (typeof options === 'function') callback = options\n\n  if (typeof array === 'function') callback = array\n\n  if (typeof callback !== 'function') {\n    throw new Error('batch(array) requires a callback argument')\n  }\n\n  if (!Array.isArray(array)) {\n    return process.nextTick(callback, new Error('batch(array) requires an array argument'))\n  }\n\n  if (array.length === 0) {\n    return process.nextTick(callback)\n  }\n\n  if (typeof options !== 'object' || options === null) options = {}\n\n  var serialized = new Array(array.length)\n\n  for (var i = 0; i < array.length; i++) {\n    if (typeof array[i] !== 'object' || array[i] === null) {\n      return process.nextTick(callback, new Error('batch(array) element must be an object and not `null`'))\n    }\n\n    var e = xtend(array[i])\n\n    if (e.type !== 'put' && e.type !== 'del') {\n      return process.nextTick(callback, new Error(\"`type` must be 'put' or 'del'\"))\n    }\n\n    var err = this._checkKey(e.key)\n    if (err) return process.nextTick(callback, err)\n\n    e.key = this._serializeKey(e.key)\n\n    if (e.type === 'put') {\n      var valueErr = this._checkValue(e.value)\n      if (valueErr) return process.nextTick(callback, valueErr)\n\n      e.value = this._serializeValue(e.value)\n    }\n\n    serialized[i] = e\n  }\n\n  this._batch(serialized, options, callback)\n}\n\nAbstractLevelDOWN.prototype._batch = function (array, options, callback) {\n  process.nextTick(callback)\n}\n\nAbstractLevelDOWN.prototype._setupIteratorOptions = function (options) {\n  options = cleanRangeOptions(this, options)\n\n  options.reverse = !!options.reverse\n  options.keys = options.keys !== false\n  options.values = options.values !== false\n  options.limit = 'limit' in options ? options.limit : -1\n  options.keyAsBuffer = options.keyAsBuffer !== false\n  options.valueAsBuffer = options.valueAsBuffer !== false\n\n  return options\n}\n\nfunction cleanRangeOptions (db, options) {\n  var result = {}\n\n  for (var k in options) {\n    if (!hasOwnProperty.call(options, k)) continue\n\n    var opt = options[k]\n\n    if (isRangeOption(k)) {\n      // Note that we don't reject nullish and empty options here. While\n      // those types are invalid as keys, they are valid as range options.\n      opt = db._serializeKey(opt)\n    }\n\n    result[k] = opt\n  }\n\n  return result\n}\n\nfunction isRangeOption (k) {\n  return rangeOptions.indexOf(k) !== -1\n}\n\nAbstractLevelDOWN.prototype.iterator = function (options) {\n  if (typeof options !== 'object' || options === null) options = {}\n  options = this._setupIteratorOptions(options)\n  return this._iterator(options)\n}\n\nAbstractLevelDOWN.prototype._iterator = function (options) {\n  return new AbstractIterator(this)\n}\n\nAbstractLevelDOWN.prototype._chainedBatch = function () {\n  return new AbstractChainedBatch(this)\n}\n\nAbstractLevelDOWN.prototype._serializeKey = function (key) {\n  return key\n}\n\nAbstractLevelDOWN.prototype._serializeValue = function (value) {\n  return value\n}\n\nAbstractLevelDOWN.prototype._checkKey = function (key) {\n  if (key === null || key === undefined) {\n    return new Error('key cannot be `null` or `undefined`')\n  } else if (Buffer.isBuffer(key) && key.length === 0) {\n    return new Error('key cannot be an empty Buffer')\n  } else if (key === '') {\n    return new Error('key cannot be an empty String')\n  } else if (Array.isArray(key) && key.length === 0) {\n    return new Error('key cannot be an empty Array')\n  }\n}\n\nAbstractLevelDOWN.prototype._checkValue = function (value) {\n  if (value === null || value === undefined) {\n    return new Error('value cannot be `null` or `undefined`')\n  }\n}\n\nmodule.exports = AbstractLevelDOWN\n","/*!\n * The buffer module from node.js, for the browser.\n *\n * @author   Feross Aboukhadijeh <feross@feross.org> <http://feross.org>\n * @license  MIT\n */\n/* eslint-disable no-proto */\n\n'use strict'\n\nvar base64 = require('base64-js')\nvar ieee754 = require('ieee754')\nvar isArray = require('isarray')\n\nexports.Buffer = Buffer\nexports.SlowBuffer = SlowBuffer\nexports.INSPECT_MAX_BYTES = 50\n\n/**\n * If `Buffer.TYPED_ARRAY_SUPPORT`:\n *   === true    Use Uint8Array implementation (fastest)\n *   === false   Use Object implementation (most compatible, even IE6)\n *\n * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,\n * Opera 11.6+, iOS 4.2+.\n *\n * Due to various browser bugs, sometimes the Object implementation will be used even\n * when the browser supports typed arrays.\n *\n * Note:\n *\n *   - Firefox 4-29 lacks support for adding new properties to `Uint8Array` instances,\n *     See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438.\n *\n *   - Chrome 9-10 is missing the `TypedArray.prototype.subarray` function.\n *\n *   - IE10 has a broken `TypedArray.prototype.subarray` function which returns arrays of\n *     incorrect length in some situations.\n\n * We detect these buggy browsers and set `Buffer.TYPED_ARRAY_SUPPORT` to `false` so they\n * get the Object implementation, which is slower but behaves correctly.\n */\nBuffer.TYPED_ARRAY_SUPPORT = global.TYPED_ARRAY_SUPPORT !== undefined\n  ? global.TYPED_ARRAY_SUPPORT\n  : typedArraySupport()\n\n/*\n * Export kMaxLength after typed array support is determined.\n */\nexports.kMaxLength = kMaxLength()\n\nfunction typedArraySupport () {\n  try {\n    var arr = new Uint8Array(1)\n    arr.__proto__ = {__proto__: Uint8Array.prototype, foo: function () { return 42 }}\n    return arr.foo() === 42 && // typed array instances can be augmented\n        typeof arr.subarray === 'function' && // chrome 9-10 lack `subarray`\n        arr.subarray(1, 1).byteLength === 0 // ie10 has broken `subarray`\n  } catch (e) {\n    return false\n  }\n}\n\nfunction kMaxLength () {\n  return Buffer.TYPED_ARRAY_SUPPORT\n    ? 0x7fffffff\n    : 0x3fffffff\n}\n\nfunction createBuffer (that, length) {\n  if (kMaxLength() < length) {\n    throw new RangeError('Invalid typed array length')\n  }\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    // Return an augmented `Uint8Array` instance, for best performance\n    that = new Uint8Array(length)\n    that.__proto__ = Buffer.prototype\n  } else {\n    // Fallback: Return an object instance of the Buffer class\n    if (that === null) {\n      that = new Buffer(length)\n    }\n    that.length = length\n  }\n\n  return that\n}\n\n/**\n * The Buffer constructor returns instances of `Uint8Array` that have their\n * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of\n * `Uint8Array`, so the returned instances will have all the node `Buffer` methods\n * and the `Uint8Array` methods. Square bracket notation works as expected -- it\n * returns a single octet.\n *\n * The `Uint8Array` prototype remains unmodified.\n */\n\nfunction Buffer (arg, encodingOrOffset, length) {\n  if (!Buffer.TYPED_ARRAY_SUPPORT && !(this instanceof Buffer)) {\n    return new Buffer(arg, encodingOrOffset, length)\n  }\n\n  // Common case.\n  if (typeof arg === 'number') {\n    if (typeof encodingOrOffset === 'string') {\n      throw new Error(\n        'If encoding is specified then the first argument must be a string'\n      )\n    }\n    return allocUnsafe(this, arg)\n  }\n  return from(this, arg, encodingOrOffset, length)\n}\n\nBuffer.poolSize = 8192 // not used by this implementation\n\n// TODO: Legacy, not needed anymore. Remove in next major version.\nBuffer._augment = function (arr) {\n  arr.__proto__ = Buffer.prototype\n  return arr\n}\n\nfunction from (that, value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (typeof ArrayBuffer !== 'undefined' && value instanceof ArrayBuffer) {\n    return fromArrayBuffer(that, value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(that, value, encodingOrOffset)\n  }\n\n  return fromObject(that, value)\n}\n\n/**\n * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError\n * if value is a number.\n * Buffer.from(str[, encoding])\n * Buffer.from(array)\n * Buffer.from(buffer)\n * Buffer.from(arrayBuffer[, byteOffset[, length]])\n **/\nBuffer.from = function (value, encodingOrOffset, length) {\n  return from(null, value, encodingOrOffset, length)\n}\n\nif (Buffer.TYPED_ARRAY_SUPPORT) {\n  Buffer.prototype.__proto__ = Uint8Array.prototype\n  Buffer.__proto__ = Uint8Array\n  if (typeof Symbol !== 'undefined' && Symbol.species &&\n      Buffer[Symbol.species] === Buffer) {\n    // Fix subarray() in ES2016. See: https://github.com/feross/buffer/pull/97\n    Object.defineProperty(Buffer, Symbol.species, {\n      value: null,\n      configurable: true\n    })\n  }\n}\n\nfunction assertSize (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('\"size\" argument must be a number')\n  } else if (size < 0) {\n    throw new RangeError('\"size\" argument must not be negative')\n  }\n}\n\nfunction alloc (that, size, fill, encoding) {\n  assertSize(size)\n  if (size <= 0) {\n    return createBuffer(that, size)\n  }\n  if (fill !== undefined) {\n    // Only pay attention to encoding if it's a string. This\n    // prevents accidentally sending in a number that would\n    // be interpretted as a start offset.\n    return typeof encoding === 'string'\n      ? createBuffer(that, size).fill(fill, encoding)\n      : createBuffer(that, size).fill(fill)\n  }\n  return createBuffer(that, size)\n}\n\n/**\n * Creates a new filled Buffer instance.\n * alloc(size[, fill[, encoding]])\n **/\nBuffer.alloc = function (size, fill, encoding) {\n  return alloc(null, size, fill, encoding)\n}\n\nfunction allocUnsafe (that, size) {\n  assertSize(size)\n  that = createBuffer(that, size < 0 ? 0 : checked(size) | 0)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) {\n    for (var i = 0; i < size; ++i) {\n      that[i] = 0\n    }\n  }\n  return that\n}\n\n/**\n * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.\n * */\nBuffer.allocUnsafe = function (size) {\n  return allocUnsafe(null, size)\n}\n/**\n * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.\n */\nBuffer.allocUnsafeSlow = function (size) {\n  return allocUnsafe(null, size)\n}\n\nfunction fromString (that, string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  var length = byteLength(string, encoding) | 0\n  that = createBuffer(that, length)\n\n  var actual = that.write(string, encoding)\n\n  if (actual !== length) {\n    // Writing a hex string, for example, that contains invalid characters will\n    // cause everything after the first invalid character to be ignored. (e.g.\n    // 'abxxcd' will be treated as 'ab')\n    that = that.slice(0, actual)\n  }\n\n  return that\n}\n\nfunction fromArrayLike (that, array) {\n  var length = array.length < 0 ? 0 : checked(array.length) | 0\n  that = createBuffer(that, length)\n  for (var i = 0; i < length; i += 1) {\n    that[i] = array[i] & 255\n  }\n  return that\n}\n\nfunction fromArrayBuffer (that, array, byteOffset, length) {\n  array.byteLength // this throws if `array` is not a valid ArrayBuffer\n\n  if (byteOffset < 0 || array.byteLength < byteOffset) {\n    throw new RangeError('\\'offset\\' is out of bounds')\n  }\n\n  if (array.byteLength < byteOffset + (length || 0)) {\n    throw new RangeError('\\'length\\' is out of bounds')\n  }\n\n  if (byteOffset === undefined && length === undefined) {\n    array = new Uint8Array(array)\n  } else if (length === undefined) {\n    array = new Uint8Array(array, byteOffset)\n  } else {\n    array = new Uint8Array(array, byteOffset, length)\n  }\n\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    // Return an augmented `Uint8Array` instance, for best performance\n    that = array\n    that.__proto__ = Buffer.prototype\n  } else {\n    // Fallback: Return an object instance of the Buffer class\n    that = fromArrayLike(that, array)\n  }\n  return that\n}\n\nfunction fromObject (that, obj) {\n  if (Buffer.isBuffer(obj)) {\n    var len = checked(obj.length) | 0\n    that = createBuffer(that, len)\n\n    if (that.length === 0) {\n      return that\n    }\n\n    obj.copy(that, 0, 0, len)\n    return that\n  }\n\n  if (obj) {\n    if ((typeof ArrayBuffer !== 'undefined' &&\n        obj.buffer instanceof ArrayBuffer) || 'length' in obj) {\n      if (typeof obj.length !== 'number' || isnan(obj.length)) {\n        return createBuffer(that, 0)\n      }\n      return fromArrayLike(that, obj)\n    }\n\n    if (obj.type === 'Buffer' && isArray(obj.data)) {\n      return fromArrayLike(that, obj.data)\n    }\n  }\n\n  throw new TypeError('First argument must be a string, Buffer, ArrayBuffer, Array, or array-like object.')\n}\n\nfunction checked (length) {\n  // Note: cannot use `length < kMaxLength()` here because that fails when\n  // length is NaN (which is otherwise coerced to zero.)\n  if (length >= kMaxLength()) {\n    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +\n                         'size: 0x' + kMaxLength().toString(16) + ' bytes')\n  }\n  return length | 0\n}\n\nfunction SlowBuffer (length) {\n  if (+length != length) { // eslint-disable-line eqeqeq\n    length = 0\n  }\n  return Buffer.alloc(+length)\n}\n\nBuffer.isBuffer = function isBuffer (b) {\n  return !!(b != null && b._isBuffer)\n}\n\nBuffer.compare = function compare (a, b) {\n  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {\n    throw new TypeError('Arguments must be Buffers')\n  }\n\n  if (a === b) return 0\n\n  var x = a.length\n  var y = b.length\n\n  for (var i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (a[i] !== b[i]) {\n      x = a[i]\n      y = b[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\nBuffer.isEncoding = function isEncoding (encoding) {\n  switch (String(encoding).toLowerCase()) {\n    case 'hex':\n    case 'utf8':\n    case 'utf-8':\n    case 'ascii':\n    case 'latin1':\n    case 'binary':\n    case 'base64':\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return true\n    default:\n      return false\n  }\n}\n\nBuffer.concat = function concat (list, length) {\n  if (!isArray(list)) {\n    throw new TypeError('\"list\" argument must be an Array of Buffers')\n  }\n\n  if (list.length === 0) {\n    return Buffer.alloc(0)\n  }\n\n  var i\n  if (length === undefined) {\n    length = 0\n    for (i = 0; i < list.length; ++i) {\n      length += list[i].length\n    }\n  }\n\n  var buffer = Buffer.allocUnsafe(length)\n  var pos = 0\n  for (i = 0; i < list.length; ++i) {\n    var buf = list[i]\n    if (!Buffer.isBuffer(buf)) {\n      throw new TypeError('\"list\" argument must be an Array of Buffers')\n    }\n    buf.copy(buffer, pos)\n    pos += buf.length\n  }\n  return buffer\n}\n\nfunction byteLength (string, encoding) {\n  if (Buffer.isBuffer(string)) {\n    return string.length\n  }\n  if (typeof ArrayBuffer !== 'undefined' && typeof ArrayBuffer.isView === 'function' &&\n      (ArrayBuffer.isView(string) || string instanceof ArrayBuffer)) {\n    return string.byteLength\n  }\n  if (typeof string !== 'string') {\n    string = '' + string\n  }\n\n  var len = string.length\n  if (len === 0) return 0\n\n  // Use a for loop to avoid recursion\n  var loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'ascii':\n      case 'latin1':\n      case 'binary':\n        return len\n      case 'utf8':\n      case 'utf-8':\n      case undefined:\n        return utf8ToBytes(string).length\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return len * 2\n      case 'hex':\n        return len >>> 1\n      case 'base64':\n        return base64ToBytes(string).length\n      default:\n        if (loweredCase) return utf8ToBytes(string).length // assume utf8\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\nBuffer.byteLength = byteLength\n\nfunction slowToString (encoding, start, end) {\n  var loweredCase = false\n\n  // No need to verify that \"this.length <= MAX_UINT32\" since it's a read-only\n  // property of a typed array.\n\n  // This behaves neither like String nor Uint8Array in that we set start/end\n  // to their upper/lower bounds if the value passed is out of range.\n  // undefined is handled specially as per ECMA-262 6th Edition,\n  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.\n  if (start === undefined || start < 0) {\n    start = 0\n  }\n  // Return early if start > this.length. Done here to prevent potential uint32\n  // coercion fail below.\n  if (start > this.length) {\n    return ''\n  }\n\n  if (end === undefined || end > this.length) {\n    end = this.length\n  }\n\n  if (end <= 0) {\n    return ''\n  }\n\n  // Force coersion to uint32. This will also coerce falsey/NaN values to 0.\n  end >>>= 0\n  start >>>= 0\n\n  if (end <= start) {\n    return ''\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  while (true) {\n    switch (encoding) {\n      case 'hex':\n        return hexSlice(this, start, end)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Slice(this, start, end)\n\n      case 'ascii':\n        return asciiSlice(this, start, end)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Slice(this, start, end)\n\n      case 'base64':\n        return base64Slice(this, start, end)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return utf16leSlice(this, start, end)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = (encoding + '').toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\n// The property is used by `Buffer.isBuffer` and `is-buffer` (in Safari 5-7) to detect\n// Buffer instances.\nBuffer.prototype._isBuffer = true\n\nfunction swap (b, n, m) {\n  var i = b[n]\n  b[n] = b[m]\n  b[m] = i\n}\n\nBuffer.prototype.swap16 = function swap16 () {\n  var len = this.length\n  if (len % 2 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 16-bits')\n  }\n  for (var i = 0; i < len; i += 2) {\n    swap(this, i, i + 1)\n  }\n  return this\n}\n\nBuffer.prototype.swap32 = function swap32 () {\n  var len = this.length\n  if (len % 4 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 32-bits')\n  }\n  for (var i = 0; i < len; i += 4) {\n    swap(this, i, i + 3)\n    swap(this, i + 1, i + 2)\n  }\n  return this\n}\n\nBuffer.prototype.swap64 = function swap64 () {\n  var len = this.length\n  if (len % 8 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 64-bits')\n  }\n  for (var i = 0; i < len; i += 8) {\n    swap(this, i, i + 7)\n    swap(this, i + 1, i + 6)\n    swap(this, i + 2, i + 5)\n    swap(this, i + 3, i + 4)\n  }\n  return this\n}\n\nBuffer.prototype.toString = function toString () {\n  var length = this.length | 0\n  if (length === 0) return ''\n  if (arguments.length === 0) return utf8Slice(this, 0, length)\n  return slowToString.apply(this, arguments)\n}\n\nBuffer.prototype.equals = function equals (b) {\n  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')\n  if (this === b) return true\n  return Buffer.compare(this, b) === 0\n}\n\nBuffer.prototype.inspect = function inspect () {\n  var str = ''\n  var max = exports.INSPECT_MAX_BYTES\n  if (this.length > 0) {\n    str = this.toString('hex', 0, max).match(/.{2}/g).join(' ')\n    if (this.length > max) str += ' ... '\n  }\n  return '<Buffer ' + str + '>'\n}\n\nBuffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {\n  if (!Buffer.isBuffer(target)) {\n    throw new TypeError('Argument must be a Buffer')\n  }\n\n  if (start === undefined) {\n    start = 0\n  }\n  if (end === undefined) {\n    end = target ? target.length : 0\n  }\n  if (thisStart === undefined) {\n    thisStart = 0\n  }\n  if (thisEnd === undefined) {\n    thisEnd = this.length\n  }\n\n  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {\n    throw new RangeError('out of range index')\n  }\n\n  if (thisStart >= thisEnd && start >= end) {\n    return 0\n  }\n  if (thisStart >= thisEnd) {\n    return -1\n  }\n  if (start >= end) {\n    return 1\n  }\n\n  start >>>= 0\n  end >>>= 0\n  thisStart >>>= 0\n  thisEnd >>>= 0\n\n  if (this === target) return 0\n\n  var x = thisEnd - thisStart\n  var y = end - start\n  var len = Math.min(x, y)\n\n  var thisCopy = this.slice(thisStart, thisEnd)\n  var targetCopy = target.slice(start, end)\n\n  for (var i = 0; i < len; ++i) {\n    if (thisCopy[i] !== targetCopy[i]) {\n      x = thisCopy[i]\n      y = targetCopy[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\n// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,\n// OR the last index of `val` in `buffer` at offset <= `byteOffset`.\n//\n// Arguments:\n// - buffer - a Buffer to search\n// - val - a string, Buffer, or number\n// - byteOffset - an index into `buffer`; will be clamped to an int32\n// - encoding - an optional encoding, relevant is val is a string\n// - dir - true for indexOf, false for lastIndexOf\nfunction bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {\n  // Empty buffer means no match\n  if (buffer.length === 0) return -1\n\n  // Normalize byteOffset\n  if (typeof byteOffset === 'string') {\n    encoding = byteOffset\n    byteOffset = 0\n  } else if (byteOffset > 0x7fffffff) {\n    byteOffset = 0x7fffffff\n  } else if (byteOffset < -0x80000000) {\n    byteOffset = -0x80000000\n  }\n  byteOffset = +byteOffset  // Coerce to Number.\n  if (isNaN(byteOffset)) {\n    // byteOffset: it it's undefined, null, NaN, \"foo\", etc, search whole buffer\n    byteOffset = dir ? 0 : (buffer.length - 1)\n  }\n\n  // Normalize byteOffset: negative offsets start from the end of the buffer\n  if (byteOffset < 0) byteOffset = buffer.length + byteOffset\n  if (byteOffset >= buffer.length) {\n    if (dir) return -1\n    else byteOffset = buffer.length - 1\n  } else if (byteOffset < 0) {\n    if (dir) byteOffset = 0\n    else return -1\n  }\n\n  // Normalize val\n  if (typeof val === 'string') {\n    val = Buffer.from(val, encoding)\n  }\n\n  // Finally, search either indexOf (if dir is true) or lastIndexOf\n  if (Buffer.isBuffer(val)) {\n    // Special case: looking for empty string/buffer always fails\n    if (val.length === 0) {\n      return -1\n    }\n    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)\n  } else if (typeof val === 'number') {\n    val = val & 0xFF // Search for a byte value [0-255]\n    if (Buffer.TYPED_ARRAY_SUPPORT &&\n        typeof Uint8Array.prototype.indexOf === 'function') {\n      if (dir) {\n        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)\n      } else {\n        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)\n      }\n    }\n    return arrayIndexOf(buffer, [ val ], byteOffset, encoding, dir)\n  }\n\n  throw new TypeError('val must be string, number or Buffer')\n}\n\nfunction arrayIndexOf (arr, val, byteOffset, encoding, dir) {\n  var indexSize = 1\n  var arrLength = arr.length\n  var valLength = val.length\n\n  if (encoding !== undefined) {\n    encoding = String(encoding).toLowerCase()\n    if (encoding === 'ucs2' || encoding === 'ucs-2' ||\n        encoding === 'utf16le' || encoding === 'utf-16le') {\n      if (arr.length < 2 || val.length < 2) {\n        return -1\n      }\n      indexSize = 2\n      arrLength /= 2\n      valLength /= 2\n      byteOffset /= 2\n    }\n  }\n\n  function read (buf, i) {\n    if (indexSize === 1) {\n      return buf[i]\n    } else {\n      return buf.readUInt16BE(i * indexSize)\n    }\n  }\n\n  var i\n  if (dir) {\n    var foundIndex = -1\n    for (i = byteOffset; i < arrLength; i++) {\n      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {\n        if (foundIndex === -1) foundIndex = i\n        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize\n      } else {\n        if (foundIndex !== -1) i -= i - foundIndex\n        foundIndex = -1\n      }\n    }\n  } else {\n    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength\n    for (i = byteOffset; i >= 0; i--) {\n      var found = true\n      for (var j = 0; j < valLength; j++) {\n        if (read(arr, i + j) !== read(val, j)) {\n          found = false\n          break\n        }\n      }\n      if (found) return i\n    }\n  }\n\n  return -1\n}\n\nBuffer.prototype.includes = function includes (val, byteOffset, encoding) {\n  return this.indexOf(val, byteOffset, encoding) !== -1\n}\n\nBuffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)\n}\n\nBuffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)\n}\n\nfunction hexWrite (buf, string, offset, length) {\n  offset = Number(offset) || 0\n  var remaining = buf.length - offset\n  if (!length) {\n    length = remaining\n  } else {\n    length = Number(length)\n    if (length > remaining) {\n      length = remaining\n    }\n  }\n\n  // must be an even number of digits\n  var strLen = string.length\n  if (strLen % 2 !== 0) throw new TypeError('Invalid hex string')\n\n  if (length > strLen / 2) {\n    length = strLen / 2\n  }\n  for (var i = 0; i < length; ++i) {\n    var parsed = parseInt(string.substr(i * 2, 2), 16)\n    if (isNaN(parsed)) return i\n    buf[offset + i] = parsed\n  }\n  return i\n}\n\nfunction utf8Write (buf, string, offset, length) {\n  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nfunction asciiWrite (buf, string, offset, length) {\n  return blitBuffer(asciiToBytes(string), buf, offset, length)\n}\n\nfunction latin1Write (buf, string, offset, length) {\n  return asciiWrite(buf, string, offset, length)\n}\n\nfunction base64Write (buf, string, offset, length) {\n  return blitBuffer(base64ToBytes(string), buf, offset, length)\n}\n\nfunction ucs2Write (buf, string, offset, length) {\n  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nBuffer.prototype.write = function write (string, offset, length, encoding) {\n  // Buffer#write(string)\n  if (offset === undefined) {\n    encoding = 'utf8'\n    length = this.length\n    offset = 0\n  // Buffer#write(string, encoding)\n  } else if (length === undefined && typeof offset === 'string') {\n    encoding = offset\n    length = this.length\n    offset = 0\n  // Buffer#write(string, offset[, length][, encoding])\n  } else if (isFinite(offset)) {\n    offset = offset | 0\n    if (isFinite(length)) {\n      length = length | 0\n      if (encoding === undefined) encoding = 'utf8'\n    } else {\n      encoding = length\n      length = undefined\n    }\n  // legacy write(string, encoding, offset, length) - remove in v0.13\n  } else {\n    throw new Error(\n      'Buffer.write(string, encoding, offset[, length]) is no longer supported'\n    )\n  }\n\n  var remaining = this.length - offset\n  if (length === undefined || length > remaining) length = remaining\n\n  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {\n    throw new RangeError('Attempt to write outside buffer bounds')\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  var loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'hex':\n        return hexWrite(this, string, offset, length)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Write(this, string, offset, length)\n\n      case 'ascii':\n        return asciiWrite(this, string, offset, length)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Write(this, string, offset, length)\n\n      case 'base64':\n        // Warning: maxLength not taken into account in base64Write\n        return base64Write(this, string, offset, length)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return ucs2Write(this, string, offset, length)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\nBuffer.prototype.toJSON = function toJSON () {\n  return {\n    type: 'Buffer',\n    data: Array.prototype.slice.call(this._arr || this, 0)\n  }\n}\n\nfunction base64Slice (buf, start, end) {\n  if (start === 0 && end === buf.length) {\n    return base64.fromByteArray(buf)\n  } else {\n    return base64.fromByteArray(buf.slice(start, end))\n  }\n}\n\nfunction utf8Slice (buf, start, end) {\n  end = Math.min(buf.length, end)\n  var res = []\n\n  var i = start\n  while (i < end) {\n    var firstByte = buf[i]\n    var codePoint = null\n    var bytesPerSequence = (firstByte > 0xEF) ? 4\n      : (firstByte > 0xDF) ? 3\n      : (firstByte > 0xBF) ? 2\n      : 1\n\n    if (i + bytesPerSequence <= end) {\n      var secondByte, thirdByte, fourthByte, tempCodePoint\n\n      switch (bytesPerSequence) {\n        case 1:\n          if (firstByte < 0x80) {\n            codePoint = firstByte\n          }\n          break\n        case 2:\n          secondByte = buf[i + 1]\n          if ((secondByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)\n            if (tempCodePoint > 0x7F) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 3:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)\n            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 4:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          fourthByte = buf[i + 3]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)\n            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {\n              codePoint = tempCodePoint\n            }\n          }\n      }\n    }\n\n    if (codePoint === null) {\n      // we did not generate a valid codePoint so insert a\n      // replacement char (U+FFFD) and advance only 1 byte\n      codePoint = 0xFFFD\n      bytesPerSequence = 1\n    } else if (codePoint > 0xFFFF) {\n      // encode to utf16 (surrogate pair dance)\n      codePoint -= 0x10000\n      res.push(codePoint >>> 10 & 0x3FF | 0xD800)\n      codePoint = 0xDC00 | codePoint & 0x3FF\n    }\n\n    res.push(codePoint)\n    i += bytesPerSequence\n  }\n\n  return decodeCodePointsArray(res)\n}\n\n// Based on http://stackoverflow.com/a/22747272/680742, the browser with\n// the lowest limit is Chrome, with 0x10000 args.\n// We go 1 magnitude less, for safety\nvar MAX_ARGUMENTS_LENGTH = 0x1000\n\nfunction decodeCodePointsArray (codePoints) {\n  var len = codePoints.length\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()\n  }\n\n  // Decode in chunks to avoid \"call stack size exceeded\".\n  var res = ''\n  var i = 0\n  while (i < len) {\n    res += String.fromCharCode.apply(\n      String,\n      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)\n    )\n  }\n  return res\n}\n\nfunction asciiSlice (buf, start, end) {\n  var ret = ''\n  end = Math.min(buf.length, end)\n\n  for (var i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i] & 0x7F)\n  }\n  return ret\n}\n\nfunction latin1Slice (buf, start, end) {\n  var ret = ''\n  end = Math.min(buf.length, end)\n\n  for (var i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i])\n  }\n  return ret\n}\n\nfunction hexSlice (buf, start, end) {\n  var len = buf.length\n\n  if (!start || start < 0) start = 0\n  if (!end || end < 0 || end > len) end = len\n\n  var out = ''\n  for (var i = start; i < end; ++i) {\n    out += toHex(buf[i])\n  }\n  return out\n}\n\nfunction utf16leSlice (buf, start, end) {\n  var bytes = buf.slice(start, end)\n  var res = ''\n  for (var i = 0; i < bytes.length; i += 2) {\n    res += String.fromCharCode(bytes[i] + bytes[i + 1] * 256)\n  }\n  return res\n}\n\nBuffer.prototype.slice = function slice (start, end) {\n  var len = this.length\n  start = ~~start\n  end = end === undefined ? len : ~~end\n\n  if (start < 0) {\n    start += len\n    if (start < 0) start = 0\n  } else if (start > len) {\n    start = len\n  }\n\n  if (end < 0) {\n    end += len\n    if (end < 0) end = 0\n  } else if (end > len) {\n    end = len\n  }\n\n  if (end < start) end = start\n\n  var newBuf\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    newBuf = this.subarray(start, end)\n    newBuf.__proto__ = Buffer.prototype\n  } else {\n    var sliceLen = end - start\n    newBuf = new Buffer(sliceLen, undefined)\n    for (var i = 0; i < sliceLen; ++i) {\n      newBuf[i] = this[i + start]\n    }\n  }\n\n  return newBuf\n}\n\n/*\n * Need to make sure that buffer isn't trying to write out of bounds.\n */\nfunction checkOffset (offset, ext, length) {\n  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')\n  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')\n}\n\nBuffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var val = this[offset]\n  var mul = 1\n  var i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    checkOffset(offset, byteLength, this.length)\n  }\n\n  var val = this[offset + --byteLength]\n  var mul = 1\n  while (byteLength > 0 && (mul *= 0x100)) {\n    val += this[offset + --byteLength] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  return this[offset]\n}\n\nBuffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return this[offset] | (this[offset + 1] << 8)\n}\n\nBuffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return (this[offset] << 8) | this[offset + 1]\n}\n\nBuffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return ((this[offset]) |\n      (this[offset + 1] << 8) |\n      (this[offset + 2] << 16)) +\n      (this[offset + 3] * 0x1000000)\n}\n\nBuffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] * 0x1000000) +\n    ((this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    this[offset + 3])\n}\n\nBuffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var val = this[offset]\n  var mul = 1\n  var i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var i = byteLength\n  var mul = 1\n  var val = this[offset + --i]\n  while (i > 0 && (mul *= 0x100)) {\n    val += this[offset + --i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readInt8 = function readInt8 (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  if (!(this[offset] & 0x80)) return (this[offset])\n  return ((0xff - this[offset] + 1) * -1)\n}\n\nBuffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  var val = this[offset] | (this[offset + 1] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  var val = this[offset + 1] | (this[offset] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset]) |\n    (this[offset + 1] << 8) |\n    (this[offset + 2] << 16) |\n    (this[offset + 3] << 24)\n}\n\nBuffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] << 24) |\n    (this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    (this[offset + 3])\n}\n\nBuffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, true, 23, 4)\n}\n\nBuffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, false, 23, 4)\n}\n\nBuffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, true, 52, 8)\n}\n\nBuffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, false, 52, 8)\n}\n\nfunction checkInt (buf, value, offset, ext, max, min) {\n  if (!Buffer.isBuffer(buf)) throw new TypeError('\"buffer\" argument must be a Buffer instance')\n  if (value > max || value < min) throw new RangeError('\"value\" argument is out of bounds')\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n}\n\nBuffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    var maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  var mul = 1\n  var i = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    var maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  var i = byteLength - 1\n  var mul = 1\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nfunction objectWriteUInt16 (buf, value, offset, littleEndian) {\n  if (value < 0) value = 0xffff + value + 1\n  for (var i = 0, j = Math.min(buf.length - offset, 2); i < j; ++i) {\n    buf[offset + i] = (value & (0xff << (8 * (littleEndian ? i : 1 - i)))) >>>\n      (littleEndian ? i : 1 - i) * 8\n  }\n}\n\nBuffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n  } else {\n    objectWriteUInt16(this, value, offset, true)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 8)\n    this[offset + 1] = (value & 0xff)\n  } else {\n    objectWriteUInt16(this, value, offset, false)\n  }\n  return offset + 2\n}\n\nfunction objectWriteUInt32 (buf, value, offset, littleEndian) {\n  if (value < 0) value = 0xffffffff + value + 1\n  for (var i = 0, j = Math.min(buf.length - offset, 4); i < j; ++i) {\n    buf[offset + i] = (value >>> (littleEndian ? i : 3 - i) * 8) & 0xff\n  }\n}\n\nBuffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset + 3] = (value >>> 24)\n    this[offset + 2] = (value >>> 16)\n    this[offset + 1] = (value >>> 8)\n    this[offset] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, true)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 24)\n    this[offset + 1] = (value >>> 16)\n    this[offset + 2] = (value >>> 8)\n    this[offset + 3] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, false)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) {\n    var limit = Math.pow(2, 8 * byteLength - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  var i = 0\n  var mul = 1\n  var sub = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) {\n    var limit = Math.pow(2, 8 * byteLength - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  var i = byteLength - 1\n  var mul = 1\n  var sub = 0\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)\n  if (value < 0) value = 0xff + value + 1\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nBuffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n  } else {\n    objectWriteUInt16(this, value, offset, true)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 8)\n    this[offset + 1] = (value & 0xff)\n  } else {\n    objectWriteUInt16(this, value, offset, false)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n    this[offset + 2] = (value >>> 16)\n    this[offset + 3] = (value >>> 24)\n  } else {\n    objectWriteUInt32(this, value, offset, true)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (value < 0) value = 0xffffffff + value + 1\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 24)\n    this[offset + 1] = (value >>> 16)\n    this[offset + 2] = (value >>> 8)\n    this[offset + 3] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, false)\n  }\n  return offset + 4\n}\n\nfunction checkIEEE754 (buf, value, offset, ext, max, min) {\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n  if (offset < 0) throw new RangeError('Index out of range')\n}\n\nfunction writeFloat (buf, value, offset, littleEndian, noAssert) {\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 23, 4)\n  return offset + 4\n}\n\nBuffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, false, noAssert)\n}\n\nfunction writeDouble (buf, value, offset, littleEndian, noAssert) {\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 52, 8)\n  return offset + 8\n}\n\nBuffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, false, noAssert)\n}\n\n// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)\nBuffer.prototype.copy = function copy (target, targetStart, start, end) {\n  if (!start) start = 0\n  if (!end && end !== 0) end = this.length\n  if (targetStart >= target.length) targetStart = target.length\n  if (!targetStart) targetStart = 0\n  if (end > 0 && end < start) end = start\n\n  // Copy 0 bytes; we're done\n  if (end === start) return 0\n  if (target.length === 0 || this.length === 0) return 0\n\n  // Fatal error conditions\n  if (targetStart < 0) {\n    throw new RangeError('targetStart out of bounds')\n  }\n  if (start < 0 || start >= this.length) throw new RangeError('sourceStart out of bounds')\n  if (end < 0) throw new RangeError('sourceEnd out of bounds')\n\n  // Are we oob?\n  if (end > this.length) end = this.length\n  if (target.length - targetStart < end - start) {\n    end = target.length - targetStart + start\n  }\n\n  var len = end - start\n  var i\n\n  if (this === target && start < targetStart && targetStart < end) {\n    // descending copy from end\n    for (i = len - 1; i >= 0; --i) {\n      target[i + targetStart] = this[i + start]\n    }\n  } else if (len < 1000 || !Buffer.TYPED_ARRAY_SUPPORT) {\n    // ascending copy from start\n    for (i = 0; i < len; ++i) {\n      target[i + targetStart] = this[i + start]\n    }\n  } else {\n    Uint8Array.prototype.set.call(\n      target,\n      this.subarray(start, start + len),\n      targetStart\n    )\n  }\n\n  return len\n}\n\n// Usage:\n//    buffer.fill(number[, offset[, end]])\n//    buffer.fill(buffer[, offset[, end]])\n//    buffer.fill(string[, offset[, end]][, encoding])\nBuffer.prototype.fill = function fill (val, start, end, encoding) {\n  // Handle string cases:\n  if (typeof val === 'string') {\n    if (typeof start === 'string') {\n      encoding = start\n      start = 0\n      end = this.length\n    } else if (typeof end === 'string') {\n      encoding = end\n      end = this.length\n    }\n    if (val.length === 1) {\n      var code = val.charCodeAt(0)\n      if (code < 256) {\n        val = code\n      }\n    }\n    if (encoding !== undefined && typeof encoding !== 'string') {\n      throw new TypeError('encoding must be a string')\n    }\n    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {\n      throw new TypeError('Unknown encoding: ' + encoding)\n    }\n  } else if (typeof val === 'number') {\n    val = val & 255\n  }\n\n  // Invalid ranges are not set to a default, so can range check early.\n  if (start < 0 || this.length < start || this.length < end) {\n    throw new RangeError('Out of range index')\n  }\n\n  if (end <= start) {\n    return this\n  }\n\n  start = start >>> 0\n  end = end === undefined ? this.length : end >>> 0\n\n  if (!val) val = 0\n\n  var i\n  if (typeof val === 'number') {\n    for (i = start; i < end; ++i) {\n      this[i] = val\n    }\n  } else {\n    var bytes = Buffer.isBuffer(val)\n      ? val\n      : utf8ToBytes(new Buffer(val, encoding).toString())\n    var len = bytes.length\n    for (i = 0; i < end - start; ++i) {\n      this[i + start] = bytes[i % len]\n    }\n  }\n\n  return this\n}\n\n// HELPER FUNCTIONS\n// ================\n\nvar INVALID_BASE64_RE = /[^+\\/0-9A-Za-z-_]/g\n\nfunction base64clean (str) {\n  // Node strips out invalid characters like \\n and \\t from the string, base64-js does not\n  str = stringtrim(str).replace(INVALID_BASE64_RE, '')\n  // Node converts strings with length < 2 to ''\n  if (str.length < 2) return ''\n  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not\n  while (str.length % 4 !== 0) {\n    str = str + '='\n  }\n  return str\n}\n\nfunction stringtrim (str) {\n  if (str.trim) return str.trim()\n  return str.replace(/^\\s+|\\s+$/g, '')\n}\n\nfunction toHex (n) {\n  if (n < 16) return '0' + n.toString(16)\n  return n.toString(16)\n}\n\nfunction utf8ToBytes (string, units) {\n  units = units || Infinity\n  var codePoint\n  var length = string.length\n  var leadSurrogate = null\n  var bytes = []\n\n  for (var i = 0; i < length; ++i) {\n    codePoint = string.charCodeAt(i)\n\n    // is surrogate component\n    if (codePoint > 0xD7FF && codePoint < 0xE000) {\n      // last char was a lead\n      if (!leadSurrogate) {\n        // no lead yet\n        if (codePoint > 0xDBFF) {\n          // unexpected trail\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        } else if (i + 1 === length) {\n          // unpaired lead\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        }\n\n        // valid lead\n        leadSurrogate = codePoint\n\n        continue\n      }\n\n      // 2 leads in a row\n      if (codePoint < 0xDC00) {\n        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n        leadSurrogate = codePoint\n        continue\n      }\n\n      // valid surrogate pair\n      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000\n    } else if (leadSurrogate) {\n      // valid bmp char, but last char was a lead\n      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n    }\n\n    leadSurrogate = null\n\n    // encode utf8\n    if (codePoint < 0x80) {\n      if ((units -= 1) < 0) break\n      bytes.push(codePoint)\n    } else if (codePoint < 0x800) {\n      if ((units -= 2) < 0) break\n      bytes.push(\n        codePoint >> 0x6 | 0xC0,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x10000) {\n      if ((units -= 3) < 0) break\n      bytes.push(\n        codePoint >> 0xC | 0xE0,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x110000) {\n      if ((units -= 4) < 0) break\n      bytes.push(\n        codePoint >> 0x12 | 0xF0,\n        codePoint >> 0xC & 0x3F | 0x80,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else {\n      throw new Error('Invalid code point')\n    }\n  }\n\n  return bytes\n}\n\nfunction asciiToBytes (str) {\n  var byteArray = []\n  for (var i = 0; i < str.length; ++i) {\n    // Node's code seems to be doing this and not & 0x7F..\n    byteArray.push(str.charCodeAt(i) & 0xFF)\n  }\n  return byteArray\n}\n\nfunction utf16leToBytes (str, units) {\n  var c, hi, lo\n  var byteArray = []\n  for (var i = 0; i < str.length; ++i) {\n    if ((units -= 2) < 0) break\n\n    c = str.charCodeAt(i)\n    hi = c >> 8\n    lo = c % 256\n    byteArray.push(lo)\n    byteArray.push(hi)\n  }\n\n  return byteArray\n}\n\nfunction base64ToBytes (str) {\n  return base64.toByteArray(base64clean(str))\n}\n\nfunction blitBuffer (src, dst, offset, length) {\n  for (var i = 0; i < length; ++i) {\n    if ((i + offset >= dst.length) || (i >= src.length)) break\n    dst[i + offset] = src[i]\n  }\n  return i\n}\n\nfunction isnan (val) {\n  return val !== val // eslint-disable-line no-self-compare\n}\n","'use strict'\n\nexports.byteLength = byteLength\nexports.toByteArray = toByteArray\nexports.fromByteArray = fromByteArray\n\nvar lookup = []\nvar revLookup = []\nvar Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array\n\nvar code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\nfor (var i = 0, len = code.length; i < len; ++i) {\n  lookup[i] = code[i]\n  revLookup[code.charCodeAt(i)] = i\n}\n\n// Support decoding URL-safe base64 strings, as Node.js does.\n// See: https://en.wikipedia.org/wiki/Base64#URL_applications\nrevLookup['-'.charCodeAt(0)] = 62\nrevLookup['_'.charCodeAt(0)] = 63\n\nfunction getLens (b64) {\n  var len = b64.length\n\n  if (len % 4 > 0) {\n    throw new Error('Invalid string. Length must be a multiple of 4')\n  }\n\n  // Trim off extra bytes after placeholder bytes are found\n  // See: https://github.com/beatgammit/base64-js/issues/42\n  var validLen = b64.indexOf('=')\n  if (validLen === -1) validLen = len\n\n  var placeHoldersLen = validLen === len\n    ? 0\n    : 4 - (validLen % 4)\n\n  return [validLen, placeHoldersLen]\n}\n\n// base64 is 4/3 + up to two characters of the original data\nfunction byteLength (b64) {\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction _byteLength (b64, validLen, placeHoldersLen) {\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction toByteArray (b64) {\n  var tmp\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n\n  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))\n\n  var curByte = 0\n\n  // if there are placeholders, only get up to the last complete 4 chars\n  var len = placeHoldersLen > 0\n    ? validLen - 4\n    : validLen\n\n  var i\n  for (i = 0; i < len; i += 4) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 18) |\n      (revLookup[b64.charCodeAt(i + 1)] << 12) |\n      (revLookup[b64.charCodeAt(i + 2)] << 6) |\n      revLookup[b64.charCodeAt(i + 3)]\n    arr[curByte++] = (tmp >> 16) & 0xFF\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 2) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 2) |\n      (revLookup[b64.charCodeAt(i + 1)] >> 4)\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 1) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 10) |\n      (revLookup[b64.charCodeAt(i + 1)] << 4) |\n      (revLookup[b64.charCodeAt(i + 2)] >> 2)\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  return arr\n}\n\nfunction tripletToBase64 (num) {\n  return lookup[num >> 18 & 0x3F] +\n    lookup[num >> 12 & 0x3F] +\n    lookup[num >> 6 & 0x3F] +\n    lookup[num & 0x3F]\n}\n\nfunction encodeChunk (uint8, start, end) {\n  var tmp\n  var output = []\n  for (var i = start; i < end; i += 3) {\n    tmp =\n      ((uint8[i] << 16) & 0xFF0000) +\n      ((uint8[i + 1] << 8) & 0xFF00) +\n      (uint8[i + 2] & 0xFF)\n    output.push(tripletToBase64(tmp))\n  }\n  return output.join('')\n}\n\nfunction fromByteArray (uint8) {\n  var tmp\n  var len = uint8.length\n  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes\n  var parts = []\n  var maxChunkLength = 16383 // must be multiple of 3\n\n  // go through the array every three bytes, we'll deal with trailing stuff later\n  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {\n    parts.push(encodeChunk(\n      uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)\n    ))\n  }\n\n  // pad the end with zeros, but make sure to not forget the extra bytes\n  if (extraBytes === 1) {\n    tmp = uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 2] +\n      lookup[(tmp << 4) & 0x3F] +\n      '=='\n    )\n  } else if (extraBytes === 2) {\n    tmp = (uint8[len - 2] << 8) + uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 10] +\n      lookup[(tmp >> 4) & 0x3F] +\n      lookup[(tmp << 2) & 0x3F] +\n      '='\n    )\n  }\n\n  return parts.join('')\n}\n","exports.read = function (buffer, offset, isLE, mLen, nBytes) {\n  var e, m\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var nBits = -7\n  var i = isLE ? (nBytes - 1) : 0\n  var d = isLE ? -1 : 1\n  var s = buffer[offset + i]\n\n  i += d\n\n  e = s & ((1 << (-nBits)) - 1)\n  s >>= (-nBits)\n  nBits += eLen\n  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  m = e & ((1 << (-nBits)) - 1)\n  e >>= (-nBits)\n  nBits += mLen\n  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  if (e === 0) {\n    e = 1 - eBias\n  } else if (e === eMax) {\n    return m ? NaN : ((s ? -1 : 1) * Infinity)\n  } else {\n    m = m + Math.pow(2, mLen)\n    e = e - eBias\n  }\n  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)\n}\n\nexports.write = function (buffer, value, offset, isLE, mLen, nBytes) {\n  var e, m, c\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)\n  var i = isLE ? 0 : (nBytes - 1)\n  var d = isLE ? 1 : -1\n  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0\n\n  value = Math.abs(value)\n\n  if (isNaN(value) || value === Infinity) {\n    m = isNaN(value) ? 1 : 0\n    e = eMax\n  } else {\n    e = Math.floor(Math.log(value) / Math.LN2)\n    if (value * (c = Math.pow(2, -e)) < 1) {\n      e--\n      c *= 2\n    }\n    if (e + eBias >= 1) {\n      value += rt / c\n    } else {\n      value += rt * Math.pow(2, 1 - eBias)\n    }\n    if (value * c >= 2) {\n      e++\n      c /= 2\n    }\n\n    if (e + eBias >= eMax) {\n      m = 0\n      e = eMax\n    } else if (e + eBias >= 1) {\n      m = ((value * c) - 1) * Math.pow(2, mLen)\n      e = e + eBias\n    } else {\n      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)\n      e = 0\n    }\n  }\n\n  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}\n\n  e = (e << mLen) | m\n  eLen += mLen\n  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}\n\n  buffer[offset + i - d] |= s * 128\n}\n","var toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n","function AbstractIterator (db) {\n  if (typeof db !== 'object' || db === null) {\n    throw new TypeError('First argument must be an abstract-leveldown compliant store')\n  }\n\n  this.db = db\n  this._ended = false\n  this._nexting = false\n}\n\nAbstractIterator.prototype.next = function (callback) {\n  var self = this\n\n  if (typeof callback !== 'function') {\n    throw new Error('next() requires a callback argument')\n  }\n\n  if (self._ended) {\n    process.nextTick(callback, new Error('cannot call next() after end()'))\n    return self\n  }\n\n  if (self._nexting) {\n    process.nextTick(callback, new Error('cannot call next() before previous next() has completed'))\n    return self\n  }\n\n  self._nexting = true\n  self._next(function () {\n    self._nexting = false\n    callback.apply(null, arguments)\n  })\n\n  return self\n}\n\nAbstractIterator.prototype._next = function (callback) {\n  process.nextTick(callback)\n}\n\nAbstractIterator.prototype.seek = function (target) {\n  if (this._ended) {\n    throw new Error('cannot call seek() after end()')\n  }\n  if (this._nexting) {\n    throw new Error('cannot call seek() before next() has completed')\n  }\n\n  target = this.db._serializeKey(target)\n  this._seek(target)\n}\n\nAbstractIterator.prototype._seek = function (target) {}\n\nAbstractIterator.prototype.end = function (callback) {\n  if (typeof callback !== 'function') {\n    throw new Error('end() requires a callback argument')\n  }\n\n  if (this._ended) {\n    return process.nextTick(callback, new Error('end() already called on iterator'))\n  }\n\n  this._ended = true\n  this._end(callback)\n}\n\nAbstractIterator.prototype._end = function (callback) {\n  process.nextTick(callback)\n}\n\nmodule.exports = AbstractIterator\n","function AbstractChainedBatch (db) {\n  if (typeof db !== 'object' || db === null) {\n    throw new TypeError('First argument must be an abstract-leveldown compliant store')\n  }\n\n  this.db = db\n  this._operations = []\n  this._written = false\n}\n\nAbstractChainedBatch.prototype._checkWritten = function () {\n  if (this._written) {\n    throw new Error('write() already called on this batch')\n  }\n}\n\nAbstractChainedBatch.prototype.put = function (key, value) {\n  this._checkWritten()\n\n  var err = this.db._checkKey(key) || this.db._checkValue(value)\n  if (err) throw err\n\n  key = this.db._serializeKey(key)\n  value = this.db._serializeValue(value)\n\n  this._put(key, value)\n\n  return this\n}\n\nAbstractChainedBatch.prototype._put = function (key, value) {\n  this._operations.push({ type: 'put', key: key, value: value })\n}\n\nAbstractChainedBatch.prototype.del = function (key) {\n  this._checkWritten()\n\n  var err = this.db._checkKey(key)\n  if (err) throw err\n\n  key = this.db._serializeKey(key)\n  this._del(key)\n\n  return this\n}\n\nAbstractChainedBatch.prototype._del = function (key) {\n  this._operations.push({ type: 'del', key: key })\n}\n\nAbstractChainedBatch.prototype.clear = function () {\n  this._checkWritten()\n  this._clear()\n\n  return this\n}\n\nAbstractChainedBatch.prototype._clear = function () {\n  this._operations = []\n}\n\nAbstractChainedBatch.prototype.write = function (options, callback) {\n  this._checkWritten()\n\n  if (typeof options === 'function') { callback = options }\n  if (typeof callback !== 'function') {\n    throw new Error('write() requires a callback argument')\n  }\n  if (typeof options !== 'object' || options === null) {\n    options = {}\n  }\n\n  this._written = true\n  this._write(options, callback)\n}\n\nAbstractChainedBatch.prototype._write = function (options, callback) {\n  this.db._batch(this._operations, options, callback)\n}\n\nmodule.exports = AbstractChainedBatch\n","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n","var AbstractIterator = require('abstract-leveldown').AbstractIterator\nvar inherits = require('inherits')\n\nfunction DeferredIterator (options) {\n  AbstractIterator.call(this, options)\n\n  this._options = options\n  this._iterator = null\n  this._operations = []\n}\n\ninherits(DeferredIterator, AbstractIterator)\n\nDeferredIterator.prototype.setDb = function (db) {\n  var it = this._iterator = db.iterator(this._options)\n  this._operations.forEach(function (op) {\n    it[op.method].apply(it, op.args)\n  })\n}\n\nDeferredIterator.prototype._operation = function (method, args) {\n  if (this._iterator) return this._iterator[method].apply(this._iterator, args)\n  this._operations.push({ method: method, args: args })\n}\n\n'next end'.split(' ').forEach(function (m) {\n  DeferredIterator.prototype['_' + m] = function () {\n    this._operation(m, arguments)\n  }\n})\n\nmodule.exports = DeferredIterator\n","var inherits = require('inherits')\nvar Readable = require('readable-stream').Readable\nvar extend = require('xtend')\n\nmodule.exports = ReadStream\ninherits(ReadStream, Readable)\n\nfunction ReadStream (iterator, options) {\n  if (!(this instanceof ReadStream)) return new ReadStream(iterator, options)\n  options = options || {}\n  Readable.call(this, extend(options, {\n    objectMode: true\n  }))\n  this._iterator = iterator\n  this._options = options\n  this.on('end', this.destroy.bind(this, null, null))\n}\n\nReadStream.prototype._read = function () {\n  var self = this\n  var options = this._options\n  if (this.destroyed) return\n\n  this._iterator.next(function (err, key, value) {\n    if (self.destroyed) return\n    if (err) return self.destroy(err)\n\n    if (key === undefined && value === undefined) {\n      self.push(null)\n    } else if (options.keys !== false && options.values === false) {\n      self.push(key)\n    } else if (options.keys === false && options.values !== false) {\n      self.push(value)\n    } else {\n      self.push({ key: key, value: value })\n    }\n  })\n}\n\nReadStream.prototype._destroy = function (err, callback) {\n  this._iterator.end(function (err2) {\n    callback(err || err2)\n  })\n}\n","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n","exports = module.exports = require('./lib/_stream_readable.js');\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = require('./lib/_stream_writable.js');\nexports.Duplex = require('./lib/_stream_duplex.js');\nexports.Transform = require('./lib/_stream_transform.js');\nexports.PassThrough = require('./lib/_stream_passthrough.js');\nexports.finished = require('./lib/internal/streams/end-of-stream.js');\nexports.pipeline = require('./lib/internal/streams/pipeline.js');\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n'use strict';\n\nmodule.exports = Readable;\n/*<replacement>*/\n\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n/*<replacement>*/\n\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function EElistenerCount(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\n\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n\nvar Buffer = require('buffer').Buffer;\n\nvar OurUint8Array = global.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n/*<replacement>*/\n\n\nvar debugUtil = require('util');\n\nvar debug;\n\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function debug() {};\n}\n/*</replacement>*/\n\n\nvar BufferList = require('./internal/streams/buffer_list');\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nvar _require = require('./internal/streams/state'),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = require('../errors').codes,\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT;\n\nvar _require2 = require('../experimentalWarning'),\n    emitExperimentalWarning = _require2.emitExperimentalWarning; // Lazy loaded to improve the startup performance.\n\n\nvar StringDecoder;\nvar createReadableStreamAsyncIterator;\n\nrequire('inherits')(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream, isDuplex) {\n  Duplex = Duplex || require('./_stream_duplex');\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n\n  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n\n  this.sync = true; // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n  this.paused = true; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // has it been destroyed\n\n  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s\n\n  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled\n\n  this.readingMore = false;\n  this.decoder = null;\n  this.encoding = null;\n\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  this._readableState = new ReadableState(options, this, isDuplex); // legacy\n\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n  }\n});\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\n\nReadable.prototype._destroy = function (err, cb) {\n  cb(err);\n}; // Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\n\n\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n}; // Unshift should *always* be something directly out of read()\n\n\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  debug('readableAddChunk', chunk);\n  var state = stream._readableState;\n\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new ERR_STREAM_PUSH_AFTER_EOF());\n      } else if (state.destroyed) {\n        return false;\n      } else {\n        state.reading = false;\n\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n      maybeReadMore(stream, state);\n    }\n  } // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n\n\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    state.awaitDrain = 0;\n    stream.emit('data', chunk);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n    if (state.needReadable) emitReadable(stream);\n  }\n\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n  }\n\n  return er;\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n}; // backwards compatibility.\n\n\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc); // if setEncoding(null), decoder.encoding equals utf8\n\n  this._readableState.encoding = this._readableState.decoder.encoding;\n  return this;\n}; // Don't raise the hwm > 8MB\n\n\nvar MAX_HWM = 0x800000;\n\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n\n  return n;\n} // This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\n\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  } // If we're asking for more than the current hwm, then raise the hwm.\n\n\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n; // Don't have enough\n\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n\n  return state.length;\n} // you can override either this method, or the async _read(n) below.\n\n\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n\n  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.\n\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  } // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n  // if we need a readable event, then we need to do some reading.\n\n\n  var doRead = state.needReadable;\n  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some\n\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  } // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n\n\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true; // if the length is currently zero, then we *need* a readable event.\n\n    if (state.length === 0) state.needReadable = true; // call internal read method\n\n    this._read(state.highWaterMark);\n\n    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n    state.awaitDrain = 0;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.\n\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n\n  state.ended = true;\n\n  if (state.sync) {\n    // if we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call\n    emitReadable(stream);\n  } else {\n    // emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false;\n\n    if (!state.emittedReadable) {\n      state.emittedReadable = true;\n      emitReadable_(stream);\n    }\n  }\n} // Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\n\n\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    process.nextTick(emitReadable_, stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  var state = stream._readableState;\n  debug('emitReadable_', state.destroyed, state.length, state.ended);\n\n  if (!state.destroyed && (state.length || state.ended)) {\n    stream.emit('readable');\n  } // The stream needs another readable event if\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n\n\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n  flow(stream);\n} // at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\n\n\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n    var len = state.length;\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length) // didn't get any data, stop spinning.\n      break;\n  }\n\n  state.readingMore = false;\n} // abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\n\n\nReadable.prototype._read = function (n) {\n  this.emit('error', new ERR_METHOD_NOT_IMPLEMENTED('_read()'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n  dest.on('unpipe', onunpipe);\n\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  } // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n\n\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n  var cleanedUp = false;\n\n  function cleanup() {\n    debug('cleanup'); // cleanup event handlers once the pipe is broken\n\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n    cleanedUp = true; // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  src.on('data', ondata);\n\n  function ondata(chunk) {\n    debug('ondata');\n    var ret = dest.write(chunk);\n    debug('dest.write', ret);\n\n    if (ret === false) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', state.awaitDrain);\n        state.awaitDrain++;\n      }\n\n      src.pause();\n    }\n  } // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n\n\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  } // Make sure our error handler is attached before userland ones.\n\n\n  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.\n\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n\n  dest.once('close', onclose);\n\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  } // tell the dest that it's being piped to\n\n\n  dest.emit('pipe', src); // start the flow if it hasn't been started already.\n\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function pipeOnDrainFunctionResult() {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = {\n    hasUnpiped: false\n  }; // if we're not piping anywhere, then do nothing.\n\n  if (state.pipesCount === 0) return this; // just one destination.  most common case.\n\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n    if (!dest) dest = state.pipes; // got a match.\n\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  } // slow case. multiple pipe destinations.\n\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, {\n        hasUnpiped: false\n      });\n    }\n\n    return this;\n  } // try to find the right one.\n\n\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n  dest.emit('unpipe', this, unpipeInfo);\n  return this;\n}; // set up data events if they are asked for\n// Ensure readable listeners eventually get something\n\n\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n  var state = this._readableState;\n\n  if (ev === 'data') {\n    // update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused\n\n    if (state.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.flowing = false;\n      state.emittedReadable = false;\n      debug('on readable', state.length, state.reading);\n\n      if (state.length) {\n        emitReadable(this);\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this);\n      }\n    }\n  }\n\n  return res;\n};\n\nReadable.prototype.addListener = Readable.prototype.on;\n\nReadable.prototype.removeListener = function (ev, fn) {\n  var res = Stream.prototype.removeListener.call(this, ev, fn);\n\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nReadable.prototype.removeAllListeners = function (ev) {\n  var res = Stream.prototype.removeAllListeners.apply(this, arguments);\n\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nfunction updateReadableListening(self) {\n  var state = self._readableState;\n  state.readableListening = self.listenerCount('readable') > 0;\n\n  if (state.resumeScheduled && !state.paused) {\n    // flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true; // crude way to check if we should resume\n  } else if (self.listenerCount('data') > 0) {\n    self.resume();\n  }\n}\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n} // pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\n\n\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n\n  if (!state.flowing) {\n    debug('resume'); // we flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume()\n\n    state.flowing = !state.readableListening;\n    resume(this, state);\n  }\n\n  state.paused = false;\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  debug('resume', state.reading);\n\n  if (!state.reading) {\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n\n  if (this._readableState.flowing !== false) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n\n  this._readableState.paused = true;\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n\n  while (state.flowing && stream.read() !== null) {\n    ;\n  }\n} // wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\n\n\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n  stream.on('end', function () {\n    debug('wrapped end');\n\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode\n\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  }); // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function methodWrap(method) {\n        return function methodWrapReturnFunction() {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  } // proxy certain important events.\n\n\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  } // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n\n\n  this._read = function (n) {\n    debug('wrapped _read', n);\n\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nif (typeof Symbol === 'function') {\n  Readable.prototype[Symbol.asyncIterator] = function () {\n    emitExperimentalWarning('Readable[Symbol.asyncIterator]');\n\n    if (createReadableStreamAsyncIterator === undefined) {\n      createReadableStreamAsyncIterator = require('./internal/streams/async_iterator');\n    }\n\n    return createReadableStreamAsyncIterator(this);\n  };\n}\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.highWaterMark;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState && this._readableState.buffer;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableFlowing', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.flowing;\n  },\n  set: function set(state) {\n    if (this._readableState) {\n      this._readableState.flowing = state;\n    }\n  }\n}); // exposed for testing purposes only.\n\nReadable._fromList = fromList;\nObject.defineProperty(Readable.prototype, 'readableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.length;\n  }\n}); // Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = state.buffer.consume(n, state.decoder);\n  }\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n  debug('endReadable', state.endEmitted);\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.\n\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n\n  return -1;\n}","module.exports = require('events').EventEmitter;\n","/* (ignored) */","'use strict';\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nvar _require = require('buffer'),\n    Buffer = _require.Buffer;\n\nvar _require2 = require('util'),\n    inspect = _require2.inspect;\n\nvar custom = inspect && inspect.custom || 'inspect';\n\nfunction copyBuffer(src, target, offset) {\n  Buffer.prototype.copy.call(src, target, offset);\n}\n\nmodule.exports =\n/*#__PURE__*/\nfunction () {\n  function BufferList() {\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  var _proto = BufferList.prototype;\n\n  _proto.push = function push(v) {\n    var entry = {\n      data: v,\n      next: null\n    };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  _proto.unshift = function unshift(v) {\n    var entry = {\n      data: v,\n      next: this.head\n    };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  _proto.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  _proto.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  _proto.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n\n    while (p = p.next) {\n      ret += s + p.data;\n    }\n\n    return ret;\n  };\n\n  _proto.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n\n    return ret;\n  } // Consumes a specified amount of bytes or characters from the buffered data.\n  ;\n\n  _proto.consume = function consume(n, hasStrings) {\n    var ret;\n\n    if (n < this.head.data.length) {\n      // `slice` is the same for buffers and strings.\n      ret = this.head.data.slice(0, n);\n      this.head.data = this.head.data.slice(n);\n    } else if (n === this.head.data.length) {\n      // First chunk is a perfect match.\n      ret = this.shift();\n    } else {\n      // Result spans more than one buffer.\n      ret = hasStrings ? this._getString(n) : this._getBuffer(n);\n    }\n\n    return ret;\n  };\n\n  _proto.first = function first() {\n    return this.head.data;\n  } // Consumes a specified amount of characters from the buffered data.\n  ;\n\n  _proto._getString = function _getString(n) {\n    var p = this.head;\n    var c = 1;\n    var ret = p.data;\n    n -= ret.length;\n\n    while (p = p.next) {\n      var str = p.data;\n      var nb = n > str.length ? str.length : n;\n      if (nb === str.length) ret += str;else ret += str.slice(0, n);\n      n -= nb;\n\n      if (n === 0) {\n        if (nb === str.length) {\n          ++c;\n          if (p.next) this.head = p.next;else this.head = this.tail = null;\n        } else {\n          this.head = p;\n          p.data = str.slice(nb);\n        }\n\n        break;\n      }\n\n      ++c;\n    }\n\n    this.length -= c;\n    return ret;\n  } // Consumes a specified amount of bytes from the buffered data.\n  ;\n\n  _proto._getBuffer = function _getBuffer(n) {\n    var ret = Buffer.allocUnsafe(n);\n    var p = this.head;\n    var c = 1;\n    p.data.copy(ret);\n    n -= p.data.length;\n\n    while (p = p.next) {\n      var buf = p.data;\n      var nb = n > buf.length ? buf.length : n;\n      buf.copy(ret, ret.length - n, 0, nb);\n      n -= nb;\n\n      if (n === 0) {\n        if (nb === buf.length) {\n          ++c;\n          if (p.next) this.head = p.next;else this.head = this.tail = null;\n        } else {\n          this.head = p;\n          p.data = buf.slice(nb);\n        }\n\n        break;\n      }\n\n      ++c;\n    }\n\n    this.length -= c;\n    return ret;\n  } // Make sure the linked list only shows the minimal necessary information.\n  ;\n\n  _proto[custom] = function (_, options) {\n    return inspect(this, _objectSpread({}, options, {\n      // Only inspect one level.\n      depth: 0,\n      // It should not recurse.\n      customInspect: false\n    }));\n  };\n\n  return BufferList;\n}();","/* (ignored) */","'use strict'; // undocumented cb() API, needed for core, not for public API\n\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      process.nextTick(emitErrorNT, this, err);\n    }\n\n    return this;\n  } // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  } // if this is a duplex stream mark the writable part as destroyed as well\n\n\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      process.nextTick(emitErrorAndCloseNT, _this, err);\n\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      process.nextTick(emitCloseNT, _this);\n      cb(err);\n    } else {\n      process.nextTick(emitCloseNT, _this);\n    }\n  });\n\n  return this;\n}\n\nfunction emitErrorAndCloseNT(self, err) {\n  emitErrorNT(self, err);\n  emitCloseNT(self);\n}\n\nfunction emitCloseNT(self) {\n  if (self._writableState && !self._writableState.emitClose) return;\n  if (self._readableState && !self._readableState.emitClose) return;\n  self.emit('close');\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finalCalled = false;\n    this._writableState.prefinished = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};","'use strict';\n\nvar ERR_INVALID_OPT_VALUE = require('../../../errors').codes.ERR_INVALID_OPT_VALUE;\n\nfunction highWaterMarkFrom(options, isDuplex, duplexKey) {\n  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null;\n}\n\nfunction getHighWaterMark(state, options, duplexKey, isDuplex) {\n  var hwm = highWaterMarkFrom(options, isDuplex, duplexKey);\n\n  if (hwm != null) {\n    if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {\n      var name = isDuplex ? duplexKey : 'highWaterMark';\n      throw new ERR_INVALID_OPT_VALUE(name, hwm);\n    }\n\n    return Math.floor(hwm);\n  } // Default value\n\n\n  return state.objectMode ? 16 : 16 * 1024;\n}\n\nmodule.exports = {\n  getHighWaterMark: getHighWaterMark\n};","'use strict';\n\nfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\n\nvar codes = {};\n\nfunction createErrorType(code, message, Base) {\n  if (!Base) {\n    Base = Error;\n  }\n\n  function getMessage(arg1, arg2, arg3) {\n    if (typeof message === 'string') {\n      return message;\n    } else {\n      return message(arg1, arg2, arg3);\n    }\n  }\n\n  var NodeError =\n  /*#__PURE__*/\n  function (_Base) {\n    _inheritsLoose(NodeError, _Base);\n\n    function NodeError(arg1, arg2, arg3) {\n      return _Base.call(this, getMessage(arg1, arg2, arg3)) || this;\n    }\n\n    return NodeError;\n  }(Base);\n\n  NodeError.prototype.name = Base.name;\n  NodeError.prototype.code = code;\n  codes[code] = NodeError;\n} // https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js\n\n\nfunction oneOf(expected, thing) {\n  if (Array.isArray(expected)) {\n    var len = expected.length;\n    expected = expected.map(function (i) {\n      return String(i);\n    });\n\n    if (len > 2) {\n      return \"one of \".concat(thing, \" \").concat(expected.slice(0, len - 1).join(', '), \", or \") + expected[len - 1];\n    } else if (len === 2) {\n      return \"one of \".concat(thing, \" \").concat(expected[0], \" or \").concat(expected[1]);\n    } else {\n      return \"of \".concat(thing, \" \").concat(expected[0]);\n    }\n  } else {\n    return \"of \".concat(thing, \" \").concat(String(expected));\n  }\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith\n\n\nfunction startsWith(str, search, pos) {\n  return str.substr(!pos || pos < 0 ? 0 : +pos, search.length) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith\n\n\nfunction endsWith(str, search, this_len) {\n  if (this_len === undefined || this_len > str.length) {\n    this_len = str.length;\n  }\n\n  return str.substring(this_len - search.length, this_len) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes\n\n\nfunction includes(str, search, start) {\n  if (typeof start !== 'number') {\n    start = 0;\n  }\n\n  if (start + search.length > str.length) {\n    return false;\n  } else {\n    return str.indexOf(search, start) !== -1;\n  }\n}\n\ncreateErrorType('ERR_INVALID_OPT_VALUE', function (name, value) {\n  return 'The value \"' + value + '\" is invalid for option \"' + name + '\"';\n}, TypeError);\ncreateErrorType('ERR_INVALID_ARG_TYPE', function (name, expected, actual) {\n  // determiner: 'must be' or 'must not be'\n  var determiner;\n\n  if (typeof expected === 'string' && startsWith(expected, 'not ')) {\n    determiner = 'must not be';\n    expected = expected.replace(/^not /, '');\n  } else {\n    determiner = 'must be';\n  }\n\n  var msg;\n\n  if (endsWith(name, ' argument')) {\n    // For cases like 'first argument'\n    msg = \"The \".concat(name, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  } else {\n    var type = includes(name, '.') ? 'property' : 'argument';\n    msg = \"The \\\"\".concat(name, \"\\\" \").concat(type, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  }\n\n  msg += \". Received type \".concat(typeof actual);\n  return msg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF');\ncreateErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {\n  return 'The ' + name + ' method is not implemented';\n});\ncreateErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close');\ncreateErrorType('ERR_STREAM_DESTROYED', function (name) {\n  return 'Cannot call ' + name + ' after a stream was destroyed';\n});\ncreateErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times');\ncreateErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable');\ncreateErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end');\ncreateErrorType('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);\ncreateErrorType('ERR_UNKNOWN_ENCODING', function (arg) {\n  return 'Unknown encoding: ' + arg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event');\nmodule.exports.codes = codes;\n","'use strict'\n\nvar experimentalWarnings = new Set();\n\nfunction emitExperimentalWarning(feature) {\n  if (experimentalWarnings.has(feature)) return;\n  var msg = feature + ' is an experimental feature. This feature could ' +\n       'change at any time';\n  experimentalWarnings.add(feature);\n  process.emitWarning(msg, 'ExperimentalWarning');\n}\n\nfunction noop() {}\n\nmodule.exports.emitExperimentalWarning = process.emitWarning\n  ? emitExperimentalWarning\n  : noop;\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n'use strict';\n/*<replacement>*/\n\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n\n  for (var key in obj) {\n    keys.push(key);\n  }\n\n  return keys;\n};\n/*</replacement>*/\n\n\nmodule.exports = Duplex;\n\nvar Readable = require('./_stream_readable');\n\nvar Writable = require('./_stream_writable');\n\nrequire('inherits')(Duplex, Readable);\n\n{\n  // Allow the keys array to be GC'ed.\n  var keys = objectKeys(Writable.prototype);\n\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n  Readable.call(this, options);\n  Writable.call(this, options);\n  this.allowHalfOpen = true;\n\n  if (options) {\n    if (options.readable === false) this.readable = false;\n    if (options.writable === false) this.writable = false;\n\n    if (options.allowHalfOpen === false) {\n      this.allowHalfOpen = false;\n      this.once('end', onend);\n    }\n  }\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n}); // the no-half-open enforcer\n\nfunction onend() {\n  // If the writable side ended, then we're ok.\n  if (this._writableState.ended) return; // no more data can be written.\n  // But allow more writes to happen in this tick.\n\n  process.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n'use strict';\n\nmodule.exports = Writable;\n/* <replacement> */\n\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n} // It seems a linked list but it is not\n// there will be only 2 of these for each stream\n\n\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\n\n\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n/*<replacement>*/\n\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n\nvar Buffer = require('buffer').Buffer;\n\nvar OurUint8Array = global.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nvar _require = require('./internal/streams/state'),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = require('../errors').codes,\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n    ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,\n    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,\n    ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,\n    ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,\n    ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING;\n\nrequire('inherits')(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream, isDuplex) {\n  Duplex = Duplex || require('./_stream_duplex');\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream,\n  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode; // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n\n  this.highWaterMark = getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex); // if _final has been called\n\n  this.finalCalled = false; // drain event flag.\n\n  this.needDrain = false; // at the start of calling end()\n\n  this.ending = false; // when end() has been called, and returned\n\n  this.ended = false; // when 'finish' is emitted\n\n  this.finished = false; // has it been destroyed\n\n  this.destroyed = false; // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n\n  this.length = 0; // a flag to see when we're in the middle of a write.\n\n  this.writing = false; // when true all writes will be buffered until .uncork() call\n\n  this.corked = 0; // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n\n  this.sync = true; // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n\n  this.bufferProcessing = false; // the callback that's passed to _write(chunk,cb)\n\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  }; // the callback that the user supplies to write(chunk,encoding,cb)\n\n\n  this.writecb = null; // the amount that is being written when _write is called.\n\n  this.writelen = 0;\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null; // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n\n  this.pendingcb = 0; // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n\n  this.prefinished = false; // True if the error was already emitted and should not be thrown again\n\n  this.errorEmitted = false; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // count buffered requests\n\n  this.bufferedRequestCount = 0; // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function writableStateBufferGetter() {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})(); // Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\n\n\nvar realHasInstance;\n\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function value(object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function realHasInstance(object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex'); // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the WritableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  if (!isDuplex && !realHasInstance.call(Writable, this)) return new Writable(options);\n  this._writableState = new WritableState(options, this, isDuplex); // legacy.\n\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n    if (typeof options.writev === 'function') this._writev = options.writev;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n} // Otherwise people can pipe Writable streams, which is just wrong.\n\n\nWritable.prototype.pipe = function () {\n  this.emit('error', new ERR_STREAM_CANNOT_PIPE());\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new ERR_STREAM_WRITE_AFTER_END(); // TODO: defer error events consistently everywhere, not just the cb\n\n  stream.emit('error', er);\n  process.nextTick(cb, er);\n} // Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\n\n\nfunction validChunk(stream, state, chunk, cb) {\n  var er;\n\n  if (chunk === null) {\n    er = new ERR_STREAM_NULL_VALUES();\n  } else if (typeof chunk !== 'string' && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk);\n  }\n\n  if (er) {\n    stream.emit('error', er);\n    process.nextTick(cb, er);\n    return false;\n  }\n\n  return true;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n  if (typeof cb !== 'function') cb = nop;\n  if (state.ending) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  this._writableState.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n    if (!state.writing && !state.corked && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new ERR_UNKNOWN_ENCODING(encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nObject.defineProperty(Writable.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n}); // if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\n\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n\n  var len = state.objectMode ? 1 : chunk.length;\n  state.length += len;\n  var ret = state.length < state.highWaterMark; // we must ensure that previous needDrain will not be reset to false.\n\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'));else if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    process.nextTick(cb, er); // this can emit finish, and it will always happen\n    // after error\n\n    process.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er); // this can emit finish, but finish must\n    // always follow error\n\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n  if (typeof cb !== 'function') throw new ERR_MULTIPLE_CALLBACK();\n  onwriteStateUpdate(state);\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state) || stream.destroyed;\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      process.nextTick(afterWrite, stream, state, finished, cb);\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n} // Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\n\n\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n} // if there's something in the buffer waiting, then process it\n\n\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n    var count = 0;\n    var allBuffers = true;\n\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n\n    buffer.allBuffers = allBuffers;\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish); // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--; // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding); // .end() fully uncorks\n\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  } // ignore unnecessary end() calls.\n\n\n  if (!state.ending) endWritable(this, state, cb);\n  return this;\n};\n\nObject.defineProperty(Writable.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n});\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\n\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n\n    if (err) {\n      stream.emit('error', err);\n    }\n\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\n\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function' && !state.destroyed) {\n      state.pendingcb++;\n      state.finalCalled = true;\n      process.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n\n  if (need) {\n    prefinish(stream, state);\n\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n\n  if (cb) {\n    if (state.finished) process.nextTick(cb);else stream.once('finish', cb);\n  }\n\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  } // reuse the free corkReq.\n\n\n  state.corkedRequestsFree.next = corkReq;\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._writableState === undefined) {\n      return false;\n    }\n\n    return this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._writableState.destroyed = value;\n  }\n});\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\n\nWritable.prototype._destroy = function (err, cb) {\n  cb(err);\n};","\n/**\n * Module exports.\n */\n\nmodule.exports = deprecate;\n\n/**\n * Mark that a method should not be used.\n * Returns a modified function which warns once by default.\n *\n * If `localStorage.noDeprecation = true` is set, then it is a no-op.\n *\n * If `localStorage.throwDeprecation = true` is set, then deprecated functions\n * will throw an Error when invoked.\n *\n * If `localStorage.traceDeprecation = true` is set, then deprecated functions\n * will invoke `console.trace()` instead of `console.error()`.\n *\n * @param {Function} fn - the function to deprecate\n * @param {String} msg - the string to print to the console when `fn` is invoked\n * @returns {Function} a new \"deprecated\" version of `fn`\n * @api public\n */\n\nfunction deprecate (fn, msg) {\n  if (config('noDeprecation')) {\n    return fn;\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (config('throwDeprecation')) {\n        throw new Error(msg);\n      } else if (config('traceDeprecation')) {\n        console.trace(msg);\n      } else {\n        console.warn(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n}\n\n/**\n * Checks `localStorage` for boolean values for the given `name`.\n *\n * @param {String} name\n * @returns {Boolean}\n * @api private\n */\n\nfunction config (name) {\n  // accessing global.localStorage can trigger a DOMException in sandboxed iframes\n  try {\n    if (!global.localStorage) return false;\n  } catch (_) {\n    return false;\n  }\n  var val = global.localStorage[name];\n  if (null == val) return false;\n  return String(val).toLowerCase() === 'true';\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}","/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n","'use strict';\n\nvar _Object$setPrototypeO;\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nvar finished = require('./end-of-stream');\n\nvar kLastResolve = Symbol('lastResolve');\nvar kLastReject = Symbol('lastReject');\nvar kError = Symbol('error');\nvar kEnded = Symbol('ended');\nvar kLastPromise = Symbol('lastPromise');\nvar kHandlePromise = Symbol('handlePromise');\nvar kStream = Symbol('stream');\n\nfunction createIterResult(value, done) {\n  return {\n    value: value,\n    done: done\n  };\n}\n\nfunction readAndResolve(iter) {\n  var resolve = iter[kLastResolve];\n\n  if (resolve !== null) {\n    var data = iter[kStream].read(); // we defer if data is null\n    // we can be expecting either 'end' or\n    // 'error'\n\n    if (data !== null) {\n      iter[kLastPromise] = null;\n      iter[kLastResolve] = null;\n      iter[kLastReject] = null;\n      resolve(createIterResult(data, false));\n    }\n  }\n}\n\nfunction onReadable(iter) {\n  // we wait for the next tick, because it might\n  // emit an error with process.nextTick\n  process.nextTick(readAndResolve, iter);\n}\n\nfunction wrapForNext(lastPromise, iter) {\n  return function (resolve, reject) {\n    lastPromise.then(function () {\n      if (iter[kEnded]) {\n        resolve(createIterResult(undefined, true));\n        return;\n      }\n\n      iter[kHandlePromise](resolve, reject);\n    }, reject);\n  };\n}\n\nvar AsyncIteratorPrototype = Object.getPrototypeOf(function () {});\nvar ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf((_Object$setPrototypeO = {\n  get stream() {\n    return this[kStream];\n  },\n\n  next: function next() {\n    var _this = this;\n\n    // if we have detected an error in the meanwhile\n    // reject straight away\n    var error = this[kError];\n\n    if (error !== null) {\n      return Promise.reject(error);\n    }\n\n    if (this[kEnded]) {\n      return Promise.resolve(createIterResult(undefined, true));\n    }\n\n    if (this[kStream].destroyed) {\n      // We need to defer via nextTick because if .destroy(err) is\n      // called, the error will be emitted via nextTick, and\n      // we cannot guarantee that there is no error lingering around\n      // waiting to be emitted.\n      return new Promise(function (resolve, reject) {\n        process.nextTick(function () {\n          if (_this[kError]) {\n            reject(_this[kError]);\n          } else {\n            resolve(createIterResult(undefined, true));\n          }\n        });\n      });\n    } // if we have multiple next() calls\n    // we will wait for the previous Promise to finish\n    // this logic is optimized to support for await loops,\n    // where next() is only called once at a time\n\n\n    var lastPromise = this[kLastPromise];\n    var promise;\n\n    if (lastPromise) {\n      promise = new Promise(wrapForNext(lastPromise, this));\n    } else {\n      // fast path needed to support multiple this.push()\n      // without triggering the next() queue\n      var data = this[kStream].read();\n\n      if (data !== null) {\n        return Promise.resolve(createIterResult(data, false));\n      }\n\n      promise = new Promise(this[kHandlePromise]);\n    }\n\n    this[kLastPromise] = promise;\n    return promise;\n  }\n}, _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {\n  return this;\n}), _defineProperty(_Object$setPrototypeO, \"return\", function _return() {\n  var _this2 = this;\n\n  // destroy(err, cb) is a private API\n  // we can guarantee we have that here, because we control the\n  // Readable class this is attached to\n  return new Promise(function (resolve, reject) {\n    _this2[kStream].destroy(null, function (err) {\n      if (err) {\n        reject(err);\n        return;\n      }\n\n      resolve(createIterResult(undefined, true));\n    });\n  });\n}), _Object$setPrototypeO), AsyncIteratorPrototype);\n\nvar createReadableStreamAsyncIterator = function createReadableStreamAsyncIterator(stream) {\n  var _Object$create;\n\n  var iterator = Object.create(ReadableStreamAsyncIteratorPrototype, (_Object$create = {}, _defineProperty(_Object$create, kStream, {\n    value: stream,\n    writable: true\n  }), _defineProperty(_Object$create, kLastResolve, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kLastReject, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kError, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kEnded, {\n    value: stream._readableState.endEmitted,\n    writable: true\n  }), _defineProperty(_Object$create, kHandlePromise, {\n    value: function value(resolve, reject) {\n      var data = iterator[kStream].read();\n\n      if (data) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        resolve(createIterResult(data, false));\n      } else {\n        iterator[kLastResolve] = resolve;\n        iterator[kLastReject] = reject;\n      }\n    },\n    writable: true\n  }), _Object$create));\n  iterator[kLastPromise] = null;\n  finished(stream, function (err) {\n    if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {\n      var reject = iterator[kLastReject]; // reject if we are waiting for data in the Promise\n      // returned by next() and store the error\n\n      if (reject !== null) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        reject(err);\n      }\n\n      iterator[kError] = err;\n      return;\n    }\n\n    var resolve = iterator[kLastResolve];\n\n    if (resolve !== null) {\n      iterator[kLastPromise] = null;\n      iterator[kLastResolve] = null;\n      iterator[kLastReject] = null;\n      resolve(createIterResult(undefined, true));\n    }\n\n    iterator[kEnded] = true;\n  });\n  stream.on('readable', onReadable.bind(null, iterator));\n  return iterator;\n};\n\nmodule.exports = createReadableStreamAsyncIterator;","// Ported from https://github.com/mafintosh/end-of-stream with\n// permission from the author, Mathias Buus (@mafintosh).\n'use strict';\n\nvar ERR_STREAM_PREMATURE_CLOSE = require('../../../errors').codes.ERR_STREAM_PREMATURE_CLOSE;\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    callback.apply(this, args);\n  };\n}\n\nfunction noop() {}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction eos(stream, opts, callback) {\n  if (typeof opts === 'function') return eos(stream, null, opts);\n  if (!opts) opts = {};\n  callback = once(callback || noop);\n  var readable = opts.readable || opts.readable !== false && stream.readable;\n  var writable = opts.writable || opts.writable !== false && stream.writable;\n\n  var onlegacyfinish = function onlegacyfinish() {\n    if (!stream.writable) onfinish();\n  };\n\n  var writableEnded = stream._writableState && stream._writableState.finished;\n\n  var onfinish = function onfinish() {\n    writable = false;\n    writableEnded = true;\n    if (!readable) callback.call(stream);\n  };\n\n  var readableEnded = stream._readableState && stream._readableState.endEmitted;\n\n  var onend = function onend() {\n    readable = false;\n    readableEnded = true;\n    if (!writable) callback.call(stream);\n  };\n\n  var onerror = function onerror(err) {\n    callback.call(stream, err);\n  };\n\n  var onclose = function onclose() {\n    var err;\n\n    if (readable && !readableEnded) {\n      if (!stream._readableState || !stream._readableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n\n    if (writable && !writableEnded) {\n      if (!stream._writableState || !stream._writableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n  };\n\n  var onrequest = function onrequest() {\n    stream.req.on('finish', onfinish);\n  };\n\n  if (isRequest(stream)) {\n    stream.on('complete', onfinish);\n    stream.on('abort', onclose);\n    if (stream.req) onrequest();else stream.on('request', onrequest);\n  } else if (writable && !stream._writableState) {\n    // legacy streams\n    stream.on('end', onlegacyfinish);\n    stream.on('close', onlegacyfinish);\n  }\n\n  stream.on('end', onend);\n  stream.on('finish', onfinish);\n  if (opts.error !== false) stream.on('error', onerror);\n  stream.on('close', onclose);\n  return function () {\n    stream.removeListener('complete', onfinish);\n    stream.removeListener('abort', onclose);\n    stream.removeListener('request', onrequest);\n    if (stream.req) stream.req.removeListener('finish', onfinish);\n    stream.removeListener('end', onlegacyfinish);\n    stream.removeListener('close', onlegacyfinish);\n    stream.removeListener('finish', onfinish);\n    stream.removeListener('end', onend);\n    stream.removeListener('error', onerror);\n    stream.removeListener('close', onclose);\n  };\n}\n\nmodule.exports = eos;","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n'use strict';\n\nmodule.exports = Transform;\n\nvar _require$codes = require('../errors').codes,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n    ERR_TRANSFORM_ALREADY_TRANSFORMING = _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,\n    ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0;\n\nvar Duplex = require('./_stream_duplex');\n\nrequire('inherits')(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n  var cb = ts.writecb;\n\n  if (cb === null) {\n    return this.emit('error', new ERR_MULTIPLE_CALLBACK());\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n  cb(er);\n  var rs = this._readableState;\n  rs.reading = false;\n\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n  Duplex.call(this, options);\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  }; // start out asking for a readable event once data is transformed.\n\n  this._readableState.needReadable = true; // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  } // When the writable side finishes, then flush out anything remaining.\n\n\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function' && !this._readableState.destroyed) {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n}; // This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\n\n\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'));\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n}; // Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\n\n\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && !ts.transforming) {\n    ts.transforming = true;\n\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data); // TODO(BridgeAR): Write a test for these two error cases\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n\n  if (stream._writableState.length) throw new ERR_TRANSFORM_WITH_LENGTH_0();\n  if (stream._transformState.transforming) throw new ERR_TRANSFORM_ALREADY_TRANSFORMING();\n  return stream.push(null);\n}","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\nrequire('inherits')(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};","// Ported from https://github.com/mafintosh/pump with\n// permission from the author, Mathias Buus (@mafintosh).\n'use strict';\n\nvar eos;\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n    callback.apply(void 0, arguments);\n  };\n}\n\nvar _require$codes = require('../../../errors').codes,\n    ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,\n    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED;\n\nfunction noop(err) {\n  // Rethrow the error if it exists to avoid swallowing it\n  if (err) throw err;\n}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction destroyer(stream, reading, writing, callback) {\n  callback = once(callback);\n  var closed = false;\n  stream.on('close', function () {\n    closed = true;\n  });\n  if (eos === undefined) eos = require('./end-of-stream');\n  eos(stream, {\n    readable: reading,\n    writable: writing\n  }, function (err) {\n    if (err) return callback(err);\n    closed = true;\n    callback();\n  });\n  var destroyed = false;\n  return function (err) {\n    if (closed) return;\n    if (destroyed) return;\n    destroyed = true; // request.destroy just do .end - .abort is what we want\n\n    if (isRequest(stream)) return stream.abort();\n    if (typeof stream.destroy === 'function') return stream.destroy();\n    callback(err || new ERR_STREAM_DESTROYED('pipe'));\n  };\n}\n\nfunction call(fn) {\n  fn();\n}\n\nfunction pipe(from, to) {\n  return from.pipe(to);\n}\n\nfunction popCallback(streams) {\n  if (!streams.length) return noop;\n  if (typeof streams[streams.length - 1] !== 'function') return noop;\n  return streams.pop();\n}\n\nfunction pipeline() {\n  for (var _len = arguments.length, streams = new Array(_len), _key = 0; _key < _len; _key++) {\n    streams[_key] = arguments[_key];\n  }\n\n  var callback = popCallback(streams);\n  if (Array.isArray(streams[0])) streams = streams[0];\n\n  if (streams.length < 2) {\n    throw new ERR_MISSING_ARGS('streams');\n  }\n\n  var error;\n  var destroys = streams.map(function (stream, i) {\n    var reading = i < streams.length - 1;\n    var writing = i > 0;\n    return destroyer(stream, reading, writing, function (err) {\n      if (!error) error = err;\n      if (err) destroys.forEach(call);\n      if (reading) return;\n      destroys.forEach(call);\n      callback(error);\n    });\n  });\n  return streams.reduce(pipe);\n}\n\nmodule.exports = pipeline;","var WriteError = require('level-errors').WriteError\nvar promisify = require('./promisify')\nvar getCallback = require('./common').getCallback\nvar getOptions = require('./common').getOptions\n\nfunction Batch (levelup) {\n  this._levelup = levelup\n  this.batch = levelup.db.batch()\n  this.ops = []\n  this.length = 0\n}\n\nBatch.prototype.put = function (key, value) {\n  try {\n    this.batch.put(key, value)\n  } catch (e) {\n    throw new WriteError(e)\n  }\n\n  this.ops.push({ type: 'put', key: key, value: value })\n  this.length++\n\n  return this\n}\n\nBatch.prototype.del = function (key) {\n  try {\n    this.batch.del(key)\n  } catch (err) {\n    throw new WriteError(err)\n  }\n\n  this.ops.push({ type: 'del', key: key })\n  this.length++\n\n  return this\n}\n\nBatch.prototype.clear = function () {\n  try {\n    this.batch.clear()\n  } catch (err) {\n    throw new WriteError(err)\n  }\n\n  this.ops = []\n  this.length = 0\n\n  return this\n}\n\nBatch.prototype.write = function (options, callback) {\n  var levelup = this._levelup\n  var ops = this.ops\n  var promise\n\n  callback = getCallback(options, callback)\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  options = getOptions(options)\n\n  try {\n    this.batch.write(options, function (err) {\n      if (err) { return callback(new WriteError(err)) }\n      levelup.emit('batch', ops)\n      callback()\n    })\n  } catch (err) {\n    throw new WriteError(err)\n  }\n\n  return promise\n}\n\nmodule.exports = Batch\n","var createError = require('errno').create\nvar LevelUPError = createError('LevelUPError')\nvar NotFoundError = createError('NotFoundError', LevelUPError)\n\nNotFoundError.prototype.notFound = true\nNotFoundError.prototype.status = 404\n\nmodule.exports = {\n  LevelUPError: LevelUPError,\n  InitializationError: createError('InitializationError', LevelUPError),\n  OpenError: createError('OpenError', LevelUPError),\n  ReadError: createError('ReadError', LevelUPError),\n  WriteError: createError('WriteError', LevelUPError),\n  NotFoundError: NotFoundError,\n  EncodingError: createError('EncodingError', LevelUPError)\n}\n","var all = module.exports.all = [\n  {\n    errno: -2,\n    code: 'ENOENT',\n    description: 'no such file or directory'\n  },\n  {\n    errno: -1,\n    code: 'UNKNOWN',\n    description: 'unknown error'\n  },\n  {\n    errno: 0,\n    code: 'OK',\n    description: 'success'\n  },\n  {\n    errno: 1,\n    code: 'EOF',\n    description: 'end of file'\n  },\n  {\n    errno: 2,\n    code: 'EADDRINFO',\n    description: 'getaddrinfo error'\n  },\n  {\n    errno: 3,\n    code: 'EACCES',\n    description: 'permission denied'\n  },\n  {\n    errno: 4,\n    code: 'EAGAIN',\n    description: 'resource temporarily unavailable'\n  },\n  {\n    errno: 5,\n    code: 'EADDRINUSE',\n    description: 'address already in use'\n  },\n  {\n    errno: 6,\n    code: 'EADDRNOTAVAIL',\n    description: 'address not available'\n  },\n  {\n    errno: 7,\n    code: 'EAFNOSUPPORT',\n    description: 'address family not supported'\n  },\n  {\n    errno: 8,\n    code: 'EALREADY',\n    description: 'connection already in progress'\n  },\n  {\n    errno: 9,\n    code: 'EBADF',\n    description: 'bad file descriptor'\n  },\n  {\n    errno: 10,\n    code: 'EBUSY',\n    description: 'resource busy or locked'\n  },\n  {\n    errno: 11,\n    code: 'ECONNABORTED',\n    description: 'software caused connection abort'\n  },\n  {\n    errno: 12,\n    code: 'ECONNREFUSED',\n    description: 'connection refused'\n  },\n  {\n    errno: 13,\n    code: 'ECONNRESET',\n    description: 'connection reset by peer'\n  },\n  {\n    errno: 14,\n    code: 'EDESTADDRREQ',\n    description: 'destination address required'\n  },\n  {\n    errno: 15,\n    code: 'EFAULT',\n    description: 'bad address in system call argument'\n  },\n  {\n    errno: 16,\n    code: 'EHOSTUNREACH',\n    description: 'host is unreachable'\n  },\n  {\n    errno: 17,\n    code: 'EINTR',\n    description: 'interrupted system call'\n  },\n  {\n    errno: 18,\n    code: 'EINVAL',\n    description: 'invalid argument'\n  },\n  {\n    errno: 19,\n    code: 'EISCONN',\n    description: 'socket is already connected'\n  },\n  {\n    errno: 20,\n    code: 'EMFILE',\n    description: 'too many open files'\n  },\n  {\n    errno: 21,\n    code: 'EMSGSIZE',\n    description: 'message too long'\n  },\n  {\n    errno: 22,\n    code: 'ENETDOWN',\n    description: 'network is down'\n  },\n  {\n    errno: 23,\n    code: 'ENETUNREACH',\n    description: 'network is unreachable'\n  },\n  {\n    errno: 24,\n    code: 'ENFILE',\n    description: 'file table overflow'\n  },\n  {\n    errno: 25,\n    code: 'ENOBUFS',\n    description: 'no buffer space available'\n  },\n  {\n    errno: 26,\n    code: 'ENOMEM',\n    description: 'not enough memory'\n  },\n  {\n    errno: 27,\n    code: 'ENOTDIR',\n    description: 'not a directory'\n  },\n  {\n    errno: 28,\n    code: 'EISDIR',\n    description: 'illegal operation on a directory'\n  },\n  {\n    errno: 29,\n    code: 'ENONET',\n    description: 'machine is not on the network'\n  },\n  {\n    errno: 31,\n    code: 'ENOTCONN',\n    description: 'socket is not connected'\n  },\n  {\n    errno: 32,\n    code: 'ENOTSOCK',\n    description: 'socket operation on non-socket'\n  },\n  {\n    errno: 33,\n    code: 'ENOTSUP',\n    description: 'operation not supported on socket'\n  },\n  {\n    errno: 34,\n    code: 'ENOENT',\n    description: 'no such file or directory'\n  },\n  {\n    errno: 35,\n    code: 'ENOSYS',\n    description: 'function not implemented'\n  },\n  {\n    errno: 36,\n    code: 'EPIPE',\n    description: 'broken pipe'\n  },\n  {\n    errno: 37,\n    code: 'EPROTO',\n    description: 'protocol error'\n  },\n  {\n    errno: 38,\n    code: 'EPROTONOSUPPORT',\n    description: 'protocol not supported'\n  },\n  {\n    errno: 39,\n    code: 'EPROTOTYPE',\n    description: 'protocol wrong type for socket'\n  },\n  {\n    errno: 40,\n    code: 'ETIMEDOUT',\n    description: 'connection timed out'\n  },\n  {\n    errno: 41,\n    code: 'ECHARSET',\n    description: 'invalid Unicode character'\n  },\n  {\n    errno: 42,\n    code: 'EAIFAMNOSUPPORT',\n    description: 'address family for hostname not supported'\n  },\n  {\n    errno: 44,\n    code: 'EAISERVICE',\n    description: 'servname not supported for ai_socktype'\n  },\n  {\n    errno: 45,\n    code: 'EAISOCKTYPE',\n    description: 'ai_socktype not supported'\n  },\n  {\n    errno: 46,\n    code: 'ESHUTDOWN',\n    description: 'cannot send after transport endpoint shutdown'\n  },\n  {\n    errno: 47,\n    code: 'EEXIST',\n    description: 'file already exists'\n  },\n  {\n    errno: 48,\n    code: 'ESRCH',\n    description: 'no such process'\n  },\n  {\n    errno: 49,\n    code: 'ENAMETOOLONG',\n    description: 'name too long'\n  },\n  {\n    errno: 50,\n    code: 'EPERM',\n    description: 'operation not permitted'\n  },\n  {\n    errno: 51,\n    code: 'ELOOP',\n    description: 'too many symbolic links encountered'\n  },\n  {\n    errno: 52,\n    code: 'EXDEV',\n    description: 'cross-device link not permitted'\n  },\n  {\n    errno: 53,\n    code: 'ENOTEMPTY',\n    description: 'directory not empty'\n  },\n  {\n    errno: 54,\n    code: 'ENOSPC',\n    description: 'no space left on device'\n  },\n  {\n    errno: 55,\n    code: 'EIO',\n    description: 'i/o error'\n  },\n  {\n    errno: 56,\n    code: 'EROFS',\n    description: 'read-only file system'\n  },\n  {\n    errno: 57,\n    code: 'ENODEV',\n    description: 'no such device'\n  },\n  {\n    errno: 58,\n    code: 'ESPIPE',\n    description: 'invalid seek'\n  },\n  {\n    errno: 59,\n    code: 'ECANCELED',\n    description: 'operation canceled'\n  }\n]\n\nmodule.exports.errno = {}\nmodule.exports.code = {}\n\nall.forEach(function (error) {\n  module.exports.errno[error.errno] = error\n  module.exports.code[error.code] = error\n})\n\nmodule.exports.custom = require('./custom')(module.exports)\nmodule.exports.create = module.exports.custom.createError\n","var prr = require('prr')\n\nfunction init (type, message, cause) {\n  if (!!message && typeof message != 'string') {\n    message = message.message || message.name\n  }\n  prr(this, {\n      type    : type\n    , name    : type\n      // can be passed just a 'cause'\n    , cause   : typeof message != 'string' ? message : cause\n    , message : message\n  }, 'ewr')\n}\n\n// generic prototype, not intended to be actually used - helpful for `instanceof`\nfunction CustomError (message, cause) {\n  Error.call(this)\n  if (Error.captureStackTrace)\n    Error.captureStackTrace(this, this.constructor)\n  init.call(this, 'CustomError', message, cause)\n}\n\nCustomError.prototype = new Error()\n\nfunction createError (errno, type, proto) {\n  var err = function (message, cause) {\n    init.call(this, type, message, cause)\n    //TODO: the specificity here is stupid, errno should be available everywhere\n    if (type == 'FilesystemError') {\n      this.code    = this.cause.code\n      this.path    = this.cause.path\n      this.errno   = this.cause.errno\n      this.message =\n        (errno.errno[this.cause.errno]\n          ? errno.errno[this.cause.errno].description\n          : this.cause.message)\n        + (this.cause.path ? ' [' + this.cause.path + ']' : '')\n    }\n    Error.call(this)\n    if (Error.captureStackTrace)\n      Error.captureStackTrace(this, err)\n  }\n  err.prototype = !!proto ? new proto() : new CustomError()\n  return err\n}\n\nmodule.exports = function (errno) {\n  var ce = function (type, proto) {\n    return createError(errno, type, proto)\n  }\n  return {\n      CustomError     : CustomError\n    , FilesystemError : ce('FilesystemError')\n    , createError     : ce\n  }\n}\n","/*!\n  * prr\n  * (c) 2013 Rod Vagg <rod@vagg.org>\n  * https://github.com/rvagg/prr\n  * License: MIT\n  */\n\n(function (name, context, definition) {\n  if (typeof module != 'undefined' && module.exports)\n    module.exports = definition()\n  else\n    context[name] = definition()\n})('prr', this, function() {\n\n  var setProperty = typeof Object.defineProperty == 'function'\n      ? function (obj, key, options) {\n          Object.defineProperty(obj, key, options)\n          return obj\n        }\n      : function (obj, key, options) { // < es5\n          obj[key] = options.value\n          return obj\n        }\n\n    , makeOptions = function (value, options) {\n        var oo = typeof options == 'object'\n          , os = !oo && typeof options == 'string'\n          , op = function (p) {\n              return oo\n                ? !!options[p]\n                : os\n                  ? options.indexOf(p[0]) > -1\n                  : false\n            }\n\n        return {\n            enumerable   : op('enumerable')\n          , configurable : op('configurable')\n          , writable     : op('writable')\n          , value        : value\n        }\n      }\n\n    , prr = function (obj, key, value, options) {\n        var k\n\n        options = makeOptions(value, options)\n\n        if (typeof key == 'object') {\n          for (k in key) {\n            if (Object.hasOwnProperty.call(key, k)) {\n              options.value = key[k]\n              setProperty(obj, k, options)\n            }\n          }\n          return obj\n        }\n\n        return setProperty(obj, key, options)\n      }\n\n  return prr\n})","function promisify () {\n  var callback\n  var promise = new Promise(function (resolve, reject) {\n    callback = function callback (err, value) {\n      if (err) reject(err)\n      else resolve(value)\n    }\n  })\n  callback.promise = promise\n  return callback\n}\n\nmodule.exports = promisify\n","exports.getCallback = function (options, callback) {\n  return typeof options === 'function' ? options : callback\n}\n\nexports.getOptions = function (options) {\n  return typeof options === 'object' && options !== null ? options : {}\n}\n","'use strict';\n\nvar objectAssign = require('object-assign');\n\n// compare and isBuffer taken from https://github.com/feross/buffer/blob/680e9e5e488f22aac27599a57dc844a6315928dd/index.js\n// original notice:\n\n/*!\n * The buffer module from node.js, for the browser.\n *\n * @author   Feross Aboukhadijeh <feross@feross.org> <http://feross.org>\n * @license  MIT\n */\nfunction compare(a, b) {\n  if (a === b) {\n    return 0;\n  }\n\n  var x = a.length;\n  var y = b.length;\n\n  for (var i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (a[i] !== b[i]) {\n      x = a[i];\n      y = b[i];\n      break;\n    }\n  }\n\n  if (x < y) {\n    return -1;\n  }\n  if (y < x) {\n    return 1;\n  }\n  return 0;\n}\nfunction isBuffer(b) {\n  if (global.Buffer && typeof global.Buffer.isBuffer === 'function') {\n    return global.Buffer.isBuffer(b);\n  }\n  return !!(b != null && b._isBuffer);\n}\n\n// based on node assert, original notice:\n// NB: The URL to the CommonJS spec is kept just for tradition.\n//     node-assert has evolved a lot since then, both in API and behavior.\n\n// http://wiki.commonjs.org/wiki/Unit_Testing/1.0\n//\n// THIS IS NOT TESTED NOR LIKELY TO WORK OUTSIDE V8!\n//\n// Originally from narwhal.js (http://narwhaljs.org)\n// Copyright (c) 2009 Thomas Robinson <280north.com>\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the 'Software'), to\n// deal in the Software without restriction, including without limitation the\n// rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n// sell copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n// ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n// WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar util = require('util/');\nvar hasOwn = Object.prototype.hasOwnProperty;\nvar pSlice = Array.prototype.slice;\nvar functionsHaveNames = (function () {\n  return function foo() {}.name === 'foo';\n}());\nfunction pToString (obj) {\n  return Object.prototype.toString.call(obj);\n}\nfunction isView(arrbuf) {\n  if (isBuffer(arrbuf)) {\n    return false;\n  }\n  if (typeof global.ArrayBuffer !== 'function') {\n    return false;\n  }\n  if (typeof ArrayBuffer.isView === 'function') {\n    return ArrayBuffer.isView(arrbuf);\n  }\n  if (!arrbuf) {\n    return false;\n  }\n  if (arrbuf instanceof DataView) {\n    return true;\n  }\n  if (arrbuf.buffer && arrbuf.buffer instanceof ArrayBuffer) {\n    return true;\n  }\n  return false;\n}\n// 1. The assert module provides functions that throw\n// AssertionError's when particular conditions are not met. The\n// assert module must conform to the following interface.\n\nvar assert = module.exports = ok;\n\n// 2. The AssertionError is defined in assert.\n// new assert.AssertionError({ message: message,\n//                             actual: actual,\n//                             expected: expected })\n\nvar regex = /\\s*function\\s+([^\\(\\s]*)\\s*/;\n// based on https://github.com/ljharb/function.prototype.name/blob/adeeeec8bfcc6068b187d7d9fb3d5bb1d3a30899/implementation.js\nfunction getName(func) {\n  if (!util.isFunction(func)) {\n    return;\n  }\n  if (functionsHaveNames) {\n    return func.name;\n  }\n  var str = func.toString();\n  var match = str.match(regex);\n  return match && match[1];\n}\nassert.AssertionError = function AssertionError(options) {\n  this.name = 'AssertionError';\n  this.actual = options.actual;\n  this.expected = options.expected;\n  this.operator = options.operator;\n  if (options.message) {\n    this.message = options.message;\n    this.generatedMessage = false;\n  } else {\n    this.message = getMessage(this);\n    this.generatedMessage = true;\n  }\n  var stackStartFunction = options.stackStartFunction || fail;\n  if (Error.captureStackTrace) {\n    Error.captureStackTrace(this, stackStartFunction);\n  } else {\n    // non v8 browsers so we can have a stacktrace\n    var err = new Error();\n    if (err.stack) {\n      var out = err.stack;\n\n      // try to strip useless frames\n      var fn_name = getName(stackStartFunction);\n      var idx = out.indexOf('\\n' + fn_name);\n      if (idx >= 0) {\n        // once we have located the function frame\n        // we need to strip out everything before it (and its line)\n        var next_line = out.indexOf('\\n', idx + 1);\n        out = out.substring(next_line + 1);\n      }\n\n      this.stack = out;\n    }\n  }\n};\n\n// assert.AssertionError instanceof Error\nutil.inherits(assert.AssertionError, Error);\n\nfunction truncate(s, n) {\n  if (typeof s === 'string') {\n    return s.length < n ? s : s.slice(0, n);\n  } else {\n    return s;\n  }\n}\nfunction inspect(something) {\n  if (functionsHaveNames || !util.isFunction(something)) {\n    return util.inspect(something);\n  }\n  var rawname = getName(something);\n  var name = rawname ? ': ' + rawname : '';\n  return '[Function' +  name + ']';\n}\nfunction getMessage(self) {\n  return truncate(inspect(self.actual), 128) + ' ' +\n         self.operator + ' ' +\n         truncate(inspect(self.expected), 128);\n}\n\n// At present only the three keys mentioned above are used and\n// understood by the spec. Implementations or sub modules can pass\n// other keys to the AssertionError's constructor - they will be\n// ignored.\n\n// 3. All of the following functions must throw an AssertionError\n// when a corresponding condition is not met, with a message that\n// may be undefined if not provided.  All assertion methods provide\n// both the actual and expected values to the assertion error for\n// display purposes.\n\nfunction fail(actual, expected, message, operator, stackStartFunction) {\n  throw new assert.AssertionError({\n    message: message,\n    actual: actual,\n    expected: expected,\n    operator: operator,\n    stackStartFunction: stackStartFunction\n  });\n}\n\n// EXTENSION! allows for well behaved errors defined elsewhere.\nassert.fail = fail;\n\n// 4. Pure assertion tests whether a value is truthy, as determined\n// by !!guard.\n// assert.ok(guard, message_opt);\n// This statement is equivalent to assert.equal(true, !!guard,\n// message_opt);. To test strictly for the value true, use\n// assert.strictEqual(true, guard, message_opt);.\n\nfunction ok(value, message) {\n  if (!value) fail(value, true, message, '==', assert.ok);\n}\nassert.ok = ok;\n\n// 5. The equality assertion tests shallow, coercive equality with\n// ==.\n// assert.equal(actual, expected, message_opt);\n\nassert.equal = function equal(actual, expected, message) {\n  if (actual != expected) fail(actual, expected, message, '==', assert.equal);\n};\n\n// 6. The non-equality assertion tests for whether two objects are not equal\n// with != assert.notEqual(actual, expected, message_opt);\n\nassert.notEqual = function notEqual(actual, expected, message) {\n  if (actual == expected) {\n    fail(actual, expected, message, '!=', assert.notEqual);\n  }\n};\n\n// 7. The equivalence assertion tests a deep equality relation.\n// assert.deepEqual(actual, expected, message_opt);\n\nassert.deepEqual = function deepEqual(actual, expected, message) {\n  if (!_deepEqual(actual, expected, false)) {\n    fail(actual, expected, message, 'deepEqual', assert.deepEqual);\n  }\n};\n\nassert.deepStrictEqual = function deepStrictEqual(actual, expected, message) {\n  if (!_deepEqual(actual, expected, true)) {\n    fail(actual, expected, message, 'deepStrictEqual', assert.deepStrictEqual);\n  }\n};\n\nfunction _deepEqual(actual, expected, strict, memos) {\n  // 7.1. All identical values are equivalent, as determined by ===.\n  if (actual === expected) {\n    return true;\n  } else if (isBuffer(actual) && isBuffer(expected)) {\n    return compare(actual, expected) === 0;\n\n  // 7.2. If the expected value is a Date object, the actual value is\n  // equivalent if it is also a Date object that refers to the same time.\n  } else if (util.isDate(actual) && util.isDate(expected)) {\n    return actual.getTime() === expected.getTime();\n\n  // 7.3 If the expected value is a RegExp object, the actual value is\n  // equivalent if it is also a RegExp object with the same source and\n  // properties (`global`, `multiline`, `lastIndex`, `ignoreCase`).\n  } else if (util.isRegExp(actual) && util.isRegExp(expected)) {\n    return actual.source === expected.source &&\n           actual.global === expected.global &&\n           actual.multiline === expected.multiline &&\n           actual.lastIndex === expected.lastIndex &&\n           actual.ignoreCase === expected.ignoreCase;\n\n  // 7.4. Other pairs that do not both pass typeof value == 'object',\n  // equivalence is determined by ==.\n  } else if ((actual === null || typeof actual !== 'object') &&\n             (expected === null || typeof expected !== 'object')) {\n    return strict ? actual === expected : actual == expected;\n\n  // If both values are instances of typed arrays, wrap their underlying\n  // ArrayBuffers in a Buffer each to increase performance\n  // This optimization requires the arrays to have the same type as checked by\n  // Object.prototype.toString (aka pToString). Never perform binary\n  // comparisons for Float*Arrays, though, since e.g. +0 === -0 but their\n  // bit patterns are not identical.\n  } else if (isView(actual) && isView(expected) &&\n             pToString(actual) === pToString(expected) &&\n             !(actual instanceof Float32Array ||\n               actual instanceof Float64Array)) {\n    return compare(new Uint8Array(actual.buffer),\n                   new Uint8Array(expected.buffer)) === 0;\n\n  // 7.5 For all other Object pairs, including Array objects, equivalence is\n  // determined by having the same number of owned properties (as verified\n  // with Object.prototype.hasOwnProperty.call), the same set of keys\n  // (although not necessarily the same order), equivalent values for every\n  // corresponding key, and an identical 'prototype' property. Note: this\n  // accounts for both named and indexed properties on Arrays.\n  } else if (isBuffer(actual) !== isBuffer(expected)) {\n    return false;\n  } else {\n    memos = memos || {actual: [], expected: []};\n\n    var actualIndex = memos.actual.indexOf(actual);\n    if (actualIndex !== -1) {\n      if (actualIndex === memos.expected.indexOf(expected)) {\n        return true;\n      }\n    }\n\n    memos.actual.push(actual);\n    memos.expected.push(expected);\n\n    return objEquiv(actual, expected, strict, memos);\n  }\n}\n\nfunction isArguments(object) {\n  return Object.prototype.toString.call(object) == '[object Arguments]';\n}\n\nfunction objEquiv(a, b, strict, actualVisitedObjects) {\n  if (a === null || a === undefined || b === null || b === undefined)\n    return false;\n  // if one is a primitive, the other must be same\n  if (util.isPrimitive(a) || util.isPrimitive(b))\n    return a === b;\n  if (strict && Object.getPrototypeOf(a) !== Object.getPrototypeOf(b))\n    return false;\n  var aIsArgs = isArguments(a);\n  var bIsArgs = isArguments(b);\n  if ((aIsArgs && !bIsArgs) || (!aIsArgs && bIsArgs))\n    return false;\n  if (aIsArgs) {\n    a = pSlice.call(a);\n    b = pSlice.call(b);\n    return _deepEqual(a, b, strict);\n  }\n  var ka = objectKeys(a);\n  var kb = objectKeys(b);\n  var key, i;\n  // having the same number of owned properties (keys incorporates\n  // hasOwnProperty)\n  if (ka.length !== kb.length)\n    return false;\n  //the same set of keys (although not necessarily the same order),\n  ka.sort();\n  kb.sort();\n  //~~~cheap key test\n  for (i = ka.length - 1; i >= 0; i--) {\n    if (ka[i] !== kb[i])\n      return false;\n  }\n  //equivalent values for every corresponding key, and\n  //~~~possibly expensive deep test\n  for (i = ka.length - 1; i >= 0; i--) {\n    key = ka[i];\n    if (!_deepEqual(a[key], b[key], strict, actualVisitedObjects))\n      return false;\n  }\n  return true;\n}\n\n// 8. The non-equivalence assertion tests for any deep inequality.\n// assert.notDeepEqual(actual, expected, message_opt);\n\nassert.notDeepEqual = function notDeepEqual(actual, expected, message) {\n  if (_deepEqual(actual, expected, false)) {\n    fail(actual, expected, message, 'notDeepEqual', assert.notDeepEqual);\n  }\n};\n\nassert.notDeepStrictEqual = notDeepStrictEqual;\nfunction notDeepStrictEqual(actual, expected, message) {\n  if (_deepEqual(actual, expected, true)) {\n    fail(actual, expected, message, 'notDeepStrictEqual', notDeepStrictEqual);\n  }\n}\n\n\n// 9. The strict equality assertion tests strict equality, as determined by ===.\n// assert.strictEqual(actual, expected, message_opt);\n\nassert.strictEqual = function strictEqual(actual, expected, message) {\n  if (actual !== expected) {\n    fail(actual, expected, message, '===', assert.strictEqual);\n  }\n};\n\n// 10. The strict non-equality assertion tests for strict inequality, as\n// determined by !==.  assert.notStrictEqual(actual, expected, message_opt);\n\nassert.notStrictEqual = function notStrictEqual(actual, expected, message) {\n  if (actual === expected) {\n    fail(actual, expected, message, '!==', assert.notStrictEqual);\n  }\n};\n\nfunction expectedException(actual, expected) {\n  if (!actual || !expected) {\n    return false;\n  }\n\n  if (Object.prototype.toString.call(expected) == '[object RegExp]') {\n    return expected.test(actual);\n  }\n\n  try {\n    if (actual instanceof expected) {\n      return true;\n    }\n  } catch (e) {\n    // Ignore.  The instanceof check doesn't work for arrow functions.\n  }\n\n  if (Error.isPrototypeOf(expected)) {\n    return false;\n  }\n\n  return expected.call({}, actual) === true;\n}\n\nfunction _tryBlock(block) {\n  var error;\n  try {\n    block();\n  } catch (e) {\n    error = e;\n  }\n  return error;\n}\n\nfunction _throws(shouldThrow, block, expected, message) {\n  var actual;\n\n  if (typeof block !== 'function') {\n    throw new TypeError('\"block\" argument must be a function');\n  }\n\n  if (typeof expected === 'string') {\n    message = expected;\n    expected = null;\n  }\n\n  actual = _tryBlock(block);\n\n  message = (expected && expected.name ? ' (' + expected.name + ').' : '.') +\n            (message ? ' ' + message : '.');\n\n  if (shouldThrow && !actual) {\n    fail(actual, expected, 'Missing expected exception' + message);\n  }\n\n  var userProvidedMessage = typeof message === 'string';\n  var isUnwantedException = !shouldThrow && util.isError(actual);\n  var isUnexpectedException = !shouldThrow && actual && !expected;\n\n  if ((isUnwantedException &&\n      userProvidedMessage &&\n      expectedException(actual, expected)) ||\n      isUnexpectedException) {\n    fail(actual, expected, 'Got unwanted exception' + message);\n  }\n\n  if ((shouldThrow && actual && expected &&\n      !expectedException(actual, expected)) || (!shouldThrow && actual)) {\n    throw actual;\n  }\n}\n\n// 11. Expected to throw an error:\n// assert.throws(block, Error_opt, message_opt);\n\nassert.throws = function(block, /*optional*/error, /*optional*/message) {\n  _throws(true, block, error, message);\n};\n\n// EXTENSION! This is annoying to write outside this module.\nassert.doesNotThrow = function(block, /*optional*/error, /*optional*/message) {\n  _throws(false, block, error, message);\n};\n\nassert.ifError = function(err) { if (err) throw err; };\n\n// Expose a strict only variant of assert\nfunction strict(value, message) {\n  if (!value) fail(value, true, message, '==', strict);\n}\nassert.strict = objectAssign(strict, assert, {\n  equal: assert.strictEqual,\n  deepEqual: assert.deepStrictEqual,\n  notEqual: assert.notStrictEqual,\n  notDeepEqual: assert.notDeepStrictEqual\n});\nassert.strict.strict = assert.strict;\n\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    if (hasOwn.call(obj, key)) keys.push(key);\n  }\n  return keys;\n};\n","/*\nobject-assign\n(c) Sindre Sorhus\n@license MIT\n*/\n\n'use strict';\n/* eslint-disable no-unused-vars */\nvar getOwnPropertySymbols = Object.getOwnPropertySymbols;\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nvar propIsEnumerable = Object.prototype.propertyIsEnumerable;\n\nfunction toObject(val) {\n\tif (val === null || val === undefined) {\n\t\tthrow new TypeError('Object.assign cannot be called with null or undefined');\n\t}\n\n\treturn Object(val);\n}\n\nfunction shouldUseNative() {\n\ttry {\n\t\tif (!Object.assign) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// Detect buggy property enumeration order in older V8 versions.\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=4118\n\t\tvar test1 = new String('abc');  // eslint-disable-line no-new-wrappers\n\t\ttest1[5] = 'de';\n\t\tif (Object.getOwnPropertyNames(test1)[0] === '5') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test2 = {};\n\t\tfor (var i = 0; i < 10; i++) {\n\t\t\ttest2['_' + String.fromCharCode(i)] = i;\n\t\t}\n\t\tvar order2 = Object.getOwnPropertyNames(test2).map(function (n) {\n\t\t\treturn test2[n];\n\t\t});\n\t\tif (order2.join('') !== '0123456789') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test3 = {};\n\t\t'abcdefghijklmnopqrst'.split('').forEach(function (letter) {\n\t\t\ttest3[letter] = letter;\n\t\t});\n\t\tif (Object.keys(Object.assign({}, test3)).join('') !==\n\t\t\t\t'abcdefghijklmnopqrst') {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn true;\n\t} catch (err) {\n\t\t// We don't expect any of the above to throw, but better to be safe.\n\t\treturn false;\n\t}\n}\n\nmodule.exports = shouldUseNative() ? Object.assign : function (target, source) {\n\tvar from;\n\tvar to = toObject(target);\n\tvar symbols;\n\n\tfor (var s = 1; s < arguments.length; s++) {\n\t\tfrom = Object(arguments[s]);\n\n\t\tfor (var key in from) {\n\t\t\tif (hasOwnProperty.call(from, key)) {\n\t\t\t\tto[key] = from[key];\n\t\t\t}\n\t\t}\n\n\t\tif (getOwnPropertySymbols) {\n\t\t\tsymbols = getOwnPropertySymbols(from);\n\t\t\tfor (var i = 0; i < symbols.length; i++) {\n\t\t\t\tif (propIsEnumerable.call(from, symbols[i])) {\n\t\t\t\t\tto[symbols[i]] = from[symbols[i]];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn to;\n};\n","import ltgt from 'ltgt';\nimport events from 'events';\nimport Codec from 'level-codec';\nimport ReadableStreamCore from 'readable-stream';\nimport inherits from 'inherits';\n\nfunction isFunction(f) {\n  return 'function' === typeof f;\n}\n\nfunction getPrefix(db) {\n  if (isFunction(db.prefix)) {\n    return db.prefix();\n  }\n  return db;\n}\n\nfunction clone(_obj) {\n  var obj = {};\n  for (var k in _obj) {\n    obj[k] = _obj[k];\n  }\n  return obj;\n}\n\nfunction nut(db, precodec, codec) {\n  function encodePrefix(prefix, key, opts1, opts2) {\n    return precodec.encode([ prefix, codec.encodeKey(key, opts1, opts2 ) ]);\n  }\n\n  function addEncodings(op, prefix) {\n    if (prefix && prefix.options) {\n      op.keyEncoding =\n        op.keyEncoding || prefix.options.keyEncoding;\n      op.valueEncoding =\n        op.valueEncoding || prefix.options.valueEncoding;\n    }\n    return op;\n  }\n\n  db.open(function () { /* no-op */});\n\n  return {\n    apply: function (ops, opts, cb) {\n      opts = opts || {};\n\n      var batch = [];\n      var i = -1;\n      var len = ops.length;\n\n      while (++i < len) {\n        var op = ops[i];\n        addEncodings(op, op.prefix);\n        op.prefix = getPrefix(op.prefix);\n        batch.push({\n          key: encodePrefix(op.prefix, op.key, opts, op),\n          value: op.type !== 'del' && codec.encodeValue(op.value, opts, op),\n          type: op.type\n        });\n      }\n      db.db.batch(batch, opts, cb);\n    },\n    get: function (key, prefix, opts, cb) {\n      opts.asBuffer = codec.valueAsBuffer(opts);\n      return db.db.get(\n        encodePrefix(prefix, key, opts),\n        opts,\n        function (err, value) {\n          if (err) {\n            cb(err);\n          } else {\n            cb(null, codec.decodeValue(value, opts));\n          }\n        }\n      );\n    },\n    createDecoder: function (opts) {\n      return function (key, value) {\n        return {\n          key: codec.decodeKey(precodec.decode(key)[1], opts),\n          value: codec.decodeValue(value, opts)\n        };\n      };\n    },\n    isClosed: function isClosed() {\n      return db.isClosed();\n    },\n    close: function close(cb) {\n      return db.close(cb);\n    },\n    iterator: function (_opts) {\n      var opts = clone(_opts || {});\n      var prefix = _opts.prefix || [];\n\n      function encodeKey(key) {\n        return encodePrefix(prefix, key, opts, {});\n      }\n\n      ltgt.toLtgt(_opts, opts, encodeKey, precodec.lowerBound, precodec.upperBound);\n\n      // if these legacy values are in the options, remove them\n\n      opts.prefix = null;\n\n      //************************************************\n      //hard coded defaults, for now...\n      //TODO: pull defaults and encoding out of levelup.\n      opts.keyAsBuffer = opts.valueAsBuffer = false;\n      //************************************************\n\n\n      //this is vital, otherwise limit: undefined will\n      //create an empty stream.\n      /* istanbul ignore next */\n      if ('number' !== typeof opts.limit) {\n        opts.limit = -1;\n      }\n\n      opts.keyAsBuffer = precodec.buffer;\n      opts.valueAsBuffer = codec.valueAsBuffer(opts);\n\n      function wrapIterator(iterator) {\n        return {\n          next: function (cb) {\n            return iterator.next(cb);\n          },\n          end: function (cb) {\n            iterator.end(cb);\n          }\n        };\n      }\n\n      return wrapIterator(db.db.iterator(opts));\n    }\n  };\n}\n\nfunction NotFoundError() {\n  Error.call(this);\n}\n\ninherits(NotFoundError, Error);\n\nNotFoundError.prototype.name = 'NotFoundError';\n\nvar EventEmitter = events.EventEmitter;\nvar version = \"6.5.4\";\n\nvar NOT_FOUND_ERROR = new NotFoundError();\n\nvar sublevel = function (nut, prefix, createStream, options) {\n  var emitter = new EventEmitter();\n  emitter.sublevels = {};\n  emitter.options = options;\n\n  emitter.version = version;\n\n  emitter.methods = {};\n  prefix = prefix || [];\n\n  function mergeOpts(opts) {\n    var o = {};\n    var k;\n    if (options) {\n      for (k in options) {\n        if (typeof options[k] !== 'undefined') {\n          o[k] = options[k];\n        }\n      }\n    }\n    if (opts) {\n      for (k in opts) {\n        if (typeof opts[k] !== 'undefined') {\n          o[k] = opts[k];\n        }\n      }\n    }\n    return o;\n  }\n\n  emitter.put = function (key, value, opts, cb) {\n    if ('function' === typeof opts) {\n      cb = opts;\n      opts = {};\n    }\n\n    nut.apply([{\n      key: key, value: value,\n      prefix: prefix.slice(), type: 'put'\n    }], mergeOpts(opts), function (err) {\n      /* istanbul ignore next */\n      if (err) {\n        return cb(err);\n      }\n      emitter.emit('put', key, value);\n      cb(null);\n    });\n  };\n\n  emitter.prefix = function () {\n    return prefix.slice();\n  };\n\n  emitter.batch = function (ops, opts, cb) {\n    if ('function' === typeof opts) {\n      cb = opts;\n      opts = {};\n    }\n\n    ops = ops.map(function (op) {\n      return {\n        key: op.key,\n        value: op.value,\n        prefix: op.prefix || prefix,\n        keyEncoding: op.keyEncoding,    // *\n        valueEncoding: op.valueEncoding,  // * (TODO: encodings on sublevel)\n        type: op.type\n      };\n    });\n\n    nut.apply(ops, mergeOpts(opts), function (err) {\n      /* istanbul ignore next */\n      if (err) {\n        return cb(err);\n      }\n      emitter.emit('batch', ops);\n      cb(null);\n    });\n  };\n\n  emitter.get = function (key, opts, cb) {\n    /* istanbul ignore else */\n    if ('function' === typeof opts) {\n      cb = opts;\n      opts = {};\n    }\n    nut.get(key, prefix, mergeOpts(opts), function (err, value) {\n      if (err) {\n        cb(NOT_FOUND_ERROR);\n      } else {\n        cb(null, value);\n      }\n    });\n  };\n\n  emitter.sublevel = function (name, opts) {\n    return emitter.sublevels[name] =\n      emitter.sublevels[name] || sublevel(nut, prefix.concat(name), createStream, mergeOpts(opts));\n  };\n\n  emitter.readStream = emitter.createReadStream = function (opts) {\n    opts = mergeOpts(opts);\n    opts.prefix = prefix;\n    var stream;\n    var it = nut.iterator(opts);\n\n    stream = createStream(opts, nut.createDecoder(opts));\n    stream.setIterator(it);\n\n    return stream;\n  };\n\n  emitter.close = function (cb) {\n    nut.close(cb);\n  };\n\n  emitter.isOpen = nut.isOpen;\n  emitter.isClosed = nut.isClosed;\n\n  return emitter;\n};\n\n/* Copyright (c) 2012-2014 LevelUP contributors\n * See list at <https://github.com/rvagg/node-levelup#contributing>\n * MIT License <https://github.com/rvagg/node-levelup/blob/master/LICENSE.md>\n */\n\nvar Readable = ReadableStreamCore.Readable;\n\nfunction ReadStream(options, makeData) {\n  if (!(this instanceof ReadStream)) {\n    return new ReadStream(options, makeData);\n  }\n\n  Readable.call(this, { objectMode: true, highWaterMark: options.highWaterMark });\n\n  // purely to keep `db` around until we're done so it's not GCed if the user doesn't keep a ref\n\n  this._waiting = false;\n  this._options = options;\n  this._makeData = makeData;\n}\n\ninherits(ReadStream, Readable);\n\nReadStream.prototype.setIterator = function (it) {\n  this._iterator = it;\n  /* istanbul ignore if */\n  if (this._destroyed) {\n    return it.end(function () {});\n  }\n  /* istanbul ignore if */\n  if (this._waiting) {\n    this._waiting = false;\n    return this._read();\n  }\n  return this;\n};\n\nReadStream.prototype._read = function read() {\n  var self = this;\n  /* istanbul ignore if */\n  if (self._destroyed) {\n    return;\n  }\n  /* istanbul ignore if */\n  if (!self._iterator) {\n    return this._waiting = true;\n  }\n\n  self._iterator.next(function (err, key, value) {\n    if (err || (key === undefined && value === undefined)) {\n      if (!err && !self._destroyed) {\n        self.push(null);\n      }\n      return self._cleanup(err);\n    }\n\n\n    value = self._makeData(key, value);\n    if (!self._destroyed) {\n      self.push(value);\n    }\n  });\n};\n\nReadStream.prototype._cleanup = function (err) {\n  if (this._destroyed) {\n    return;\n  }\n\n  this._destroyed = true;\n\n  var self = this;\n  /* istanbul ignore if */\n  if (err && err.message !== 'iterator has ended') {\n    self.emit('error', err);\n  }\n\n  /* istanbul ignore else */\n  if (self._iterator) {\n    self._iterator.end(function () {\n      self._iterator = null;\n      self.emit('close');\n    });\n  } else {\n    self.emit('close');\n  }\n};\n\nReadStream.prototype.destroy = function () {\n  this._cleanup();\n};\n\nvar precodec = {\n  encode: function (decodedKey) {\n    return '\\xff' + decodedKey[0] + '\\xff' + decodedKey[1];\n  },\n  decode: function (encodedKeyAsBuffer) {\n    var str = encodedKeyAsBuffer.toString();\n    var idx = str.indexOf('\\xff', 1);\n    return [str.substring(1, idx), str.substring(idx + 1)];\n  },\n  lowerBound: '\\x00',\n  upperBound: '\\xff'\n};\n\nvar codec = new Codec();\n\nfunction sublevelPouch(db) {\n  return sublevel(nut(db, precodec, codec), [], ReadStream, db.options);\n}\n\nexport default sublevelPouch;\n","\nexports.compare = function (a, b) {\n\n  if(Buffer.isBuffer(a)) {\n    var l = Math.min(a.length, b.length)\n    for(var i = 0; i < l; i++) {\n      var cmp = a[i] - b[i]\n      if(cmp) return cmp\n    }\n    return a.length - b.length\n  }\n\n  return a < b ? -1 : a > b ? 1 : 0\n}\n\n// to be compatible with the current abstract-leveldown tests\n// nullish or empty strings.\n// I could use !!val but I want to permit numbers and booleans,\n// if possible.\n\nfunction isDef (val) {\n  return val !== undefined && val !== ''\n}\n\nfunction has (range, name) {\n  return Object.hasOwnProperty.call(range, name)\n}\n\nfunction hasKey(range, name) {\n  return Object.hasOwnProperty.call(range, name) && name\n}\n\nvar lowerBoundKey = exports.lowerBoundKey = function (range) {\n    return (\n       hasKey(range, 'gt')\n    || hasKey(range, 'gte')\n    || hasKey(range, 'min')\n    || (range.reverse ? hasKey(range, 'end') : hasKey(range, 'start'))\n    || undefined\n    )\n}\n\nvar lowerBound = exports.lowerBound = function (range, def) {\n  var k = lowerBoundKey(range)\n  return k ? range[k] : def\n}\n\nvar lowerBoundInclusive = exports.lowerBoundInclusive = function (range) {\n  return has(range, 'gt') ? false : true\n}\n\nvar upperBoundInclusive = exports.upperBoundInclusive =\n  function (range) {\n    return (has(range, 'lt') /*&& !range.maxEx*/) ? false : true\n  }\n\nvar lowerBoundExclusive = exports.lowerBoundExclusive =\n  function (range) {\n    return !lowerBoundInclusive(range)\n  }\n\nvar upperBoundExclusive = exports.upperBoundExclusive =\n  function (range) {\n    return !upperBoundInclusive(range)\n  }\n\nvar upperBoundKey = exports.upperBoundKey = function (range) {\n    return (\n       hasKey(range, 'lt')\n    || hasKey(range, 'lte')\n    || hasKey(range, 'max')\n    || (range.reverse ? hasKey(range, 'start') : hasKey(range, 'end'))\n    || undefined\n    )\n}\n\nvar upperBound = exports.upperBound = function (range, def) {\n  var k = upperBoundKey(range)\n  return k ? range[k] : def\n}\n\nexports.start = function (range, def) {\n  return range.reverse ? upperBound(range, def) : lowerBound(range, def)\n}\nexports.end = function (range, def) {\n  return range.reverse ? lowerBound(range, def) : upperBound(range, def)\n}\nexports.startInclusive = function (range) {\n  return (\n    range.reverse\n  ? upperBoundInclusive(range)\n  : lowerBoundInclusive(range)\n  )\n}\nexports.endInclusive = function (range) {\n  return (\n    range.reverse\n  ? lowerBoundInclusive(range)\n  : upperBoundInclusive(range)\n  )\n}\n\nfunction id (e) { return e }\n\nexports.toLtgt = function (range, _range, map, lower, upper) {\n  _range = _range || {}\n  map = map || id\n  var defaults = arguments.length > 3\n  var lb = exports.lowerBoundKey(range)\n  var ub = exports.upperBoundKey(range)\n  if(lb) {\n    if(lb === 'gt') _range.gt = map(range.gt, false)\n    else            _range.gte = map(range[lb], false)\n  }\n  else if(defaults)\n    _range.gte = map(lower, false)\n\n  if(ub) {\n    if(ub === 'lt') _range.lt = map(range.lt, true)\n    else            _range.lte = map(range[ub], true)\n  }\n  else if(defaults)\n    _range.lte = map(upper, true)\n\n  if(range.reverse != null)\n    _range.reverse = !!range.reverse\n\n  //if range was used mutably\n  //(in level-sublevel it's part of an options object\n  //that has more properties on it.)\n  if(has(_range, 'max'))   delete _range.max\n  if(has(_range, 'min'))   delete _range.min\n  if(has(_range, 'start')) delete _range.start\n  if(has(_range, 'end'))   delete _range.end\n\n  return _range\n}\n\nexports.contains = function (range, key, compare) {\n  compare = compare || exports.compare\n\n  var lb = lowerBound(range)\n  if(isDef(lb)) {\n    var cmp = compare(key, lb)\n    if(cmp < 0 || (cmp === 0 && lowerBoundExclusive(range)))\n      return false\n  }\n\n  var ub = upperBound(range)\n  if(isDef(ub)) {\n    var cmp = compare(key, ub)\n    if(cmp > 0 || (cmp === 0) && upperBoundExclusive(range))\n      return false\n  }\n\n  return true\n}\n\nexports.filter = function (range, compare) {\n  return function (key) {\n    return exports.contains(range, key, compare)\n  }\n}\n\n\n","var encodings = require('./lib/encodings')\n\nmodule.exports = Codec\n\nfunction Codec (opts) {\n  if (!(this instanceof Codec)) {\n    return new Codec(opts)\n  }\n  this.opts = opts || {}\n  this.encodings = encodings\n}\n\nCodec.prototype._encoding = function (encoding) {\n  if (typeof encoding === 'string') encoding = encodings[encoding]\n  if (!encoding) encoding = encodings.id\n  return encoding\n}\n\nCodec.prototype._keyEncoding = function (opts, batchOpts) {\n  return this._encoding((batchOpts && batchOpts.keyEncoding) ||\n                        (opts && opts.keyEncoding) ||\n                        this.opts.keyEncoding)\n}\n\nCodec.prototype._valueEncoding = function (opts, batchOpts) {\n  return this._encoding((batchOpts && (batchOpts.valueEncoding || batchOpts.encoding)) ||\n                        (opts && (opts.valueEncoding || opts.encoding)) ||\n                        (this.opts.valueEncoding || this.opts.encoding))\n}\n\nCodec.prototype.encodeKey = function (key, opts, batchOpts) {\n  return this._keyEncoding(opts, batchOpts).encode(key)\n}\n\nCodec.prototype.encodeValue = function (value, opts, batchOpts) {\n  return this._valueEncoding(opts, batchOpts).encode(value)\n}\n\nCodec.prototype.decodeKey = function (key, opts) {\n  return this._keyEncoding(opts).decode(key)\n}\n\nCodec.prototype.decodeValue = function (value, opts) {\n  return this._valueEncoding(opts).decode(value)\n}\n\nCodec.prototype.encodeBatch = function (ops, opts) {\n  var self = this\n\n  return ops.map(function (_op) {\n    var op = {\n      type: _op.type,\n      key: self.encodeKey(_op.key, opts, _op)\n    }\n    if (self.keyAsBuffer(opts, _op)) op.keyEncoding = 'binary'\n    if (_op.prefix) op.prefix = _op.prefix\n    if ('value' in _op) {\n      op.value = self.encodeValue(_op.value, opts, _op)\n      if (self.valueAsBuffer(opts, _op)) op.valueEncoding = 'binary'\n    }\n    return op\n  })\n}\n\nvar ltgtKeys = ['lt', 'gt', 'lte', 'gte', 'start', 'end']\n\nCodec.prototype.encodeLtgt = function (ltgt) {\n  var self = this\n  var ret = {}\n  Object.keys(ltgt).forEach(function (key) {\n    ret[key] = ltgtKeys.indexOf(key) > -1\n      ? self.encodeKey(ltgt[key], ltgt)\n      : ltgt[key]\n  })\n  return ret\n}\n\nCodec.prototype.createStreamDecoder = function (opts) {\n  var self = this\n\n  if (opts.keys && opts.values) {\n    return function (key, value) {\n      return {\n        key: self.decodeKey(key, opts),\n        value: self.decodeValue(value, opts)\n      }\n    }\n  } else if (opts.keys) {\n    return function (key) {\n      return self.decodeKey(key, opts)\n    }\n  } else if (opts.values) {\n    return function (_, value) {\n      return self.decodeValue(value, opts)\n    }\n  } else {\n    return function () {}\n  }\n}\n\nCodec.prototype.keyAsBuffer = function (opts) {\n  return this._keyEncoding(opts).buffer\n}\n\nCodec.prototype.valueAsBuffer = function (opts) {\n  return this._valueEncoding(opts).buffer\n}\n","exports.utf8 = exports['utf-8'] = {\n  encode: function (data) {\n    return isBinary(data) ? data : String(data)\n  },\n  decode: identity,\n  buffer: false,\n  type: 'utf8'\n}\n\nexports.json = {\n  encode: JSON.stringify,\n  decode: JSON.parse,\n  buffer: false,\n  type: 'json'\n}\n\nexports.binary = {\n  encode: function (data) {\n    return isBinary(data) ? data : Buffer.from(data)\n  },\n  decode: identity,\n  buffer: true,\n  type: 'binary'\n}\n\nexports.none = {\n  encode: identity,\n  decode: identity,\n  buffer: false,\n  type: 'id'\n}\n\nexports.id = exports.none\n\nvar bufferEncodings = [\n  'hex',\n  'ascii',\n  'base64',\n  'ucs2',\n  'ucs-2',\n  'utf16le',\n  'utf-16le'\n]\n\nbufferEncodings.forEach(function (type) {\n  exports[type] = {\n    encode: function (data) {\n      return isBinary(data) ? data : Buffer.from(data, type)\n    },\n    decode: function (buffer) {\n      return buffer.toString(type)\n    },\n    buffer: true,\n    type: type\n  }\n})\n\nfunction identity (value) {\n  return value\n}\n\nfunction isBinary (data) {\n  return data === undefined || data === null || Buffer.isBuffer(data)\n}\n","var Stream = require('stream'); // hack to fix a circular dependency issue when used with browserify\nexports = module.exports = require('./lib/_stream_readable.js');\nexports.Stream = Stream;\nexports.Readable = exports;\nexports.Writable = require('./lib/_stream_writable.js');\nexports.Duplex = require('./lib/_stream_duplex.js');\nexports.Transform = require('./lib/_stream_transform.js');\nexports.PassThrough = require('./lib/_stream_passthrough.js');\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nmodule.exports = Stream;\n\nvar EE = require('events').EventEmitter;\nvar inherits = require('inherits');\n\ninherits(Stream, EE);\nStream.Readable = require('readable-stream/readable.js');\nStream.Writable = require('readable-stream/writable.js');\nStream.Duplex = require('readable-stream/duplex.js');\nStream.Transform = require('readable-stream/transform.js');\nStream.PassThrough = require('readable-stream/passthrough.js');\n\n// Backwards-compat with node 0.4.x\nStream.Stream = Stream;\n\n\n\n// old-style streams.  Note that the pipe method (the only relevant\n// part of this class) is overridden in the Readable class.\n\nfunction Stream() {\n  EE.call(this);\n}\n\nStream.prototype.pipe = function(dest, options) {\n  var source = this;\n\n  function ondata(chunk) {\n    if (dest.writable) {\n      if (false === dest.write(chunk) && source.pause) {\n        source.pause();\n      }\n    }\n  }\n\n  source.on('data', ondata);\n\n  function ondrain() {\n    if (source.readable && source.resume) {\n      source.resume();\n    }\n  }\n\n  dest.on('drain', ondrain);\n\n  // If the 'end' option is not supplied, dest.end() will be called when\n  // source gets the 'end' or 'close' events.  Only dest.end() once.\n  if (!dest._isStdio && (!options || options.end !== false)) {\n    source.on('end', onend);\n    source.on('close', onclose);\n  }\n\n  var didOnEnd = false;\n  function onend() {\n    if (didOnEnd) return;\n    didOnEnd = true;\n\n    dest.end();\n  }\n\n\n  function onclose() {\n    if (didOnEnd) return;\n    didOnEnd = true;\n\n    if (typeof dest.destroy === 'function') dest.destroy();\n  }\n\n  // don't leave dangling pipes when there are errors.\n  function onerror(er) {\n    cleanup();\n    if (EE.listenerCount(this, 'error') === 0) {\n      throw er; // Unhandled stream error in pipe.\n    }\n  }\n\n  source.on('error', onerror);\n  dest.on('error', onerror);\n\n  // remove all the event listeners that were added.\n  function cleanup() {\n    source.removeListener('data', ondata);\n    dest.removeListener('drain', ondrain);\n\n    source.removeListener('end', onend);\n    source.removeListener('close', onclose);\n\n    source.removeListener('error', onerror);\n    dest.removeListener('error', onerror);\n\n    source.removeListener('end', cleanup);\n    source.removeListener('close', cleanup);\n\n    dest.removeListener('close', cleanup);\n  }\n\n  source.on('end', cleanup);\n  source.on('close', cleanup);\n\n  dest.on('close', cleanup);\n\n  dest.emit('pipe', source);\n\n  // Allow for unix-like usage: A.pipe(B).pipe(C)\n  return dest;\n};\n","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n","exports = module.exports = require('./lib/_stream_readable.js');\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = require('./lib/_stream_writable.js');\nexports.Duplex = require('./lib/_stream_duplex.js');\nexports.Transform = require('./lib/_stream_transform.js');\nexports.PassThrough = require('./lib/_stream_passthrough.js');\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = require('util');\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = require('./internal/streams/BufferList');\nvar destroyImpl = require('./internal/streams/destroy');\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}","'use strict';\n\nif (typeof process === 'undefined' ||\n    !process.version ||\n    process.version.indexOf('v0.') === 0 ||\n    process.version.indexOf('v1.') === 0 && process.version.indexOf('v1.8.') !== 0) {\n  module.exports = { nextTick: nextTick };\n} else {\n  module.exports = process\n}\n\nfunction nextTick(fn, arg1, arg2, arg3) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('\"callback\" argument must be a function');\n  }\n  var len = arguments.length;\n  var args, i;\n  switch (len) {\n  case 0:\n  case 1:\n    return process.nextTick(fn);\n  case 2:\n    return process.nextTick(function afterTickOne() {\n      fn.call(null, arg1);\n    });\n  case 3:\n    return process.nextTick(function afterTickTwo() {\n      fn.call(null, arg1, arg2);\n    });\n  case 4:\n    return process.nextTick(function afterTickThree() {\n      fn.call(null, arg1, arg2, arg3);\n    });\n  default:\n    args = new Array(len - 1);\n    i = 0;\n    while (i < args.length) {\n      args[i++] = arguments[i];\n    }\n    return process.nextTick(function afterTick() {\n      fn.apply(null, args);\n    });\n  }\n}\n\n","module.exports = require('events').EventEmitter;\n","/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\n\nfunction isArray(arg) {\n  if (Array.isArray) {\n    return Array.isArray(arg);\n  }\n  return objectToString(arg) === '[object Array]';\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = Buffer.isBuffer;\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n","/* (ignored) */","'use strict';\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = require('safe-buffer').Buffer;\nvar util = require('util');\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}","/* (ignored) */","'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};","var scope = (typeof global !== \"undefined\" && global) ||\n            (typeof self !== \"undefined\" && self) ||\n            window;\nvar apply = Function.prototype.apply;\n\n// DOM APIs, for completeness\n\nexports.setTimeout = function() {\n  return new Timeout(apply.call(setTimeout, scope, arguments), clearTimeout);\n};\nexports.setInterval = function() {\n  return new Timeout(apply.call(setInterval, scope, arguments), clearInterval);\n};\nexports.clearTimeout =\nexports.clearInterval = function(timeout) {\n  if (timeout) {\n    timeout.close();\n  }\n};\n\nfunction Timeout(id, clearFn) {\n  this._id = id;\n  this._clearFn = clearFn;\n}\nTimeout.prototype.unref = Timeout.prototype.ref = function() {};\nTimeout.prototype.close = function() {\n  this._clearFn.call(scope, this._id);\n};\n\n// Does not start the time, just sets up the members needed.\nexports.enroll = function(item, msecs) {\n  clearTimeout(item._idleTimeoutId);\n  item._idleTimeout = msecs;\n};\n\nexports.unenroll = function(item) {\n  clearTimeout(item._idleTimeoutId);\n  item._idleTimeout = -1;\n};\n\nexports._unrefActive = exports.active = function(item) {\n  clearTimeout(item._idleTimeoutId);\n\n  var msecs = item._idleTimeout;\n  if (msecs >= 0) {\n    item._idleTimeoutId = setTimeout(function onTimeout() {\n      if (item._onTimeout)\n        item._onTimeout();\n    }, msecs);\n  }\n};\n\n// setimmediate attaches itself to the global object\nrequire(\"setimmediate\");\n// On some exotic environments, it's not clear which object `setimmediate` was\n// able to install onto.  Search each possibility in the same order as the\n// `setimmediate` library.\nexports.setImmediate = (typeof self !== \"undefined\" && self.setImmediate) ||\n                       (typeof global !== \"undefined\" && global.setImmediate) ||\n                       (this && this.setImmediate);\nexports.clearImmediate = (typeof self !== \"undefined\" && self.clearImmediate) ||\n                         (typeof global !== \"undefined\" && global.clearImmediate) ||\n                         (this && this.clearImmediate);\n","(function (global, undefined) {\n    \"use strict\";\n\n    if (global.setImmediate) {\n        return;\n    }\n\n    var nextHandle = 1; // Spec says greater than zero\n    var tasksByHandle = {};\n    var currentlyRunningATask = false;\n    var doc = global.document;\n    var registerImmediate;\n\n    function setImmediate(callback) {\n      // Callback can either be a function or a string\n      if (typeof callback !== \"function\") {\n        callback = new Function(\"\" + callback);\n      }\n      // Copy function arguments\n      var args = new Array(arguments.length - 1);\n      for (var i = 0; i < args.length; i++) {\n          args[i] = arguments[i + 1];\n      }\n      // Store and register the task\n      var task = { callback: callback, args: args };\n      tasksByHandle[nextHandle] = task;\n      registerImmediate(nextHandle);\n      return nextHandle++;\n    }\n\n    function clearImmediate(handle) {\n        delete tasksByHandle[handle];\n    }\n\n    function run(task) {\n        var callback = task.callback;\n        var args = task.args;\n        switch (args.length) {\n        case 0:\n            callback();\n            break;\n        case 1:\n            callback(args[0]);\n            break;\n        case 2:\n            callback(args[0], args[1]);\n            break;\n        case 3:\n            callback(args[0], args[1], args[2]);\n            break;\n        default:\n            callback.apply(undefined, args);\n            break;\n        }\n    }\n\n    function runIfPresent(handle) {\n        // From the spec: \"Wait until any invocations of this algorithm started before this one have completed.\"\n        // So if we're currently running a task, we'll need to delay this invocation.\n        if (currentlyRunningATask) {\n            // Delay by doing a setTimeout. setImmediate was tried instead, but in Firefox 7 it generated a\n            // \"too much recursion\" error.\n            setTimeout(runIfPresent, 0, handle);\n        } else {\n            var task = tasksByHandle[handle];\n            if (task) {\n                currentlyRunningATask = true;\n                try {\n                    run(task);\n                } finally {\n                    clearImmediate(handle);\n                    currentlyRunningATask = false;\n                }\n            }\n        }\n    }\n\n    function installNextTickImplementation() {\n        registerImmediate = function(handle) {\n            process.nextTick(function () { runIfPresent(handle); });\n        };\n    }\n\n    function canUsePostMessage() {\n        // The test against `importScripts` prevents this implementation from being installed inside a web worker,\n        // where `global.postMessage` means something completely different and can't be used for this purpose.\n        if (global.postMessage && !global.importScripts) {\n            var postMessageIsAsynchronous = true;\n            var oldOnMessage = global.onmessage;\n            global.onmessage = function() {\n                postMessageIsAsynchronous = false;\n            };\n            global.postMessage(\"\", \"*\");\n            global.onmessage = oldOnMessage;\n            return postMessageIsAsynchronous;\n        }\n    }\n\n    function installPostMessageImplementation() {\n        // Installs an event handler on `global` for the `message` event: see\n        // * https://developer.mozilla.org/en/DOM/window.postMessage\n        // * http://www.whatwg.org/specs/web-apps/current-work/multipage/comms.html#crossDocumentMessages\n\n        var messagePrefix = \"setImmediate$\" + Math.random() + \"$\";\n        var onGlobalMessage = function(event) {\n            if (event.source === global &&\n                typeof event.data === \"string\" &&\n                event.data.indexOf(messagePrefix) === 0) {\n                runIfPresent(+event.data.slice(messagePrefix.length));\n            }\n        };\n\n        if (global.addEventListener) {\n            global.addEventListener(\"message\", onGlobalMessage, false);\n        } else {\n            global.attachEvent(\"onmessage\", onGlobalMessage);\n        }\n\n        registerImmediate = function(handle) {\n            global.postMessage(messagePrefix + handle, \"*\");\n        };\n    }\n\n    function installMessageChannelImplementation() {\n        var channel = new MessageChannel();\n        channel.port1.onmessage = function(event) {\n            var handle = event.data;\n            runIfPresent(handle);\n        };\n\n        registerImmediate = function(handle) {\n            channel.port2.postMessage(handle);\n        };\n    }\n\n    function installReadyStateChangeImplementation() {\n        var html = doc.documentElement;\n        registerImmediate = function(handle) {\n            // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n            // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n            var script = doc.createElement(\"script\");\n            script.onreadystatechange = function () {\n                runIfPresent(handle);\n                script.onreadystatechange = null;\n                html.removeChild(script);\n                script = null;\n            };\n            html.appendChild(script);\n        };\n    }\n\n    function installSetTimeoutImplementation() {\n        registerImmediate = function(handle) {\n            setTimeout(runIfPresent, 0, handle);\n        };\n    }\n\n    // If supported, we should attach to the prototype of global, since that is where setTimeout et al. live.\n    var attachTo = Object.getPrototypeOf && Object.getPrototypeOf(global);\n    attachTo = attachTo && attachTo.setTimeout ? attachTo : global;\n\n    // Don't get fooled by e.g. browserify environments.\n    if ({}.toString.call(global.process) === \"[object process]\") {\n        // For Node.js before 0.9\n        installNextTickImplementation();\n\n    } else if (canUsePostMessage()) {\n        // For non-IE10 modern browsers\n        installPostMessageImplementation();\n\n    } else if (global.MessageChannel) {\n        // For web workers, where supported\n        installMessageChannelImplementation();\n\n    } else if (doc && \"onreadystatechange\" in doc.createElement(\"script\")) {\n        // For IE 6–8\n        installReadyStateChangeImplementation();\n\n    } else {\n        // For older browsers\n        installSetTimeoutImplementation();\n    }\n\n    attachTo.setImmediate = setImmediate;\n    attachTo.clearImmediate = clearImmediate;\n}(typeof self === \"undefined\" ? typeof global === \"undefined\" ? this : global : self));\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};","module.exports = require('./lib/_stream_writable.js');\n","module.exports = require('./lib/_stream_duplex.js');\n","module.exports = require('./readable').Transform\n","module.exports = require('./readable').PassThrough\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n\n/*<replacement>*/\nvar Buffer = require('buffer').Buffer;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\nvar EE = require('events').EventEmitter;\n\n/*<replacement>*/\nif (!EE.listenerCount) EE.listenerCount = function(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\nvar Stream = require('stream');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nfunction ReadableState(options, stream) {\n  options = options || {};\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  this.highWaterMark = (hwm || hwm === 0) ? hwm : 16 * 1024;\n\n  // cast to ints.\n  this.highWaterMark = ~~this.highWaterMark;\n\n  this.buffer = [];\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = false;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // In streams that never have any data, and do push(null) right away,\n  // the consumer can miss the 'end' event if they do some I/O before\n  // consuming the stream.  So, we don't emit('end') until some reading\n  // happens.\n  this.calledRead = false;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, becuase any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // when piping, we only care about 'readable' events that happen\n  // after read()ing all the bytes and not getting any pushback.\n  this.ranOut = false;\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder)\n      StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  if (!(this instanceof Readable))\n    return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  Stream.call(this);\n}\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function(chunk, encoding) {\n  var state = this._readableState;\n\n  if (typeof chunk === 'string' && !state.objectMode) {\n    encoding = encoding || state.defaultEncoding;\n    if (encoding !== state.encoding) {\n      chunk = new Buffer(chunk, encoding);\n      encoding = '';\n    }\n  }\n\n  return readableAddChunk(this, state, chunk, encoding, false);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function(chunk) {\n  var state = this._readableState;\n  return readableAddChunk(this, state, chunk, '', true);\n};\n\nfunction readableAddChunk(stream, state, chunk, encoding, addToFront) {\n  var er = chunkInvalid(state, chunk);\n  if (er) {\n    stream.emit('error', er);\n  } else if (chunk === null || chunk === undefined) {\n    state.reading = false;\n    if (!state.ended)\n      onEofChunk(stream, state);\n  } else if (state.objectMode || chunk && chunk.length > 0) {\n    if (state.ended && !addToFront) {\n      var e = new Error('stream.push() after EOF');\n      stream.emit('error', e);\n    } else if (state.endEmitted && addToFront) {\n      var e = new Error('stream.unshift() after end event');\n      stream.emit('error', e);\n    } else {\n      if (state.decoder && !addToFront && !encoding)\n        chunk = state.decoder.write(chunk);\n\n      // update the buffer info.\n      state.length += state.objectMode ? 1 : chunk.length;\n      if (addToFront) {\n        state.buffer.unshift(chunk);\n      } else {\n        state.reading = false;\n        state.buffer.push(chunk);\n      }\n\n      if (state.needReadable)\n        emitReadable(stream);\n\n      maybeReadMore(stream, state);\n    }\n  } else if (!addToFront) {\n    state.reading = false;\n  }\n\n  return needMoreData(state);\n}\n\n\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended &&\n         (state.needReadable ||\n          state.length < state.highWaterMark ||\n          state.length === 0);\n}\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function(enc) {\n  if (!StringDecoder)\n    StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n};\n\n// Don't raise the hwm > 128MB\nvar MAX_HWM = 0x800000;\nfunction roundUpToNextPowerOf2(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2\n    n--;\n    for (var p = 1; p < 32; p <<= 1) n |= n >> p;\n    n++;\n  }\n  return n;\n}\n\nfunction howMuchToRead(n, state) {\n  if (state.length === 0 && state.ended)\n    return 0;\n\n  if (state.objectMode)\n    return n === 0 ? 0 : 1;\n\n  if (n === null || isNaN(n)) {\n    // only flow one buffer at a time\n    if (state.flowing && state.buffer.length)\n      return state.buffer[0].length;\n    else\n      return state.length;\n  }\n\n  if (n <= 0)\n    return 0;\n\n  // If we're asking for more than the target buffer level,\n  // then raise the water mark.  Bump up to the next highest\n  // power of 2, to prevent increasing it excessively in tiny\n  // amounts.\n  if (n > state.highWaterMark)\n    state.highWaterMark = roundUpToNextPowerOf2(n);\n\n  // don't have that much.  return null, unless we've ended.\n  if (n > state.length) {\n    if (!state.ended) {\n      state.needReadable = true;\n      return 0;\n    } else\n      return state.length;\n  }\n\n  return n;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function(n) {\n  var state = this._readableState;\n  state.calledRead = true;\n  var nOrig = n;\n  var ret;\n\n  if (typeof n !== 'number' || n > 0)\n    state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 &&\n      state.needReadable &&\n      (state.length >= state.highWaterMark || state.ended)) {\n    emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    ret = null;\n\n    // In cases where the decoder did not receive enough data\n    // to produce a full chunk, then immediately received an\n    // EOF, state.buffer will contain [<Buffer >, <Buffer 00 ...>].\n    // howMuchToRead will see this and coerce the amount to\n    // read to zero (because it's looking at the length of the\n    // first <Buffer > in state.buffer), and we'll end up here.\n    //\n    // This can only happen via state.decoder -- no other venue\n    // exists for pushing a zero-length chunk into state.buffer\n    // and triggering this behavior. In this case, we return our\n    // remaining data and end the stream, if appropriate.\n    if (state.length > 0 && state.decoder) {\n      ret = fromList(n, state);\n      state.length -= ret.length;\n    }\n\n    if (state.length === 0)\n      endReadable(this);\n\n    return ret;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length - n <= state.highWaterMark)\n    doRead = true;\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading)\n    doRead = false;\n\n  if (doRead) {\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0)\n      state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n  }\n\n  // If _read called its callback synchronously, then `reading`\n  // will be false, and we need to re-evaluate how much data we\n  // can return to the user.\n  if (doRead && !state.reading)\n    n = howMuchToRead(nOrig, state);\n\n  if (n > 0)\n    ret = fromList(n, state);\n  else\n    ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  }\n\n  state.length -= n;\n\n  // If we have nothing in the buffer, then we want to know\n  // as soon as we *do* get something into the buffer.\n  if (state.length === 0 && !state.ended)\n    state.needReadable = true;\n\n  // If we happened to read() exactly the remaining amount in the\n  // buffer, and the EOF has been seen at this point, then make sure\n  // that we emit 'end' on the very next tick.\n  if (state.ended && !state.endEmitted && state.length === 0)\n    endReadable(this);\n\n  return ret;\n};\n\nfunction chunkInvalid(state, chunk) {\n  var er = null;\n  if (!Buffer.isBuffer(chunk) &&\n      'string' !== typeof chunk &&\n      chunk !== null &&\n      chunk !== undefined &&\n      !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n\nfunction onEofChunk(stream, state) {\n  if (state.decoder && !state.ended) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // if we've ended and we have some data left, then emit\n  // 'readable' now to make sure it gets picked up.\n  if (state.length > 0)\n    emitReadable(stream);\n  else\n    endReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (state.emittedReadable)\n    return;\n\n  state.emittedReadable = true;\n  if (state.sync)\n    process.nextTick(function() {\n      emitReadable_(stream);\n    });\n  else\n    emitReadable_(stream);\n}\n\nfunction emitReadable_(stream) {\n  stream.emit('readable');\n}\n\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(function() {\n      maybeReadMore_(stream, state);\n    });\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended &&\n         state.length < state.highWaterMark) {\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;\n    else\n      len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function(n) {\n  this.emit('error', new Error('not implemented'));\n};\n\nReadable.prototype.pipe = function(dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) &&\n              dest !== process.stdout &&\n              dest !== process.stderr;\n\n  var endFn = doEnd ? onend : cleanup;\n  if (state.endEmitted)\n    process.nextTick(endFn);\n  else\n    src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable) {\n    if (readable !== src) return;\n    cleanup();\n  }\n\n  function onend() {\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  function cleanup() {\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', cleanup);\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (!dest._writableState || dest._writableState.needDrain)\n      ondrain();\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EE.listenerCount(dest, 'error') === 0)\n      dest.emit('error', er);\n  }\n  // This is a brutally ugly hack to make sure that our error handler\n  // is attached before any userland ones.  NEVER DO THIS.\n  if (!dest._events || !dest._events.error)\n    dest.on('error', onerror);\n  else if (isArray(dest._events.error))\n    dest._events.error.unshift(onerror);\n  else\n    dest._events.error = [onerror, dest._events.error];\n\n\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    // the handler that waits for readable events after all\n    // the data gets sucked out in flow.\n    // This would be easier to follow with a .once() handler\n    // in flow(), but that is too slow.\n    this.on('readable', pipeOnReadable);\n\n    state.flowing = true;\n    process.nextTick(function() {\n      flow(src);\n    });\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function() {\n    var dest = this;\n    var state = src._readableState;\n    state.awaitDrain--;\n    if (state.awaitDrain === 0)\n      flow(src);\n  };\n}\n\nfunction flow(src) {\n  var state = src._readableState;\n  var chunk;\n  state.awaitDrain = 0;\n\n  function write(dest, i, list) {\n    var written = dest.write(chunk);\n    if (false === written) {\n      state.awaitDrain++;\n    }\n  }\n\n  while (state.pipesCount && null !== (chunk = src.read())) {\n\n    if (state.pipesCount === 1)\n      write(state.pipes, 0, null);\n    else\n      forEach(state.pipes, write);\n\n    src.emit('data', chunk);\n\n    // if anyone needs a drain, then we have to wait for that.\n    if (state.awaitDrain > 0)\n      return;\n  }\n\n  // if every destination was unpiped, either before entering this\n  // function, or in the while loop, then stop flowing.\n  //\n  // NB: This is a pretty rare edge case.\n  if (state.pipesCount === 0) {\n    state.flowing = false;\n\n    // if there were data event listeners added, then switch to old mode.\n    if (EE.listenerCount(src, 'data') > 0)\n      emitDataEvents(src);\n    return;\n  }\n\n  // at this point, no one needed a drain, so we just ran out of data\n  // on the next readable event, start it over again.\n  state.ranOut = true;\n}\n\nfunction pipeOnReadable() {\n  if (this._readableState.ranOut) {\n    this._readableState.ranOut = false;\n    flow(this);\n  }\n}\n\n\nReadable.prototype.unpipe = function(dest) {\n  var state = this._readableState;\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0)\n    return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes)\n      return this;\n\n    if (!dest)\n      dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    this.removeListener('readable', pipeOnReadable);\n    state.flowing = false;\n    if (dest)\n      dest.emit('unpipe', this);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    this.removeListener('readable', pipeOnReadable);\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++)\n      dests[i].emit('unpipe', this);\n    return this;\n  }\n\n  // try to find the right one.\n  var i = indexOf(state.pipes, dest);\n  if (i === -1)\n    return this;\n\n  state.pipes.splice(i, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1)\n    state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function(ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data' && !this._readableState.flowing)\n    emitDataEvents(this);\n\n  if (ev === 'readable' && this.readable) {\n    var state = this._readableState;\n    if (!state.readableListening) {\n      state.readableListening = true;\n      state.emittedReadable = false;\n      state.needReadable = true;\n      if (!state.reading) {\n        this.read(0);\n      } else if (state.length) {\n        emitReadable(this, state);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function() {\n  emitDataEvents(this);\n  this.read(0);\n  this.emit('resume');\n};\n\nReadable.prototype.pause = function() {\n  emitDataEvents(this, true);\n  this.emit('pause');\n};\n\nfunction emitDataEvents(stream, startPaused) {\n  var state = stream._readableState;\n\n  if (state.flowing) {\n    // https://github.com/isaacs/readable-stream/issues/16\n    throw new Error('Cannot switch to old mode now.');\n  }\n\n  var paused = startPaused || false;\n  var readable = false;\n\n  // convert to an old-style stream.\n  stream.readable = true;\n  stream.pipe = Stream.prototype.pipe;\n  stream.on = stream.addListener = Stream.prototype.on;\n\n  stream.on('readable', function() {\n    readable = true;\n\n    var c;\n    while (!paused && (null !== (c = stream.read())))\n      stream.emit('data', c);\n\n    if (c === null) {\n      readable = false;\n      stream._readableState.needReadable = true;\n    }\n  });\n\n  stream.pause = function() {\n    paused = true;\n    this.emit('pause');\n  };\n\n  stream.resume = function() {\n    paused = false;\n    if (readable)\n      process.nextTick(function() {\n        stream.emit('readable');\n      });\n    else\n      this.read(0);\n    this.emit('resume');\n  };\n\n  // now make it start, just in case it hadn't already.\n  stream.emit('readable');\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function(stream) {\n  var state = this._readableState;\n  var paused = false;\n\n  var self = this;\n  stream.on('end', function() {\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length)\n        self.push(chunk);\n    }\n\n    self.push(null);\n  });\n\n  stream.on('data', function(chunk) {\n    if (state.decoder)\n      chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    //if (state.objectMode && util.isNullOrUndefined(chunk))\n    if (state.objectMode && (chunk === null || chunk === undefined))\n      return;\n    else if (!state.objectMode && (!chunk || !chunk.length))\n      return;\n\n    var ret = self.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (typeof stream[i] === 'function' &&\n        typeof this[i] === 'undefined') {\n      this[i] = function(method) { return function() {\n        return stream[method].apply(stream, arguments);\n      }}(i);\n    }\n  }\n\n  // proxy certain important events.\n  var events = ['error', 'close', 'destroy', 'pause', 'resume'];\n  forEach(events, function(ev) {\n    stream.on(ev, self.emit.bind(self, ev));\n  });\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  self._read = function(n) {\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return self;\n};\n\n\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\nfunction fromList(n, state) {\n  var list = state.buffer;\n  var length = state.length;\n  var stringMode = !!state.decoder;\n  var objectMode = !!state.objectMode;\n  var ret;\n\n  // nothing in the list, definitely empty.\n  if (list.length === 0)\n    return null;\n\n  if (length === 0)\n    ret = null;\n  else if (objectMode)\n    ret = list.shift();\n  else if (!n || n >= length) {\n    // read it all, truncate the array.\n    if (stringMode)\n      ret = list.join('');\n    else\n      ret = Buffer.concat(list, length);\n    list.length = 0;\n  } else {\n    // read just some of it.\n    if (n < list[0].length) {\n      // just take a part of the first list item.\n      // slice is the same for buffers and strings.\n      var buf = list[0];\n      ret = buf.slice(0, n);\n      list[0] = buf.slice(n);\n    } else if (n === list[0].length) {\n      // first list is a perfect match\n      ret = list.shift();\n    } else {\n      // complex case.\n      // we have enough to cover it, but it spans past the first buffer.\n      if (stringMode)\n        ret = '';\n      else\n        ret = new Buffer(n);\n\n      var c = 0;\n      for (var i = 0, l = list.length; i < l && c < n; i++) {\n        var buf = list[0];\n        var cpy = Math.min(n - c, buf.length);\n\n        if (stringMode)\n          ret += buf.slice(0, cpy);\n        else\n          buf.copy(ret, c, 0, cpy);\n\n        if (cpy < buf.length)\n          list[0] = buf.slice(cpy);\n        else\n          list.shift();\n\n        c += cpy;\n      }\n    }\n  }\n\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0)\n    throw new Error('endReadable called on non-empty stream');\n\n  if (!state.endEmitted && state.calledRead) {\n    state.ended = true;\n    process.nextTick(function() {\n      // Check that we didn't get one last unshift.\n      if (!state.endEmitted && state.length === 0) {\n        state.endEmitted = true;\n        stream.readable = false;\n        stream.emit('end');\n      }\n    });\n  }\n}\n\nfunction forEach (xs, f) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    f(xs[i], i);\n  }\n}\n\nfunction indexOf (xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}\n","module.exports = Array.isArray || function (arr) {\n  return Object.prototype.toString.call(arr) == '[object Array]';\n};\n","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, cb), and it'll handle all\n// the drain event emission and buffering.\n\nmodule.exports = Writable;\n\n/*<replacement>*/\nvar Buffer = require('buffer').Buffer;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Stream = require('stream');\n\nutil.inherits(Writable, Stream);\n\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n}\n\nfunction WritableState(options, stream) {\n  options = options || {};\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  this.highWaterMark = (hwm || hwm === 0) ? hwm : 16 * 1024;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  // cast to ints.\n  this.highWaterMark = ~~this.highWaterMark;\n\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, becuase any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function(er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.buffer = [];\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n}\n\nfunction Writable(options) {\n  var Duplex = require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, though they're not\n  // instanceof Writable, they're instanceof Readable.\n  if (!(this instanceof Writable) && !(this instanceof Duplex))\n    return new Writable(options);\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function() {\n  this.emit('error', new Error('Cannot pipe. Not readable.'));\n};\n\n\nfunction writeAfterEnd(stream, state, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  process.nextTick(function() {\n    cb(er);\n  });\n}\n\n// If we get something that is not a buffer, string, null, or undefined,\n// and we're not in objectMode, then that's an error.\n// Otherwise stream chunks are all considered to be of length=1, and the\n// watermarks determine how many objects to keep in the buffer, rather than\n// how many bytes or characters.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  if (!Buffer.isBuffer(chunk) &&\n      'string' !== typeof chunk &&\n      chunk !== null &&\n      chunk !== undefined &&\n      !state.objectMode) {\n    var er = new TypeError('Invalid non-string/buffer chunk');\n    stream.emit('error', er);\n    process.nextTick(function() {\n      cb(er);\n    });\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function(chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (Buffer.isBuffer(chunk))\n    encoding = 'buffer';\n  else if (!encoding)\n    encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function')\n    cb = function() {};\n\n  if (state.ended)\n    writeAfterEnd(this, state, cb);\n  else if (validChunk(this, state, chunk, cb))\n    ret = writeOrBuffer(this, state, chunk, encoding, cb);\n\n  return ret;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode &&\n      state.decodeStrings !== false &&\n      typeof chunk === 'string') {\n    chunk = new Buffer(chunk, encoding);\n  }\n  return chunk;\n}\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, chunk, encoding, cb) {\n  chunk = decodeChunk(state, chunk, encoding);\n  if (Buffer.isBuffer(chunk))\n    encoding = 'buffer';\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret)\n    state.needDrain = true;\n\n  if (state.writing)\n    state.buffer.push(new WriteReq(chunk, encoding, cb));\n  else\n    doWrite(stream, state, len, chunk, encoding, cb);\n\n  return ret;\n}\n\nfunction doWrite(stream, state, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  if (sync)\n    process.nextTick(function() {\n      cb(er);\n    });\n  else\n    cb(er);\n\n  stream._writableState.errorEmitted = true;\n  stream.emit('error', er);\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er)\n    onwriteError(stream, state, sync, er, cb);\n  else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(stream, state);\n\n    if (!finished && !state.bufferProcessing && state.buffer.length)\n      clearBuffer(stream, state);\n\n    if (sync) {\n      process.nextTick(function() {\n        afterWrite(stream, state, finished, cb);\n      });\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished)\n    onwriteDrain(stream, state);\n  cb();\n  if (finished)\n    finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n\n  for (var c = 0; c < state.buffer.length; c++) {\n    var entry = state.buffer[c];\n    var chunk = entry.chunk;\n    var encoding = entry.encoding;\n    var cb = entry.callback;\n    var len = state.objectMode ? 1 : chunk.length;\n\n    doWrite(stream, state, len, chunk, encoding, cb);\n\n    // if we didn't call the onwrite immediately, then\n    // it means that we need to wait until it does.\n    // also, that means that the chunk and cb are currently\n    // being processed, so move the buffer counter past them.\n    if (state.writing) {\n      c++;\n      break;\n    }\n  }\n\n  state.bufferProcessing = false;\n  if (c < state.buffer.length)\n    state.buffer = state.buffer.slice(c);\n  else\n    state.buffer.length = 0;\n}\n\nWritable.prototype._write = function(chunk, encoding, cb) {\n  cb(new Error('not implemented'));\n};\n\nWritable.prototype.end = function(chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (typeof chunk !== 'undefined' && chunk !== null)\n    this.write(chunk, encoding);\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished)\n    endWritable(this, state, cb);\n};\n\n\nfunction needFinish(stream, state) {\n  return (state.ending &&\n          state.length === 0 &&\n          !state.finished &&\n          !state.writing);\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(stream, state);\n  if (need) {\n    state.finished = true;\n    stream.emit('finish');\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished)\n      process.nextTick(cb);\n    else\n      stream.once('finish', cb);\n  }\n  state.ended = true;\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) keys.push(key);\n  return keys;\n}\n/*</replacement>*/\n\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\nforEach(objectKeys(Writable.prototype), function(method) {\n  if (!Duplex.prototype[method])\n    Duplex.prototype[method] = Writable.prototype[method];\n});\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex))\n    return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false)\n    this.readable = false;\n\n  if (options && options.writable === false)\n    this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false)\n    this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended)\n    return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  process.nextTick(this.end.bind(this));\n}\n\nfunction forEach (xs, f) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    f(xs[i], i);\n  }\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\n\nfunction TransformState(options, stream) {\n  this.afterTransform = function(er, data) {\n    return afterTransform(stream, er, data);\n  };\n\n  this.needTransform = false;\n  this.transforming = false;\n  this.writecb = null;\n  this.writechunk = null;\n}\n\nfunction afterTransform(stream, er, data) {\n  var ts = stream._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb)\n    return stream.emit('error', new Error('no writecb in Transform class'));\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data !== null && data !== undefined)\n    stream.push(data);\n\n  if (cb)\n    cb(er);\n\n  var rs = stream._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    stream._read(rs.highWaterMark);\n  }\n}\n\n\nfunction Transform(options) {\n  if (!(this instanceof Transform))\n    return new Transform(options);\n\n  Duplex.call(this, options);\n\n  var ts = this._transformState = new TransformState(options, this);\n\n  // when the writable side finishes, then flush out anything remaining.\n  var stream = this;\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  this.once('finish', function() {\n    if ('function' === typeof this._flush)\n      this._flush(function(er) {\n        done(stream, er);\n      });\n    else\n      done(stream);\n  });\n}\n\nTransform.prototype.push = function(chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function(chunk, encoding, cb) {\n  throw new Error('not implemented');\n};\n\nTransform.prototype._write = function(chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform ||\n        rs.needReadable ||\n        rs.length < rs.highWaterMark)\n      this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function(n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\n\nfunction done(stream, er) {\n  if (er)\n    return stream.emit('error', er);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  var ws = stream._writableState;\n  var rs = stream._readableState;\n  var ts = stream._transformState;\n\n  if (ws.length)\n    throw new Error('calling transform done when ws.length != 0');\n\n  if (ts.transforming)\n    throw new Error('calling transform done when still transforming');\n\n  return stream.push(null);\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough))\n    return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function(chunk, encoding, cb) {\n  cb(null, chunk);\n};\n","var Transform = require('readable-stream').Transform\n  , inherits  = require('util').inherits\n\nfunction DestroyableTransform(opts) {\n  Transform.call(this, opts)\n  this._destroyed = false\n}\n\ninherits(DestroyableTransform, Transform)\n\nDestroyableTransform.prototype.destroy = function(err) {\n  if (this._destroyed) return\n  this._destroyed = true\n  \n  var self = this\n  process.nextTick(function() {\n    if (err)\n      self.emit('error', err)\n    self.emit('close')\n  })\n}\n\n// a noop _transform function\nfunction noop (chunk, enc, callback) {\n  callback(null, chunk)\n}\n\n\n// create a new export function, used by both the main export and\n// the .ctor export, contains common logic for dealing with arguments\nfunction through2 (construct) {\n  return function (options, transform, flush) {\n    if (typeof options == 'function') {\n      flush     = transform\n      transform = options\n      options   = {}\n    }\n\n    if (typeof transform != 'function')\n      transform = noop\n\n    if (typeof flush != 'function')\n      flush = null\n\n    return construct(options, transform, flush)\n  }\n}\n\n\n// main export, just make me a transform stream!\nmodule.exports = through2(function (options, transform, flush) {\n  var t2 = new DestroyableTransform(options)\n\n  t2._transform = transform\n\n  if (flush)\n    t2._flush = flush\n\n  return t2\n})\n\n\n// make me a reusable prototype that I can `new`, or implicitly `new`\n// with a constructor call\nmodule.exports.ctor = through2(function (options, transform, flush) {\n  function Through2 (override) {\n    if (!(this instanceof Through2))\n      return new Through2(override)\n\n    this.options = Object.assign({}, options, override)\n\n    DestroyableTransform.call(this, this.options)\n  }\n\n  inherits(Through2, DestroyableTransform)\n\n  Through2.prototype._transform = transform\n\n  if (flush)\n    Through2.prototype._flush = flush\n\n  return Through2\n})\n\n\nmodule.exports.obj = through2(function (options, transform, flush) {\n  var t2 = new DestroyableTransform(Object.assign({ objectMode: true, highWaterMark: 16 }, options))\n\n  t2._transform = transform\n\n  if (flush)\n    t2._flush = flush\n\n  return t2\n})\n","/**\n * Copyright (c) 2013 Petka Antonov\n * \n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:</p>\n * \n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n * \n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n * THE SOFTWARE.\n */\n\"use strict\";\nfunction Deque(capacity) {\n    this._capacity = getCapacity(capacity);\n    this._length = 0;\n    this._front = 0;\n    if (isArray(capacity)) {\n        var len = capacity.length;\n        for (var i = 0; i < len; ++i) {\n            this[i] = capacity[i];\n        }\n        this._length = len;\n    }\n}\n\nDeque.prototype.toArray = function Deque$toArray() {\n    var len = this._length;\n    var ret = new Array(len);\n    var front = this._front;\n    var capacity = this._capacity;\n    for (var j = 0; j < len; ++j) {\n        ret[j] = this[(front + j) & (capacity - 1)];\n    }\n    return ret;\n};\n\nDeque.prototype.push = function Deque$push(item) {\n    var argsLength = arguments.length;\n    var length = this._length;\n    if (argsLength > 1) {\n        var capacity = this._capacity;\n        if (length + argsLength > capacity) {\n            for (var i = 0; i < argsLength; ++i) {\n                this._checkCapacity(length + 1);\n                var j = (this._front + length) & (this._capacity - 1);\n                this[j] = arguments[i];\n                length++;\n                this._length = length;\n            }\n            return length;\n        }\n        else {\n            var j = this._front;\n            for (var i = 0; i < argsLength; ++i) {\n                this[(j + length) & (capacity - 1)] = arguments[i];\n                j++;\n            }\n            this._length = length + argsLength;\n            return length + argsLength;\n        }\n\n    }\n\n    if (argsLength === 0) return length;\n\n    this._checkCapacity(length + 1);\n    var i = (this._front + length) & (this._capacity - 1);\n    this[i] = item;\n    this._length = length + 1;\n    return length + 1;\n};\n\nDeque.prototype.pop = function Deque$pop() {\n    var length = this._length;\n    if (length === 0) {\n        return void 0;\n    }\n    var i = (this._front + length - 1) & (this._capacity - 1);\n    var ret = this[i];\n    this[i] = void 0;\n    this._length = length - 1;\n    return ret;\n};\n\nDeque.prototype.shift = function Deque$shift() {\n    var length = this._length;\n    if (length === 0) {\n        return void 0;\n    }\n    var front = this._front;\n    var ret = this[front];\n    this[front] = void 0;\n    this._front = (front + 1) & (this._capacity - 1);\n    this._length = length - 1;\n    return ret;\n};\n\nDeque.prototype.unshift = function Deque$unshift(item) {\n    var length = this._length;\n    var argsLength = arguments.length;\n\n\n    if (argsLength > 1) {\n        var capacity = this._capacity;\n        if (length + argsLength > capacity) {\n            for (var i = argsLength - 1; i >= 0; i--) {\n                this._checkCapacity(length + 1);\n                var capacity = this._capacity;\n                var j = (((( this._front - 1 ) &\n                    ( capacity - 1) ) ^ capacity ) - capacity );\n                this[j] = arguments[i];\n                length++;\n                this._length = length;\n                this._front = j;\n            }\n            return length;\n        }\n        else {\n            var front = this._front;\n            for (var i = argsLength - 1; i >= 0; i--) {\n                var j = (((( front - 1 ) &\n                    ( capacity - 1) ) ^ capacity ) - capacity );\n                this[j] = arguments[i];\n                front = j;\n            }\n            this._front = front;\n            this._length = length + argsLength;\n            return length + argsLength;\n        }\n    }\n\n    if (argsLength === 0) return length;\n\n    this._checkCapacity(length + 1);\n    var capacity = this._capacity;\n    var i = (((( this._front - 1 ) &\n        ( capacity - 1) ) ^ capacity ) - capacity );\n    this[i] = item;\n    this._length = length + 1;\n    this._front = i;\n    return length + 1;\n};\n\nDeque.prototype.peekBack = function Deque$peekBack() {\n    var length = this._length;\n    if (length === 0) {\n        return void 0;\n    }\n    var index = (this._front + length - 1) & (this._capacity - 1);\n    return this[index];\n};\n\nDeque.prototype.peekFront = function Deque$peekFront() {\n    if (this._length === 0) {\n        return void 0;\n    }\n    return this[this._front];\n};\n\nDeque.prototype.get = function Deque$get(index) {\n    var i = index;\n    if ((i !== (i | 0))) {\n        return void 0;\n    }\n    var len = this._length;\n    if (i < 0) {\n        i = i + len;\n    }\n    if (i < 0 || i >= len) {\n        return void 0;\n    }\n    return this[(this._front + i) & (this._capacity - 1)];\n};\n\nDeque.prototype.isEmpty = function Deque$isEmpty() {\n    return this._length === 0;\n};\n\nDeque.prototype.clear = function Deque$clear() {\n    var len = this._length;\n    var front = this._front;\n    var capacity = this._capacity;\n    for (var j = 0; j < len; ++j) {\n        this[(front + j) & (capacity - 1)] = void 0;\n    }\n    this._length = 0;\n    this._front = 0;\n};\n\nDeque.prototype.toString = function Deque$toString() {\n    return this.toArray().toString();\n};\n\nDeque.prototype.valueOf = Deque.prototype.toString;\nDeque.prototype.removeFront = Deque.prototype.shift;\nDeque.prototype.removeBack = Deque.prototype.pop;\nDeque.prototype.insertFront = Deque.prototype.unshift;\nDeque.prototype.insertBack = Deque.prototype.push;\nDeque.prototype.enqueue = Deque.prototype.push;\nDeque.prototype.dequeue = Deque.prototype.shift;\nDeque.prototype.toJSON = Deque.prototype.toArray;\n\nObject.defineProperty(Deque.prototype, \"length\", {\n    get: function() {\n        return this._length;\n    },\n    set: function() {\n        throw new RangeError(\"\");\n    }\n});\n\nDeque.prototype._checkCapacity = function Deque$_checkCapacity(size) {\n    if (this._capacity < size) {\n        this._resizeTo(getCapacity(this._capacity * 1.5 + 16));\n    }\n};\n\nDeque.prototype._resizeTo = function Deque$_resizeTo(capacity) {\n    var oldCapacity = this._capacity;\n    this._capacity = capacity;\n    var front = this._front;\n    var length = this._length;\n    if (front + length > oldCapacity) {\n        var moveItemsCount = (front + length) & (oldCapacity - 1);\n        arrayMove(this, 0, this, oldCapacity, moveItemsCount);\n    }\n};\n\n\nvar isArray = Array.isArray;\n\nfunction arrayMove(src, srcIndex, dst, dstIndex, len) {\n    for (var j = 0; j < len; ++j) {\n        dst[j + dstIndex] = src[j + srcIndex];\n        src[j + srcIndex] = void 0;\n    }\n}\n\nfunction pow2AtLeast(n) {\n    n = n >>> 0;\n    n = n - 1;\n    n = n | (n >> 1);\n    n = n | (n >> 2);\n    n = n | (n >> 4);\n    n = n | (n >> 8);\n    n = n | (n >> 16);\n    return n + 1;\n}\n\nfunction getCapacity(capacity) {\n    if (typeof capacity !== \"number\") {\n        if (isArray(capacity)) {\n            capacity = capacity.length;\n        }\n        else {\n            return 16;\n        }\n    }\n    return pow2AtLeast(\n        Math.min(\n            Math.max(16, capacity), 1073741824)\n    );\n}\n\nmodule.exports = Deque;\n","var toString = Object.prototype.toString\n\nvar isModern = (\n  typeof Buffer.alloc === 'function' &&\n  typeof Buffer.allocUnsafe === 'function' &&\n  typeof Buffer.from === 'function'\n)\n\nfunction isArrayBuffer (input) {\n  return toString.call(input).slice(8, -1) === 'ArrayBuffer'\n}\n\nfunction fromArrayBuffer (obj, byteOffset, length) {\n  byteOffset >>>= 0\n\n  var maxLength = obj.byteLength - byteOffset\n\n  if (maxLength < 0) {\n    throw new RangeError(\"'offset' is out of bounds\")\n  }\n\n  if (length === undefined) {\n    length = maxLength\n  } else {\n    length >>>= 0\n\n    if (length > maxLength) {\n      throw new RangeError(\"'length' is out of bounds\")\n    }\n  }\n\n  return isModern\n    ? Buffer.from(obj.slice(byteOffset, byteOffset + length))\n    : new Buffer(new Uint8Array(obj.slice(byteOffset, byteOffset + length)))\n}\n\nfunction fromString (string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  return isModern\n    ? Buffer.from(string, encoding)\n    : new Buffer(string, encoding)\n}\n\nfunction bufferFrom (value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (isArrayBuffer(value)) {\n    return fromArrayBuffer(value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(value, encodingOrOffset)\n  }\n\n  return isModern\n    ? Buffer.from(value)\n    : new Buffer(value)\n}\n\nmodule.exports = bufferFrom\n","import { assign, uuid, rev, invalidIdError, normalizeDdocFunctionName, parseDdocFunctionName } from 'pouchdb-utils';\nexport { invalidIdError, normalizeDdocFunctionName, parseDdocFunctionName } from 'pouchdb-utils';\nimport { atob, btoa, binaryStringToBlobOrBuffer, blobOrBufferToBinaryString, blobOrBufferToBase64 } from 'pouchdb-binary-utils';\nimport { binaryMd5 } from 'pouchdb-md5';\nimport { Map } from 'pouchdb-collections';\nimport { DOC_VALIDATION, INVALID_REV, createError, BAD_ARG, REV_CONFLICT, MISSING_DOC } from 'pouchdb-errors';\nimport { isDeleted, merge, winningRev, revExists, isLocalId } from 'pouchdb-merge';\nexport { isDeleted, isLocalId } from 'pouchdb-merge';\n\nfunction allDocsKeysQuery(api, opts) {\n  var keys = opts.keys;\n  var finalResults = {\n    offset: opts.skip\n  };\n  return Promise.all(keys.map(function (key) {\n    var subOpts = assign({key: key, deleted: 'ok'}, opts);\n    ['limit', 'skip', 'keys'].forEach(function (optKey) {\n      delete subOpts[optKey];\n    });\n    return new Promise(function (resolve, reject) {\n      api._allDocs(subOpts, function (err, res) {\n        /* istanbul ignore if */\n        if (err) {\n          return reject(err);\n        }\n        /* istanbul ignore if */\n        if (opts.update_seq && res.update_seq !== undefined) {\n          finalResults.update_seq = res.update_seq;\n        }\n        finalResults.total_rows = res.total_rows;\n        resolve(res.rows[0] || {key: key, error: 'not_found'});\n      });\n    });\n  })).then(function (results) {\n    finalResults.rows = results;\n    return finalResults;\n  });\n}\n\nfunction toObject(array) {\n  return array.reduce(function (obj, item) {\n    obj[item] = true;\n    return obj;\n  }, {});\n}\n// List of top level reserved words for doc\nvar reservedWords = toObject([\n  '_id',\n  '_rev',\n  '_attachments',\n  '_deleted',\n  '_revisions',\n  '_revs_info',\n  '_conflicts',\n  '_deleted_conflicts',\n  '_local_seq',\n  '_rev_tree',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats',\n  // Specific to Couchbase Sync Gateway\n  '_removed'\n]);\n\n// List of reserved words that should end up the document\nvar dataWords = toObject([\n  '_attachments',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats'\n]);\n\nfunction parseRevisionInfo(rev$$1) {\n  if (!/^\\d+-./.test(rev$$1)) {\n    return createError(INVALID_REV);\n  }\n  var idx = rev$$1.indexOf('-');\n  var left = rev$$1.substring(0, idx);\n  var right = rev$$1.substring(idx + 1);\n  return {\n    prefix: parseInt(left, 10),\n    id: right\n  };\n}\n\nfunction makeRevTreeFromRevisions(revisions, opts) {\n  var pos = revisions.start - revisions.ids.length + 1;\n\n  var revisionIds = revisions.ids;\n  var ids = [revisionIds[0], opts, []];\n\n  for (var i = 1, len = revisionIds.length; i < len; i++) {\n    ids = [revisionIds[i], {status: 'missing'}, [ids]];\n  }\n\n  return [{\n    pos: pos,\n    ids: ids\n  }];\n}\n\n// Preprocess documents, parse their revisions, assign an id and a\n// revision for new writes that are missing them, etc\nfunction parseDoc(doc, newEdits, dbOpts) {\n  if (!dbOpts) {\n    dbOpts = {\n      deterministic_revs: true\n    };\n  }\n\n  var nRevNum;\n  var newRevId;\n  var revInfo;\n  var opts = {status: 'available'};\n  if (doc._deleted) {\n    opts.deleted = true;\n  }\n\n  if (newEdits) {\n    if (!doc._id) {\n      doc._id = uuid();\n    }\n    newRevId = rev(doc, dbOpts.deterministic_revs);\n    if (doc._rev) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      doc._rev_tree = [{\n        pos: revInfo.prefix,\n        ids: [revInfo.id, {status: 'missing'}, [[newRevId, opts, []]]]\n      }];\n      nRevNum = revInfo.prefix + 1;\n    } else {\n      doc._rev_tree = [{\n        pos: 1,\n        ids : [newRevId, opts, []]\n      }];\n      nRevNum = 1;\n    }\n  } else {\n    if (doc._revisions) {\n      doc._rev_tree = makeRevTreeFromRevisions(doc._revisions, opts);\n      nRevNum = doc._revisions.start;\n      newRevId = doc._revisions.ids[0];\n    }\n    if (!doc._rev_tree) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      nRevNum = revInfo.prefix;\n      newRevId = revInfo.id;\n      doc._rev_tree = [{\n        pos: nRevNum,\n        ids: [newRevId, opts, []]\n      }];\n    }\n  }\n\n  invalidIdError(doc._id);\n\n  doc._rev = nRevNum + '-' + newRevId;\n\n  var result = {metadata : {}, data : {}};\n  for (var key in doc) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(doc, key)) {\n      var specialKey = key[0] === '_';\n      if (specialKey && !reservedWords[key]) {\n        var error = createError(DOC_VALIDATION, key);\n        error.message = DOC_VALIDATION.message + ': ' + key;\n        throw error;\n      } else if (specialKey && !dataWords[key]) {\n        result.metadata[key.slice(1)] = doc[key];\n      } else {\n        result.data[key] = doc[key];\n      }\n    }\n  }\n  return result;\n}\n\nfunction parseBase64(data) {\n  try {\n    return atob(data);\n  } catch (e) {\n    var err = createError(BAD_ARG,\n      'Attachment is not a valid base64 string');\n    return {error: err};\n  }\n}\n\nfunction preprocessString(att, blobType, callback) {\n  var asBinary = parseBase64(att.data);\n  if (asBinary.error) {\n    return callback(asBinary.error);\n  }\n\n  att.length = asBinary.length;\n  if (blobType === 'blob') {\n    att.data = binaryStringToBlobOrBuffer(asBinary, att.content_type);\n  } else if (blobType === 'base64') {\n    att.data = btoa(asBinary);\n  } else { // binary\n    att.data = asBinary;\n  }\n  binaryMd5(asBinary, function (result) {\n    att.digest = 'md5-' + result;\n    callback();\n  });\n}\n\nfunction preprocessBlob(att, blobType, callback) {\n  binaryMd5(att.data, function (md5) {\n    att.digest = 'md5-' + md5;\n    // size is for blobs (browser), length is for buffers (node)\n    att.length = att.data.size || att.data.length || 0;\n    if (blobType === 'binary') {\n      blobOrBufferToBinaryString(att.data, function (binString) {\n        att.data = binString;\n        callback();\n      });\n    } else if (blobType === 'base64') {\n      blobOrBufferToBase64(att.data, function (b64) {\n        att.data = b64;\n        callback();\n      });\n    } else {\n      callback();\n    }\n  });\n}\n\nfunction preprocessAttachment(att, blobType, callback) {\n  if (att.stub) {\n    return callback();\n  }\n  if (typeof att.data === 'string') { // input is a base64 string\n    preprocessString(att, blobType, callback);\n  } else { // input is a blob\n    preprocessBlob(att, blobType, callback);\n  }\n}\n\nfunction preprocessAttachments(docInfos, blobType, callback) {\n\n  if (!docInfos.length) {\n    return callback();\n  }\n\n  var docv = 0;\n  var overallErr;\n\n  docInfos.forEach(function (docInfo) {\n    var attachments = docInfo.data && docInfo.data._attachments ?\n      Object.keys(docInfo.data._attachments) : [];\n    var recv = 0;\n\n    if (!attachments.length) {\n      return done();\n    }\n\n    function processedAttachment(err) {\n      overallErr = err;\n      recv++;\n      if (recv === attachments.length) {\n        done();\n      }\n    }\n\n    for (var key in docInfo.data._attachments) {\n      if (docInfo.data._attachments.hasOwnProperty(key)) {\n        preprocessAttachment(docInfo.data._attachments[key],\n          blobType, processedAttachment);\n      }\n    }\n  });\n\n  function done() {\n    docv++;\n    if (docInfos.length === docv) {\n      if (overallErr) {\n        callback(overallErr);\n      } else {\n        callback();\n      }\n    }\n  }\n}\n\nfunction updateDoc(revLimit, prev, docInfo, results,\n                   i, cb, writeDoc, newEdits) {\n\n  if (revExists(prev.rev_tree, docInfo.metadata.rev) && !newEdits) {\n    results[i] = docInfo;\n    return cb();\n  }\n\n  // sometimes this is pre-calculated. historically not always\n  var previousWinningRev = prev.winningRev || winningRev(prev);\n  var previouslyDeleted = 'deleted' in prev ? prev.deleted :\n    isDeleted(prev, previousWinningRev);\n  var deleted = 'deleted' in docInfo.metadata ? docInfo.metadata.deleted :\n    isDeleted(docInfo.metadata);\n  var isRoot = /^1-/.test(docInfo.metadata.rev);\n\n  if (previouslyDeleted && !deleted && newEdits && isRoot) {\n    var newDoc = docInfo.data;\n    newDoc._rev = previousWinningRev;\n    newDoc._id = docInfo.metadata.id;\n    docInfo = parseDoc(newDoc, newEdits);\n  }\n\n  var merged = merge(prev.rev_tree, docInfo.metadata.rev_tree[0], revLimit);\n\n  var inConflict = newEdits && ((\n    (previouslyDeleted && deleted && merged.conflicts !== 'new_leaf') ||\n    (!previouslyDeleted && merged.conflicts !== 'new_leaf') ||\n    (previouslyDeleted && !deleted && merged.conflicts === 'new_branch')));\n\n  if (inConflict) {\n    var err = createError(REV_CONFLICT);\n    results[i] = err;\n    return cb();\n  }\n\n  var newRev = docInfo.metadata.rev;\n  docInfo.metadata.rev_tree = merged.tree;\n  docInfo.stemmedRevs = merged.stemmedRevs || [];\n  /* istanbul ignore else */\n  if (prev.rev_map) {\n    docInfo.metadata.rev_map = prev.rev_map; // used only by leveldb\n  }\n\n  // recalculate\n  var winningRev$$1 = winningRev(docInfo.metadata);\n  var winningRevIsDeleted = isDeleted(docInfo.metadata, winningRev$$1);\n\n  // calculate the total number of documents that were added/removed,\n  // from the perspective of total_rows/doc_count\n  var delta = (previouslyDeleted === winningRevIsDeleted) ? 0 :\n    previouslyDeleted < winningRevIsDeleted ? -1 : 1;\n\n  var newRevIsDeleted;\n  if (newRev === winningRev$$1) {\n    // if the new rev is the same as the winning rev, we can reuse that value\n    newRevIsDeleted = winningRevIsDeleted;\n  } else {\n    // if they're not the same, then we need to recalculate\n    newRevIsDeleted = isDeleted(docInfo.metadata, newRev);\n  }\n\n  writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n    true, delta, i, cb);\n}\n\nfunction rootIsMissing(docInfo) {\n  return docInfo.metadata.rev_tree[0].ids[1].status === 'missing';\n}\n\nfunction processDocs(revLimit, docInfos, api, fetchedDocs, tx, results,\n                     writeDoc, opts, overallCallback) {\n\n  // Default to 1000 locally\n  revLimit = revLimit || 1000;\n\n  function insertDoc(docInfo, resultsIdx, callback) {\n    // Cant insert new deleted documents\n    var winningRev$$1 = winningRev(docInfo.metadata);\n    var deleted = isDeleted(docInfo.metadata, winningRev$$1);\n    if ('was_delete' in opts && deleted) {\n      results[resultsIdx] = createError(MISSING_DOC, 'deleted');\n      return callback();\n    }\n\n    // 4712 - detect whether a new document was inserted with a _rev\n    var inConflict = newEdits && rootIsMissing(docInfo);\n\n    if (inConflict) {\n      var err = createError(REV_CONFLICT);\n      results[resultsIdx] = err;\n      return callback();\n    }\n\n    var delta = deleted ? 0 : 1;\n\n    writeDoc(docInfo, winningRev$$1, deleted, deleted, false,\n      delta, resultsIdx, callback);\n  }\n\n  var newEdits = opts.new_edits;\n  var idsToDocs = new Map();\n\n  var docsDone = 0;\n  var docsToDo = docInfos.length;\n\n  function checkAllDocsDone() {\n    if (++docsDone === docsToDo && overallCallback) {\n      overallCallback();\n    }\n  }\n\n  docInfos.forEach(function (currentDoc, resultsIdx) {\n\n    if (currentDoc._id && isLocalId(currentDoc._id)) {\n      var fun = currentDoc._deleted ? '_removeLocal' : '_putLocal';\n      api[fun](currentDoc, {ctx: tx}, function (err, res) {\n        results[resultsIdx] = err || res;\n        checkAllDocsDone();\n      });\n      return;\n    }\n\n    var id = currentDoc.metadata.id;\n    if (idsToDocs.has(id)) {\n      docsToDo--; // duplicate\n      idsToDocs.get(id).push([currentDoc, resultsIdx]);\n    } else {\n      idsToDocs.set(id, [[currentDoc, resultsIdx]]);\n    }\n  });\n\n  // in the case of new_edits, the user can provide multiple docs\n  // with the same id. these need to be processed sequentially\n  idsToDocs.forEach(function (docs, id) {\n    var numDone = 0;\n\n    function docWritten() {\n      if (++numDone < docs.length) {\n        nextDoc();\n      } else {\n        checkAllDocsDone();\n      }\n    }\n    function nextDoc() {\n      var value = docs[numDone];\n      var currentDoc = value[0];\n      var resultsIdx = value[1];\n\n      if (fetchedDocs.has(id)) {\n        updateDoc(revLimit, fetchedDocs.get(id), currentDoc, results,\n          resultsIdx, docWritten, writeDoc, newEdits);\n      } else {\n        // Ensure stemming applies to new writes as well\n        var merged = merge([], currentDoc.metadata.rev_tree[0], revLimit);\n        currentDoc.metadata.rev_tree = merged.tree;\n        currentDoc.stemmedRevs = merged.stemmedRevs || [];\n        insertDoc(currentDoc, resultsIdx, docWritten);\n      }\n    }\n    nextDoc();\n  });\n}\n\nexport { allDocsKeysQuery, parseDoc, preprocessAttachments, processDocs, updateDoc };\n","// We fetch all leafs of the revision tree, and sort them based on tree length\n// and whether they were deleted, undeleted documents with the longest revision\n// tree (most edits) win\n// The final sort algorithm is slightly documented in a sidebar here:\n// http://guide.couchdb.org/draft/conflicts.html\nfunction winningRev(metadata) {\n  var winningId;\n  var winningPos;\n  var winningDeleted;\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var tree = node.ids;\n    var branches = tree[2];\n    var pos = node.pos;\n    if (branches.length) { // non-leaf\n      for (var i = 0, len = branches.length; i < len; i++) {\n        toVisit.push({pos: pos + 1, ids: branches[i]});\n      }\n      continue;\n    }\n    var deleted = !!tree[1].deleted;\n    var id = tree[0];\n    // sort by deleted, then pos, then id\n    if (!winningId || (winningDeleted !== deleted ? winningDeleted :\n        winningPos !== pos ? winningPos < pos : winningId < id)) {\n      winningId = id;\n      winningPos = pos;\n      winningDeleted = deleted;\n    }\n  }\n\n  return winningPos + '-' + winningId;\n}\n\n// Pretty much all below can be combined into a higher order function to\n// traverse revisions\n// The return value from the callback will be passed as context to all\n// children of that node\nfunction traverseRevTree(revs, callback) {\n  var toVisit = revs.slice();\n\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var branches = tree[2];\n    var newCtx =\n      callback(branches.length === 0, pos, tree[0], node.ctx, tree[1]);\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], ctx: newCtx});\n    }\n  }\n}\n\nfunction sortByPos(a, b) {\n  return a.pos - b.pos;\n}\n\nfunction collectLeaves(revs) {\n  var leaves = [];\n  traverseRevTree(revs, function (isLeaf, pos, id, acc, opts) {\n    if (isLeaf) {\n      leaves.push({rev: pos + \"-\" + id, pos: pos, opts: opts});\n    }\n  });\n  leaves.sort(sortByPos).reverse();\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    delete leaves[i].pos;\n  }\n  return leaves;\n}\n\n// returns revs of all conflicts that is leaves such that\n// 1. are not deleted and\n// 2. are different than winning revision\nfunction collectConflicts(metadata) {\n  var win = winningRev(metadata);\n  var leaves = collectLeaves(metadata.rev_tree);\n  var conflicts = [];\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    var leaf = leaves[i];\n    if (leaf.rev !== win && !leaf.opts.deleted) {\n      conflicts.push(leaf.rev);\n    }\n  }\n  return conflicts;\n}\n\n// compact a tree by marking its non-leafs as missing,\n// and return a list of revs to delete\nfunction compactTree(metadata) {\n  var revs = [];\n  traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                               revHash, ctx, opts) {\n    if (opts.status === 'available' && !isLeaf) {\n      revs.push(pos + '-' + revHash);\n      opts.status = 'missing';\n    }\n  });\n  return revs;\n}\n\n// build up a list of all the paths to the leafs in this revision tree\nfunction rootToLeaf(revs) {\n  var paths = [];\n  var toVisit = revs.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, opts: opts});\n    if (isLeaf) {\n      paths.push({pos: (pos + 1 - history.length), ids: history});\n    }\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], history: history});\n    }\n  }\n  return paths.reverse();\n}\n\n// for a better overview of what this is doing, read:\n\nfunction sortByPos$1(a, b) {\n  return a.pos - b.pos;\n}\n\n// classic binary search\nfunction binarySearch(arr, item, comparator) {\n  var low = 0;\n  var high = arr.length;\n  var mid;\n  while (low < high) {\n    mid = (low + high) >>> 1;\n    if (comparator(arr[mid], item) < 0) {\n      low = mid + 1;\n    } else {\n      high = mid;\n    }\n  }\n  return low;\n}\n\n// assuming the arr is sorted, insert the item in the proper place\nfunction insertSorted(arr, item, comparator) {\n  var idx = binarySearch(arr, item, comparator);\n  arr.splice(idx, 0, item);\n}\n\n// Turn a path as a flat array into a tree with a single branch.\n// If any should be stemmed from the beginning of the array, that's passed\n// in as the second argument\nfunction pathToTree(path, numStemmed) {\n  var root;\n  var leaf;\n  for (var i = numStemmed, len = path.length; i < len; i++) {\n    var node = path[i];\n    var currentLeaf = [node.id, node.opts, []];\n    if (leaf) {\n      leaf[2].push(currentLeaf);\n      leaf = currentLeaf;\n    } else {\n      root = leaf = currentLeaf;\n    }\n  }\n  return root;\n}\n\n// compare the IDs of two trees\nfunction compareTree(a, b) {\n  return a[0] < b[0] ? -1 : 1;\n}\n\n// Merge two trees together\n// The roots of tree1 and tree2 must be the same revision\nfunction mergeTree(in_tree1, in_tree2) {\n  var queue = [{tree1: in_tree1, tree2: in_tree2}];\n  var conflicts = false;\n  while (queue.length > 0) {\n    var item = queue.pop();\n    var tree1 = item.tree1;\n    var tree2 = item.tree2;\n\n    if (tree1[1].status || tree2[1].status) {\n      tree1[1].status =\n        (tree1[1].status ===  'available' ||\n        tree2[1].status === 'available') ? 'available' : 'missing';\n    }\n\n    for (var i = 0; i < tree2[2].length; i++) {\n      if (!tree1[2][0]) {\n        conflicts = 'new_leaf';\n        tree1[2][0] = tree2[2][i];\n        continue;\n      }\n\n      var merged = false;\n      for (var j = 0; j < tree1[2].length; j++) {\n        if (tree1[2][j][0] === tree2[2][i][0]) {\n          queue.push({tree1: tree1[2][j], tree2: tree2[2][i]});\n          merged = true;\n        }\n      }\n      if (!merged) {\n        conflicts = 'new_branch';\n        insertSorted(tree1[2], tree2[2][i], compareTree);\n      }\n    }\n  }\n  return {conflicts: conflicts, tree: in_tree1};\n}\n\nfunction doMerge(tree, path, dontExpand) {\n  var restree = [];\n  var conflicts = false;\n  var merged = false;\n  var res;\n\n  if (!tree.length) {\n    return {tree: [path], conflicts: 'new_leaf'};\n  }\n\n  for (var i = 0, len = tree.length; i < len; i++) {\n    var branch = tree[i];\n    if (branch.pos === path.pos && branch.ids[0] === path.ids[0]) {\n      // Paths start at the same position and have the same root, so they need\n      // merged\n      res = mergeTree(branch.ids, path.ids);\n      restree.push({pos: branch.pos, ids: res.tree});\n      conflicts = conflicts || res.conflicts;\n      merged = true;\n    } else if (dontExpand !== true) {\n      // The paths start at a different position, take the earliest path and\n      // traverse up until it as at the same point from root as the path we\n      // want to merge.  If the keys match we return the longer path with the\n      // other merged After stemming we dont want to expand the trees\n\n      var t1 = branch.pos < path.pos ? branch : path;\n      var t2 = branch.pos < path.pos ? path : branch;\n      var diff = t2.pos - t1.pos;\n\n      var candidateParents = [];\n\n      var trees = [];\n      trees.push({ids: t1.ids, diff: diff, parent: null, parentIdx: null});\n      while (trees.length > 0) {\n        var item = trees.pop();\n        if (item.diff === 0) {\n          if (item.ids[0] === t2.ids[0]) {\n            candidateParents.push(item);\n          }\n          continue;\n        }\n        var elements = item.ids[2];\n        for (var j = 0, elementsLen = elements.length; j < elementsLen; j++) {\n          trees.push({\n            ids: elements[j],\n            diff: item.diff - 1,\n            parent: item.ids,\n            parentIdx: j\n          });\n        }\n      }\n\n      var el = candidateParents[0];\n\n      if (!el) {\n        restree.push(branch);\n      } else {\n        res = mergeTree(el.ids, t2.ids);\n        el.parent[2][el.parentIdx] = res.tree;\n        restree.push({pos: t1.pos, ids: t1.ids});\n        conflicts = conflicts || res.conflicts;\n        merged = true;\n      }\n    } else {\n      restree.push(branch);\n    }\n  }\n\n  // We didnt find\n  if (!merged) {\n    restree.push(path);\n  }\n\n  restree.sort(sortByPos$1);\n\n  return {\n    tree: restree,\n    conflicts: conflicts || 'internal_node'\n  };\n}\n\n// To ensure we dont grow the revision tree infinitely, we stem old revisions\nfunction stem(tree, depth) {\n  // First we break out the tree into a complete list of root to leaf paths\n  var paths = rootToLeaf(tree);\n  var stemmedRevs;\n\n  var result;\n  for (var i = 0, len = paths.length; i < len; i++) {\n    // Then for each path, we cut off the start of the path based on the\n    // `depth` to stem to, and generate a new set of flat trees\n    var path = paths[i];\n    var stemmed = path.ids;\n    var node;\n    if (stemmed.length > depth) {\n      // only do the stemming work if we actually need to stem\n      if (!stemmedRevs) {\n        stemmedRevs = {}; // avoid allocating this object unnecessarily\n      }\n      var numStemmed = stemmed.length - depth;\n      node = {\n        pos: path.pos + numStemmed,\n        ids: pathToTree(stemmed, numStemmed)\n      };\n\n      for (var s = 0; s < numStemmed; s++) {\n        var rev = (path.pos + s) + '-' + stemmed[s].id;\n        stemmedRevs[rev] = true;\n      }\n    } else { // no need to actually stem\n      node = {\n        pos: path.pos,\n        ids: pathToTree(stemmed, 0)\n      };\n    }\n\n    // Then we remerge all those flat trees together, ensuring that we dont\n    // connect trees that would go beyond the depth limit\n    if (result) {\n      result = doMerge(result, node, true).tree;\n    } else {\n      result = [node];\n    }\n  }\n\n  // this is memory-heavy per Chrome profiler, avoid unless we actually stemmed\n  if (stemmedRevs) {\n    traverseRevTree(result, function (isLeaf, pos, revHash) {\n      // some revisions may have been removed in a branch but not in another\n      delete stemmedRevs[pos + '-' + revHash];\n    });\n  }\n\n  return {\n    tree: result,\n    revs: stemmedRevs ? Object.keys(stemmedRevs) : []\n  };\n}\n\nfunction merge(tree, path, depth) {\n  var newTree = doMerge(tree, path);\n  var stemmed = stem(newTree.tree, depth);\n  return {\n    tree: stemmed.tree,\n    stemmedRevs: stemmed.revs,\n    conflicts: newTree.conflicts\n  };\n}\n\n// return true if a rev exists in the rev tree, false otherwise\nfunction revExists(revs, rev) {\n  var toVisit = revs.slice();\n  var splitRev = rev.split('-');\n  var targetPos = parseInt(splitRev[0], 10);\n  var targetId = splitRev[1];\n\n  var node;\n  while ((node = toVisit.pop())) {\n    if (node.pos === targetPos && node.ids[0] === targetId) {\n      return true;\n    }\n    var branches = node.ids[2];\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: node.pos + 1, ids: branches[i]});\n    }\n  }\n  return false;\n}\n\nfunction getTrees(node) {\n  return node.ids;\n}\n\n// check if a specific revision of a doc has been deleted\n//  - metadata: the metadata object from the doc store\n//  - rev: (optional) the revision to check. defaults to winning revision\nfunction isDeleted(metadata, rev) {\n  if (!rev) {\n    rev = winningRev(metadata);\n  }\n  var id = rev.substring(rev.indexOf('-') + 1);\n  var toVisit = metadata.rev_tree.map(getTrees);\n\n  var tree;\n  while ((tree = toVisit.pop())) {\n    if (tree[0] === id) {\n      return !!tree[1].deleted;\n    }\n    toVisit = toVisit.concat(tree[2]);\n  }\n}\n\nfunction isLocalId(id) {\n  return (/^_local/).test(id);\n}\n\n// returns the current leaf node for a given revision\nfunction latest(rev, metadata) {\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, pos: pos, opts: opts});\n\n    if (isLeaf) {\n      for (var i = 0, len = history.length; i < len; i++) {\n        var historyNode = history[i];\n        var historyRev = historyNode.pos + '-' + historyNode.id;\n\n        if (historyRev === rev) {\n          // return the rev of this leaf\n          return pos + '-' + id;\n        }\n      }\n    }\n\n    for (var j = 0, l = branches.length; j < l; j++) {\n      toVisit.push({pos: pos + 1, ids: branches[j], history: history});\n    }\n  }\n\n  /* istanbul ignore next */\n  throw new Error('Unable to resolve latest revision for id ' + metadata.id + ', rev ' + rev);\n}\n\nexport { collectConflicts, collectLeaves, compactTree, isDeleted, isLocalId, merge, revExists, rootToLeaf, traverseRevTree, winningRev, latest };\n","import vuvuzela from 'vuvuzela';\n\nfunction safeJsonParse(str) {\n  // This try/catch guards against stack overflow errors.\n  // JSON.parse() is faster than vuvuzela.parse() but vuvuzela\n  // cannot overflow.\n  try {\n    return JSON.parse(str);\n  } catch (e) {\n    /* istanbul ignore next */\n    return vuvuzela.parse(str);\n  }\n}\n\nfunction safeJsonStringify(json) {\n  try {\n    return JSON.stringify(json);\n  } catch (e) {\n    /* istanbul ignore next */\n    return vuvuzela.stringify(json);\n  }\n}\n\nexport { safeJsonParse, safeJsonStringify };\n","var inherits          = require('inherits')\n  , AbstractLevelDOWN = require('abstract-leveldown').AbstractLevelDOWN\n  , AbstractIterator  = require('abstract-leveldown').AbstractIterator\n  , ltgt              = require('ltgt')\n  , createRBT = require('functional-red-black-tree')\n  , globalStore       = {}\n\n// In Node, use global.setImmediate. In the browser, use a consistent\n// microtask library to give consistent microtask experience to all browsers\nvar setImmediate = require('./immediate')\n\nfunction gt(value) {\n  return ltgt.compare(value, this._end) > 0\n}\n\nfunction gte(value) {\n  return ltgt.compare(value, this._end) >= 0\n}\n\nfunction lt(value) {\n  return ltgt.compare(value, this._end) < 0\n}\n\nfunction lte(value) {\n  return ltgt.compare(value, this._end) <= 0\n}\n\n\nfunction MemIterator (db, options) {\n  AbstractIterator.call(this, db)\n  this._limit   = options.limit\n\n  if (this._limit === -1)\n    this._limit = Infinity\n\n  var tree = db._store[db._location]\n\n  this.keyAsBuffer = options.keyAsBuffer !== false\n  this.valueAsBuffer = options.valueAsBuffer !== false\n  this._reverse   = options.reverse\n  this._options = options\n  this._done = 0\n\n  if (!this._reverse) {\n    this._incr = 'next'\n    this._start = ltgt.lowerBound(options)\n    this._end = ltgt.upperBound(options)\n\n    if (typeof this._start === 'undefined')\n      this._tree = tree.begin\n    else if (ltgt.lowerBoundInclusive(options))\n      this._tree = tree.ge(this._start)\n    else\n      this._tree = tree.gt(this._start)\n\n    if (this._end) {\n      if (ltgt.upperBoundInclusive(options))\n        this._test = lte\n      else\n        this._test = lt\n    }\n\n  } else {\n    this._incr = 'prev'\n    this._start = ltgt.upperBound(options)\n    this._end = ltgt.lowerBound(options)\n\n    if (typeof this._start === 'undefined')\n      this._tree = tree.end\n    else if (ltgt.upperBoundInclusive(options))\n      this._tree = tree.le(this._start)\n    else\n      this._tree = tree.lt(this._start)\n\n    if (this._end) {\n      if (ltgt.lowerBoundInclusive(options))\n        this._test = gte\n      else\n        this._test = gt\n    }\n\n  }\n\n}\n\ninherits(MemIterator, AbstractIterator)\n\nMemIterator.prototype._next = function (callback) {\n  var key\n    , value\n\n  if (this._done++ >= this._limit)\n    return setImmediate(callback)\n\n  if (!this._tree.valid)\n    return setImmediate(callback)\n\n  key = this._tree.key\n  value = this._tree.value\n\n  if (!this._test(key))\n    return setImmediate(callback)\n\n  if (this.keyAsBuffer)\n    key = new Buffer(key)\n\n  if (this.valueAsBuffer)\n    value = new Buffer(value)\n\n  this._tree[this._incr]()\n\n  setImmediate(function callNext() {\n    callback(null, key, value)\n  })\n}\n\nMemIterator.prototype._test = function () {return true}\n\nfunction MemDOWN (location) {\n  if (!(this instanceof MemDOWN))\n    return new MemDOWN(location)\n\n  AbstractLevelDOWN.call(this, typeof location == 'string' ? location : '')\n\n  this._location = this.location ? ('$' + this.location) : '_tree'\n  this._store = this.location ? globalStore: this\n  this._store[this._location] = this._store[this._location] || createRBT(ltgt.compare)\n}\n\nMemDOWN.clearGlobalStore = function (strict) {\n  if (strict) {\n    Object.keys(globalStore).forEach(function (key) {\n      delete globalStore[key]\n    })\n  } else {\n    globalStore = {}\n  }\n}\n\ninherits(MemDOWN, AbstractLevelDOWN)\n\nMemDOWN.prototype._open = function (options, callback) {\n  var self = this\n  setImmediate(function callNext() { callback(null, self) })\n}\n\nMemDOWN.prototype._put = function (key, value, options, callback) {\n  if (typeof value === 'undefined' || value === null) value = ''\n\n  var iter = this._store[this._location].find(key)\n\n  if (iter.valid) {\n    this._store[this._location] = iter.update(value)\n  } else {\n    this._store[this._location] = this._store[this._location].insert(key, value)\n  }\n\n  setImmediate(callback)\n}\n\nMemDOWN.prototype._get = function (key, options, callback) {\n  var value = this._store[this._location].get(key)\n\n  if (typeof value === 'undefined') {\n    // 'NotFound' error, consistent with LevelDOWN API\n    return setImmediate(function callNext() { callback(new Error('NotFound')) })\n  }\n\n  if (options.asBuffer !== false && !this._isBuffer(value))\n    value = new Buffer(String(value))\n\n  setImmediate(function callNext () {\n    callback(null, value)\n  })\n\n}\n\nMemDOWN.prototype._del = function (key, options, callback) {\n  this._store[this._location] = this._store[this._location].remove(key)\n  setImmediate(callback)\n}\n\nMemDOWN.prototype._batch = function (array, options, callback) {\n  var i = -1\n    , key\n    , value\n    , iter\n    , len = array.length\n    , tree = this._store[this._location]\n\n  while (++i < len) {\n    if (!array[i])\n      continue\n\n    key = this._isBuffer(array[i].key) ? array[i].key : String(array[i].key)\n    iter = tree.find(key)\n\n    if (array[i].type === 'put') {\n      value = this._isBuffer(array[i].value) ? array[i].value : String(array[i].value)\n      tree = iter.valid ? iter.update(value) : tree.insert(key, value)\n    } else {\n      tree = iter.remove()\n    }\n  }\n\n  this._store[this._location] = tree\n\n  setImmediate(callback)\n}\n\nMemDOWN.prototype._iterator = function (options) {\n  return new MemIterator(this, options)\n}\n\nMemDOWN.prototype._isBuffer = function (obj) {\n  return Buffer.isBuffer(obj)\n}\n\nMemDOWN.destroy = function (name, callback) {\n  var key = '$' + name\n\n  if (key in globalStore)\n    delete globalStore[key]\n\n  setImmediate(callback)\n}\n\nmodule.exports = MemDOWN\n","exports.AbstractLevelDOWN    = require('./abstract-leveldown')\nexports.AbstractIterator     = require('./abstract-iterator')\nexports.AbstractChainedBatch = require('./abstract-chained-batch')\nexports.isLevelDOWN          = require('./is-leveldown')\n","/* Copyright (c) 2013 Rod Vagg, MIT License */\n\nvar xtend                = require('xtend')\n  , AbstractIterator     = require('./abstract-iterator')\n  , AbstractChainedBatch = require('./abstract-chained-batch')\n\nfunction AbstractLevelDOWN (location) {\n  if (!arguments.length || location === undefined)\n    throw new Error('constructor requires at least a location argument')\n\n  if (typeof location != 'string')\n    throw new Error('constructor requires a location string argument')\n\n  this.location = location\n  this.status = 'new'\n}\n\nAbstractLevelDOWN.prototype.open = function (options, callback) {\n  var self      = this\n    , oldStatus = this.status\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof callback != 'function')\n    throw new Error('open() requires a callback argument')\n\n  if (typeof options != 'object')\n    options = {}\n\n  options.createIfMissing = options.createIfMissing != false\n  options.errorIfExists = !!options.errorIfExists\n\n  if (typeof this._open == 'function') {\n    this.status = 'opening'\n    this._open(options, function (err) {\n      if (err) {\n        self.status = oldStatus\n        return callback(err)\n      }\n      self.status = 'open'\n      callback()\n    })\n  } else {\n    this.status = 'open'\n    process.nextTick(callback)\n  }\n}\n\nAbstractLevelDOWN.prototype.close = function (callback) {\n  var self      = this\n    , oldStatus = this.status\n\n  if (typeof callback != 'function')\n    throw new Error('close() requires a callback argument')\n\n  if (typeof this._close == 'function') {\n    this.status = 'closing'\n    this._close(function (err) {\n      if (err) {\n        self.status = oldStatus\n        return callback(err)\n      }\n      self.status = 'closed'\n      callback()\n    })\n  } else {\n    this.status = 'closed'\n    process.nextTick(callback)\n  }\n}\n\nAbstractLevelDOWN.prototype.get = function (key, options, callback) {\n  var err\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof callback != 'function')\n    throw new Error('get() requires a callback argument')\n\n  if (err = this._checkKey(key, 'key', this._isBuffer))\n    return callback(err)\n\n  if (!this._isBuffer(key))\n    key = String(key)\n\n  if (typeof options != 'object')\n    options = {}\n\n  options.asBuffer = options.asBuffer != false\n\n  if (typeof this._get == 'function')\n    return this._get(key, options, callback)\n\n  process.nextTick(function () { callback(new Error('NotFound')) })\n}\n\nAbstractLevelDOWN.prototype.put = function (key, value, options, callback) {\n  var err\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof callback != 'function')\n    throw new Error('put() requires a callback argument')\n\n  if (err = this._checkKey(key, 'key', this._isBuffer))\n    return callback(err)\n\n  if (!this._isBuffer(key))\n    key = String(key)\n\n  // coerce value to string in node, don't touch it in browser\n  // (indexeddb can store any JS type)\n  if (value != null && !this._isBuffer(value) && !process.browser)\n    value = String(value)\n\n  if (typeof options != 'object')\n    options = {}\n\n  if (typeof this._put == 'function')\n    return this._put(key, value, options, callback)\n\n  process.nextTick(callback)\n}\n\nAbstractLevelDOWN.prototype.del = function (key, options, callback) {\n  var err\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof callback != 'function')\n    throw new Error('del() requires a callback argument')\n\n  if (err = this._checkKey(key, 'key', this._isBuffer))\n    return callback(err)\n\n  if (!this._isBuffer(key))\n    key = String(key)\n\n  if (typeof options != 'object')\n    options = {}\n\n  if (typeof this._del == 'function')\n    return this._del(key, options, callback)\n\n  process.nextTick(callback)\n}\n\nAbstractLevelDOWN.prototype.batch = function (array, options, callback) {\n  if (!arguments.length)\n    return this._chainedBatch()\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof array == 'function')\n    callback = array\n\n  if (typeof callback != 'function')\n    throw new Error('batch(array) requires a callback argument')\n\n  if (!Array.isArray(array))\n    return callback(new Error('batch(array) requires an array argument'))\n\n  if (!options || typeof options != 'object')\n    options = {}\n\n  var i = 0\n    , l = array.length\n    , e\n    , err\n\n  for (; i < l; i++) {\n    e = array[i]\n    if (typeof e != 'object')\n      continue\n\n    if (err = this._checkKey(e.type, 'type', this._isBuffer))\n      return callback(err)\n\n    if (err = this._checkKey(e.key, 'key', this._isBuffer))\n      return callback(err)\n  }\n\n  if (typeof this._batch == 'function')\n    return this._batch(array, options, callback)\n\n  process.nextTick(callback)\n}\n\n//TODO: remove from here, not a necessary primitive\nAbstractLevelDOWN.prototype.approximateSize = function (start, end, callback) {\n  if (   start == null\n      || end == null\n      || typeof start == 'function'\n      || typeof end == 'function') {\n    throw new Error('approximateSize() requires valid `start`, `end` and `callback` arguments')\n  }\n\n  if (typeof callback != 'function')\n    throw new Error('approximateSize() requires a callback argument')\n\n  if (!this._isBuffer(start))\n    start = String(start)\n\n  if (!this._isBuffer(end))\n    end = String(end)\n\n  if (typeof this._approximateSize == 'function')\n    return this._approximateSize(start, end, callback)\n\n  process.nextTick(function () {\n    callback(null, 0)\n  })\n}\n\nAbstractLevelDOWN.prototype._setupIteratorOptions = function (options) {\n  var self = this\n\n  options = xtend(options)\n\n  ;[ 'start', 'end', 'gt', 'gte', 'lt', 'lte' ].forEach(function (o) {\n    if (options[o] && self._isBuffer(options[o]) && options[o].length === 0)\n      delete options[o]\n  })\n\n  options.reverse = !!options.reverse\n  options.keys = options.keys != false\n  options.values = options.values != false\n  options.limit = 'limit' in options ? options.limit : -1\n  options.keyAsBuffer = options.keyAsBuffer != false\n  options.valueAsBuffer = options.valueAsBuffer != false\n\n  return options\n}\n\nAbstractLevelDOWN.prototype.iterator = function (options) {\n  if (typeof options != 'object')\n    options = {}\n\n  options = this._setupIteratorOptions(options)\n\n  if (typeof this._iterator == 'function')\n    return this._iterator(options)\n\n  return new AbstractIterator(this)\n}\n\nAbstractLevelDOWN.prototype._chainedBatch = function () {\n  return new AbstractChainedBatch(this)\n}\n\nAbstractLevelDOWN.prototype._isBuffer = function (obj) {\n  return Buffer.isBuffer(obj)\n}\n\nAbstractLevelDOWN.prototype._checkKey = function (obj, type) {\n\n  if (obj === null || obj === undefined)\n    return new Error(type + ' cannot be `null` or `undefined`')\n\n  if (this._isBuffer(obj)) {\n    if (obj.length === 0)\n      return new Error(type + ' cannot be an empty Buffer')\n  } else if (String(obj) === '')\n    return new Error(type + ' cannot be an empty String')\n}\n\nmodule.exports = AbstractLevelDOWN\n","/* Copyright (c) 2013 Rod Vagg, MIT License */\n\nfunction AbstractIterator (db) {\n  this.db = db\n  this._ended = false\n  this._nexting = false\n}\n\nAbstractIterator.prototype.next = function (callback) {\n  var self = this\n\n  if (typeof callback != 'function')\n    throw new Error('next() requires a callback argument')\n\n  if (self._ended)\n    return callback(new Error('cannot call next() after end()'))\n  if (self._nexting)\n    return callback(new Error('cannot call next() before previous next() has completed'))\n\n  self._nexting = true\n  if (typeof self._next == 'function') {\n    return self._next(function () {\n      self._nexting = false\n      callback.apply(null, arguments)\n    })\n  }\n\n  process.nextTick(function () {\n    self._nexting = false\n    callback()\n  })\n}\n\nAbstractIterator.prototype.end = function (callback) {\n  if (typeof callback != 'function')\n    throw new Error('end() requires a callback argument')\n\n  if (this._ended)\n    return callback(new Error('end() already called on iterator'))\n\n  this._ended = true\n\n  if (typeof this._end == 'function')\n    return this._end(callback)\n\n  process.nextTick(callback)\n}\n\nmodule.exports = AbstractIterator\n","/* Copyright (c) 2013 Rod Vagg, MIT License */\n\nfunction AbstractChainedBatch (db) {\n  this._db         = db\n  this._operations = []\n  this._written    = false\n}\n\nAbstractChainedBatch.prototype._checkWritten = function () {\n  if (this._written)\n    throw new Error('write() already called on this batch')\n}\n\nAbstractChainedBatch.prototype.put = function (key, value) {\n  this._checkWritten()\n\n  var err = this._db._checkKey(key, 'key', this._db._isBuffer)\n  if (err)\n    throw err\n\n  if (!this._db._isBuffer(key)) key = String(key)\n  if (!this._db._isBuffer(value)) value = String(value)\n\n  if (typeof this._put == 'function' )\n    this._put(key, value)\n  else\n    this._operations.push({ type: 'put', key: key, value: value })\n\n  return this\n}\n\nAbstractChainedBatch.prototype.del = function (key) {\n  this._checkWritten()\n\n  var err = this._db._checkKey(key, 'key', this._db._isBuffer)\n  if (err) throw err\n\n  if (!this._db._isBuffer(key)) key = String(key)\n\n  if (typeof this._del == 'function' )\n    this._del(key)\n  else\n    this._operations.push({ type: 'del', key: key })\n\n  return this\n}\n\nAbstractChainedBatch.prototype.clear = function () {\n  this._checkWritten()\n\n  this._operations = []\n\n  if (typeof this._clear == 'function' )\n    this._clear()\n\n  return this\n}\n\nAbstractChainedBatch.prototype.write = function (options, callback) {\n  this._checkWritten()\n\n  if (typeof options == 'function')\n    callback = options\n  if (typeof callback != 'function')\n    throw new Error('write() requires a callback argument')\n  if (typeof options != 'object')\n    options = {}\n\n  this._written = true\n\n  if (typeof this._write == 'function' )\n    return this._write(callback)\n\n  if (typeof this._db._batch == 'function')\n    return this._db._batch(this._operations, options, callback)\n\n  process.nextTick(callback)\n}\n\nmodule.exports = AbstractChainedBatch","var AbstractLevelDOWN = require('./abstract-leveldown')\n\nfunction isLevelDOWN (db) {\n  if (!db || typeof db !== 'object')\n    return false\n  return Object.keys(AbstractLevelDOWN.prototype).filter(function (name) {\n    // TODO remove approximateSize check when method is gone\n    return name[0] != '_' && name != 'approximateSize'\n  }).every(function (name) {\n    return typeof db[name] == 'function'\n  })\n}\n\nmodule.exports = isLevelDOWN\n","\nexports.compare = function (a, b) {\n\n  if(Buffer.isBuffer(a)) {\n    var l = Math.min(a.length, b.length)\n    for(var i = 0; i < l; i++) {\n      var cmp = a[i] - b[i]\n      if(cmp) return cmp\n    }\n    return a.length - b.length\n  }\n\n  return a < b ? -1 : a > b ? 1 : 0\n}\n\nfunction has(obj, key) {\n  return Object.hasOwnProperty.call(obj, key)\n}\n\n// to be compatible with the current abstract-leveldown tests\n// nullish or empty strings.\n// I could use !!val but I want to permit numbers and booleans,\n// if possible.\n\nfunction isDef (val) {\n  return val !== undefined && val !== ''\n}\n\nfunction has (range, name) {\n  return Object.hasOwnProperty.call(range, name)\n}\n\nfunction hasKey(range, name) {\n  return Object.hasOwnProperty.call(range, name) && name\n}\n\nvar lowerBoundKey = exports.lowerBoundKey = function (range) {\n    return (\n       hasKey(range, 'gt')\n    || hasKey(range, 'gte')\n    || hasKey(range, 'min')\n    || (range.reverse ? hasKey(range, 'end') : hasKey(range, 'start'))\n    || undefined\n    )\n}\n\nvar lowerBound = exports.lowerBound = function (range) {\n  var k = lowerBoundKey(range)\n  return k && range[k]\n}\n\nvar lowerBoundInclusive = exports.lowerBoundInclusive = function (range) {\n  return has(range, 'gt') ? false : true\n}\n\nvar upperBoundInclusive = exports.upperBoundInclusive =\n  function (range) {\n    return (has(range, 'lt') /*&& !range.maxEx*/) ? false : true\n  }\n\nvar lowerBoundExclusive = exports.lowerBoundExclusive =\n  function (range) {\n    return !lowerBoundInclusive(range)\n  }\n\nvar upperBoundExclusive = exports.upperBoundExclusive =\n  function (range) {\n    return !upperBoundInclusive(range)\n  }\n\nvar upperBoundKey = exports.upperBoundKey = function (range) {\n    return (\n       hasKey(range, 'lt')\n    || hasKey(range, 'lte')\n    || hasKey(range, 'max')\n    || (range.reverse ? hasKey(range, 'start') : hasKey(range, 'end'))\n    || undefined\n    )\n}\n\nvar upperBound = exports.upperBound = function (range) {\n  var k = upperBoundKey(range)\n  return k && range[k]\n}\n\nfunction id (e) { return e }\n\nexports.toLtgt = function (range, _range, map, lower, upper) {\n  _range = _range || {}\n  map = map || id\n  var defaults = arguments.length > 3\n  var lb = exports.lowerBoundKey(range)\n  var ub = exports.upperBoundKey(range)\n  if(lb) {\n    if(lb === 'gt') _range.gt = map(range.gt, false)\n    else            _range.gte = map(range[lb], false)\n  }\n  else if(defaults)\n    _range.gte = map(lower, false)\n\n  if(ub) {\n    if(ub === 'lt') _range.lt = map(range.lt, true)\n    else            _range.lte = map(range[ub], true)\n  }\n  else if(defaults)\n    _range.lte = map(upper, true)\n\n  if(range.reverse != null)\n    _range.reverse = !!range.reverse\n\n  //if range was used mutably\n  //(in level-sublevel it's part of an options object\n  //that has more properties on it.)\n  if(has(_range, 'max'))   delete _range.max\n  if(has(_range, 'min'))   delete _range.min\n  if(has(_range, 'start')) delete _range.start\n  if(has(_range, 'end'))   delete _range.end\n\n  return _range\n}\n\nexports.contains = function (range, key, compare) {\n  compare = compare || exports.compare\n\n  var lb = lowerBound(range)\n  if(isDef(lb)) {\n    var cmp = compare(key, lb)\n    if(cmp < 0 || (cmp === 0 && lowerBoundExclusive(range)))\n      return false\n  }\n\n  var ub = upperBound(range)\n  if(isDef(ub)) {\n    var cmp = compare(key, ub)\n    if(cmp > 0 || (cmp === 0) && upperBoundExclusive(range))\n      return false\n  }\n\n  return true\n}\n\nexports.filter = function (range, compare) {\n  return function (key) {\n    return exports.contains(range, key, compare)\n  }\n}\n\n\n\n\n\n","\"use strict\"\n\nmodule.exports = createRBTree\n\nvar RED   = 0\nvar BLACK = 1\n\nfunction RBNode(color, key, value, left, right, count) {\n  this._color = color\n  this.key = key\n  this.value = value\n  this.left = left\n  this.right = right\n  this._count = count\n}\n\nfunction cloneNode(node) {\n  return new RBNode(node._color, node.key, node.value, node.left, node.right, node._count)\n}\n\nfunction repaint(color, node) {\n  return new RBNode(color, node.key, node.value, node.left, node.right, node._count)\n}\n\nfunction recount(node) {\n  node._count = 1 + (node.left ? node.left._count : 0) + (node.right ? node.right._count : 0)\n}\n\nfunction RedBlackTree(compare, root) {\n  this._compare = compare\n  this.root = root\n}\n\nvar proto = RedBlackTree.prototype\n\nObject.defineProperty(proto, \"keys\", {\n  get: function() {\n    var result = []\n    this.forEach(function(k,v) {\n      result.push(k)\n    })\n    return result\n  }\n})\n\nObject.defineProperty(proto, \"values\", {\n  get: function() {\n    var result = []\n    this.forEach(function(k,v) {\n      result.push(v)\n    })\n    return result\n  }\n})\n\n//Returns the number of nodes in the tree\nObject.defineProperty(proto, \"length\", {\n  get: function() {\n    if(this.root) {\n      return this.root._count\n    }\n    return 0\n  }\n})\n\n//Insert a new item into the tree\nproto.insert = function(key, value) {\n  var cmp = this._compare\n  //Find point to insert new node at\n  var n = this.root\n  var n_stack = []\n  var d_stack = []\n  while(n) {\n    var d = cmp(key, n.key)\n    n_stack.push(n)\n    d_stack.push(d)\n    if(d <= 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  //Rebuild path to leaf node\n  n_stack.push(new RBNode(RED, key, value, null, null, 1))\n  for(var s=n_stack.length-2; s>=0; --s) {\n    var n = n_stack[s]\n    if(d_stack[s] <= 0) {\n      n_stack[s] = new RBNode(n._color, n.key, n.value, n_stack[s+1], n.right, n._count+1)\n    } else {\n      n_stack[s] = new RBNode(n._color, n.key, n.value, n.left, n_stack[s+1], n._count+1)\n    }\n  }\n  //Rebalance tree using rotations\n  //console.log(\"start insert\", key, d_stack)\n  for(var s=n_stack.length-1; s>1; --s) {\n    var p = n_stack[s-1]\n    var n = n_stack[s]\n    if(p._color === BLACK || n._color === BLACK) {\n      break\n    }\n    var pp = n_stack[s-2]\n    if(pp.left === p) {\n      if(p.left === n) {\n        var y = pp.right\n        if(y && y._color === RED) {\n          //console.log(\"LLr\")\n          p._color = BLACK\n          pp.right = repaint(BLACK, y)\n          pp._color = RED\n          s -= 1\n        } else {\n          //console.log(\"LLb\")\n          pp._color = RED\n          pp.left = p.right\n          p._color = BLACK\n          p.right = pp\n          n_stack[s-2] = p\n          n_stack[s-1] = n\n          recount(pp)\n          recount(p)\n          if(s >= 3) {\n            var ppp = n_stack[s-3]\n            if(ppp.left === pp) {\n              ppp.left = p\n            } else {\n              ppp.right = p\n            }\n          }\n          break\n        }\n      } else {\n        var y = pp.right\n        if(y && y._color === RED) {\n          //console.log(\"LRr\")\n          p._color = BLACK\n          pp.right = repaint(BLACK, y)\n          pp._color = RED\n          s -= 1\n        } else {\n          //console.log(\"LRb\")\n          p.right = n.left\n          pp._color = RED\n          pp.left = n.right\n          n._color = BLACK\n          n.left = p\n          n.right = pp\n          n_stack[s-2] = n\n          n_stack[s-1] = p\n          recount(pp)\n          recount(p)\n          recount(n)\n          if(s >= 3) {\n            var ppp = n_stack[s-3]\n            if(ppp.left === pp) {\n              ppp.left = n\n            } else {\n              ppp.right = n\n            }\n          }\n          break\n        }\n      }\n    } else {\n      if(p.right === n) {\n        var y = pp.left\n        if(y && y._color === RED) {\n          //console.log(\"RRr\", y.key)\n          p._color = BLACK\n          pp.left = repaint(BLACK, y)\n          pp._color = RED\n          s -= 1\n        } else {\n          //console.log(\"RRb\")\n          pp._color = RED\n          pp.right = p.left\n          p._color = BLACK\n          p.left = pp\n          n_stack[s-2] = p\n          n_stack[s-1] = n\n          recount(pp)\n          recount(p)\n          if(s >= 3) {\n            var ppp = n_stack[s-3]\n            if(ppp.right === pp) {\n              ppp.right = p\n            } else {\n              ppp.left = p\n            }\n          }\n          break\n        }\n      } else {\n        var y = pp.left\n        if(y && y._color === RED) {\n          //console.log(\"RLr\")\n          p._color = BLACK\n          pp.left = repaint(BLACK, y)\n          pp._color = RED\n          s -= 1\n        } else {\n          //console.log(\"RLb\")\n          p.left = n.right\n          pp._color = RED\n          pp.right = n.left\n          n._color = BLACK\n          n.right = p\n          n.left = pp\n          n_stack[s-2] = n\n          n_stack[s-1] = p\n          recount(pp)\n          recount(p)\n          recount(n)\n          if(s >= 3) {\n            var ppp = n_stack[s-3]\n            if(ppp.right === pp) {\n              ppp.right = n\n            } else {\n              ppp.left = n\n            }\n          }\n          break\n        }\n      }\n    }\n  }\n  //Return new tree\n  n_stack[0]._color = BLACK\n  return new RedBlackTree(cmp, n_stack[0])\n}\n\n\n//Visit all nodes inorder\nfunction doVisitFull(visit, node) {\n  if(node.left) {\n    var v = doVisitFull(visit, node.left)\n    if(v) { return v }\n  }\n  var v = visit(node.key, node.value)\n  if(v) { return v }\n  if(node.right) {\n    return doVisitFull(visit, node.right)\n  }\n}\n\n//Visit half nodes in order\nfunction doVisitHalf(lo, compare, visit, node) {\n  var l = compare(lo, node.key)\n  if(l <= 0) {\n    if(node.left) {\n      var v = doVisitHalf(lo, compare, visit, node.left)\n      if(v) { return v }\n    }\n    var v = visit(node.key, node.value)\n    if(v) { return v }\n  }\n  if(node.right) {\n    return doVisitHalf(lo, compare, visit, node.right)\n  }\n}\n\n//Visit all nodes within a range\nfunction doVisit(lo, hi, compare, visit, node) {\n  var l = compare(lo, node.key)\n  var h = compare(hi, node.key)\n  var v\n  if(l <= 0) {\n    if(node.left) {\n      v = doVisit(lo, hi, compare, visit, node.left)\n      if(v) { return v }\n    }\n    if(h > 0) {\n      v = visit(node.key, node.value)\n      if(v) { return v }\n    }\n  }\n  if(h > 0 && node.right) {\n    return doVisit(lo, hi, compare, visit, node.right)\n  }\n}\n\n\nproto.forEach = function rbTreeForEach(visit, lo, hi) {\n  if(!this.root) {\n    return\n  }\n  switch(arguments.length) {\n    case 1:\n      return doVisitFull(visit, this.root)\n    break\n\n    case 2:\n      return doVisitHalf(lo, this._compare, visit, this.root)\n    break\n\n    case 3:\n      if(this._compare(lo, hi) >= 0) {\n        return\n      }\n      return doVisit(lo, hi, this._compare, visit, this.root)\n    break\n  }\n}\n\n//First item in list\nObject.defineProperty(proto, \"begin\", {\n  get: function() {\n    var stack = []\n    var n = this.root\n    while(n) {\n      stack.push(n)\n      n = n.left\n    }\n    return new RedBlackTreeIterator(this, stack)\n  }\n})\n\n//Last item in list\nObject.defineProperty(proto, \"end\", {\n  get: function() {\n    var stack = []\n    var n = this.root\n    while(n) {\n      stack.push(n)\n      n = n.right\n    }\n    return new RedBlackTreeIterator(this, stack)\n  }\n})\n\n//Find the ith item in the tree\nproto.at = function(idx) {\n  if(idx < 0) {\n    return new RedBlackTreeIterator(this, [])\n  }\n  var n = this.root\n  var stack = []\n  while(true) {\n    stack.push(n)\n    if(n.left) {\n      if(idx < n.left._count) {\n        n = n.left\n        continue\n      }\n      idx -= n.left._count\n    }\n    if(!idx) {\n      return new RedBlackTreeIterator(this, stack)\n    }\n    idx -= 1\n    if(n.right) {\n      if(idx >= n.right._count) {\n        break\n      }\n      n = n.right\n    } else {\n      break\n    }\n  }\n  return new RedBlackTreeIterator(this, [])\n}\n\nproto.ge = function(key) {\n  var cmp = this._compare\n  var n = this.root\n  var stack = []\n  var last_ptr = 0\n  while(n) {\n    var d = cmp(key, n.key)\n    stack.push(n)\n    if(d <= 0) {\n      last_ptr = stack.length\n    }\n    if(d <= 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  stack.length = last_ptr\n  return new RedBlackTreeIterator(this, stack)\n}\n\nproto.gt = function(key) {\n  var cmp = this._compare\n  var n = this.root\n  var stack = []\n  var last_ptr = 0\n  while(n) {\n    var d = cmp(key, n.key)\n    stack.push(n)\n    if(d < 0) {\n      last_ptr = stack.length\n    }\n    if(d < 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  stack.length = last_ptr\n  return new RedBlackTreeIterator(this, stack)\n}\n\nproto.lt = function(key) {\n  var cmp = this._compare\n  var n = this.root\n  var stack = []\n  var last_ptr = 0\n  while(n) {\n    var d = cmp(key, n.key)\n    stack.push(n)\n    if(d > 0) {\n      last_ptr = stack.length\n    }\n    if(d <= 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  stack.length = last_ptr\n  return new RedBlackTreeIterator(this, stack)\n}\n\nproto.le = function(key) {\n  var cmp = this._compare\n  var n = this.root\n  var stack = []\n  var last_ptr = 0\n  while(n) {\n    var d = cmp(key, n.key)\n    stack.push(n)\n    if(d >= 0) {\n      last_ptr = stack.length\n    }\n    if(d < 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  stack.length = last_ptr\n  return new RedBlackTreeIterator(this, stack)\n}\n\n//Finds the item with key if it exists\nproto.find = function(key) {\n  var cmp = this._compare\n  var n = this.root\n  var stack = []\n  while(n) {\n    var d = cmp(key, n.key)\n    stack.push(n)\n    if(d === 0) {\n      return new RedBlackTreeIterator(this, stack)\n    }\n    if(d <= 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  return new RedBlackTreeIterator(this, [])\n}\n\n//Removes item with key from tree\nproto.remove = function(key) {\n  var iter = this.find(key)\n  if(iter) {\n    return iter.remove()\n  }\n  return this\n}\n\n//Returns the item at `key`\nproto.get = function(key) {\n  var cmp = this._compare\n  var n = this.root\n  while(n) {\n    var d = cmp(key, n.key)\n    if(d === 0) {\n      return n.value\n    }\n    if(d <= 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  return\n}\n\n//Iterator for red black tree\nfunction RedBlackTreeIterator(tree, stack) {\n  this.tree = tree\n  this._stack = stack\n}\n\nvar iproto = RedBlackTreeIterator.prototype\n\n//Test if iterator is valid\nObject.defineProperty(iproto, \"valid\", {\n  get: function() {\n    return this._stack.length > 0\n  }\n})\n\n//Node of the iterator\nObject.defineProperty(iproto, \"node\", {\n  get: function() {\n    if(this._stack.length > 0) {\n      return this._stack[this._stack.length-1]\n    }\n    return null\n  },\n  enumerable: true\n})\n\n//Makes a copy of an iterator\niproto.clone = function() {\n  return new RedBlackTreeIterator(this.tree, this._stack.slice())\n}\n\n//Swaps two nodes\nfunction swapNode(n, v) {\n  n.key = v.key\n  n.value = v.value\n  n.left = v.left\n  n.right = v.right\n  n._color = v._color\n  n._count = v._count\n}\n\n//Fix up a double black node in a tree\nfunction fixDoubleBlack(stack) {\n  var n, p, s, z\n  for(var i=stack.length-1; i>=0; --i) {\n    n = stack[i]\n    if(i === 0) {\n      n._color = BLACK\n      return\n    }\n    //console.log(\"visit node:\", n.key, i, stack[i].key, stack[i-1].key)\n    p = stack[i-1]\n    if(p.left === n) {\n      //console.log(\"left child\")\n      s = p.right\n      if(s.right && s.right._color === RED) {\n        //console.log(\"case 1: right sibling child red\")\n        s = p.right = cloneNode(s)\n        z = s.right = cloneNode(s.right)\n        p.right = s.left\n        s.left = p\n        s.right = z\n        s._color = p._color\n        n._color = BLACK\n        p._color = BLACK\n        z._color = BLACK\n        recount(p)\n        recount(s)\n        if(i > 1) {\n          var pp = stack[i-2]\n          if(pp.left === p) {\n            pp.left = s\n          } else {\n            pp.right = s\n          }\n        }\n        stack[i-1] = s\n        return\n      } else if(s.left && s.left._color === RED) {\n        //console.log(\"case 1: left sibling child red\")\n        s = p.right = cloneNode(s)\n        z = s.left = cloneNode(s.left)\n        p.right = z.left\n        s.left = z.right\n        z.left = p\n        z.right = s\n        z._color = p._color\n        p._color = BLACK\n        s._color = BLACK\n        n._color = BLACK\n        recount(p)\n        recount(s)\n        recount(z)\n        if(i > 1) {\n          var pp = stack[i-2]\n          if(pp.left === p) {\n            pp.left = z\n          } else {\n            pp.right = z\n          }\n        }\n        stack[i-1] = z\n        return\n      }\n      if(s._color === BLACK) {\n        if(p._color === RED) {\n          //console.log(\"case 2: black sibling, red parent\", p.right.value)\n          p._color = BLACK\n          p.right = repaint(RED, s)\n          return\n        } else {\n          //console.log(\"case 2: black sibling, black parent\", p.right.value)\n          p.right = repaint(RED, s)\n          continue  \n        }\n      } else {\n        //console.log(\"case 3: red sibling\")\n        s = cloneNode(s)\n        p.right = s.left\n        s.left = p\n        s._color = p._color\n        p._color = RED\n        recount(p)\n        recount(s)\n        if(i > 1) {\n          var pp = stack[i-2]\n          if(pp.left === p) {\n            pp.left = s\n          } else {\n            pp.right = s\n          }\n        }\n        stack[i-1] = s\n        stack[i] = p\n        if(i+1 < stack.length) {\n          stack[i+1] = n\n        } else {\n          stack.push(n)\n        }\n        i = i+2\n      }\n    } else {\n      //console.log(\"right child\")\n      s = p.left\n      if(s.left && s.left._color === RED) {\n        //console.log(\"case 1: left sibling child red\", p.value, p._color)\n        s = p.left = cloneNode(s)\n        z = s.left = cloneNode(s.left)\n        p.left = s.right\n        s.right = p\n        s.left = z\n        s._color = p._color\n        n._color = BLACK\n        p._color = BLACK\n        z._color = BLACK\n        recount(p)\n        recount(s)\n        if(i > 1) {\n          var pp = stack[i-2]\n          if(pp.right === p) {\n            pp.right = s\n          } else {\n            pp.left = s\n          }\n        }\n        stack[i-1] = s\n        return\n      } else if(s.right && s.right._color === RED) {\n        //console.log(\"case 1: right sibling child red\")\n        s = p.left = cloneNode(s)\n        z = s.right = cloneNode(s.right)\n        p.left = z.right\n        s.right = z.left\n        z.right = p\n        z.left = s\n        z._color = p._color\n        p._color = BLACK\n        s._color = BLACK\n        n._color = BLACK\n        recount(p)\n        recount(s)\n        recount(z)\n        if(i > 1) {\n          var pp = stack[i-2]\n          if(pp.right === p) {\n            pp.right = z\n          } else {\n            pp.left = z\n          }\n        }\n        stack[i-1] = z\n        return\n      }\n      if(s._color === BLACK) {\n        if(p._color === RED) {\n          //console.log(\"case 2: black sibling, red parent\")\n          p._color = BLACK\n          p.left = repaint(RED, s)\n          return\n        } else {\n          //console.log(\"case 2: black sibling, black parent\")\n          p.left = repaint(RED, s)\n          continue  \n        }\n      } else {\n        //console.log(\"case 3: red sibling\")\n        s = cloneNode(s)\n        p.left = s.right\n        s.right = p\n        s._color = p._color\n        p._color = RED\n        recount(p)\n        recount(s)\n        if(i > 1) {\n          var pp = stack[i-2]\n          if(pp.right === p) {\n            pp.right = s\n          } else {\n            pp.left = s\n          }\n        }\n        stack[i-1] = s\n        stack[i] = p\n        if(i+1 < stack.length) {\n          stack[i+1] = n\n        } else {\n          stack.push(n)\n        }\n        i = i+2\n      }\n    }\n  }\n}\n\n//Removes item at iterator from tree\niproto.remove = function() {\n  var stack = this._stack\n  if(stack.length === 0) {\n    return this.tree\n  }\n  //First copy path to node\n  var cstack = new Array(stack.length)\n  var n = stack[stack.length-1]\n  cstack[cstack.length-1] = new RBNode(n._color, n.key, n.value, n.left, n.right, n._count)\n  for(var i=stack.length-2; i>=0; --i) {\n    var n = stack[i]\n    if(n.left === stack[i+1]) {\n      cstack[i] = new RBNode(n._color, n.key, n.value, cstack[i+1], n.right, n._count)\n    } else {\n      cstack[i] = new RBNode(n._color, n.key, n.value, n.left, cstack[i+1], n._count)\n    }\n  }\n\n  //Get node\n  n = cstack[cstack.length-1]\n  //console.log(\"start remove: \", n.value)\n\n  //If not leaf, then swap with previous node\n  if(n.left && n.right) {\n    //console.log(\"moving to leaf\")\n\n    //First walk to previous leaf\n    var split = cstack.length\n    n = n.left\n    while(n.right) {\n      cstack.push(n)\n      n = n.right\n    }\n    //Copy path to leaf\n    var v = cstack[split-1]\n    cstack.push(new RBNode(n._color, v.key, v.value, n.left, n.right, n._count))\n    cstack[split-1].key = n.key\n    cstack[split-1].value = n.value\n\n    //Fix up stack\n    for(var i=cstack.length-2; i>=split; --i) {\n      n = cstack[i]\n      cstack[i] = new RBNode(n._color, n.key, n.value, n.left, cstack[i+1], n._count)\n    }\n    cstack[split-1].left = cstack[split]\n  }\n  //console.log(\"stack=\", cstack.map(function(v) { return v.value }))\n\n  //Remove leaf node\n  n = cstack[cstack.length-1]\n  if(n._color === RED) {\n    //Easy case: removing red leaf\n    //console.log(\"RED leaf\")\n    var p = cstack[cstack.length-2]\n    if(p.left === n) {\n      p.left = null\n    } else if(p.right === n) {\n      p.right = null\n    }\n    cstack.pop()\n    for(var i=0; i<cstack.length; ++i) {\n      cstack[i]._count--\n    }\n    return new RedBlackTree(this.tree._compare, cstack[0])\n  } else {\n    if(n.left || n.right) {\n      //Second easy case:  Single child black parent\n      //console.log(\"BLACK single child\")\n      if(n.left) {\n        swapNode(n, n.left)\n      } else if(n.right) {\n        swapNode(n, n.right)\n      }\n      //Child must be red, so repaint it black to balance color\n      n._color = BLACK\n      for(var i=0; i<cstack.length-1; ++i) {\n        cstack[i]._count--\n      }\n      return new RedBlackTree(this.tree._compare, cstack[0])\n    } else if(cstack.length === 1) {\n      //Third easy case: root\n      //console.log(\"ROOT\")\n      return new RedBlackTree(this.tree._compare, null)\n    } else {\n      //Hard case: Repaint n, and then do some nasty stuff\n      //console.log(\"BLACK leaf no children\")\n      for(var i=0; i<cstack.length; ++i) {\n        cstack[i]._count--\n      }\n      var parent = cstack[cstack.length-2]\n      fixDoubleBlack(cstack)\n      //Fix up links\n      if(parent.left === n) {\n        parent.left = null\n      } else {\n        parent.right = null\n      }\n    }\n  }\n  return new RedBlackTree(this.tree._compare, cstack[0])\n}\n\n//Returns key\nObject.defineProperty(iproto, \"key\", {\n  get: function() {\n    if(this._stack.length > 0) {\n      return this._stack[this._stack.length-1].key\n    }\n    return\n  },\n  enumerable: true\n})\n\n//Returns value\nObject.defineProperty(iproto, \"value\", {\n  get: function() {\n    if(this._stack.length > 0) {\n      return this._stack[this._stack.length-1].value\n    }\n    return\n  },\n  enumerable: true\n})\n\n\n//Returns the position of this iterator in the sorted list\nObject.defineProperty(iproto, \"index\", {\n  get: function() {\n    var idx = 0\n    var stack = this._stack\n    if(stack.length === 0) {\n      var r = this.tree.root\n      if(r) {\n        return r._count\n      }\n      return 0\n    } else if(stack[stack.length-1].left) {\n      idx = stack[stack.length-1].left._count\n    }\n    for(var s=stack.length-2; s>=0; --s) {\n      if(stack[s+1] === stack[s].right) {\n        ++idx\n        if(stack[s].left) {\n          idx += stack[s].left._count\n        }\n      }\n    }\n    return idx\n  },\n  enumerable: true\n})\n\n//Advances iterator to next element in list\niproto.next = function() {\n  var stack = this._stack\n  if(stack.length === 0) {\n    return\n  }\n  var n = stack[stack.length-1]\n  if(n.right) {\n    n = n.right\n    while(n) {\n      stack.push(n)\n      n = n.left\n    }\n  } else {\n    stack.pop()\n    while(stack.length > 0 && stack[stack.length-1].right === n) {\n      n = stack[stack.length-1]\n      stack.pop()\n    }\n  }\n}\n\n//Checks if iterator is at end of tree\nObject.defineProperty(iproto, \"hasNext\", {\n  get: function() {\n    var stack = this._stack\n    if(stack.length === 0) {\n      return false\n    }\n    if(stack[stack.length-1].right) {\n      return true\n    }\n    for(var s=stack.length-1; s>0; --s) {\n      if(stack[s-1].left === stack[s]) {\n        return true\n      }\n    }\n    return false\n  }\n})\n\n//Update value\niproto.update = function(value) {\n  var stack = this._stack\n  if(stack.length === 0) {\n    throw new Error(\"Can't update empty node!\")\n  }\n  var cstack = new Array(stack.length)\n  var n = stack[stack.length-1]\n  cstack[cstack.length-1] = new RBNode(n._color, n.key, value, n.left, n.right, n._count)\n  for(var i=stack.length-2; i>=0; --i) {\n    n = stack[i]\n    if(n.left === stack[i+1]) {\n      cstack[i] = new RBNode(n._color, n.key, n.value, cstack[i+1], n.right, n._count)\n    } else {\n      cstack[i] = new RBNode(n._color, n.key, n.value, n.left, cstack[i+1], n._count)\n    }\n  }\n  return new RedBlackTree(this.tree._compare, cstack[0])\n}\n\n//Moves iterator backward one element\niproto.prev = function() {\n  var stack = this._stack\n  if(stack.length === 0) {\n    return\n  }\n  var n = stack[stack.length-1]\n  if(n.left) {\n    n = n.left\n    while(n) {\n      stack.push(n)\n      n = n.right\n    }\n  } else {\n    stack.pop()\n    while(stack.length > 0 && stack[stack.length-1].left === n) {\n      n = stack[stack.length-1]\n      stack.pop()\n    }\n  }\n}\n\n//Checks if iterator is at start of tree\nObject.defineProperty(iproto, \"hasPrev\", {\n  get: function() {\n    var stack = this._stack\n    if(stack.length === 0) {\n      return false\n    }\n    if(stack[stack.length-1].left) {\n      return true\n    }\n    for(var s=stack.length-1; s>0; --s) {\n      if(stack[s-1].right === stack[s]) {\n        return true\n      }\n    }\n    return false\n  }\n})\n\n//Default comparison function\nfunction defaultCompare(a, b) {\n  if(a < b) {\n    return -1\n  }\n  if(a > b) {\n    return 1\n  }\n  return 0\n}\n\n//Build a tree\nfunction createRBTree(compare) {\n  return new RedBlackTree(compare || defaultCompare, null)\n}","module.exports = require('immediate')\n","'use strict';\nvar types = [\n  require('./nextTick'),\n  require('./mutation.js'),\n  require('./messageChannel'),\n  require('./stateChange'),\n  require('./timeout')\n];\nvar draining;\nvar currentQueue;\nvar queueIndex = -1;\nvar queue = [];\nvar scheduled = false;\nfunction cleanUpNextTick() {\n  if (!draining || !currentQueue) {\n    return;\n  }\n  draining = false;\n  if (currentQueue.length) {\n    queue = currentQueue.concat(queue);\n  } else {\n    queueIndex = -1;\n  }\n  if (queue.length) {\n    nextTick();\n  }\n}\n\n//named nextTick for less confusing stack traces\nfunction nextTick() {\n  if (draining) {\n    return;\n  }\n  scheduled = false;\n  draining = true;\n  var len = queue.length;\n  var timeout = setTimeout(cleanUpNextTick);\n  while (len) {\n    currentQueue = queue;\n    queue = [];\n    while (currentQueue && ++queueIndex < len) {\n      currentQueue[queueIndex].run();\n    }\n    queueIndex = -1;\n    len = queue.length;\n  }\n  currentQueue = null;\n  queueIndex = -1;\n  draining = false;\n  clearTimeout(timeout);\n}\nvar scheduleDrain;\nvar i = -1;\nvar len = types.length;\nwhile (++i < len) {\n  if (types[i] && types[i].test && types[i].test()) {\n    scheduleDrain = types[i].install(nextTick);\n    break;\n  }\n}\n// v8 likes predictible objects\nfunction Item(fun, array) {\n  this.fun = fun;\n  this.array = array;\n}\nItem.prototype.run = function () {\n  var fun = this.fun;\n  var array = this.array;\n  switch (array.length) {\n  case 0:\n    return fun();\n  case 1:\n    return fun(array[0]);\n  case 2:\n    return fun(array[0], array[1]);\n  case 3:\n    return fun(array[0], array[1], array[2]);\n  default:\n    return fun.apply(null, array);\n  }\n\n};\nmodule.exports = immediate;\nfunction immediate(task) {\n  var args = new Array(arguments.length - 1);\n  if (arguments.length > 1) {\n    for (var i = 1; i < arguments.length; i++) {\n      args[i - 1] = arguments[i];\n    }\n  }\n  queue.push(new Item(task, args));\n  if (!scheduled && !draining) {\n    scheduled = true;\n    scheduleDrain();\n  }\n}\n","'use strict';\nexports.test = function () {\n  // Don't get fooled by e.g. browserify environments.\n  return (typeof process !== 'undefined') && !process.browser;\n};\n\nexports.install = function (func) {\n  return function () {\n    process.nextTick(func);\n  };\n};\n","'use strict';\n//based off rsvp https://github.com/tildeio/rsvp.js\n//license https://github.com/tildeio/rsvp.js/blob/master/LICENSE\n//https://github.com/tildeio/rsvp.js/blob/master/lib/rsvp/asap.js\n\nvar Mutation = global.MutationObserver || global.WebKitMutationObserver;\n\nexports.test = function () {\n  return Mutation;\n};\n\nexports.install = function (handle) {\n  var called = 0;\n  var observer = new Mutation(handle);\n  var element = global.document.createTextNode('');\n  observer.observe(element, {\n    characterData: true\n  });\n  return function () {\n    element.data = (called = ++called % 2);\n  };\n};","'use strict';\n\nexports.test = function () {\n  if (global.setImmediate) {\n    // we can only get here in IE10\n    // which doesn't handel postMessage well\n    return false;\n  }\n  return typeof global.MessageChannel !== 'undefined';\n};\n\nexports.install = function (func) {\n  var channel = new global.MessageChannel();\n  channel.port1.onmessage = func;\n  return function () {\n    channel.port2.postMessage(0);\n  };\n};","'use strict';\n\nexports.test = function () {\n  return 'document' in global && 'onreadystatechange' in global.document.createElement('script');\n};\n\nexports.install = function (handle) {\n  return function () {\n\n    // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n    // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n    var scriptEl = global.document.createElement('script');\n    scriptEl.onreadystatechange = function () {\n      handle();\n\n      scriptEl.onreadystatechange = null;\n      scriptEl.parentNode.removeChild(scriptEl);\n      scriptEl = null;\n    };\n    global.document.documentElement.appendChild(scriptEl);\n\n    return handle;\n  };\n};","'use strict';\nexports.test = function () {\n  return true;\n};\n\nexports.install = function (t) {\n  return function () {\n    setTimeout(t, 0);\n  };\n};","import debug from 'debug';\n\nfunction debugPouch(PouchDB) {\n  PouchDB.debug = debug;\n  var logs = {};\n  /* istanbul ignore next */\n  PouchDB.on('debug', function (args) {\n    // first argument is log identifier\n    var logId = args[0];\n    // rest should be passed verbatim to debug module\n    var logArgs = args.slice(1);\n    if (!logs[logId]) {\n      logs[logId] = debug('pouchdb:' + logId);\n    }\n    logs[logId].apply(null, logArgs);\n  });\n}\n\nexport default debugPouch;\n","/**\n * This is the web browser implementation of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = require('./debug');\nexports.log = log;\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = 'undefined' != typeof chrome\n               && 'undefined' != typeof chrome.storage\n                  ? chrome.storage.local\n                  : localstorage();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n  '#0000CC', '#0000FF', '#0033CC', '#0033FF', '#0066CC', '#0066FF', '#0099CC',\n  '#0099FF', '#00CC00', '#00CC33', '#00CC66', '#00CC99', '#00CCCC', '#00CCFF',\n  '#3300CC', '#3300FF', '#3333CC', '#3333FF', '#3366CC', '#3366FF', '#3399CC',\n  '#3399FF', '#33CC00', '#33CC33', '#33CC66', '#33CC99', '#33CCCC', '#33CCFF',\n  '#6600CC', '#6600FF', '#6633CC', '#6633FF', '#66CC00', '#66CC33', '#9900CC',\n  '#9900FF', '#9933CC', '#9933FF', '#99CC00', '#99CC33', '#CC0000', '#CC0033',\n  '#CC0066', '#CC0099', '#CC00CC', '#CC00FF', '#CC3300', '#CC3333', '#CC3366',\n  '#CC3399', '#CC33CC', '#CC33FF', '#CC6600', '#CC6633', '#CC9900', '#CC9933',\n  '#CCCC00', '#CCCC33', '#FF0000', '#FF0033', '#FF0066', '#FF0099', '#FF00CC',\n  '#FF00FF', '#FF3300', '#FF3333', '#FF3366', '#FF3399', '#FF33CC', '#FF33FF',\n  '#FF6600', '#FF6633', '#FF9900', '#FF9933', '#FFCC00', '#FFCC33'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\nfunction useColors() {\n  // NB: In an Electron preload script, document will be defined but not fully\n  // initialized. Since we know we're in Chrome, we'll just detect this case\n  // explicitly\n  if (typeof window !== 'undefined' && window.process && window.process.type === 'renderer') {\n    return true;\n  }\n\n  // Internet Explorer and Edge do not support colors.\n  if (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\\/(\\d+)/)) {\n    return false;\n  }\n\n  // is webkit? http://stackoverflow.com/a/16459606/376773\n  // document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n  return (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n    // is firebug? http://stackoverflow.com/a/398120/376773\n    (typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n    // is firefox >= v31?\n    // https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n    (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n    // double check webkit in userAgent just in case we are in a worker\n    (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nexports.formatters.j = function(v) {\n  try {\n    return JSON.stringify(v);\n  } catch (err) {\n    return '[UnexpectedJSONParseError]: ' + err.message;\n  }\n};\n\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n  var useColors = this.useColors;\n\n  args[0] = (useColors ? '%c' : '')\n    + this.namespace\n    + (useColors ? ' %c' : ' ')\n    + args[0]\n    + (useColors ? '%c ' : ' ')\n    + '+' + exports.humanize(this.diff);\n\n  if (!useColors) return;\n\n  var c = 'color: ' + this.color;\n  args.splice(1, 0, c, 'color: inherit')\n\n  // the final \"%c\" is somewhat tricky, because there could be other\n  // arguments passed either before or after the %c, so we need to\n  // figure out the correct index to insert the CSS into\n  var index = 0;\n  var lastC = 0;\n  args[0].replace(/%[a-zA-Z%]/g, function(match) {\n    if ('%%' === match) return;\n    index++;\n    if ('%c' === match) {\n      // we only are interested in the *last* %c\n      // (the user may have provided their own)\n      lastC = index;\n    }\n  });\n\n  args.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.log()` when available.\n * No-op when `console.log` is not a \"function\".\n *\n * @api public\n */\n\nfunction log() {\n  // this hackery is required for IE8/9, where\n  // the `console.log` function doesn't have 'apply'\n  return 'object' === typeof console\n    && console.log\n    && Function.prototype.apply.call(console.log, console, arguments);\n}\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\n\nfunction save(namespaces) {\n  try {\n    if (null == namespaces) {\n      exports.storage.removeItem('debug');\n    } else {\n      exports.storage.debug = namespaces;\n    }\n  } catch(e) {}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\n\nfunction load() {\n  var r;\n  try {\n    r = exports.storage.debug;\n  } catch(e) {}\n\n  // If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n  if (!r && typeof process !== 'undefined' && 'env' in process) {\n    r = process.env.DEBUG;\n  }\n\n  return r;\n}\n\n/**\n * Enable namespaces listed in `localStorage.debug` initially.\n */\n\nexports.enable(load());\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n  try {\n    return window.localStorage;\n  } catch (e) {}\n}\n","\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = createDebug.debug = createDebug['default'] = createDebug;\nexports.coerce = coerce;\nexports.disable = disable;\nexports.enable = enable;\nexports.enabled = enabled;\nexports.humanize = require('ms');\n\n/**\n * Active `debug` instances.\n */\nexports.instances = [];\n\n/**\n * The currently active debug mode names, and names to skip.\n */\n\nexports.names = [];\nexports.skips = [];\n\n/**\n * Map of special \"%n\" handling functions, for the debug \"format\" argument.\n *\n * Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n */\n\nexports.formatters = {};\n\n/**\n * Select a color.\n * @param {String} namespace\n * @return {Number}\n * @api private\n */\n\nfunction selectColor(namespace) {\n  var hash = 0, i;\n\n  for (i in namespace) {\n    hash  = ((hash << 5) - hash) + namespace.charCodeAt(i);\n    hash |= 0; // Convert to 32bit integer\n  }\n\n  return exports.colors[Math.abs(hash) % exports.colors.length];\n}\n\n/**\n * Create a debugger with the given `namespace`.\n *\n * @param {String} namespace\n * @return {Function}\n * @api public\n */\n\nfunction createDebug(namespace) {\n\n  var prevTime;\n\n  function debug() {\n    // disabled?\n    if (!debug.enabled) return;\n\n    var self = debug;\n\n    // set `diff` timestamp\n    var curr = +new Date();\n    var ms = curr - (prevTime || curr);\n    self.diff = ms;\n    self.prev = prevTime;\n    self.curr = curr;\n    prevTime = curr;\n\n    // turn the `arguments` into a proper Array\n    var args = new Array(arguments.length);\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i];\n    }\n\n    args[0] = exports.coerce(args[0]);\n\n    if ('string' !== typeof args[0]) {\n      // anything else let's inspect with %O\n      args.unshift('%O');\n    }\n\n    // apply any `formatters` transformations\n    var index = 0;\n    args[0] = args[0].replace(/%([a-zA-Z%])/g, function(match, format) {\n      // if we encounter an escaped % then don't increase the array index\n      if (match === '%%') return match;\n      index++;\n      var formatter = exports.formatters[format];\n      if ('function' === typeof formatter) {\n        var val = args[index];\n        match = formatter.call(self, val);\n\n        // now we need to remove `args[index]` since it's inlined in the `format`\n        args.splice(index, 1);\n        index--;\n      }\n      return match;\n    });\n\n    // apply env-specific formatting (colors, etc.)\n    exports.formatArgs.call(self, args);\n\n    var logFn = debug.log || exports.log || console.log.bind(console);\n    logFn.apply(self, args);\n  }\n\n  debug.namespace = namespace;\n  debug.enabled = exports.enabled(namespace);\n  debug.useColors = exports.useColors();\n  debug.color = selectColor(namespace);\n  debug.destroy = destroy;\n\n  // env-specific initialization logic for debug instances\n  if ('function' === typeof exports.init) {\n    exports.init(debug);\n  }\n\n  exports.instances.push(debug);\n\n  return debug;\n}\n\nfunction destroy () {\n  var index = exports.instances.indexOf(this);\n  if (index !== -1) {\n    exports.instances.splice(index, 1);\n    return true;\n  } else {\n    return false;\n  }\n}\n\n/**\n * Enables a debug mode by namespaces. This can include modes\n * separated by a colon and wildcards.\n *\n * @param {String} namespaces\n * @api public\n */\n\nfunction enable(namespaces) {\n  exports.save(namespaces);\n\n  exports.names = [];\n  exports.skips = [];\n\n  var i;\n  var split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n  var len = split.length;\n\n  for (i = 0; i < len; i++) {\n    if (!split[i]) continue; // ignore empty strings\n    namespaces = split[i].replace(/\\*/g, '.*?');\n    if (namespaces[0] === '-') {\n      exports.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));\n    } else {\n      exports.names.push(new RegExp('^' + namespaces + '$'));\n    }\n  }\n\n  for (i = 0; i < exports.instances.length; i++) {\n    var instance = exports.instances[i];\n    instance.enabled = exports.enabled(instance.namespace);\n  }\n}\n\n/**\n * Disable debug output.\n *\n * @api public\n */\n\nfunction disable() {\n  exports.enable('');\n}\n\n/**\n * Returns true if the given mode name is enabled, false otherwise.\n *\n * @param {String} name\n * @return {Boolean}\n * @api public\n */\n\nfunction enabled(name) {\n  if (name[name.length - 1] === '*') {\n    return true;\n  }\n  var i, len;\n  for (i = 0, len = exports.skips.length; i < len; i++) {\n    if (exports.skips[i].test(name)) {\n      return false;\n    }\n  }\n  for (i = 0, len = exports.names.length; i < len; i++) {\n    if (exports.names[i].test(name)) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Coerce `val`.\n *\n * @param {Mixed} val\n * @return {Mixed}\n * @api private\n */\n\nfunction coerce(val) {\n  if (val instanceof Error) return val.stack || val.message;\n  return val;\n}\n","/**\n * Helpers.\n */\n\nvar s = 1000;\nvar m = s * 60;\nvar h = m * 60;\nvar d = h * 24;\nvar y = d * 365.25;\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} [options]\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function(val, options) {\n  options = options || {};\n  var type = typeof val;\n  if (type === 'string' && val.length > 0) {\n    return parse(val);\n  } else if (type === 'number' && isNaN(val) === false) {\n    return options.long ? fmtLong(val) : fmtShort(val);\n  }\n  throw new Error(\n    'val is not a non-empty string or a valid number. val=' +\n      JSON.stringify(val)\n  );\n};\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str);\n  if (str.length > 100) {\n    return;\n  }\n  var match = /^((?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(\n    str\n  );\n  if (!match) {\n    return;\n  }\n  var n = parseFloat(match[1]);\n  var type = (match[2] || 'ms').toLowerCase();\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y;\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d;\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h;\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m;\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s;\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  if (ms >= d) {\n    return Math.round(ms / d) + 'd';\n  }\n  if (ms >= h) {\n    return Math.round(ms / h) + 'h';\n  }\n  if (ms >= m) {\n    return Math.round(ms / m) + 'm';\n  }\n  if (ms >= s) {\n    return Math.round(ms / s) + 's';\n  }\n  return ms + 'ms';\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  return plural(ms, d, 'day') ||\n    plural(ms, h, 'hour') ||\n    plural(ms, m, 'minute') ||\n    plural(ms, s, 'second') ||\n    ms + ' ms';\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, n, name) {\n  if (ms < n) {\n    return;\n  }\n  if (ms < n * 1.5) {\n    return Math.floor(ms / n) + ' ' + name;\n  }\n  return Math.ceil(ms / n) + ' ' + name + 's';\n}\n"],"sourceRoot":""}