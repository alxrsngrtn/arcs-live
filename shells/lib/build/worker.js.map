{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///./shells/lib/source/worker.js","webpack:///(webpack)/buildin/global.js","webpack:///./build/runtime/particle-execution-context.js","webpack:///./build/platform/assert-web.js","webpack:///./build/runtime/api-channel.js","webpack:///./build/runtime/particle-spec.js","webpack:///./build/runtime/modality.js","webpack:///./build/runtime/recipe/type-checker.js","webpack:///./build/runtime/type.js","webpack:///./build/runtime/interface-info.js","webpack:///./build/runtime/schema.js","webpack:///./build/runtime/entity.js","webpack:///./build/runtime/reference.js","webpack:///./build/runtime/handle.js","webpack:///./build/runtime/arc-exceptions.js","webpack:///./build/runtime/id.js","webpack:///./build/runtime/random.js","webpack:///./build/runtime/symbols.js","webpack:///./build/runtime/slot-info.js","webpack:///./build/runtime/synthetic-types.js","webpack:///./build/runtime/type-variable-info.js","webpack:///./build/runtime/particle-check.js","webpack:///./build/runtime/particle-claim.js","webpack:///./build/runtime/util.js","webpack:///./build/runtime/slot-proxy.js","webpack:///./build/runtime/storage-proxy.js","webpack:///./build/platform/sourcemapped-stacktrace-node.js","webpack:///./build/runtime/storage/crdt-collection-model.js","webpack:///./build/runtime/wasm.js","webpack:///./build/runtime/particle.js","webpack:///./build/platform/loader-web.js","webpack:///./build/platform/loader-platform.js","webpack:///./build/runtime/loader.js","webpack:///./build/platform/fetch-web.js","webpack:///./build/platform/fs-web.js","webpack:///./build/platform/vm-web.js","webpack:///./build/runtime/converters/jsonldToManifest.js","webpack:///./build/runtime/dom-particle.js","webpack:///./modalities/dom/components/xen/xen-state.js","webpack:///./build/runtime/dom-particle-base.js","webpack:///./build/runtime/multiplexer-dom-particle.js","webpack:///./build/runtime/transformation-dom-particle.js","webpack:///./build/platform/log-web.js"],"names":[],"mappings":";AAAA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,kDAA0C,gCAAgC;AAC1E;AACA;;AAEA;AACA;AACA;AACA,gEAAwD,kBAAkB;AAC1E;AACA,yDAAiD,cAAc;AAC/D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAyC,iCAAiC;AAC1E,wHAAgH,mBAAmB,EAAE;AACrI;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;;AAGA;AACA;;;;;;;;AClFA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE8F;AACzB;AACR;;AAE7D;AACA;AACA,SAAS,mBAAmB;AAC5B;AACA;AACA;AACA,MAAM,qGAAwB,aAAa,uDAAE,iBAAiB,gEAAW,mBAAmB,4EAAc;AAC1G;;;;;;;;ACrBA;;AAEA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;;AAEA;AACA;AACA,4CAA4C;;AAE5C;;;;;;;;ACnBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACH;AACR;AACI;AAC6B;AACjB;AACJ;AAC7C;AACP;AACA;AACA;AACA,6BAA6B,uEAAqB;AAClD;AACA;AACA;AACA,yCAAyC,4DAAY;AACrD;AACA,uBAAuB,8DAAY;AACnC;AACA;AACA,8BAA8B,8DAAY;AAC1C;AACA;AACA;AACA;AACA,8BAA8B,8DAAY;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,0CAA0C,wDAAS;AACnD;AACA;AACA;AACA,gBAAgB,sEAAM,qEAAqE,mBAAmB,QAAQ,SAAS;AAC/H;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,4DAAS;AAC5C;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA,iBAAiB,kBAAkB;AACnC,aAAa;AACb;AACA,0GAA0G;AAC1G;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,4DAAS;AACpC;AACA;AACA;AACA,+BAA+B,0BAA0B;AACzD,SAAS;AACT;AACA;AACA,oCAAoC,gEAAa;AACjD;AACA,iBAAiB;AACjB,uCAAuC,0BAA0B;AACjE;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA,+DAA+D,cAAc;AAC7E;AACA,4BAA4B,sDAAa;AACzC;AACA;AACA;AACA;AACA;AACA,QAAQ,qDAAY;AACpB,6BAA6B,qDAAY;AACzC,QAAQ,qDAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sD;;;;;;;;AClPA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,sC;;;;;;;ACnBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,SAAI,IAAI,SAAI;AAC9B;AACA;AACA,4CAA4C,QAAQ;AACpD;AACA;AACA,eAAe,SAAI,IAAI,SAAI;AAC3B,mCAAmC,oCAAoC;AACvE;AACmD;AACD;AACjB;AACyB;AACP;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,kCAAkC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,OAAO,gBAAgB,YAAY,sBAAsB,eAAe;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,2BAA2B;AACrF;AACA;AACA,0DAA0D,2BAA2B;AACrF;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA,sBAAsB,oCAAoC,YAAY,UAAU,cAAc;AAC9F;AACA;AACA;AACA;AACA;AACA,sBAAsB,iCAAiC,cAAc;AACrE;AACA;AACA;AACA;AACA,0DAA0D,gCAAgC;AAC1F;AACA;AACA,0DAA0D,iCAAiC;AAC3F;AACA;AACA;AACA;AACA;AACA,0DAA0D,+DAA+D;AACzH;AACA;AACA,0DAA0D,8CAA8C;AACxG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM,0BAA0B,sGAAsG,GAAG,GAAG;AACpJ;AACA,QAAQ,uEAAsB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sEAAM;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM,kDAAkD,MAAM;AACtE;AACA;AACA;AACA,QAAQ,sEAAM,qCAAqC,GAAG;AACtD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,UAAU;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,UAAU;AACtD;AACA;AACA;AACA,6DAA6D,UAAU;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,uBAAuB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,sEAAM;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,uBAAuB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,yCAAyC;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,wBAAwB,sEAAM;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ,qCAAqC;AACrC,qDAAqD;AACrD,wCAAwC;AACxC,oCAAoC;AACpC,wBAAwB;AACxB,kEAAkE;AAClE,oCAAoC;AACpC,0EAA0E;AAC1E,yCAAyC;AACzC,4DAA4D;AAC5D,gDAAgD;AAChD,sDAAsD;AACtD,2FAA2F;AAC3F;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,2DAA2D,6CAAI;AAC/D;AACA;AACA,8FAA8F,8DAAY;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E,6CAAI;AAChF;AACA;AACA;AACA;AACA;AACA,4EAA4E,6CAAI;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC,uCAAuC;AACvC,wCAAwC;AACxC,iCAAiC;AACjC,oCAAoC;AACpC,kDAAkD;AAClD,8CAA8C;AAC9C,qDAAqD;AACrD,sDAAsD;AACtD,8DAA8D;AAC9D,uDAAuD;AACvD,kDAAkD;AAClD,yCAAyC;AACzC,8BAA8B;AAC9B,iDAAiD;AACjD,2CAA2C;AAC3C,gDAAgD;AAChD,yCAAyC;AACzC;AACA,iDAAiD;AACjD,4FAA4F;AAC5F,0CAA0C;AAC1C,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,6CAAI;AAC1E;AACA;AACA;AACA;AACA;AACA,4EAA4E,6CAAI;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,sEAAmB;AAC5C;AACA;AACA;AACA;AACwB;AACxB,uC;;;;;;;AChiBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACV;AACc;AACG;AACR;AACA;AAClD;AACA,yBAAyB,6CAAI,QAAQ,6CAAI;AACzC;AACA;AACA,yBAAyB,6CAAI;AAC7B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,mEAAW,eAAe,OAAO,GAAG,6CAA6C;AAChG;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,+CAA+C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,sBAAsB,yBAAyB;AAC/C,qBAAqB,mBAAmB;AACxC,gBAAgB,QAAQ,iDAAQ,6BAA6B,EAAE;AAC/D,gCAAgC,oCAAoC;AACpE;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,wBAAwB,qDAAQ;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,sEAAM;AAC9C,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,6GAA6G;AAC5H,sCAAsC,0DAA0D,OAAO,8HAA8H;AACrO;AACA,gBAAgB;AAChB;AACA;AACA,aAAa,6GAA6G;AAC1H,wCAAwC,0DAA0D,OAAO,qJAAqJ;AAC9P;AACA,iCAAiC,0HAA0H;AAC3J;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sEAAM,+GAA+G,EAAE;AACnI,SAAS;AACT;AACA;AACA;AACA,QAAQ,sEAAM;AACd,8CAA8C,wBAAwB,OAAO,sCAAsC;AACnH;AACA,eAAe,sDAAa;AAC5B;AACA;AACA;AACA;AACA;AACA,qDAAqD,KAAK;AAC1D;AACA,iCAAiC,UAAU,EAAE,MAAM,OAAO,cAAc;AACxE;AACA;AACA,2DAA2D,IAAI;AAC/D,4BAA4B,OAAO,EAAE,qBAAqB,EAAE,iCAAiC,GAAG,2BAA2B,GAAG,gBAAgB,EAAE,KAAK;AACrJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,yBAAyB;AACrF,4DAA4D,yBAAyB;AACrF,oEAAoE,EAAE;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,EAAE;AAClD;AACA,4BAA4B,OAAO,EAAE,iBAAiB;AACtD;AACA,gCAAgC,OAAO,eAAe,aAAa;AACnE;AACA;AACA,gCAAgC,OAAO,WAAW,OAAO;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,aAAa;AACzD;AACA;AACA,wCAAwC,QAAQ,KAAK,WAAW;AAChE;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E,aAAa;AACzF;AACA;AACA,oEAAoE,aAAa;AACjF;AACA;AACA,sFAAsF,aAAa;AACnG;AACA,+BAA+B,sEAAW;AAC1C;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oFAAoF,WAAW;AAC/F;AACA;AACA,4EAA4E,WAAW;AACvF;AACA;AACA,6FAA6F,WAAW;AACxG;AACA,uCAAuC,sEAAW;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,SAAS;AACjE;AACA;AACA,sFAAsF,SAAS;AAC/F;AACA;AACA,yCAAyC,sEAAW;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,KAAK;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;AC9UA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACnD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC;AAC9B;AACP;AACA;AACA;AACA;AACA,QAAQ,sEAAM,qFAAqF,MAAM;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,qBAAqB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;AC3CA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACuI;AAChI;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,qDAAY;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,qDAAY;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,6CAAI;AACnD,qCAAqC,qDAAY;AACjD,yCAAyC,qDAAY;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,qDAAY;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,sDAAa,6BAA6B,sDAAa;AACjG;AACA;AACA;AACA;AACA,uBAAuB,sDAAa;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,kBAAkB;AAC/D,6DAA6D,6CAAI;AACjE,2CAA2C,qDAAY;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,qDAAY;AAC3C,uDAAuD,uDAAc;AACrE,kEAAkE,uDAAc;AAChF;AACA,4DAA4D,0DAAiB;AAC7E,kEAAkE,0DAAiB;AACnF;AACA;AACA,kEAAkE,sDAAa;AAC/E;AACA,+BAA+B,6CAAI;AACnC;AACA,qDAAqD,qDAAY;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,sCAAsC,6CAAI;AAC1C;AACA,gCAAgC,qDAAY;AAC5C;AACA;AACA,iCAAiC,qDAAY;AAC7C;AACA;AACA,gCAAgC,qDAAY,yBAAyB,qDAAY;AACjF;AACA;AACA,mBAAmB,6CAAI;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,iDAAQ;AACxC;AACA;AACA;AACA;AACA,gCAAgC,sDAAa,yBAAyB,sDAAa;AACnF;AACA;AACA;AACA;AACA,kCAAkC,mDAAU,4BAA4B,mDAAU;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;ACpRA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACoD;AACf;AACK;AACK;AACY;AACpD;AACP;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,iDAAM;AAC5C;AACA,wCAAwC,uEAAgB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,gEAAa;AACtD;AACA,oCAAoC,sDAAQ;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,QAAQ;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iDAAM;AAC7B;AACA,4FAA4F,wBAAwB;AACpH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iDAAM;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,KAAK;AACrE;AACA;AACA,6DAA6D,KAAK;AAClE;AACA;AACA;AACA;AACA;AACA,kEAAkE,KAAK;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,kCAAkC,iDAAM;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,oCAAoC,uEAAgB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,uEAAgB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,uEAAgB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA,mBAAmB,mBAAmB;AACtC;AACA;AACA;AACA;AACA;AACA,wFAAwF,mBAAmB;AAC3G;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,sBAAsB;AACvD;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA,mBAAmB,sCAAsC;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,qCAAqC;AACvD;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,sBAAsB;AACvD;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA,gCAAgC,yCAAyC;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,wCAAwC;AACxE;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,qCAAqC,gEAAa;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,sBAAsB;AACvD;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,gCAAgC,sDAAQ;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA,+BAA+B,IAAI,GAAG,eAAe;AACrD;AACA;AACA;AACA;AACA,8BAA8B,EAAE,mBAAmB;AACnD;AACA,sBAAsB,aAAa;AACnC;AACA;AACA;AACA;AACA;AACA,+BAA+B,IAAI,GAAG,eAAe;AACrD;AACA;AACA;AACA;AACA,8BAA8B,EAAE,mBAAmB;AACnD;AACA,sBAAsB,aAAa;AACnC;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,sBAAsB;AACvD;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2DAAO;AAC1B;AACA;AACA,gBAAgB;AAChB;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA,gC;;;;;;;ACroBA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACI;AACR;AAC/C;AACA,WAAW,6CAAI;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,wBAAwB;AACrD;AACA;AACA,YAAY;AACZ;AACA,2BAA2B,qCAAqC;AAChE;AACA,YAAY;AACZ;AACA;AACA;AACA;AACA;AACA,0BAA0B,qDAAY;AACtC;AACA;AACA;AACA;AACA,2BAA2B,wBAAwB;AACnD;AACA;AACA,YAAY;AACZ;AACA,yBAAyB,qCAAqC;AAC9D;AACA,YAAY;AACZ;AACA;AACA;AACO;AACP;AACA,QAAQ,sEAAM;AACd,QAAQ,sEAAM;AACd,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,wBAAwB;AAChE;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,sBAAsB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,gBAAgB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,0BAA0B;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,qCAAqC,EAAE,kBAAkB,GAAG,sBAAsB;AAC7G;AACA;AACA;AACA;AACA;AACA,8BAA8B,eAAe,GAAG,4BAA4B,EAAE,iCAAiC;AAC/G;AACA;AACA;AACA;AACA,4BAA4B;AAC5B,EAAE;AACF,EAAE,8BAA8B;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA,2CAA2C,wBAAwB,OAAO,oEAAoE;AAC9I,uCAAuC,qCAAqC,OAAO,qCAAqC;AACxH;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,wBAAwB,OAAO,oFAAoF;AAC9J,uCAAuC,qCAAqC,OAAO,qCAAqC;AACxH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,0GAA0G;AAClL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,mEAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,gHAAgH;AAC7I;AACA,uCAAuC,qCAAqC,OAAO,qCAAqC;AACxH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,mEAAW,eAAe,oBAAoB,GAAG,yBAAyB;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,qDAAY,yBAAyB,6CAAI;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,6CAAI;AAClC,4BAA4B,qDAAY;AACxC,qBAAqB,gEAAgE;AACrF;AACA;AACA,mBAAmB,mEAAW,eAAe,aAAa,GAAG,cAAc;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8FAA8F,qDAAqD;AACnJ;AACA;AACA;AACA,gCAAgC,gHAAgH;AAChJ;AACA,oCAAoC,8FAA8F;AAClI,aAAa;AACb,SAAS;AACT;AACA,oFAAoF,4BAA4B;AAChH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,qDAAY;AAC/E;AACA;AACA,qBAAqB,mEAAW;AAChC;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB,mEAAW,eAAe,2CAA2C,GAAG,yBAAyB;AACtH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0C;;;;;;;AC3XA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACqC;AACQ;AACtC;AACP,mEAAmE;AACnE,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oCAAoC,qDAAqD;AACjH;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA,+BAA+B,WAAW,4BAA4B,EAAE;AACxE;AACA;AACA;AACA;AACA,wBAAwB,oCAAoC,2BAA2B,6CAAI,4BAA4B;AACvH;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,yCAAyC;AACpE;AACA,2BAA2B,uCAAuC;AAClE;AACA,oCAAoC,gCAAgC;AACpE;AACA;AACA;AACA;AACA,2BAA2B,gCAAgC;AAC3D;AACA,qDAAqD,UAAU,aAAa,UAAU;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mDAAU;AAC7B;AACA;AACA,eAAe,iDAAM;AACrB;AACA;AACA;AACA,4EAA4E,yBAAyB,GAAG,KAAK;AAC7G,kBAAkB,MAAM,EAAE,EAAE,qEAAqE;AACjG;AACA;AACA;AACA,+BAA+B,qBAAqB;AACpD,+EAA+E,yBAAyB,GAAG,KAAK;AAChH;AACA,4CAA4C,yBAAyB;AACrE;AACA;AACA,wCAAwC,KAAK,KAAK,uBAAuB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;ACjLA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACG;AACX;AACY;AACP;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA,oBAAoB,oBAAoB,OAAO,qBAAqB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,4DAAgB;AACrC;AACA;AACA,+CAA+C,mCAAmC;AAClF,mCAAmC,cAAc;AACjD;AACA;AACO;AACP;AACA,sEAAsE,KAAK,IAAI,sBAAsB;AACrG,kBAAkB,sBAAsB,EAAE,GAAG,kBAAkB,EAAE;AACjE;AACA;AACA;AACA,cAAc,+CAA+C,uCAAuC;AACpG,mBAAmB,oDAAoD,8CAA8C;AACrH,qBAAqB,wDAAwD,sDAAsD;AACnI;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sEAAM;AACtB,gBAAgB,sEAAM;AACtB;AACA;AACA;AACA,4CAA4C,4DAAgB;AAC5D;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yEAAyE,KAAK;AAC9E;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,2BAA2B,mDAAU;AACrC;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,qBAAqB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,4DAAgB;AAC7C,IAAI,sEAAM;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,mBAAmB,aAAa,WAAW;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,MAAM,iBAAiB,YAAY;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,KAAK,SAAS,eAAe,EAAE;AAClG,8BAA8B,MAAM,YAAY,eAAe;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,KAAK,WAAW,gBAAgB,GAAG;AAClG,0BAA0B,MAAM,YAAY,eAAe;AAC3D;AACA;AACA;AACA,wDAAwD,KAAK,yBAAyB,MAAM;AAC5F;AACA;AACA,qEAAqE,KAAK;AAC1E,wBAAwB,gBAAgB,gBAAgB,MAAM;AAC9D;AACA;AACA;AACA;AACA,uEAAuE,KAAK,WAAW,gBAAgB,GAAG;AAC1G,kCAAkC,MAAM,aAAa,kBAAkB,YAAY,EAAE;AACrF;AACA,aAAa;AACb;AACA;AACA,mCAAmC,uDAAS;AAC5C,4DAA4D,KAAK,uBAAuB,MAAM;AAC9F;AACA,iBAAiB,mEAAW,eAAe,mBAAmB,GAAG,WAAW,sDAAa,0BAA0B;AACnH,4DAA4D,KAAK,eAAe,MAAM;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,KAAK,iBAAiB,MAAM;AACzF;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,eAAe,cAAc,KAAK,aAAa,YAAY;AACxG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,uDAAS;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,uDAAS,YAAY,sDAAa;AACzD;AACA;AACA,wDAAwD,KAAK,uBAAuB,MAAM;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,KAAK,wBAAwB,MAAM;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;AClYA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACX;AACE;AACL;AACW;AAChD;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AAChC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,4DAAgB;AAC7B,+BAA+B,yCAAyC;AACxE;AACA;AACA;AACA;AACA;AACA,0BAA0B,4DAAS;AACnC;AACA,gBAAgB,sEAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACO;AACP;AACA;AACA;AACA,eAAe,KAAK,iDAAM,+BAA+B,MAAM,sDAAa,CAAC,iDAAM;AACnF;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,iDAAM;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;AC5FA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACkB;AACnB;AACP;AAC6D;AACnE;AACR;AACmB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,sEAAM;AACV,WAAW,cAAc;AACzB;AACA;AACA,QAAQ,iDAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,gEAAa;AAC5D;AACA;AACA,+CAA+C,kEAAe;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA,yEAAyE,QAAQ;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd,8BAA8B,iDAAM;AACpC,iBAAiB,iDAAM;AACvB;AACA;AACA;AACA,sBAAsB,4DAAgB;AACtC;AACA;AACA,QAAQ,iDAAM,wBAAwB,yCAAE;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,SAAS;AAC5B;AACA;AACA,2CAA2C,yCAAE;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,gBAAgB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,mDAAU;AAC3C;AACA;AACA,iCAAiC,sDAAa;AAC9C,mBAAmB,8DAAY;AAC/B;AACA,iCAAiC,sDAAa;AAC9C,uBAAuB,uDAAS;AAChC;AACA,yEAAyE,UAAU;AACnF;AACA;AACA;AACA,gBAAgB,MAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4BAA4B,4CAA4C;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,WAAW;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA,gBAAgB,MAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM;AACtB;AACA;AACA,kBAAkB,2BAA2B;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,gCAAgC,uDAAc;AAC9C;AACA;AACA,qCAAqC,0DAAiB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,mDAAU;AAClC;AACA;AACA;AACA;AACA,kC;;;;;;;AC/YA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,iBAAiB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,sBAAsB;AACjF;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,6CAA6C,gBAAgB,wCAAwC,YAAY,yBAAyB,aAAa,IAAI,mBAAmB;AAC9K;AACA;AACA;AACO;AACP;AACA;AACA,2CAA2C,gBAAgB,iCAAiC,YAAY,eAAe,aAAa,IAAI,mBAAmB;AAC3J;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,0C;;;;;;;AC5EA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACqC;AACrC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,iDAAM;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,UAAU,GAAG,sBAAsB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,sBAAsB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,uFAAuF;AACvF;AACA;AACA;AACA;AACA,8B;;;;;;;AC3GA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,kC;;;;;;;AC1BA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,uBAAuB,IAAI,EAAE;AAC/E;AACO;AACP,mC;;;;;;;ACbA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,qBAAqB;AAC7C;AACA;AACA;AACA,qC;;;;;;;ACrBA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACjC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2C;;;;;;;AC9BA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACd;AACgC;AAC9D;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,iDAAQ,0BAA0B,iDAAQ;AACpF;AACA;AACA;AACA,0CAA0C,mDAAU,0BAA0B,mDAAU;AACxF,iCAAiC,iDAAM;AACvC;AACA;AACA;AACA,qCAAqC,mDAAU;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,iDAAQ,0BAA0B,iDAAQ;AACvF;AACA;AACA;AACA,6CAA6C,mDAAU,0BAA0B,mDAAU;AAC3F,iCAAiC,iDAAM;AACvC;AACA;AACA;AACA,wCAAwC,mDAAU;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,mDAAU,uBAAuB,mDAAU;AAC/E,uEAAuE,KAAK,OAAO,KAAK;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,qDAAY;AAC/C,oBAAoB;AACpB;AACA,gBAAgB;AAChB;AACA;AACA,QAAQ,sEAAM;AACd;AACA,QAAQ,sEAAM;AACd;AACA;AACA,mCAAmC,qDAAY;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sEAAM;AAClB,4CAA4C,qDAAY;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA,YAAY,sEAAM;AAClB,4CAA4C,qDAAY;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,6CAAI,iEAAiE,6CAAI;AAChJ;AACA;AACA;AACA;AACA;AACA,8C;;;;;;;ACnMA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAC0D;AACP;AACnD;AACO;AACP;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AACxB;AACP;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,sEAAoB;AACvD;AACA;AACA;AACA,8BAA8B,iBAAiB;AAC/C;AACA,wBAAwB,aAAa,GAAG,mCAAmC;AAC3E;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2GAA2G,UAAU;AACrH,mCAAmC,IAAI;AACvC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,SAAS;AAC9B;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E,aAAa;AACxF;AACA;AACA;AACA;AACA,iCAAiC,uBAAuB;AACxD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,wBAAwB,MAAM;AAC9B;AACA,gCAAgC,MAAM;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,0C;;;;;;;ACjIA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,CAAC,8BAA8B;AACxB;AACP;AACA;AACA;AACA;AACA;AACA,wBAAwB,iBAAiB,GAAG,mCAAmC;AAC/E;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,yBAAyB,EAAE,SAAS;AACzD;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,aAAa;AACpF;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,+BAA+B,kDAAkD;AACjF;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0C;;;;;;;ACvEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACnD;AACA;AACA;AACO;AACP,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,0CAA0C;AACjD,gC;;;;;;;ACtEA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,wCAAwC,EAAE;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;ACtDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACwB;AACrB;AACmB;AACX;AACjC;AAC7B;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,uDAAc;AAC1C;AACA;AACA,4BAA4B,0DAAiB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sFAAa;AACzB,YAAY,8FAAa;AACzB;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,mBAAmB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA,0CAA0C,QAAQ,iCAAiC,SAAS;AAC5F,8BAA8B,aAAa;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,SAAS;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,QAAQ,kCAAkC,gBAAgB;AACpG,8BAA8B,aAAa;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,mBAAmB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,mBAAmB;AAC/C;AACA,wFAAwF;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,yCAAE;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,yBAAyB,qFAAmB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,qFAAmB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,SAAS;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E,uBAAuB;AAClG;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB,2CAA2C,EAAE;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA,wDAAwD,EAAE;AAC1D;AACA,sDAAsD,iDAAiD;AACvG,oDAAoD,EAAE;AACtD,4BAA4B,WAAW,OAAO,qDAAqD;AACnG;AACA;AACA,oCAAoC,0CAA0C;AAC9E;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B,gDAAgD,EAAE;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB,4CAA4C,EAAE;AAC9C;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,0EAA0E;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E,cAAc;AAC1F;AACA;AACA,6EAA6E,eAAe;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,kEAAe;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;ACnjBA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,wD;;;;;;;ACbA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACsD;AAC/C;AACP;AACA,kBAAkB;AAClB;AACA;AACA,sBAAsB,kBAAkB;AACxC;AACA;AACA;AACA,oCAAoC,6BAA6B;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sEAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,cAAc;AACvC,yBAAyB,6BAA6B;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iD;;;;;;;ACvHA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACd;AACI;AACD;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,WAAW;AAC1B;AACA;AACA,YAAY,iDAAM;AAClB;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,iDAAM;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,WAAW;AAC/C;AACA,uDAAuD,WAAW;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,KAAK;AACzC;AACA,iEAAiE,KAAK;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,KAAK,kBAAkB,SAAS;AACxG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,IAAI,wBAAwB,SAAS;AAC7G;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,MAAM,iBAAiB,SAAS;AACxG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+GAA+G,SAAS;AACxH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,cAAc,QAAQ;AAC7F,uBAAuB,gBAAgB;AACvC;AACA;AACA,qEAAqE,eAAe,GAAG,gBAAgB;AACvG,uBAAuB,YAAY,GAAG,YAAY;AAClD;AACA;AACA,gEAAgE,UAAU,GAAG,WAAW;AACxF,uBAAuB,YAAY,GAAG,YAAY;AAClD;AACA,0CAA0C;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,uDAAuD;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,+EAA+E;AACzH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,sCAAsC,EAAE;AAC5E,gDAAgD,4CAA4C,KAAK,IAAI,EAAE;AACvG;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,gBAAgB,GAAG,gBAAgB;AACxE;AACA,uBAAuB,YAAY;AACnC;AACA;AACA,2BAA2B,SAAS;AACpC;AACA,gDAAgD;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,EAAE;AAClD,iDAAiD,EAAE;AACnD;AACA;AACA,0BAA0B,EAAE;AAC5B;AACA;AACA;AACA,uCAAuC,iEAAiE,EAAE;AAC1G,qCAAqC,EAAE;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,2BAA2B,EAAE;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB,2DAA2D,cAAc;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,gBAAgB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,2BAA2B,qDAAQ;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,eAAe;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E,KAAK;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oDAAS;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oDAAS;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,eAAe;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,iDAAM;AACnB;AACA,qCAAqC,iDAAM;AAC3C;AACA;AACA;AACA,iDAAiD;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,gBAAgB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;ACjlBA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAC4C;AACH;AACJ;AACrC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,eAAe;AAC3C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iBAAiB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,qDAAU,4BAA4B,wDAAa;AAC3F,0DAA0D,sCAAsC;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,iDAAM;AACrB;AACA;AACA,eAAe,iDAAM;AACrB;AACA;AACA,QAAQ,iDAAM;AACd;AACA;AACA,wCAAwC;AACxC,uDAAuD;AACvD,gCAAgC;AAChC;AACA,oC;;;;;;;AChOA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAC0D;AACN;AACpD,YAAY,uEAAU;AACtB,aAAa,uEAAU;AACvB,cAAc,uEAAU;AACjB,6BAA6B,sEAAkB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,IAAI,kBAAkB,SAAS;AACvD,qDAAqD,iCAAiC;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uEAAU;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;ACpFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAC8C;AACI;AACO;AACuB;AACM;AACtF;AACO,iCAAiC,yDAAM;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,uEAAQ;AACpB,YAAY,iFAAW;AACvB,YAAY,mHAAsB;AAClC,4BAA4B,oEAAW;AACvC,YAAY,4HAAyB;AACrC;AACA,gCAAgC,EAAE;AAClC;AACA,SAAS;AACT;AACA;AACA,2C;;;;;;;AC9DA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACF;AACN;AACA;AACyB;AACpB;AACuB;AAC9B;AACQ;AAC4B;AAC7E;AACA;AACA,0BAA0B,KAAK;AAC/B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,OAAO,EAAE,KAAK;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,YAAY;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,oEAAK;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sDAAE,iBAAiB,WAAW;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA,uBAAuB,oEAAK,2EAA2E,gFAAgB,gBAAgB,wBAAwB;AAC/J;AACA,mBAAmB,oEAAK,uDAAuD,gFAAgB;AAC/F;AACA,eAAe,oEAAK;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,sDAAE,cAAc,0CAA0C;AACrF;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,YAAY,mEAAK;AACjB;AACA,0FAA0F,EAAE;AAC5F;AACA,sCAAsC,0CAA0C;AAChF,QAAQ,sEAAM,iHAAiH,SAAS;AACxI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd,gCAAgC,CAAC,+DAAQ,EAAE,yEAAW,EAAE,oHAAyB,EAAE,2GAAsB,aAAa,6DAAe,qCAAqC;AAC1K;AACA;AACA,kC;;;;;;;AC5IA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,MAAM;AAClB;AACA;AAC+B;AAC/B,qC;;;;;;;ACfA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;;;;;;;;ACVP;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;;;;;;;;ACVP;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,oBAAoB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,aAAa;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,UAAU;AACzD;AACA,uBAAuB,UAAU;AACjC;AACA,6BAA6B,sBAAsB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,KAAK,GAAG,cAAc;AAClD;AACA;AACA;AACA;AACA;AACA;AACA,4C;;;;;;;ACzGA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACiF;AACxB;AACzD;AACA;AACA;AACA;AACO,0BAA0B,iGAAa,CAAC,qEAAe;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,MAAM;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,kBAAkB;AACpE;AACA;AACA;AACA;AACA,0BAA0B,OAAO,GAAG,uBAAuB;AAC3D;AACA;AACA,4BAA4B,eAAe;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,eAAe;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,gCAAgC,eAAe;AAC/C;AACA;AACA;AACA,yBAAyB,gBAAgB;AACzC;AACA;AACA,2BAA2B,OAAO;AAClC;AACA;AACA;AACA,oCAAoC,IAAI;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;ACzKA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,IAAI;AAC3B;AACA;AACA;;AAEsC;;;;;;;;AC7ItC;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmE;AAC1B;AACzC;AACA;AACA;AACO,8BAA8B,qDAAQ;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,WAAW;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,IAAI;AAC7B;AACA;AACA;AACA;AACA,iFAAiF,SAAS;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D,SAAS,wBAAwB,SAAS,aAAa,GAAG,WAAW;AACnI,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,yBAAyB,gBAAgB;AACzC;AACA,2BAA2B,OAAO;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oDAAS,sBAAsB,qDAAU;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,qDAAU;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,qDAAU,sBAAsB,wDAAa;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,qDAAU,sBAAsB,wDAAa;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,oDAAS;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,qDAAU,sBAAsB,wDAAa;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6C;;;;;;;AClRA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmD;AACD;AAC2B;AACxC;AAC9B,qCAAqC,yFAAyB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,sCAAsC,QAAQ,MAAM;AAChG;AACA;AACA,yCAAyC,2BAA2B,MAAM,QAAQ;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,kBAAkB,OAAO,GAAG,kEAAkE;AAC9F,2BAA2B,eAAe;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iDAAM;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,uFAAuF,MAAM;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,8DAAY;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oGAAoG,mCAAmC,GAAG,6DAA6D;AACvM;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,eAAe,QAAQ,EAAE;AAChD;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM,6DAA6D,SAAS,sBAAsB,aAAa;AACvH,8BAA8B,0CAA0C,qBAAqB;AAC7F,uBAAuB,eAAe;AACtC;AACA;AACA,+BAA+B,OAAO;AACtC,2FAA2F,OAAO;AAClG;AACA;AACA;AACA,0DAA0D,EAAE,WAAW,cAAc,YAAY,EAAE,KAAK,cAAc;AACtH,aAAa;AACb,2BAA2B,YAAY,4DAA4D,EAAE;AACrG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oD;;;;;;;AChLA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACgD;AACX;AACrC;AACA;AACA;AACA;AACA;AACO,wCAAwC,4DAAW;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,QAAQ,iDAAM,cAAc;AAChF;AACA;AACA,uD;;;;;;;AC7CA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,SAAS;AAClB,mBAAmB,iBAAiB,cAAc,0BAA0B,oBAAoB;AAChG;;AAEA;AACA;AACA,uDAAuD,gBAAgB;AACvE;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"worker.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 0);\n","/**\n * @license\n * Copyright 2019 Google LLC.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n\nimport {ParticleExecutionContext} from '../../../build/runtime/particle-execution-context.js';\nimport {PlatformLoader} from '../../../build/platform/loader-web.js';\nimport {Id, IdGenerator} from '../../../build/runtime/id.js';\n\nself.onmessage = function(e) {\n  self.onmessage = null;\n  const {id, base, logLevel} = e.data;\n  // TODO(sjmiles): happens too late for modules that immediately construct loggers, but\n  // soon enough for `log` injected into Particle.\n  global.logLevel = logLevel;\n  new ParticleExecutionContext(e.ports[0], Id.fromString(id), IdGenerator.newSession(), new PlatformLoader(base));\n};\n","var g;\n\n// This works in non-strict mode\ng = (function() {\n\treturn this;\n})();\n\ntry {\n\t// This works if eval is allowed (see CSP)\n\tg = g || new Function(\"return this\")();\n} catch (e) {\n\t// This works if the window reference is available\n\tif (typeof window === \"object\") g = window;\n}\n\n// g can still be undefined, but nothing to do about it...\n// We return undefined, instead of nothing here, so it's\n// easier to handle this case. if(!global) { ...}\n\nmodule.exports = g;\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\nimport { PECInnerPort } from './api-channel.js';\nimport { handleFor } from './handle.js';\nimport { SlotProxy } from './slot-proxy.js';\nimport { StorageProxy, StorageProxyScheduler } from './storage-proxy.js';\nimport { WasmContainer, WasmParticle } from './wasm.js';\nimport { UserException } from './arc-exceptions.js';\nexport class ParticleExecutionContext {\n    constructor(port, pecId, idGenerator, loader) {\n        this.particles = [];\n        this.pendingLoads = [];\n        this.scheduler = new StorageProxyScheduler();\n        this.keyedProxies = {};\n        this.wasmContainers = {};\n        const pec = this;\n        this.apiPort = new class extends PECInnerPort {\n            onDefineHandle(identifier, type, name) {\n                return StorageProxy.newProxy(identifier, type, this, pec, pec.scheduler, name);\n            }\n            onGetBackingStoreCallback(callback, type, name, id, storageKey) {\n                const proxy = StorageProxy.newProxy(id, type, this, pec, pec.scheduler, name);\n                proxy.storageKey = storageKey;\n                return [proxy, () => callback(proxy, storageKey)];\n            }\n            onCreateHandleCallback(callback, type, name, id) {\n                const proxy = StorageProxy.newProxy(id, type, this, pec, pec.scheduler, name);\n                return [proxy, () => callback(proxy)];\n            }\n            onMapHandleCallback(callback, id) {\n                return [id, () => callback(id)];\n            }\n            onCreateSlotCallback(callback, hostedSlotId) {\n                return [hostedSlotId, () => callback(hostedSlotId)];\n            }\n            onInnerArcRender(transformationParticle, transformationSlotName, hostedSlotId, content) {\n                transformationParticle.renderHostedSlot(transformationSlotName, hostedSlotId, content);\n            }\n            onStop() {\n                if (global['close']) {\n                    global['close']();\n                }\n            }\n            async onInstantiateParticle(id, spec, proxies) {\n                return pec.instantiateParticle(id, spec, proxies);\n            }\n            onSimpleCallback(callback, data) {\n                callback(data);\n            }\n            onConstructArcCallback(callback, arc) {\n                callback(arc);\n            }\n            onAwaitIdle(version) {\n                pec.idle.then(a => {\n                    // TODO: dom-particles update is async, this is a workaround to allow dom-particles to\n                    // update relevance, after handles are updated. Needs better idle signal.\n                    setTimeout(() => this.Idle(version, pec.relevance), 0);\n                });\n            }\n            onUIEvent(particle, slotName, event) {\n                particle.fireEvent(slotName, event);\n            }\n            onStartRender(particle, slotName, providedSlots, contentTypes) {\n                particle.addSlotProxy(new SlotProxy(this, particle, slotName, providedSlots));\n                particle.renderSlot(slotName, contentTypes);\n            }\n            onStopRender(particle, slotName) {\n                assert(particle.hasSlotProxy(slotName), `Stop render called for particle ${particle.spec.name} slot ${slotName} without start render being called.`);\n                particle.removeSlotProxy(slotName);\n            }\n        }(port);\n        this.pecId = pecId;\n        this.idGenerator = idGenerator;\n        this.loader = loader;\n        loader.setParticleExecutionContext(this);\n        /*\n         * This code ensures that the relevant types are known\n         * in the scope object, because otherwise we can't do\n         * particleSpec resolution, which is currently a necessary\n         * part of particle construction.\n         *\n         * Possibly we should eventually consider having particle\n         * specifications separated from particle classes - and\n         * only keeping type information on the arc side.\n         */\n    }\n    generateID() {\n        return this.idGenerator.newChildId(this.pecId).toString();\n    }\n    innerArcHandle(arcId, particleId) {\n        const pec = this;\n        return {\n            async createHandle(type, name, hostParticle) {\n                return new Promise((resolve, reject) => pec.apiPort.ArcCreateHandle(proxy => {\n                    const handle = handleFor(proxy, pec.idGenerator, name, particleId);\n                    resolve(handle);\n                    if (hostParticle) {\n                        proxy.register(hostParticle, handle);\n                    }\n                }, arcId, type, name));\n            },\n            async mapHandle(handle) {\n                return new Promise((resolve, reject) => pec.apiPort.ArcMapHandle(id => {\n                    resolve(id);\n                }, arcId, handle)); // recipe handle vs not?\n            },\n            async createSlot(transformationParticle, transformationSlotName, handleId) {\n                // handleId: the ID of a handle (returned by `createHandle` above) this slot is rendering; null - if not applicable.\n                // TODO: support multiple handle IDs.\n                return new Promise((resolve, reject) => pec.apiPort.ArcCreateSlot(hostedSlotId => resolve(hostedSlotId), arcId, transformationParticle, transformationSlotName, handleId));\n            },\n            async loadRecipe(recipe) {\n                // TODO: do we want to return a promise on completion?\n                return new Promise((resolve, reject) => pec.apiPort.ArcLoadRecipe(arcId, recipe, response => {\n                    if (response.error) {\n                        reject(response.error);\n                    }\n                    else {\n                        resolve(response);\n                    }\n                }));\n            }\n        };\n    }\n    getStorageProxy(storageKey, type) {\n        if (!this.keyedProxies[storageKey]) {\n            this.keyedProxies[storageKey] = new Promise((resolve, reject) => {\n                this.apiPort.GetBackingStore((proxy, storageKey) => {\n                    this.keyedProxies[storageKey] = proxy;\n                    resolve(proxy);\n                }, storageKey, type);\n            });\n        }\n        return this.keyedProxies[storageKey];\n    }\n    capabilities(hasInnerArcs) {\n        const cap = {\n            // TODO(sjmiles): experimental `services` impl\n            serviceRequest: (particle, args, callback) => {\n                this.apiPort.ServiceRequest(particle, args, callback);\n            }\n        };\n        if (hasInnerArcs) {\n            // TODO: Particle doesn't have an id field; not sure if it needs one or innerArcHandle shouldn't have that arg.\n            cap.constructInnerArc = async (particle) => {\n                return new Promise((resolve, reject) => this.apiPort.ConstructInnerArc(arcId => resolve(this.innerArcHandle(arcId, undefined)), particle));\n            };\n        }\n        return cap;\n    }\n    // tslint:disable-next-line: no-any\n    async instantiateParticle(id, spec, proxies) {\n        let resolve;\n        const p = new Promise(res => resolve = res);\n        this.pendingLoads.push(p);\n        let particle;\n        if (spec.implFile && spec.implFile.endsWith('.wasm')) {\n            particle = await this.loadWasmParticle(spec);\n            particle.setCapabilities(this.capabilities(false));\n        }\n        else {\n            const clazz = await this.loader.loadParticleClass(spec);\n            particle = new clazz();\n            particle.setCapabilities(this.capabilities(true));\n        }\n        this.particles.push(particle);\n        const handleMap = new Map();\n        const registerList = [];\n        proxies.forEach((proxy, name) => {\n            const connSpec = spec.handleConnectionMap.get(name);\n            const handle = handleFor(proxy, this.idGenerator, name, id, connSpec.isInput, connSpec.isOutput);\n            handleMap.set(name, handle);\n            // Defer registration of handles with proxies until after particles have a chance to\n            // configure them in setHandles.\n            registerList.push({ proxy, particle, handle });\n        });\n        return [particle, async () => {\n                await particle.callSetHandles(handleMap, err => {\n                    const exc = new UserException(err, 'setHandles', id, spec.name);\n                    this.apiPort.ReportExceptionInHost(exc);\n                });\n                registerList.forEach(({ proxy, particle, handle }) => proxy.register(particle, handle));\n                const idx = this.pendingLoads.indexOf(p);\n                this.pendingLoads.splice(idx, 1);\n                resolve();\n            }];\n    }\n    async loadWasmParticle(spec) {\n        assert(spec.name.length > 0);\n        let container = this.wasmContainers[spec.implFile];\n        if (!container) {\n            const buffer = await this.loader.loadBinary(spec.implFile);\n            if (!buffer || buffer.byteLength === 0) {\n                throw new Error(`Failed to load binary file '${spec.implFile}'`);\n            }\n            container = new WasmContainer();\n            await container.initialize(buffer);\n            this.wasmContainers[spec.implFile] = container;\n        }\n        // Particle constructor expects spec to be attached to the class object (and attaches it to\n        // the particle instance at that time).\n        WasmParticle.spec = spec;\n        const particle = new WasmParticle(container);\n        WasmParticle.spec = null;\n        return particle;\n    }\n    get relevance() {\n        const rMap = new Map();\n        this.particles.forEach(p => {\n            if (p.relevances.length === 0) {\n                return;\n            }\n            rMap.set(p, p.relevances);\n            p.relevances.length = 0; // truncate\n        });\n        return rMap;\n    }\n    get busy() {\n        if (this.pendingLoads.length > 0 || this.scheduler.busy) {\n            return true;\n        }\n        if (this.particles.filter(particle => particle.busy).length > 0) {\n            return true;\n        }\n        return false;\n    }\n    get idle() {\n        if (!this.busy) {\n            return Promise.resolve();\n        }\n        const busyParticlePromises = this.particles.filter(async (particle) => particle.busy).map(async (particle) => particle.idle);\n        return Promise.all([this.scheduler.idle, ...this.pendingLoads, ...busyParticlePromises]).then(() => this.idle);\n    }\n}\n//# sourceMappingURL=particle-execution-context.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n// tslint:disable-next-line: no-any\nexport function assert(test, message) {\n    if (!test) {\n        if (typeof window !== 'object') {\n            // tslint:disable-next-line: no-debugger\n            debugger; // eslint-disable-line no-debugger\n        }\n        throw new Error(message);\n    }\n}\n//# sourceMappingURL=assert-web.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nvar __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __param = (this && this.__param) || function (paramIndex, decorator) {\n    return function (target, key) { decorator(target, key, paramIndex); }\n};\nimport { assert } from '../platform/assert-web.js';\nimport { ParticleSpec } from './particle-spec.js';\nimport { Type } from './type.js';\nimport { PropagatedException } from './arc-exceptions.js';\nimport { floatingPromiseToAudit } from './util.js';\nvar MappingType;\n(function (MappingType) {\n    MappingType[MappingType[\"Mapped\"] = 0] = \"Mapped\";\n    MappingType[MappingType[\"LocalMapped\"] = 1] = \"LocalMapped\";\n    MappingType[MappingType[\"RemoteMapped\"] = 2] = \"RemoteMapped\";\n    MappingType[MappingType[\"Direct\"] = 3] = \"Direct\";\n    MappingType[MappingType[\"ObjectMap\"] = 4] = \"ObjectMap\";\n    MappingType[MappingType[\"List\"] = 5] = \"List\";\n    MappingType[MappingType[\"ByLiteral\"] = 6] = \"ByLiteral\";\n})(MappingType || (MappingType = {}));\nconst targets = new Map();\nfunction setPropertyKey(target, propertyKey) {\n    let map = targets.get(target);\n    if (map == undefined) {\n        map = new Map();\n        targets.set(target, map);\n    }\n    let list = map.get(propertyKey);\n    if (list == undefined) {\n        list = [];\n        map.set(propertyKey, list);\n    }\n    return list;\n}\nfunction getPropertyKey(target, propertyKey, parameterIndex) {\n    const map = targets.get(target);\n    if (map) {\n        const list = map.get(propertyKey);\n        if (list) {\n            const result = list[parameterIndex];\n            if (result) {\n                return result;\n            }\n        }\n    }\n    throw new Error(`the target ${target}, propertyKey ${propertyKey} and parameterIndex ${parameterIndex} provided did not exist`);\n}\nfunction set(target, propertyKey, parameterIndex, info) {\n    const list = setPropertyKey(target, propertyKey);\n    list[parameterIndex] = info;\n}\nfunction Direct(target, propertyKey, parameterIndex) {\n    set(target.constructor, propertyKey, parameterIndex, { type: MappingType.Direct });\n}\nfunction Mapped(target, propertyKey, parameterIndex) {\n    set(target.constructor, propertyKey, parameterIndex, { type: MappingType.Mapped });\n}\nfunction ByLiteral(constructor) {\n    return (target, propertyKey, parameterIndex) => {\n        const info = { type: MappingType.ByLiteral, converter: constructor };\n        set(target.constructor, propertyKey, parameterIndex, info);\n    };\n}\nfunction ObjectMap(key, value) {\n    return (target, propertyKey, parameterIndex) => {\n        const info = { type: MappingType.ObjectMap, key: { type: key }, value: { type: value } };\n        set(target.constructor, propertyKey, parameterIndex, info);\n    };\n}\nfunction List(value) {\n    return (target, propertyKey, parameterIndex) => {\n        const info = { type: MappingType.List, value: { type: value } };\n        set(target.constructor, propertyKey, parameterIndex, info);\n    };\n}\nfunction LocalMapped(target, propertyKey, parameterIndex) {\n    set(target.constructor, propertyKey, parameterIndex, { type: MappingType.LocalMapped });\n}\nfunction RemoteMapped(target, propertyKey, parameterIndex) {\n    set(target.constructor, propertyKey, parameterIndex, { type: MappingType.RemoteMapped });\n}\nfunction NoArgs(target, propertyKey) {\n    setPropertyKey(target.constructor, propertyKey);\n}\nfunction RedundantInitializer(target, propertyKey, parameterIndex) {\n    set(target.constructor, propertyKey, parameterIndex, { type: MappingType.Direct, initializer: true, redundant: true });\n}\nfunction Initializer(target, propertyKey, parameterIndex) {\n    set(target.constructor, propertyKey, parameterIndex, { type: MappingType.Direct, initializer: true });\n}\nfunction Identifier(target, propertyKey, parameterIndex) {\n    getPropertyKey(target.constructor, propertyKey, parameterIndex).identifier = true;\n}\nfunction RemoteIgnore(target, propertyKey, parameterIndex) {\n    getPropertyKey(target.constructor, propertyKey, parameterIndex).ignore = true;\n}\nclass ThingMapper {\n    constructor(prefix) {\n        this._prefix = prefix;\n        this._nextIdentifier = 0;\n        this._idMap = new Map();\n        this._reverseIdMap = new Map();\n    }\n    _newIdentifier() {\n        return this._prefix + (this._nextIdentifier++);\n    }\n    createMappingForThing(thing, requestedId = undefined) {\n        assert(!this._reverseIdMap.has(thing));\n        let id;\n        if (requestedId) {\n            id = requestedId;\n        }\n        else if (thing.apiChannelMappingId) {\n            id = thing.apiChannelMappingId;\n        }\n        else {\n            id = this._newIdentifier();\n        }\n        assert(!this._idMap.has(id), `${requestedId ? 'requestedId' : (thing.apiChannelMappingId ? 'apiChannelMappingId' : 'newIdentifier()')} ${id} already in use`);\n        // TODO: Awaiting this promise causes tests to fail...\n        floatingPromiseToAudit(this.establishThingMapping(id, thing));\n        return id;\n    }\n    maybeCreateMappingForThing(thing) {\n        if (this.hasMappingForThing(thing)) {\n            return this.identifierForThing(thing);\n        }\n        return this.createMappingForThing(thing);\n    }\n    async establishThingMapping(id, thing) {\n        let continuation;\n        if (Array.isArray(thing)) {\n            [thing, continuation] = thing;\n        }\n        this._idMap.set(id, thing);\n        if (thing instanceof Promise) {\n            assert(continuation == null);\n            await this.establishThingMapping(id, await thing);\n        }\n        else {\n            this._reverseIdMap.set(thing, id);\n            if (continuation) {\n                await continuation();\n            }\n        }\n    }\n    hasMappingForThing(thing) {\n        return this._reverseIdMap.has(thing);\n    }\n    identifierForThing(thing) {\n        assert(this._reverseIdMap.has(thing), `Missing thing [${thing}]`);\n        return this._reverseIdMap.get(thing);\n    }\n    thingForIdentifier(id) {\n        assert(this._idMap.has(id), `Missing id: ${id}`);\n        return this._idMap.get(id);\n    }\n}\nexport class APIPort {\n    constructor(messagePort, prefix) {\n        this._port = messagePort;\n        this._mapper = new ThingMapper(prefix);\n        this._port.onmessage = async (e) => this._processMessage(e);\n        this.inspector = null;\n        this.attachStack = false;\n        this.messageCount = 0;\n        this._testingHook();\n    }\n    // Overridden by unit tests.\n    _testingHook() {\n    }\n    close() {\n        this._port.close();\n    }\n    async _processMessage(e) {\n        assert(this['before' + e.data.messageType] !== undefined);\n        const count = this.messageCount++;\n        if (this.inspector) {\n            this.inspector.pecMessage('on' + e.data.messageType, e.data.messageBody, count, e.data.stack);\n        }\n        this['before' + e.data.messageType](e.data.messageBody);\n    }\n    send(name, args) {\n        const call = { messageType: name, messageBody: args, stack: this.attachStack ? new Error().stack : undefined };\n        const count = this.messageCount++;\n        if (this.inspector) {\n            this.inspector.pecMessage(name, args, count, new Error().stack || '');\n        }\n        this._port.postMessage(call);\n    }\n    supportsJavaParticle() {\n        // TODO: improve heuristics.\n        return Object.getPrototypeOf(this._port.constructor).name === 'MessagePort';\n    }\n}\n// The horror. From https://davidwalsh.name/javascript-arguments\nfunction getArgs(func) {\n    // First match everything inside the function argument parens.\n    const args = func.toString().match(/.*?\\(([^)]*)\\)/)[1];\n    // Split the arguments string into an array comma delimited.\n    return args.split(',').map((arg) => {\n        // Ensure no inline comments are parsed and trim the whitespace.\n        return arg.replace(/\\/\\*.*\\*\\//, '').trim();\n        // Ensure no undefined values are added.\n    }).filter((arg) => arg);\n}\n// value is covariant with info, and errors will be found\n// at start of runtime.\n// tslint:disable-next-line: no-any\nfunction convert(info, value, mapper) {\n    if (info === undefined) {\n        return;\n    }\n    switch (info.type) {\n        case MappingType.Mapped:\n            return mapper.identifierForThing(value);\n        case MappingType.LocalMapped:\n            return mapper.maybeCreateMappingForThing(value);\n        case MappingType.RemoteMapped:\n            // This is on the local side, so we don't do anything here.\n            return value;\n        case MappingType.Direct:\n            return value;\n        case MappingType.ObjectMap: {\n            const r = {};\n            value.forEach((childvalue, key) => r[convert(info.key, key, mapper)] = convert(info.value, childvalue, mapper));\n            return r;\n        }\n        case MappingType.List:\n            return value.map(v => convert(info.value, v, mapper));\n        case MappingType.ByLiteral:\n            return value.toLiteral();\n        default:\n            throw new Error(`Can't yet send MappingType ${info.type}`);\n    }\n}\n// value is covariant with info, and errors will be found\n// at start of runtime.\n// tslint:disable-next-line: no-any\nfunction unconvert(info, value, mapper) {\n    if (info === undefined) {\n        return;\n    }\n    switch (info.type) {\n        case MappingType.Mapped:\n            return mapper.thingForIdentifier(value);\n        case MappingType.LocalMapped:\n            // This is on the remote side, so we don't do anything here.\n            return value;\n        case MappingType.RemoteMapped:\n            return mapper.thingForIdentifier(value);\n        case MappingType.Direct:\n            return value;\n        case MappingType.ObjectMap: {\n            const r = new Map();\n            for (const key of Object.keys(value)) {\n                r.set(unconvert(info.key, key, mapper), unconvert(info.value, value[key], mapper));\n            }\n            return r;\n        }\n        case MappingType.List:\n            return value.map(v => unconvert(info.value, v, mapper));\n        case MappingType.ByLiteral:\n            if (!info.converter) {\n                throw new Error(`Expected ${info.type} to have a converter but it doesn't`);\n            }\n            return info.converter.fromLiteral(value);\n        default:\n            throw new Error(`Can't yet recieve MappingType ${info.type}`);\n    }\n}\nfunction AutoConstruct(target) {\n    return (constructor) => {\n        const doConstruct = (me, other) => {\n            const functions = targets.get(me) || new Map();\n            for (const f of functions.keys()) {\n                const argNames = getArgs(me.prototype[f]);\n                const descriptor = functions.get(f) || [];\n                // If this descriptor is for an initializer, record that fact and we'll process it after\n                // the rest of the arguments.\n                const initializer = descriptor.findIndex(d => d.initializer || false);\n                // If this descriptor records that this argument is the identifier, record it\n                // as the requestedId for mapping below.\n                const requestedId = descriptor.findIndex(d => d.identifier || false);\n                /** @this APIPort */\n                const impl = function (...args) {\n                    const messageBody = {};\n                    for (let i = 0; i < descriptor.length; i++) {\n                        if (i === initializer) {\n                            continue;\n                        }\n                        // Process this argument.\n                        messageBody[argNames[i]] = convert(descriptor[i], args[i], this._mapper);\n                    }\n                    // Process the initializer if present.\n                    if (initializer !== -1) {\n                        if (descriptor[initializer].redundant) {\n                            assert(requestedId === -1);\n                            messageBody['identifier'] = this._mapper.maybeCreateMappingForThing(args[initializer]);\n                        }\n                        else {\n                            messageBody['identifier'] = this._mapper.createMappingForThing(args[initializer], args[requestedId]);\n                        }\n                    }\n                    this.send(f, messageBody);\n                };\n                /** @this APIPort */\n                const before = async function before(messageBody) {\n                    const args = [];\n                    const promises = [];\n                    for (let i = 0; i < descriptor.length; i++) {\n                        // If there's a requestedId then the receiving end won't expect to\n                        // see the identifier as well.\n                        if (i === initializer && (requestedId !== -1 || descriptor[i].ignore)) {\n                            continue;\n                        }\n                        const argName = i === initializer ? 'identifier' : argNames[i];\n                        const result = unconvert(descriptor[i], messageBody[argName], this._mapper);\n                        if (result instanceof Promise) {\n                            promises.push({ promise: result, position: args.length });\n                            args.push(() => unconvert(descriptor[i], messageBody[argName], this._mapper));\n                        }\n                        else {\n                            args.push(result);\n                        }\n                    }\n                    if (promises.length > 0) {\n                        await Promise.all(promises.map(async (a) => a.promise));\n                        promises.forEach(a => {\n                            args[a.position] = args[a.position]();\n                        });\n                    }\n                    const result = this['on' + f](...args);\n                    // If this message is an initializer, need to establish a mapping\n                    // with the result of processing the message.\n                    if (initializer > -1) {\n                        assert(messageBody['identifier']);\n                        await this._mapper.establishThingMapping(messageBody['identifier'], result);\n                    }\n                };\n                Object.defineProperty(me.prototype, f, {\n                    get() {\n                        return impl;\n                    }\n                });\n                Object.defineProperty(other.prototype, 'before' + f, {\n                    get() {\n                        return before;\n                    }\n                });\n            }\n        };\n        doConstruct(constructor, target);\n        doConstruct(target, constructor);\n    };\n}\nexport class PECOuterPort extends APIPort {\n    constructor(messagePort, arc) {\n        super(messagePort, 'o');\n        this.inspector = arc.inspector;\n        if (this.inspector) {\n            this.inspector.onceActive.then(() => this.DevToolsConnected(), e => console.error(e));\n        }\n    }\n    Stop() { }\n    DefineHandle(store, type, name) { }\n    InstantiateParticle(particle, id, spec, stores) { }\n    UIEvent(particle, slotName, event) { }\n    SimpleCallback(callback, data) { }\n    AwaitIdle(version) { }\n    StartRender(particle, slotName, providedSlots, contentTypes) { }\n    StopRender(particle, slotName) { }\n    GetBackingStoreCallback(store, callback, type, name, id, storageKey) { }\n    ConstructArcCallback(callback, arc) { }\n    CreateHandleCallback(handle, callback, type, name, id) { }\n    MapHandleCallback(newHandle, callback, id) { }\n    CreateSlotCallback(slot, callback, hostedSlotId) { }\n    InnerArcRender(transformationParticle, transformationSlotName, hostedSlotId, content) { }\n    // We need an API call to tell the context side that DevTools has been connected, so it can start sending\n    // stack traces attached to the API calls made from that side.\n    DevToolsConnected() { }\n}\n__decorate([\n    NoArgs\n], PECOuterPort.prototype, \"Stop\", null);\n__decorate([\n    __param(0, RedundantInitializer), __param(1, ByLiteral(Type)), __param(2, Direct)\n], PECOuterPort.prototype, \"DefineHandle\", null);\n__decorate([\n    __param(0, Initializer), __param(1, Identifier), __param(1, Direct), __param(2, ByLiteral(ParticleSpec)), __param(3, ObjectMap(MappingType.Direct, MappingType.Mapped))\n], PECOuterPort.prototype, \"InstantiateParticle\", null);\n__decorate([\n    __param(0, Mapped), __param(1, Direct), __param(2, Direct)\n], PECOuterPort.prototype, \"UIEvent\", null);\n__decorate([\n    __param(0, RemoteMapped), __param(1, Direct)\n], PECOuterPort.prototype, \"SimpleCallback\", null);\n__decorate([\n    __param(0, Direct)\n], PECOuterPort.prototype, \"AwaitIdle\", null);\n__decorate([\n    __param(0, Mapped), __param(1, Direct), __param(2, ObjectMap(MappingType.Direct, MappingType.Direct)), __param(3, List(MappingType.Direct))\n], PECOuterPort.prototype, \"StartRender\", null);\n__decorate([\n    __param(0, Mapped), __param(1, Direct)\n], PECOuterPort.prototype, \"StopRender\", null);\n__decorate([\n    __param(0, Initializer), __param(1, RemoteMapped), __param(2, ByLiteral(Type)), __param(3, Direct), __param(4, Identifier), __param(4, Direct), __param(5, Direct)\n], PECOuterPort.prototype, \"GetBackingStoreCallback\", null);\n__decorate([\n    __param(0, RemoteMapped), __param(1, LocalMapped)\n], PECOuterPort.prototype, \"ConstructArcCallback\", null);\n__decorate([\n    __param(0, Initializer), __param(1, RemoteMapped), __param(2, ByLiteral(Type)), __param(3, Direct), __param(4, Identifier), __param(4, Direct)\n], PECOuterPort.prototype, \"CreateHandleCallback\", null);\n__decorate([\n    __param(0, RemoteIgnore), __param(0, Initializer), __param(1, RemoteMapped), __param(2, Direct)\n], PECOuterPort.prototype, \"MapHandleCallback\", null);\n__decorate([\n    __param(0, RemoteIgnore), __param(0, Initializer), __param(1, RemoteMapped), __param(2, Direct)\n], PECOuterPort.prototype, \"CreateSlotCallback\", null);\n__decorate([\n    __param(0, Mapped), __param(1, Direct), __param(2, Direct), __param(3, Direct)\n], PECOuterPort.prototype, \"InnerArcRender\", null);\n__decorate([\n    NoArgs\n], PECOuterPort.prototype, \"DevToolsConnected\", null);\nlet PECInnerPort = class PECInnerPort extends APIPort {\n    constructor(messagePort) {\n        super(messagePort, 'i');\n    }\n    Render(particle, slotName, content) { }\n    InitializeProxy(handle, callback) { }\n    SynchronizeProxy(handle, callback) { }\n    HandleGet(handle, callback) { }\n    HandleToList(handle, callback) { }\n    HandleSet(handle, data, particleId, barrier) { }\n    HandleClear(handle, particleId, barrier) { }\n    HandleStore(handle, callback, data, particleId) { }\n    HandleRemove(handle, callback, data, particleId) { }\n    HandleRemoveMultiple(handle, callback, data, particleId) { }\n    HandleStream(handle, callback, pageSize, forward) { }\n    StreamCursorNext(handle, callback, cursorId) { }\n    StreamCursorClose(handle, cursorId) { }\n    Idle(version, relevance) { }\n    GetBackingStore(callback, storageKey, type) { }\n    ConstructInnerArc(callback, particle) { }\n    ArcCreateHandle(callback, arc, type, name) { }\n    ArcMapHandle(callback, arc, handle) { }\n    // TODO(sjmiles): experimental `services` impl\n    ServiceRequest(particle, content, callback) { }\n    ArcCreateSlot(callback, arc, transformationParticle, transformationSlotName, handleId) { }\n    ArcLoadRecipe(arc, recipe, callback) { }\n    ReportExceptionInHost(exception) { }\n    // To show stack traces for calls made inside the context, we need to capture the trace at the call point and\n    // send it along with the message. We only want to do this after a DevTools connection has been detected, which\n    // we can't directly detect inside a worker context, so the PECOuterPort will send an API message instead.\n    onDevToolsConnected() {\n        this.attachStack = true;\n    }\n};\n__decorate([\n    __param(0, Mapped), __param(1, Direct), __param(2, Direct)\n], PECInnerPort.prototype, \"Render\", null);\n__decorate([\n    __param(0, Mapped), __param(1, LocalMapped)\n], PECInnerPort.prototype, \"InitializeProxy\", null);\n__decorate([\n    __param(0, Mapped), __param(1, LocalMapped)\n], PECInnerPort.prototype, \"SynchronizeProxy\", null);\n__decorate([\n    __param(0, Mapped), __param(1, LocalMapped)\n], PECInnerPort.prototype, \"HandleGet\", null);\n__decorate([\n    __param(0, Mapped), __param(1, LocalMapped)\n], PECInnerPort.prototype, \"HandleToList\", null);\n__decorate([\n    __param(0, Mapped), __param(1, Direct), __param(2, Direct), __param(3, Direct)\n], PECInnerPort.prototype, \"HandleSet\", null);\n__decorate([\n    __param(0, Mapped), __param(1, Direct), __param(2, Direct)\n], PECInnerPort.prototype, \"HandleClear\", null);\n__decorate([\n    __param(0, Mapped), __param(1, LocalMapped), __param(2, Direct), __param(3, Direct)\n], PECInnerPort.prototype, \"HandleStore\", null);\n__decorate([\n    __param(0, Mapped), __param(1, LocalMapped), __param(2, Direct), __param(3, Direct)\n], PECInnerPort.prototype, \"HandleRemove\", null);\n__decorate([\n    __param(0, Mapped), __param(1, LocalMapped), __param(2, Direct), __param(3, Direct)\n], PECInnerPort.prototype, \"HandleRemoveMultiple\", null);\n__decorate([\n    __param(0, Mapped), __param(1, LocalMapped), __param(2, Direct), __param(3, Direct)\n], PECInnerPort.prototype, \"HandleStream\", null);\n__decorate([\n    __param(0, Mapped), __param(1, LocalMapped), __param(2, Direct)\n], PECInnerPort.prototype, \"StreamCursorNext\", null);\n__decorate([\n    __param(0, Mapped), __param(1, Direct)\n], PECInnerPort.prototype, \"StreamCursorClose\", null);\n__decorate([\n    __param(0, Direct), __param(1, ObjectMap(MappingType.Mapped, MappingType.Direct))\n], PECInnerPort.prototype, \"Idle\", null);\n__decorate([\n    __param(0, LocalMapped), __param(1, Direct), __param(2, ByLiteral(Type))\n], PECInnerPort.prototype, \"GetBackingStore\", null);\n__decorate([\n    __param(0, LocalMapped), __param(1, Mapped)\n], PECInnerPort.prototype, \"ConstructInnerArc\", null);\n__decorate([\n    __param(0, LocalMapped), __param(1, RemoteMapped), __param(2, ByLiteral(Type)), __param(3, Direct)\n], PECInnerPort.prototype, \"ArcCreateHandle\", null);\n__decorate([\n    __param(0, LocalMapped), __param(1, RemoteMapped), __param(2, Mapped)\n], PECInnerPort.prototype, \"ArcMapHandle\", null);\n__decorate([\n    __param(0, Mapped), __param(1, Direct), __param(2, LocalMapped)\n], PECInnerPort.prototype, \"ServiceRequest\", null);\n__decorate([\n    __param(0, LocalMapped), __param(1, RemoteMapped), __param(2, Mapped), __param(3, Direct), __param(4, Direct)\n], PECInnerPort.prototype, \"ArcCreateSlot\", null);\n__decorate([\n    __param(0, RemoteMapped), __param(1, Direct), __param(2, LocalMapped)\n], PECInnerPort.prototype, \"ArcLoadRecipe\", null);\n__decorate([\n    __param(0, ByLiteral(PropagatedException))\n], PECInnerPort.prototype, \"ReportExceptionInHost\", null);\nPECInnerPort = __decorate([\n    AutoConstruct(PECOuterPort)\n], PECInnerPort);\nexport { PECInnerPort };\n//# sourceMappingURL=api-channel.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\nimport { Modality } from './modality.js';\nimport { TypeChecker } from './recipe/type-checker.js';\nimport { InterfaceType, SlotType, Type } from './type.js';\nimport { createCheck } from './particle-check.js';\nimport { createClaim } from './particle-claim.js';\nfunction asType(t) {\n    return (t instanceof Type) ? t : Type.fromLiteral(t);\n}\nfunction asTypeLiteral(t) {\n    return (t instanceof Type) ? t.toLiteral() : t;\n}\nexport class HandleConnectionSpec {\n    constructor(rawData, typeVarMap) {\n        this.parentConnection = null;\n        this.rawData = rawData;\n        this.direction = rawData.direction;\n        this.name = rawData.name;\n        this.type = asType(rawData.type).mergeTypeVariablesByName(typeVarMap);\n        this.isOptional = rawData.isOptional;\n        this.tags = rawData.tags || [];\n        this.dependentConnections = [];\n    }\n    instantiateDependentConnections(particle, typeVarMap) {\n        for (const dependentArg of this.rawData.dependentConnections) {\n            const dependentConnection = particle.createConnection(dependentArg, typeVarMap);\n            dependentConnection.parentConnection = this;\n            this.dependentConnections.push(dependentConnection);\n        }\n    }\n    get isInput() {\n        // TODO: we probably don't really want host to be here.\n        return this.direction === 'in' || this.direction === 'inout' || this.direction === 'host';\n    }\n    get isOutput() {\n        return this.direction === 'out' || this.direction === 'inout';\n    }\n    isCompatibleType(type) {\n        return TypeChecker.compareTypes({ type }, { type: this.type, direction: this.direction });\n    }\n}\nexport class ConsumeSlotConnectionSpec {\n    constructor(slotModel) {\n        this.name = slotModel.name;\n        this.isRequired = slotModel.isRequired || false;\n        this.isSet = slotModel.isSet || false;\n        this.tags = slotModel.tags || [];\n        this.formFactor = slotModel.formFactor; // TODO: deprecate form factors?\n        this.handles = slotModel.handles || [];\n        this.provideSlotConnections = [];\n        if (!slotModel.provideSlotConnections) {\n            return;\n        }\n        slotModel.provideSlotConnections.forEach(ps => {\n            this.provideSlotConnections.push(new ProvideSlotConnectionSpec(ps));\n        });\n    }\n    // Getters to 'fake' being a Handle.\n    get isOptional() { return !this.isRequired; }\n    get direction() { return '`consume'; }\n    get type() { return SlotType.make(this.formFactor, null); } //TODO(jopra): FIX THIS NULL!\n    get dependentConnections() { return this.provideSlotConnections; }\n}\nexport class ProvideSlotConnectionSpec extends ConsumeSlotConnectionSpec {\n    constructor(slotModel) {\n        super(slotModel);\n        this.check = slotModel.check;\n    }\n}\nexport class ParticleSpec {\n    constructor(model) {\n        this.model = model;\n        this.name = model.name;\n        this.verbs = model.verbs;\n        const typeVarMap = new Map();\n        this.handleConnectionMap = new Map();\n        model.args.forEach(arg => this.createConnection(arg, typeVarMap));\n        // initialize descriptions patterns.\n        model.description = model.description || {};\n        this.validateDescription(model.description);\n        this.pattern = model.description['pattern'];\n        this.handleConnectionMap.forEach((connectionSpec, name) => {\n            connectionSpec.pattern = model.description[name];\n        });\n        this.implFile = model.implFile;\n        this.implBlobUrl = model.implBlobUrl;\n        this.modality = Modality.create(model.modality || []);\n        this.slotConnections = new Map();\n        if (model.slotConnections) {\n            model.slotConnections.forEach(s => this.slotConnections.set(s.name, new ConsumeSlotConnectionSpec(s)));\n        }\n        // Verify provided slots use valid handle connection names.\n        this.slotConnections.forEach(slot => {\n            slot.provideSlotConnections.forEach(ps => {\n                ps.handles.forEach(v => assert(this.handleConnectionMap.has(v), 'Cannot provide slot for nonexistent handle constraint ' + v));\n            });\n        });\n        this.trustClaims = this.validateTrustClaims(model.trustClaims);\n        this.trustChecks = this.validateTrustChecks(model.trustChecks);\n    }\n    createConnection(arg, typeVarMap) {\n        const connection = new HandleConnectionSpec(arg, typeVarMap);\n        this.handleConnectionMap.set(connection.name, connection);\n        connection.instantiateDependentConnections(this, typeVarMap);\n        return connection;\n    }\n    get handleConnections() {\n        return this.connections;\n    }\n    get connections() {\n        return [...this.handleConnectionMap.values()];\n    }\n    get inputs() {\n        return this.connections.filter(a => a.isInput);\n    }\n    get outputs() {\n        return this.connections.filter(a => a.isOutput);\n    }\n    isInput(param) {\n        const connection = this.handleConnectionMap.get(param);\n        return connection && connection.isInput;\n    }\n    isOutput(param) {\n        const connection = this.handleConnectionMap.get(param);\n        return connection && connection.isOutput;\n    }\n    getConnectionByName(name) {\n        return this.handleConnectionMap.get(name);\n    }\n    getSlotSpec(slotName) {\n        return this.slotConnections.get(slotName);\n    }\n    get slotConnectionNames() {\n        return [...this.slotConnections.keys()];\n    }\n    get primaryVerb() {\n        return (this.verbs.length > 0) ? this.verbs[0] : undefined;\n    }\n    isCompatible(modality) {\n        return this.slotConnections.size === 0 || this.modality.intersection(modality).isResolved();\n    }\n    setImplBlobUrl(url) {\n        this.model.implBlobUrl = this.implBlobUrl = url;\n    }\n    toLiteral() {\n        const { args, name, verbs, description, implFile, implBlobUrl, modality, slotConnections, trustClaims, trustChecks } = this.model;\n        const connectionToLiteral = ({ type, direction, name, isOptional, dependentConnections }) => ({ type: asTypeLiteral(type), direction, name, isOptional, dependentConnections: dependentConnections.map(connectionToLiteral) });\n        const argsLiteral = args.map(a => connectionToLiteral(a));\n        return { args: argsLiteral, name, verbs, description, implFile, implBlobUrl, modality, slotConnections, trustClaims, trustChecks };\n    }\n    static fromLiteral(literal) {\n        let { args, name, verbs, description, implFile, implBlobUrl, modality, slotConnections, trustClaims, trustChecks } = literal;\n        const connectionFromLiteral = ({ type, direction, name, isOptional, dependentConnections }) => ({ type: asType(type), direction, name, isOptional, dependentConnections: dependentConnections ? dependentConnections.map(connectionFromLiteral) : [] });\n        args = args.map(connectionFromLiteral);\n        return new ParticleSpec({ args, name, verbs: verbs || [], description, implFile, implBlobUrl, modality, slotConnections, trustClaims, trustChecks });\n    }\n    // Note: this method shouldn't be called directly.\n    clone() {\n        return ParticleSpec.fromLiteral(this.toLiteral());\n    }\n    // Note: this method shouldn't be called directly (only as part of particle copying).\n    cloneWithResolutions(variableMap) {\n        const spec = this.clone();\n        this.handleConnectionMap.forEach((conn, name) => {\n            spec.handleConnectionMap.get(name).type = conn.type._cloneWithResolutions(variableMap);\n        });\n        return spec;\n    }\n    equals(other) {\n        return JSON.stringify(this.toLiteral()) === JSON.stringify(other.toLiteral());\n    }\n    validateDescription(description) {\n        Object.keys(description || []).forEach(d => {\n            assert(['kind', 'location', 'pattern'].includes(d) || this.handleConnectionMap.has(d), `Unexpected description for ${d}`);\n        });\n    }\n    toInterface() {\n        // TODO: wat do?\n        assert(!this.slotConnections.size, 'please implement slots toInterface');\n        const handles = this.model.args.map(({ type, name, direction }) => ({ type: asType(type), name, direction }));\n        const slots = [];\n        return InterfaceType.make(this.name, handles, slots);\n    }\n    toString() {\n        const results = [];\n        let verbs = '';\n        if (this.verbs.length > 0) {\n            verbs = ' ' + this.verbs.map(verb => `&${verb}`).join(' ');\n        }\n        results.push(`particle ${this.name}${verbs} in '${this.implFile}'`.trim());\n        const indent = '  ';\n        const writeConnection = (connection, indent) => {\n            const tags = connection.tags.map((tag) => ` #${tag}`).join('');\n            results.push(`${indent}${connection.direction}${connection.isOptional ? '?' : ''} ${connection.type.toString()} ${connection.name}${tags}`);\n            for (const dependent of connection.dependentConnections) {\n                writeConnection(dependent, indent + '  ');\n            }\n        };\n        for (const connection of this.handleConnections) {\n            if (connection.parentConnection) {\n                continue;\n            }\n            writeConnection(connection, indent);\n        }\n        this.trustClaims.forEach(claim => results.push(`  ${claim.toManifestString()}`));\n        this.trustChecks.forEach(check => results.push(`  ${check.toManifestString()}`));\n        this.modality.names.forEach(a => results.push(`  modality ${a}`));\n        const slotToString = (s, direction, indent) => {\n            const tokens = [];\n            if (s.isRequired) {\n                tokens.push('must');\n            }\n            tokens.push(direction);\n            if (s.isSet) {\n                tokens.push('set of');\n            }\n            tokens.push(s.name);\n            if (s.tags.length > 0) {\n                tokens.push(s.tags.map(a => `#${a}`).join(' '));\n            }\n            results.push(`${indent}${tokens.join(' ')}`);\n            if (s.formFactor) {\n                results.push(`${indent}  formFactor ${s.formFactor}`);\n            }\n            for (const handle of s.handles) {\n                results.push(`${indent}  handle ${handle}`);\n            }\n            if (s.provideSlotConnections) {\n                // Provided slots.\n                s.provideSlotConnections.forEach(p => slotToString(p, 'provide', indent + '  '));\n            }\n        };\n        this.slotConnections.forEach(s => slotToString(s, 'consume', '  '));\n        // Description\n        if (this.pattern) {\n            results.push(`  description \\`${this.pattern}\\``);\n            this.handleConnectionMap.forEach(cs => {\n                if (cs.pattern) {\n                    results.push(`    ${cs.name} \\`${cs.pattern}\\``);\n                }\n            });\n        }\n        return results.join('\\n');\n    }\n    toManifestString() {\n        return this.toString();\n    }\n    validateTrustClaims(claims) {\n        const results = new Map();\n        if (claims) {\n            claims.forEach(claim => {\n                const handle = this.handleConnectionMap.get(claim.handle);\n                if (!handle) {\n                    throw new Error(`Can't make a claim on unknown handle ${claim.handle}.`);\n                }\n                if (!handle.isOutput) {\n                    throw new Error(`Can't make a claim on handle ${claim.handle} (not an output handle).`);\n                }\n                if (handle.claim) {\n                    throw new Error(`Can't make multiple claims on the same output (${claim.handle}).`);\n                }\n                handle.claim = createClaim(handle, claim, this.handleConnectionMap);\n                results.set(claim.handle, handle.claim);\n            });\n        }\n        return results;\n    }\n    validateTrustChecks(checks) {\n        const results = [];\n        if (checks) {\n            const providedSlotNames = this.getProvidedSlotsByName();\n            checks.forEach(check => {\n                switch (check.target.targetType) {\n                    case 'handle': {\n                        const handleName = check.target.name;\n                        const handle = this.handleConnectionMap.get(handleName);\n                        if (!handle) {\n                            throw new Error(`Can't make a check on unknown handle ${handleName}.`);\n                        }\n                        if (!handle.isInput) {\n                            throw new Error(`Can't make a check on handle ${handleName} (not an input handle).`);\n                        }\n                        if (handle.check) {\n                            throw new Error(`Can't make multiple checks on the same input (${handleName}).`);\n                        }\n                        handle.check = createCheck(handle, check, this.handleConnectionMap);\n                        results.push(handle.check);\n                        break;\n                    }\n                    case 'slot': {\n                        const slotName = check.target.name;\n                        const slotSpec = providedSlotNames.get(slotName);\n                        if (!slotSpec) {\n                            if (this.slotConnectionNames.includes(slotName)) {\n                                throw new Error(`Slot ${slotName} is a consumed slot. Can only make checks on provided slots.`);\n                            }\n                            else {\n                                throw new Error(`Can't make a check on unknown slot ${slotName}.`);\n                            }\n                        }\n                        slotSpec.check = createCheck(slotSpec, check, this.handleConnectionMap);\n                        results.push(slotSpec.check);\n                        break;\n                    }\n                    default:\n                        throw new Error('Unknown check target type.');\n                }\n            });\n        }\n        return results;\n    }\n    getProvidedSlotsByName() {\n        const result = new Map();\n        for (const consumeConnection of this.slotConnections.values()) {\n            for (const provideConnection of consumeConnection.provideSlotConnections) {\n                const name = provideConnection.name;\n                if (result.has(name)) {\n                    throw new Error(`Another slot with name '${name}' has already been provided by this particle.`);\n                }\n                result.set(name, provideConnection);\n            }\n        }\n        return result;\n    }\n}\n//# sourceMappingURL=particle-spec.js.map","/**\n * @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\nvar ModalityName;\n(function (ModalityName) {\n    ModalityName[\"Dom\"] = \"dom\";\n    ModalityName[\"DomTouch\"] = \"dom-touch\";\n    ModalityName[\"Vr\"] = \"vr\";\n    ModalityName[\"Voice\"] = \"voice\";\n})(ModalityName || (ModalityName = {}));\nexport class Modality {\n    constructor(names) {\n        this.names = names;\n    }\n    static create(names) {\n        assert(names.every(name => Modality.all.names.includes(name)), `Unsupported modality in: ${names}`);\n        return new Modality(names);\n    }\n    intersection(other) {\n        return new Modality(this.names.filter(name => other.names.includes(name)));\n    }\n    isResolved() {\n        return this.names.length > 0;\n    }\n    isCompatible(names) {\n        return this.intersection(Modality.create(names)).isResolved();\n    }\n    static get Name() { return ModalityName; }\n}\nModality.all = new Modality([\n    Modality.Name.Dom, Modality.Name.DomTouch, Modality.Name.Vr, Modality.Name.Voice\n]);\nModality.dom = new Modality([Modality.Name.Dom]);\nModality.domTouch = new Modality([Modality.Name.DomTouch]);\nModality.voice = new Modality([Modality.Name.Voice]);\nModality.vr = new Modality([Modality.Name.Vr]);\n//# sourceMappingURL=modality.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { BigCollectionType, CollectionType, EntityType, InterfaceType, ReferenceType, SlotType, Type, TypeVariable } from '../type.js';\nexport class TypeChecker {\n    // resolve a list of handleConnection types against a handle\n    // base type. This is the core type resolution mechanism, but should only\n    // be used when types can actually be associated with each other / constrained.\n    //\n    // By design this function is called exactly once per handle in a recipe during\n    // normalization, and should provide the same final answers regardless of the\n    // ordering of handles within that recipe\n    //\n    // NOTE: you probably don't want to call this function, if you think you\n    // do, talk to shans@.\n    static processTypeList(baseType, list) {\n        const newBaseType = TypeVariable.make('', null, null);\n        if (baseType) {\n            newBaseType.variable.resolution = baseType;\n        }\n        baseType = newBaseType;\n        const concreteTypes = [];\n        // baseType might be a variable (and is definitely a variable if no baseType was available).\n        // Some of the list might contain variables too.\n        // First attempt to merge all the variables into the baseType\n        //\n        // If the baseType is a variable then this results in a single place to manipulate the constraints\n        // of all the other connected variables at the same time.\n        for (const item of list) {\n            if (item.type.resolvedType().hasVariable) {\n                baseType = TypeChecker._tryMergeTypeVariable(baseType, item.type);\n                if (baseType == null) {\n                    return null;\n                }\n            }\n            else {\n                concreteTypes.push(item);\n            }\n        }\n        for (const item of concreteTypes) {\n            if (!TypeChecker._tryMergeConstraints(baseType, item)) {\n                return null;\n            }\n        }\n        const getResolution = (candidate) => {\n            if (!(candidate instanceof TypeVariable)) {\n                return candidate;\n            }\n            if (candidate.canReadSubset == null || candidate.canWriteSuperset == null) {\n                return candidate;\n            }\n            if (candidate.canReadSubset.isMoreSpecificThan(candidate.canWriteSuperset)) {\n                if (candidate.canWriteSuperset.isMoreSpecificThan(candidate.canReadSubset)) {\n                    candidate.variable.resolution = candidate.canReadSubset;\n                }\n                return candidate;\n            }\n            return null;\n        };\n        const candidate = baseType.resolvedType();\n        if (candidate.isCollectionType()) {\n            const resolution = getResolution(candidate.collectionType);\n            return (resolution !== null) ? resolution.collectionOf() : null;\n        }\n        if (candidate.isBigCollectionType()) {\n            const resolution = getResolution(candidate.bigCollectionType);\n            return (resolution !== null) ? resolution.bigCollectionOf() : null;\n        }\n        return getResolution(candidate);\n    }\n    static _tryMergeTypeVariable(base, onto) {\n        const [primitiveBase, primitiveOnto] = Type.unwrapPair(base.resolvedType(), onto.resolvedType());\n        if (primitiveBase instanceof TypeVariable) {\n            if (primitiveOnto instanceof TypeVariable) {\n                // base, onto both variables.\n                const result = primitiveBase.variable.maybeMergeConstraints(primitiveOnto.variable);\n                if (result === false) {\n                    return null;\n                }\n                primitiveOnto.variable.resolution = primitiveBase;\n            }\n            else {\n                // base variable, onto not.\n                if (!primitiveBase.variable.isValidResolutionCandidate(primitiveOnto).result) {\n                    return null;\n                }\n                primitiveBase.variable.resolution = primitiveOnto;\n            }\n            return base;\n        }\n        else if (primitiveOnto instanceof TypeVariable) {\n            // onto variable, base not.\n            if (!primitiveOnto.variable.isValidResolutionCandidate(primitiveBase).result) {\n                return null;\n            }\n            primitiveOnto.variable.resolution = primitiveBase;\n            return onto;\n        }\n        else if (primitiveBase instanceof InterfaceType && primitiveOnto instanceof InterfaceType) {\n            const result = primitiveBase.interfaceInfo.tryMergeTypeVariablesWith(primitiveOnto.interfaceInfo);\n            if (result == null) {\n                return null;\n            }\n            return new InterfaceType(result);\n        }\n        else if ((primitiveBase.isTypeContainer() && primitiveBase.hasVariable)\n            || (primitiveOnto.isTypeContainer() && primitiveOnto.hasVariable)) {\n            // Cannot merge [~a] with a type that is not a variable and not a collection.\n            return null;\n        }\n        throw new Error('tryMergeTypeVariable shouldn\\'t be called on two types without any type variables');\n    }\n    static _tryMergeConstraints(handleType, { type, direction }) {\n        let [primitiveHandleType, primitiveConnectionType] = Type.unwrapPair(handleType.resolvedType(), type.resolvedType());\n        if (primitiveHandleType instanceof TypeVariable) {\n            while (primitiveConnectionType.isTypeContainer()) {\n                if (primitiveHandleType.variable.resolution != null\n                    || primitiveHandleType.variable.canReadSubset != null\n                    || primitiveHandleType.variable.canWriteSuperset != null) {\n                    // Resolved and/or constrained variables can only represent Entities, not sets.\n                    return false;\n                }\n                // If this is an undifferentiated variable then we need to create structure to match against. That's\n                // allowed because this variable could represent anything, and it needs to represent this structure\n                // in order for type resolution to succeed.\n                const newVar = TypeVariable.make('a', null, null);\n                if (primitiveConnectionType instanceof CollectionType) {\n                    primitiveHandleType.variable.resolution = new CollectionType(newVar);\n                }\n                else if (primitiveConnectionType instanceof BigCollectionType) {\n                    primitiveHandleType.variable.resolution = new BigCollectionType(newVar);\n                }\n                else {\n                    primitiveHandleType.variable.resolution = new ReferenceType(newVar);\n                }\n                const unwrap = Type.unwrapPair(primitiveHandleType.resolvedType(), primitiveConnectionType);\n                [primitiveHandleType, primitiveConnectionType] = unwrap;\n                if (!(primitiveHandleType instanceof TypeVariable)) {\n                    // This should never happen, and the guard above is just here so we type-check.\n                    throw new TypeError('unwrapping a wrapped TypeVariable somehow didn\\'t become a TypeVariable');\n                }\n            }\n            if (direction === 'out' || direction === 'inout' || direction === '`provide') {\n                // the canReadSubset of the handle represents the maximal type that can be read from the\n                // handle, so we need to intersect out any type that is more specific than the maximal type\n                // that could be written.\n                if (!primitiveHandleType.variable.maybeMergeCanReadSubset(primitiveConnectionType.canWriteSuperset)) {\n                    return false;\n                }\n            }\n            if (direction === 'in' || direction === 'inout' || direction === '`consume') {\n                // the canWriteSuperset of the handle represents the maximum lower-bound type that is read from the handle,\n                // so we need to union it with the type that wants to be read here.\n                if (!primitiveHandleType.variable.maybeMergeCanWriteSuperset(primitiveConnectionType.canReadSubset)) {\n                    return false;\n                }\n            }\n        }\n        else {\n            if (primitiveConnectionType.tag !== primitiveHandleType.tag) {\n                return false;\n            }\n            if (direction === 'out' || direction === 'inout') {\n                if (!TypeChecker._writeConstraintsApply(primitiveHandleType, primitiveConnectionType)) {\n                    return false;\n                }\n            }\n            if (direction === 'in' || direction === 'inout') {\n                if (!TypeChecker._readConstraintsApply(primitiveHandleType, primitiveConnectionType)) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    }\n    static _writeConstraintsApply(handleType, connectionType) {\n        // this connection wants to write to this handle. If the written type is\n        // more specific than the canReadSubset then it isn't violating the maximal type\n        // that can be read.\n        const writtenType = connectionType.canWriteSuperset;\n        if (writtenType == null || handleType.canReadSubset == null) {\n            return true;\n        }\n        if (writtenType.isMoreSpecificThan(handleType.canReadSubset)) {\n            return true;\n        }\n        return false;\n    }\n    static _readConstraintsApply(handleType, connectionType) {\n        // this connection wants to read from this handle. If the read type\n        // is less specific than the canWriteSuperset, then it isn't violating\n        // the maximum lower-bound read type.\n        const readType = connectionType.canReadSubset;\n        if (readType == null || handleType.canWriteSuperset == null) {\n            return true;\n        }\n        if (handleType.canWriteSuperset.isMoreSpecificThan(readType)) {\n            return true;\n        }\n        return false;\n    }\n    // Compare two types to see if they could be potentially resolved (in the absence of other\n    // information). This is used as a filter when selecting compatible handles or checking\n    // validity of recipes. This function returning true never implies that full type resolution\n    // will succeed, but if the function returns false for a pair of types that are associated\n    // then type resolution is guaranteed to fail.\n    //\n    // left, right: {type, direction, connection}\n    static compareTypes(left, right) {\n        const resolvedLeft = left.type.resolvedType();\n        const resolvedRight = right.type.resolvedType();\n        const [leftType, rightType] = Type.unwrapPair(resolvedLeft, resolvedRight);\n        // a variable is compatible with a set only if it is unconstrained.\n        if (leftType instanceof TypeVariable && rightType.isTypeContainer()) {\n            return !(leftType.variable.canReadSubset || leftType.variable.canWriteSuperset);\n        }\n        if (rightType instanceof TypeVariable && leftType.isTypeContainer()) {\n            return !(rightType.variable.canReadSubset || rightType.variable.canWriteSuperset);\n        }\n        if (leftType instanceof TypeVariable || rightType instanceof TypeVariable) {\n            // TODO: everything should use this, eventually. Need to implement the\n            // right functionality in Interfaces first, though.\n            return Type.canMergeConstraints(leftType, rightType);\n        }\n        if ((leftType === undefined) !== (rightType === undefined)) {\n            return false;\n        }\n        if (leftType === rightType) {\n            return true;\n        }\n        if (leftType.tag !== rightType.tag) {\n            return false;\n        }\n        if (leftType instanceof SlotType) {\n            return true;\n        }\n        // TODO: we need a generic way to evaluate type compatibility\n        //       interfaces + entities + etc\n        if (leftType instanceof InterfaceType && rightType instanceof InterfaceType) {\n            if (leftType.interfaceInfo.equals(rightType.interfaceInfo)) {\n                return true;\n            }\n        }\n        if (!(leftType instanceof EntityType) || !(rightType instanceof EntityType)) {\n            return false;\n        }\n        const leftIsSub = leftType.entitySchema.isMoreSpecificThan(rightType.entitySchema);\n        const leftIsSuper = rightType.entitySchema.isMoreSpecificThan(leftType.entitySchema);\n        if (leftIsSuper && leftIsSub) {\n            return true;\n        }\n        if (!leftIsSuper && !leftIsSub) {\n            return false;\n        }\n        const [superclass, subclass] = leftIsSuper ? [left, right] : [right, left];\n        // treat handle types as if they were 'inout' connections. Note that this\n        // guarantees that the handle's type will be preserved, and that the fact\n        // that the type comes from a handle rather than a connection will also\n        // be preserved.\n        const superDirection = superclass.direction || (superclass.connection ? superclass.connection.direction : 'inout');\n        const subDirection = subclass.direction || (subclass.connection ? subclass.connection.direction : 'inout');\n        if (superDirection === 'in') {\n            return true;\n        }\n        if (subDirection === 'out') {\n            return true;\n        }\n        return false;\n    }\n}\n//# sourceMappingURL=type-checker.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { InterfaceInfo } from './interface-info.js';\nimport { Schema } from './schema.js';\nimport { SlotInfo } from './slot-info.js';\nimport { ArcInfo } from './synthetic-types.js';\nimport { TypeVariableInfo } from './type-variable-info.js';\nexport class Type {\n    constructor(tag) {\n        this.tag = tag;\n    }\n    static fromLiteral(literal) {\n        switch (literal.tag) {\n            case 'Entity':\n                return new EntityType(Schema.fromLiteral(literal.data));\n            case 'TypeVariable':\n                return new TypeVariable(TypeVariableInfo.fromLiteral(literal.data));\n            case 'Collection':\n                return new CollectionType(Type.fromLiteral(literal.data));\n            case 'BigCollection':\n                return new BigCollectionType(Type.fromLiteral(literal.data));\n            case 'Relation':\n                return new RelationType(literal.data.map(t => Type.fromLiteral(t)));\n            case 'Interface':\n                return new InterfaceType(InterfaceInfo.fromLiteral(literal.data));\n            case 'Slot':\n                return new SlotType(SlotInfo.fromLiteral(literal.data));\n            case 'Reference':\n                return new ReferenceType(Type.fromLiteral(literal.data));\n            case 'Arc':\n                return new ArcType();\n            case 'Handle':\n                return new HandleType();\n            default:\n                throw new Error(`fromLiteral: unknown type ${literal}`);\n        }\n    }\n    static unwrapPair(type1, type2) {\n        if (type1.tag === type2.tag) {\n            const contained1 = type1.getContainedType();\n            if (contained1 !== null) {\n                return Type.unwrapPair(contained1, type2.getContainedType());\n            }\n        }\n        return [type1, type2];\n    }\n    /** Tests whether two types' constraints are compatible with each other. */\n    static canMergeConstraints(type1, type2) {\n        return Type._canMergeCanReadSubset(type1, type2) && Type._canMergeCanWriteSuperset(type1, type2);\n    }\n    static _canMergeCanReadSubset(type1, type2) {\n        if (type1.canReadSubset && type2.canReadSubset) {\n            if (type1.canReadSubset.tag !== type2.canReadSubset.tag) {\n                return false;\n            }\n            if (type1.canReadSubset instanceof EntityType && type2.canReadSubset instanceof EntityType) {\n                return Schema.intersect(type1.canReadSubset.entitySchema, type2.canReadSubset.entitySchema) !== null;\n            }\n            throw new Error(`_canMergeCanReadSubset not implemented for types tagged with ${type1.canReadSubset.tag}`);\n        }\n        return true;\n    }\n    static _canMergeCanWriteSuperset(type1, type2) {\n        if (type1.canWriteSuperset && type2.canWriteSuperset) {\n            if (type1.canWriteSuperset.tag !== type2.canWriteSuperset.tag) {\n                return false;\n            }\n            if (type1.canWriteSuperset instanceof EntityType && type2.canWriteSuperset instanceof EntityType) {\n                return Schema.union(type1.canWriteSuperset.entitySchema, type2.canWriteSuperset.entitySchema) !== null;\n            }\n        }\n        return true;\n    }\n    isSlot() {\n        return this instanceof SlotType;\n    }\n    // If you want to type-check fully, this is an improvement over just using\n    // this instanceof CollectionType,\n    // because instanceof doesn't propagate generic restrictions.\n    isCollectionType() {\n        return this instanceof CollectionType;\n    }\n    // If you want to type-check fully, this is an improvement over just using\n    // this instaneceof BigCollectionType,\n    // because instanceof doesn't propagate generic restrictions.\n    isBigCollectionType() {\n        return this instanceof BigCollectionType;\n    }\n    isResolved() {\n        // TODO: one of these should not exist.\n        return !this.hasUnresolvedVariable;\n    }\n    mergeTypeVariablesByName(variableMap) {\n        return this;\n    }\n    _applyExistenceTypeTest(test) {\n        return test(this);\n    }\n    get hasVariable() {\n        return this._applyExistenceTypeTest(type => type instanceof TypeVariable);\n    }\n    get hasUnresolvedVariable() {\n        return this._applyExistenceTypeTest(type => type instanceof TypeVariable && !type.variable.isResolved());\n    }\n    getContainedType() {\n        return null;\n    }\n    isTypeContainer() {\n        return false;\n    }\n    collectionOf() {\n        return new CollectionType(this);\n    }\n    bigCollectionOf() {\n        return new BigCollectionType(this);\n    }\n    resolvedType() {\n        return this;\n    }\n    canEnsureResolved() {\n        return this.isResolved() || this._canEnsureResolved();\n    }\n    _canEnsureResolved() {\n        return true;\n    }\n    maybeEnsureResolved() {\n        return true;\n    }\n    get canWriteSuperset() {\n        throw new Error(`canWriteSuperset not implemented for ${this}`);\n    }\n    get canReadSubset() {\n        throw new Error(`canReadSubset not implemented for ${this}`);\n    }\n    isMoreSpecificThan(type) {\n        return this.tag === type.tag && this._isMoreSpecificThan(type);\n    }\n    _isMoreSpecificThan(type) {\n        throw new Error(`isMoreSpecificThan not implemented for ${this}`);\n    }\n    /**\n     * Clone a type object.\n     * When cloning multiple types, variables that were associated with the same name\n     * before cloning should still be associated after cloning. To maintain this\n     * property, create a Map() and pass it into all clone calls in the group.\n     */\n    clone(variableMap) {\n        return this.resolvedType()._clone(variableMap);\n    }\n    _clone(variableMap) {\n        return Type.fromLiteral(this.toLiteral());\n    }\n    /**\n     * Clone a type object, maintaining resolution information.\n     * This function SHOULD NOT BE USED at the type level. In order for type variable\n     * information to be maintained correctly, an entire context root needs to be\n     * cloned.\n     */\n    _cloneWithResolutions(variableMap) {\n        return Type.fromLiteral(this.toLiteral());\n    }\n    // TODO: is this the same as _applyExistenceTypeTest\n    hasProperty(property) {\n        return property(this) || this._hasProperty(property);\n    }\n    _hasProperty(property) {\n        return false;\n    }\n    toString(options = undefined) {\n        return this.tag;\n    }\n    getEntitySchema() {\n        return null;\n    }\n    toPrettyString() {\n        return null;\n    }\n}\nexport class EntityType extends Type {\n    constructor(schema) {\n        super('Entity');\n        this.entitySchema = schema;\n    }\n    static make(names, fields, description) {\n        return new EntityType(new Schema(names, fields, description));\n    }\n    // These type identifier methods are being left in place for non-runtime code.\n    get isEntity() {\n        return true;\n    }\n    get canWriteSuperset() {\n        return this;\n    }\n    get canReadSubset() {\n        return this;\n    }\n    _isMoreSpecificThan(type) {\n        return this.entitySchema.isMoreSpecificThan(type.entitySchema);\n    }\n    toLiteral() {\n        return { tag: this.tag, data: this.entitySchema.toLiteral() };\n    }\n    toString(options = undefined) {\n        return this.entitySchema.toInlineSchemaString(options);\n    }\n    getEntitySchema() {\n        return this.entitySchema;\n    }\n    _cloneWithResolutions(variableMap) {\n        if (variableMap.has(this.entitySchema)) {\n            return variableMap.get(this.entitySchema);\n        }\n        const clonedEntityType = new EntityType(this.entitySchema);\n        variableMap.set(this.entitySchema, clonedEntityType);\n        return clonedEntityType;\n    }\n    toPrettyString() {\n        if (this.entitySchema.description.pattern) {\n            return this.entitySchema.description.pattern;\n        }\n        // Spit MyTypeFOO to My Type FOO\n        if (this.entitySchema.name) {\n            return this.entitySchema.name.replace(/([^A-Z])([A-Z])/g, '$1 $2')\n                .replace(/([A-Z][^A-Z])/g, ' $1')\n                .replace(/[\\s]+/g, ' ')\n                .trim();\n        }\n        return JSON.stringify(this.entitySchema.toLiteral());\n    }\n}\nexport class TypeVariable extends Type {\n    constructor(variable) {\n        super('TypeVariable');\n        this.variable = variable;\n    }\n    static make(name, canWriteSuperset, canReadSubset) {\n        return new TypeVariable(new TypeVariableInfo(name, canWriteSuperset, canReadSubset));\n    }\n    get isVariable() {\n        return true;\n    }\n    mergeTypeVariablesByName(variableMap) {\n        const name = this.variable.name;\n        let variable = variableMap.get(name);\n        if (!variable) {\n            variable = this;\n            variableMap.set(name, this);\n        }\n        else if (variable instanceof TypeVariable) {\n            if (variable.variable.hasConstraint || this.variable.hasConstraint) {\n                const mergedConstraint = variable.variable.maybeMergeConstraints(this.variable);\n                if (!mergedConstraint) {\n                    throw new Error('could not merge type variables');\n                }\n            }\n        }\n        return variable;\n    }\n    resolvedType() {\n        return this.variable.resolution || this;\n    }\n    _canEnsureResolved() {\n        return this.variable.canEnsureResolved();\n    }\n    maybeEnsureResolved() {\n        return this.variable.maybeEnsureResolved();\n    }\n    get canWriteSuperset() {\n        return this.variable.canWriteSuperset;\n    }\n    get canReadSubset() {\n        return this.variable.canReadSubset;\n    }\n    _clone(variableMap) {\n        const name = this.variable.name;\n        if (variableMap.has(name)) {\n            return new TypeVariable(variableMap.get(name));\n        }\n        else {\n            const newTypeVariable = TypeVariableInfo.fromLiteral(this.variable.toLiteral());\n            variableMap.set(name, newTypeVariable);\n            return new TypeVariable(newTypeVariable);\n        }\n    }\n    _cloneWithResolutions(variableMap) {\n        if (variableMap.has(this.variable)) {\n            return new TypeVariable(variableMap.get(this.variable));\n        }\n        else {\n            const newTypeVariable = TypeVariableInfo.fromLiteral(this.variable.toLiteralIgnoringResolutions());\n            if (this.variable.resolution) {\n                newTypeVariable._resolution = this.variable._resolution._cloneWithResolutions(variableMap);\n            }\n            if (this.variable._canReadSubset) {\n                newTypeVariable.canReadSubset = this.variable.canReadSubset._cloneWithResolutions(variableMap);\n            }\n            if (this.variable._canWriteSuperset) {\n                newTypeVariable.canWriteSuperset = this.variable.canWriteSuperset._cloneWithResolutions(variableMap);\n            }\n            variableMap.set(this.variable, newTypeVariable);\n            return new TypeVariable(newTypeVariable);\n        }\n    }\n    toLiteral() {\n        return this.variable.resolution ? this.variable.resolution.toLiteral()\n            : { tag: this.tag, data: this.variable.toLiteral() };\n    }\n    toString(options = undefined) {\n        return `~${this.variable.name}`;\n    }\n    getEntitySchema() {\n        return this.variable.isResolved() ? this.resolvedType().getEntitySchema() : null;\n    }\n    toPrettyString() {\n        return this.variable.isResolved() ? this.resolvedType().toPrettyString() : `[~${this.variable.name}]`;\n    }\n}\nexport class CollectionType extends Type {\n    constructor(collectionType) {\n        super('Collection');\n        this.collectionType = collectionType;\n    }\n    get isCollection() {\n        return true;\n    }\n    mergeTypeVariablesByName(variableMap) {\n        const collectionType = this.collectionType;\n        const result = collectionType.mergeTypeVariablesByName(variableMap);\n        return (result === collectionType) ? this : result.collectionOf();\n    }\n    _applyExistenceTypeTest(test) {\n        return this.collectionType._applyExistenceTypeTest(test);\n    }\n    getContainedType() {\n        return this.collectionType;\n    }\n    isTypeContainer() {\n        return true;\n    }\n    resolvedType() {\n        const collectionType = this.collectionType;\n        const resolvedCollectionType = collectionType.resolvedType();\n        return (collectionType !== resolvedCollectionType) ? resolvedCollectionType.collectionOf() : this;\n    }\n    _canEnsureResolved() {\n        return this.collectionType.canEnsureResolved();\n    }\n    maybeEnsureResolved() {\n        return this.collectionType.maybeEnsureResolved();\n    }\n    get canWriteSuperset() {\n        return InterfaceType.make(this.tag, [], []);\n    }\n    get canReadSubset() {\n        return InterfaceType.make(this.tag, [], []);\n    }\n    _clone(variableMap) {\n        const data = this.collectionType.clone(variableMap).toLiteral();\n        return Type.fromLiteral({ tag: this.tag, data });\n    }\n    _cloneWithResolutions(variableMap) {\n        return new CollectionType(this.collectionType._cloneWithResolutions(variableMap));\n    }\n    toLiteral() {\n        return { tag: this.tag, data: this.collectionType.toLiteral() };\n    }\n    _hasProperty(property) {\n        return this.collectionType.hasProperty(property);\n    }\n    toString(options = undefined) {\n        return `[${this.collectionType.toString(options)}]`;\n    }\n    getEntitySchema() {\n        return this.collectionType.getEntitySchema();\n    }\n    toPrettyString() {\n        const entitySchema = this.getEntitySchema();\n        if (entitySchema && entitySchema.description.plural) {\n            return entitySchema.description.plural;\n        }\n        return `${this.collectionType.toPrettyString()} List`;\n    }\n}\nexport class BigCollectionType extends Type {\n    constructor(bigCollectionType) {\n        super('BigCollection');\n        this.bigCollectionType = bigCollectionType;\n    }\n    get isBigCollection() {\n        return true;\n    }\n    mergeTypeVariablesByName(variableMap) {\n        const collectionType = this.bigCollectionType;\n        const result = collectionType.mergeTypeVariablesByName(variableMap);\n        return (result === collectionType) ? this : result.bigCollectionOf();\n    }\n    _applyExistenceTypeTest(test) {\n        return this.bigCollectionType._applyExistenceTypeTest(test);\n    }\n    getContainedType() {\n        return this.bigCollectionType;\n    }\n    isTypeContainer() {\n        return true;\n    }\n    resolvedType() {\n        const collectionType = this.bigCollectionType;\n        const resolvedCollectionType = collectionType.resolvedType();\n        return (collectionType !== resolvedCollectionType) ? resolvedCollectionType.bigCollectionOf() : this;\n    }\n    _canEnsureResolved() {\n        return this.bigCollectionType.canEnsureResolved();\n    }\n    maybeEnsureResolved() {\n        return this.bigCollectionType.maybeEnsureResolved();\n    }\n    get canWriteSuperset() {\n        return InterfaceType.make(this.tag, [], []);\n    }\n    get canReadSubset() {\n        return InterfaceType.make(this.tag, [], []);\n    }\n    _clone(variableMap) {\n        const data = this.bigCollectionType.clone(variableMap).toLiteral();\n        return Type.fromLiteral({ tag: this.tag, data });\n    }\n    _cloneWithResolutions(variableMap) {\n        return new BigCollectionType(this.bigCollectionType._cloneWithResolutions(variableMap));\n    }\n    toLiteral() {\n        return { tag: this.tag, data: this.bigCollectionType.toLiteral() };\n    }\n    _hasProperty(property) {\n        return this.bigCollectionType.hasProperty(property);\n    }\n    toString(options = undefined) {\n        return `BigCollection<${this.bigCollectionType.toString(options)}>`;\n    }\n    getEntitySchema() {\n        return this.bigCollectionType.getEntitySchema();\n    }\n    toPrettyString() {\n        const entitySchema = this.getEntitySchema();\n        if (entitySchema && entitySchema.description.plural) {\n            return entitySchema.description.plural;\n        }\n        return `Collection of ${this.bigCollectionType.toPrettyString()}`;\n    }\n}\nexport class RelationType extends Type {\n    constructor(relation) {\n        super('Relation');\n        this.relationEntities = relation;\n    }\n    get isRelation() {\n        return true;\n    }\n    toLiteral() {\n        return { tag: this.tag, data: this.relationEntities.map(t => t.toLiteral()) };\n    }\n    toPrettyString() {\n        return JSON.stringify(this.relationEntities);\n    }\n}\nexport class InterfaceType extends Type {\n    constructor(iface) {\n        super('Interface');\n        this.interfaceInfo = iface;\n    }\n    static make(name, handles, slots) {\n        return new InterfaceType(new InterfaceInfo(name, handles, slots));\n    }\n    get isInterface() {\n        return true;\n    }\n    mergeTypeVariablesByName(variableMap) {\n        const interfaceInfo = this.interfaceInfo.clone(new Map());\n        interfaceInfo.mergeTypeVariablesByName(variableMap);\n        // TODO: only build a new type when a variable is modified\n        return new InterfaceType(interfaceInfo);\n    }\n    _applyExistenceTypeTest(test) {\n        return this.interfaceInfo._applyExistenceTypeTest(test);\n    }\n    resolvedType() {\n        return new InterfaceType(this.interfaceInfo.resolvedType());\n    }\n    _canEnsureResolved() {\n        return this.interfaceInfo.canEnsureResolved();\n    }\n    maybeEnsureResolved() {\n        return this.interfaceInfo.maybeEnsureResolved();\n    }\n    get canWriteSuperset() {\n        return new InterfaceType(this.interfaceInfo.canWriteSuperset);\n    }\n    get canReadSubset() {\n        return new InterfaceType(this.interfaceInfo.canReadSubset);\n    }\n    _isMoreSpecificThan(type) {\n        return this.interfaceInfo.isMoreSpecificThan(type.interfaceInfo);\n    }\n    _clone(variableMap) {\n        const data = this.interfaceInfo.clone(variableMap).toLiteral();\n        return Type.fromLiteral({ tag: this.tag, data });\n    }\n    _cloneWithResolutions(variableMap) {\n        return new InterfaceType(this.interfaceInfo._cloneWithResolutions(variableMap));\n    }\n    toLiteral() {\n        return { tag: this.tag, data: this.interfaceInfo.toLiteral() };\n    }\n    toString(options = undefined) {\n        return this.interfaceInfo.name;\n    }\n    toPrettyString() {\n        return this.interfaceInfo.toPrettyString();\n    }\n}\nexport class SlotType extends Type {\n    constructor(slot) {\n        super('Slot');\n        this.slot = slot;\n    }\n    static make(formFactor, handle) {\n        return new SlotType(new SlotInfo(formFactor, handle));\n    }\n    get canWriteSuperset() {\n        return this;\n    }\n    get canReadSubset() {\n        return this;\n    }\n    _isMoreSpecificThan(type) {\n        // TODO: formFactor checking, etc.\n        return true;\n    }\n    toLiteral() {\n        return { tag: this.tag, data: this.slot.toLiteral() };\n    }\n    toString(options = undefined) {\n        const fields = [];\n        for (const key of Object.keys(this.slot)) {\n            if (this.slot[key] !== undefined) {\n                fields.push(`${key}:${this.slot[key]}`);\n            }\n        }\n        let fieldsString = '';\n        if (fields.length !== 0) {\n            fieldsString = ` {${fields.join(', ')}}`;\n        }\n        return `Slot${fieldsString}`;\n    }\n    toPrettyString() {\n        const fields = [];\n        for (const key of Object.keys(this.slot)) {\n            if (this.slot[key] !== undefined) {\n                fields.push(`${key}:${this.slot[key]}`);\n            }\n        }\n        let fieldsString = '';\n        if (fields.length !== 0) {\n            fieldsString = ` {${fields.join(', ')}}`;\n        }\n        return `Slot${fieldsString}`;\n    }\n}\nexport class ReferenceType extends Type {\n    constructor(reference) {\n        super('Reference');\n        this.referredType = reference;\n    }\n    get isReference() {\n        return true;\n    }\n    getContainedType() {\n        return this.referredType;\n    }\n    isTypeContainer() {\n        return true;\n    }\n    resolvedType() {\n        const referredType = this.referredType;\n        const resolvedReferredType = referredType.resolvedType();\n        return (referredType !== resolvedReferredType) ? new ReferenceType(resolvedReferredType) : this;\n    }\n    _canEnsureResolved() {\n        return this.referredType.canEnsureResolved();\n    }\n    maybeEnsureResolved() {\n        return this.referredType.maybeEnsureResolved();\n    }\n    get canWriteSuperset() {\n        // TODO(cypher1): Possibly cannot write to references.\n        return this.referredType.canWriteSuperset;\n    }\n    get canReadSubset() {\n        return this.referredType.canReadSubset;\n    }\n    _clone(variableMap) {\n        const data = this.referredType.clone(variableMap).toLiteral();\n        return Type.fromLiteral({ tag: this.tag, data });\n    }\n    _cloneWithResolutions(variableMap) {\n        return new ReferenceType(this.referredType._cloneWithResolutions(variableMap));\n    }\n    toLiteral() {\n        return { tag: this.tag, data: this.referredType.toLiteral() };\n    }\n    toString(options = undefined) {\n        return 'Reference<' + this.referredType.toString() + '>';\n    }\n}\nexport class ArcType extends Type {\n    constructor() {\n        super('Arc');\n    }\n    get isArc() {\n        return true;\n    }\n    newInstance(arcId, serialization) {\n        return new ArcInfo(arcId, serialization);\n    }\n    toLiteral() {\n        return { tag: this.tag };\n    }\n}\nexport class HandleType extends Type {\n    constructor() {\n        super('Handle');\n    }\n    get isHandle() {\n        return true;\n    }\n    toLiteral() {\n        return { tag: this.tag };\n    }\n}\n//# sourceMappingURL=type.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\nimport { TypeChecker } from './recipe/type-checker.js';\nimport { Type, TypeVariable } from './type.js';\nfunction _typeFromLiteral(member) {\n    return Type.fromLiteral(member);\n}\nfunction _typeVarOrStringFromLiteral(member) {\n    if (typeof member === 'object') {\n        return _typeFromLiteral(member);\n    }\n    return member;\n}\nfunction _HandleFromLiteral({ type, name, direction }) {\n    const typel = type ? _typeFromLiteral(type) : undefined;\n    const namel = name ? _typeVarOrStringFromLiteral(name) : undefined;\n    return { type: typel, name: namel, direction };\n}\nfunction _SlotFromLiteral({ name, direction, isRequired, isSet }) {\n    const namel = name ? _typeVarOrStringFromLiteral(name) : undefined;\n    return { name: namel, direction, isRequired, isSet };\n}\nfunction _typeToLiteral(member) {\n    return member.toLiteral();\n}\nfunction _typeVarOrStringToLiteral(member) {\n    if (member instanceof TypeVariable) {\n        return member.toLiteral();\n    }\n    return member;\n}\nfunction _HandleToLiteral({ type, name, direction }) {\n    const typel = type ? _typeToLiteral(type) : undefined;\n    const namel = name ? _typeVarOrStringToLiteral(name) : undefined;\n    return { type: typel, name: namel, direction };\n}\nfunction _SlotToLiteral({ name, direction, isRequired, isSet }) {\n    const namel = name ? _typeVarOrStringToLiteral(name) : undefined;\n    return { name: namel, direction, isRequired, isSet };\n}\nconst handleFields = ['type', 'name', 'direction'];\nconst slotFields = ['name', 'direction', 'isRequired', 'isSet'];\nexport class InterfaceInfo {\n    constructor(name, handles, slots) {\n        assert(name);\n        assert(handles !== undefined);\n        assert(slots !== undefined);\n        this.name = name;\n        this.handles = handles;\n        this.slots = slots;\n        this.typeVars = [];\n        for (const handle of handles) {\n            for (const field of handleFields) {\n                if (InterfaceInfo.isTypeVar(handle[field])) {\n                    this.typeVars.push({ object: handle, field });\n                }\n            }\n        }\n        for (const slot of slots) {\n            for (const field of slotFields) {\n                if (InterfaceInfo.isTypeVar(slot[field])) {\n                    this.typeVars.push({ object: slot, field });\n                }\n            }\n        }\n    }\n    toPrettyString() {\n        return 'InterfaceInfo';\n    }\n    mergeTypeVariablesByName(variableMap) {\n        this.typeVars.map(({ object, field }) => object[field] = object[field].mergeTypeVariablesByName(variableMap));\n    }\n    get canReadSubset() {\n        return this._cloneAndUpdate(typeVar => typeVar.canReadSubset);\n    }\n    get canWriteSuperset() {\n        return this._cloneAndUpdate(typeVar => typeVar.canWriteSuperset);\n    }\n    isMoreSpecificThan(other) {\n        if (this.handles.length !== other.handles.length ||\n            this.slots.length !== other.slots.length) {\n            return false;\n        }\n        // TODO: should probably confirm that handles and slots actually match.\n        for (let i = 0; i < this.typeVars.length; i++) {\n            const thisTypeVar = this.typeVars[i];\n            const otherTypeVar = other.typeVars[i];\n            if (!thisTypeVar.object[thisTypeVar.field].isMoreSpecificThan(otherTypeVar.object[otherTypeVar.field])) {\n                return false;\n            }\n        }\n        return true;\n    }\n    _applyExistenceTypeTest(test) {\n        for (const typeRef of this.typeVars) {\n            if (test(typeRef.object[typeRef.field])) {\n                return true;\n            }\n        }\n        return false;\n    }\n    _handlesToManifestString() {\n        return this.handles\n            .map(h => `  ${h.direction ? h.direction + ' ' : ''}${h.type.toString()} ${h.name ? h.name : '*'}`)\n            .join('\\n');\n    }\n    _slotsToManifestString() {\n        // TODO deal with isRequired\n        return this.slots\n            .map(slot => `  ${slot.direction} ${slot.isSet ? 'set of ' : ''}${slot.name ? slot.name + ' ' : ''}`)\n            .join('\\n');\n    }\n    // TODO: Include name as a property of the interface and normalize this to just toString()\n    toString() {\n        return `interface ${this.name}\n${this._handlesToManifestString()}\n${this._slotsToManifestString()}`;\n    }\n    static fromLiteral(data) {\n        const handles = data.handles.map(_HandleFromLiteral);\n        const slots = data.slots.map(_SlotFromLiteral);\n        return new InterfaceInfo(data.name, handles, slots);\n    }\n    toLiteral() {\n        const handles = this.handles.map(_HandleToLiteral);\n        const slots = this.slots.map(_SlotToLiteral);\n        return { name: this.name, handles, slots };\n    }\n    clone(variableMap) {\n        const handles = this.handles.map(({ name, direction, type }) => ({ name, direction, type: type ? type.clone(variableMap) : undefined }));\n        const slots = this.slots.map(({ name, direction, isRequired, isSet }) => ({ name, direction, isRequired, isSet }));\n        return new InterfaceInfo(this.name, handles, slots);\n    }\n    cloneWithResolutions(variableMap) {\n        return this._cloneWithResolutions(variableMap);\n    }\n    _cloneWithResolutions(variableMap) {\n        const handles = this.handles.map(({ name, direction, type }) => ({ name, direction, type: type ? type._cloneWithResolutions(variableMap) : undefined }));\n        const slots = this.slots.map(({ name, direction, isRequired, isSet }) => ({ name, direction, isRequired, isSet }));\n        return new InterfaceInfo(this.name, handles, slots);\n    }\n    canEnsureResolved() {\n        for (const typeVar of this.typeVars) {\n            if (!typeVar.object[typeVar.field].canEnsureResolved()) {\n                return false;\n            }\n        }\n        return true;\n    }\n    maybeEnsureResolved() {\n        for (const typeVar of this.typeVars) {\n            let variable = typeVar.object[typeVar.field];\n            variable = variable.clone(new Map());\n            if (!variable.maybeEnsureResolved())\n                return false;\n        }\n        for (const typeVar of this.typeVars) {\n            typeVar.object[typeVar.field].maybeEnsureResolved();\n        }\n        return true;\n    }\n    tryMergeTypeVariablesWith(other) {\n        // Type variable enabled slot matching will Just Work when we\n        // unify slots and handles.\n        if (!this._equalItems(other.slots, this.slots, this._equalSlot)) {\n            return null;\n        }\n        if (other.handles.length !== this.handles.length) {\n            return null;\n        }\n        const handles = new Set(this.handles);\n        const otherHandles = new Set(other.handles);\n        const handleMap = new Map();\n        let sizeCheck = handles.size;\n        while (handles.size > 0) {\n            const handleMatches = [...handles.values()].map(handle => ({ handle, match: [...otherHandles.values()].filter(otherHandle => this._equalHandle(handle, otherHandle)) }));\n            for (const handleMatch of handleMatches) {\n                // no match!\n                if (handleMatch.match.length === 0) {\n                    return null;\n                }\n                if (handleMatch.match.length === 1) {\n                    handleMap.set(handleMatch.handle, handleMatch.match[0]);\n                    otherHandles.delete(handleMatch.match[0]);\n                    handles.delete(handleMatch.handle);\n                }\n            }\n            // no progress!\n            if (handles.size === sizeCheck) {\n                return null;\n            }\n            sizeCheck = handles.size;\n        }\n        const handleList = [];\n        for (const handle of this.handles) {\n            const otherHandle = handleMap.get(handle);\n            let resultType;\n            if (handle.type.hasVariable || otherHandle.type.hasVariable) {\n                resultType = TypeChecker._tryMergeTypeVariable(handle.type, otherHandle.type);\n                if (!resultType) {\n                    return null;\n                }\n            }\n            else {\n                resultType = handle.type || otherHandle.type;\n            }\n            handleList.push({ name: handle.name || otherHandle.name, direction: handle.direction || otherHandle.direction, type: resultType });\n        }\n        const slots = this.slots.map(({ name, direction, isRequired, isSet }) => ({ name, direction, isRequired, isSet }));\n        return new InterfaceInfo(this.name, handleList, slots);\n    }\n    resolvedType() {\n        return this._cloneAndUpdate(typeVar => typeVar.resolvedType());\n    }\n    equals(other) {\n        if (this.handles.length !== other.handles.length) {\n            return false;\n        }\n        // TODO: this isn't quite right as it doesn't deal with duplicates properly\n        if (!this._equalItems(other.handles, this.handles, this._equalHandle)) {\n            return false;\n        }\n        if (!this._equalItems(other.slots, this.slots, this._equalSlot)) {\n            return false;\n        }\n        return true;\n    }\n    _equalHandle(handle, otherHandle) {\n        return handle.name === otherHandle.name\n            && handle.direction === otherHandle.direction\n            && TypeChecker.compareTypes({ type: handle.type }, { type: otherHandle.type });\n    }\n    _equalSlot(slot, otherSlot) {\n        return slot.name === otherSlot.name && slot.direction === otherSlot.direction && slot.isRequired === otherSlot.isRequired && slot.isSet === otherSlot.isSet;\n    }\n    _equalItems(otherItems, items, compareItem) {\n        for (const otherItem of otherItems) {\n            let exists = false;\n            for (const item of items) {\n                if (compareItem(item, otherItem)) {\n                    exists = true;\n                    break;\n                }\n            }\n            if (!exists) {\n                return false;\n            }\n        }\n        return true;\n    }\n    _cloneAndUpdate(update) {\n        const copy = this.clone(new Map());\n        copy.typeVars.forEach(typeVar => InterfaceInfo._updateTypeVar(typeVar, update));\n        return copy;\n    }\n    static _updateTypeVar(typeVar, update) {\n        typeVar.object[typeVar.field] = update(typeVar.object[typeVar.field]);\n    }\n    static isTypeVar(reference) {\n        return reference instanceof TypeVariable || reference instanceof Type && reference.hasVariable;\n    }\n    static mustMatch(reference) {\n        return !(reference == undefined || InterfaceInfo.isTypeVar(reference));\n    }\n    static handlesMatch(interfaceHandle, particleHandle) {\n        if (InterfaceInfo.mustMatch(interfaceHandle.name) &&\n            interfaceHandle.name !== particleHandle.name) {\n            return false;\n        }\n        // TODO: direction subsetting?\n        if (InterfaceInfo.mustMatch(interfaceHandle.direction) &&\n            interfaceHandle.direction !== particleHandle.direction) {\n            return false;\n        }\n        if (interfaceHandle.type == undefined) {\n            return true;\n        }\n        const [left, right] = Type.unwrapPair(interfaceHandle.type, particleHandle.type);\n        if (left instanceof TypeVariable) {\n            return [{ var: left, value: right, direction: interfaceHandle.direction }];\n        }\n        else {\n            return TypeChecker.compareTypes({ type: left }, { type: right });\n        }\n    }\n    static slotsMatch(interfaceSlot, particleSlot) {\n        if (InterfaceInfo.mustMatch(interfaceSlot.name) &&\n            interfaceSlot.name !== particleSlot.name) {\n            return false;\n        }\n        if (InterfaceInfo.mustMatch(interfaceSlot.direction) &&\n            interfaceSlot.direction !== particleSlot.direction) {\n            return false;\n        }\n        if (InterfaceInfo.mustMatch(interfaceSlot.isRequired) &&\n            interfaceSlot.isRequired !== particleSlot.isRequired) {\n            return false;\n        }\n        if (InterfaceInfo.mustMatch(interfaceSlot.isSet) &&\n            interfaceSlot.isSet !== particleSlot.isSet) {\n            return false;\n        }\n        return true;\n    }\n    particleMatches(particleSpec) {\n        const interfaceInfo = this.cloneWithResolutions(new Map());\n        return interfaceInfo.restrictType(particleSpec) !== false;\n    }\n    restrictType(particleSpec) {\n        return this._restrictThis(particleSpec);\n    }\n    _restrictThis(particleSpec) {\n        const handleMatches = this.handles.map(h => particleSpec.handleConnections.map(c => ({ match: c, result: InterfaceInfo.handlesMatch(h, c) }))\n            .filter(a => a.result !== false));\n        const particleSlots = [];\n        particleSpec.slotConnections.forEach(consumedSlot => {\n            particleSlots.push({ name: consumedSlot.name, direction: 'consume', isRequired: consumedSlot.isRequired, isSet: consumedSlot.isSet });\n            consumedSlot.provideSlotConnections.forEach(providedSlot => {\n                particleSlots.push({ name: providedSlot.name, direction: 'provide', isRequired: false, isSet: providedSlot.isSet });\n            });\n        });\n        const slotsThatMatch = this.slots.map(slot => particleSlots.filter(particleSlot => InterfaceInfo.slotsMatch(slot, particleSlot)));\n        const slotMatches = slotsThatMatch.map(matchList => matchList.map(slot => ({ match: slot, result: true })));\n        // TODO: this probably doesn't deal with multiple match options.\n        function choose(list, exclusions) {\n            if (list.length === 0) {\n                return [];\n            }\n            const thisLevel = list.pop();\n            for (const connection of thisLevel) {\n                if (exclusions.includes(connection.match)) {\n                    continue;\n                }\n                const newExclusions = exclusions.slice();\n                newExclusions.push(connection.match);\n                const constraints = choose(list, newExclusions);\n                if (constraints !== false) {\n                    if (typeof connection.result === 'boolean') {\n                        return constraints;\n                    }\n                    return constraints.concat(connection.result);\n                }\n            }\n            return false;\n        }\n        const handleOptions = choose(handleMatches, []);\n        const slotOptions = choose(slotMatches, []);\n        if (handleOptions === false || slotOptions === false) {\n            return false;\n        }\n        for (const constraint of handleOptions) {\n            if (!constraint.var.variable.resolution) {\n                constraint.var.variable.resolution = constraint.value;\n            }\n            else if (constraint.var.variable.resolution instanceof TypeVariable) {\n                // TODO(shans): revisit how this should be done,\n                // consider reusing tryMergeTypeVariablesWith(other).\n                if (!TypeChecker.processTypeList(constraint.var, [{\n                        type: constraint.value, direction: constraint.direction\n                    }]))\n                    return false;\n            }\n            else {\n                if (!TypeChecker.compareTypes({ type: constraint.var.variable.resolution }, { type: constraint.value })) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    }\n}\n//# sourceMappingURL=interface-info.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { Entity } from './entity.js';\nimport { EntityType, Type } from './type.js';\nexport class Schema {\n    // For convenience, primitive field types can be specified as {name: 'Type'}\n    // in `fields`; the constructor will convert these to the correct schema form.\n    // tslint:disable-next-line: no-any\n    constructor(names, fields, description) {\n        this.description = {};\n        this.names = names;\n        this.fields = {};\n        for (const [name, field] of Object.entries(fields)) {\n            if (typeof (field) === 'string') {\n                this.fields[name] = { kind: 'schema-primitive', type: field };\n            }\n            else {\n                this.fields[name] = field;\n            }\n        }\n        if (description) {\n            description.description.forEach(desc => this.description[desc.name] = desc.pattern || desc.patterns[0]);\n        }\n    }\n    toLiteral() {\n        const fields = {};\n        const updateField = field => {\n            if (field.kind === 'schema-reference') {\n                const schema = field.schema;\n                return { kind: 'schema-reference', schema: { kind: schema.kind, model: schema.model.toLiteral() } };\n            }\n            else if (field.kind === 'schema-collection') {\n                return { kind: 'schema-collection', schema: updateField(field.schema) };\n            }\n            else {\n                return field;\n            }\n        };\n        for (const key of Object.keys(this.fields)) {\n            fields[key] = updateField(this.fields[key]);\n        }\n        return { names: this.names, fields, description: this.description };\n    }\n    static fromLiteral(data = { fields: {}, names: [], description: {} }) {\n        const fields = {};\n        const updateField = field => {\n            if (field.kind === 'schema-reference') {\n                const schema = field.schema;\n                return { kind: 'schema-reference', schema: { kind: schema.kind, model: Type.fromLiteral(schema.model) } };\n            }\n            else if (field.kind === 'schema-collection') {\n                return { kind: 'schema-collection', schema: updateField(field.schema) };\n            }\n            else {\n                return field;\n            }\n        };\n        for (const key of Object.keys(data.fields)) {\n            fields[key] = updateField(data.fields[key]);\n        }\n        const result = new Schema(data.names, fields);\n        result.description = data.description || {};\n        return result;\n    }\n    // TODO: This should only be an ident used in manifest parsing.\n    get name() {\n        return this.names[0];\n    }\n    static typesEqual(fieldType1, fieldType2) {\n        // TODO: structural check instead of stringification.\n        return Schema._typeString(fieldType1) === Schema._typeString(fieldType2);\n    }\n    static _typeString(type) {\n        switch (type.kind) {\n            case 'schema-primitive':\n                return type.type;\n            case 'schema-union':\n                return `(${type.types.map(t => t.type).join(' or ')})`;\n            case 'schema-tuple':\n                return `(${type.types.map(t => t.type).join(', ')})`;\n            case 'schema-reference':\n                return `Reference<${Schema._typeString(type.schema)}>`;\n            case 'type-name':\n            case 'schema-inline':\n                return type.model.entitySchema.toInlineSchemaString();\n            case 'schema-collection':\n                return `[${Schema._typeString(type.schema)}]`;\n            default:\n                throw new Error(`Unknown type kind ${type.kind} in schema ${this.name}`);\n        }\n    }\n    static union(schema1, schema2) {\n        const names = [...new Set([...schema1.names, ...schema2.names])];\n        const fields = {};\n        for (const [field, type] of [...Object.entries(schema1.fields), ...Object.entries(schema2.fields)]) {\n            if (fields[field]) {\n                if (!Schema.typesEqual(fields[field], type)) {\n                    return null;\n                }\n            }\n            else {\n                fields[field] = type;\n            }\n        }\n        return new Schema(names, fields);\n    }\n    static intersect(schema1, schema2) {\n        const names = [...schema1.names].filter(name => schema2.names.includes(name));\n        const fields = {};\n        for (const [field, type] of Object.entries(schema1.fields)) {\n            const otherType = schema2.fields[field];\n            if (otherType && Schema.typesEqual(type, otherType)) {\n                fields[field] = type;\n            }\n        }\n        return new Schema(names, fields);\n    }\n    equals(otherSchema) {\n        return this === otherSchema || (this.name === otherSchema.name\n            // TODO: Check equality without calling contains.\n            && this.isMoreSpecificThan(otherSchema)\n            && otherSchema.isMoreSpecificThan(this));\n    }\n    isMoreSpecificThan(otherSchema) {\n        const names = new Set(this.names);\n        for (const name of otherSchema.names) {\n            if (!names.has(name)) {\n                return false;\n            }\n        }\n        const fields = {};\n        for (const [name, type] of Object.entries(this.fields)) {\n            fields[name] = type;\n        }\n        for (const [name, type] of Object.entries(otherSchema.fields)) {\n            if (fields[name] == undefined) {\n                return false;\n            }\n            if (!Schema.typesEqual(fields[name], type)) {\n                return false;\n            }\n        }\n        return true;\n    }\n    get type() {\n        return new EntityType(this);\n    }\n    entityClass(context = null) {\n        return Entity.createEntityClass(this, context);\n    }\n    toInlineSchemaString(options) {\n        const names = this.names.join(' ') || '*';\n        const fields = Object.entries(this.fields).map(([name, type]) => `${Schema._typeString(type)} ${name}`).join(', ');\n        return `${names} {${fields.length > 0 && options && options.hideFields ? '...' : fields}}`;\n    }\n    toManifestString() {\n        const results = [];\n        results.push(`schema ${this.names.join(' ')}`);\n        results.push(...Object.entries(this.fields).map(([name, type]) => `  ${Schema._typeString(type)} ${name}`));\n        if (Object.keys(this.description).length > 0) {\n            results.push(`  description \\`${this.description.pattern}\\``);\n            for (const name of Object.keys(this.description)) {\n                if (name !== 'pattern') {\n                    results.push(`    ${name} \\`${this.description[name]}\\``);\n                }\n            }\n        }\n        return results.join('\\n');\n    }\n}\n//# sourceMappingURL=schema.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\nimport { ReferenceType, EntityType } from './type.js';\nimport { Reference } from './reference.js';\nimport { TypeChecker } from './recipe/type-checker.js';\nimport { SYMBOL_INTERNALS } from './symbols.js';\n// This class holds extra entity-related fields used by the runtime. Instances of this are stored\n// in their parent Entity via a Symbol-based key. This allows Entities to hold whatever field names\n// their Schemas describe without any possibility of names clashing. For example, an Entity can have\n// an 'id' field that is distinct (in both value and type) from the id field here. Access to this\n// class should be via the static helpers in Entity.\nclass EntityInternals {\n    constructor(entity, entityClass, schema, context, userIDComponent) {\n        // TODO: Only the Arc that \"owns\" this Entity should be allowed to mutate it.\n        this.mutable = true;\n        this.entity = entity;\n        this.entityClass = entityClass;\n        this.schema = schema;\n        this.context = context;\n        this.userIDComponent = userIDComponent;\n    }\n    getId() {\n        if (this.id === undefined) {\n            throw new Error('no id');\n        }\n        return this.id;\n    }\n    getEntityClass() {\n        return this.entityClass;\n    }\n    isIdentified() {\n        return this.id !== undefined;\n    }\n    identify(identifier) {\n        assert(!this.isIdentified(), 'identify() called on already identified entity');\n        this.id = identifier;\n        const components = identifier.split(':');\n        const uid = components.lastIndexOf('uid');\n        this.userIDComponent = uid > 0 ? components.slice(uid + 1).join(':') : '';\n    }\n    createIdentity(parentId, idGenerator) {\n        assert(!this.isIdentified(), 'createIdentity() called on already identified entity');\n        let id;\n        if (this.userIDComponent) {\n            // TODO: Stop creating IDs by manually concatenating strings.\n            id = `${parentId.toString()}:uid:${this.userIDComponent}`;\n        }\n        else {\n            id = idGenerator.newChildId(parentId).toString();\n        }\n        this.id = id;\n    }\n    isMutable() {\n        return this.mutable;\n    }\n    /**\n     * Prevents further mutation of this Entity instance. Note that calling this method only affects\n     * this particular Entity instance; the entity it represents (in a data store somewhere) can\n     * still be mutated by others. Also note that this doesn't necessarily offer any security against\n     * malicious developers.\n     */\n    makeImmutable() {\n        this.mutable = false;\n    }\n    /**\n     * Mutates the entity. Supply either the new data for the entity, which replaces the existing\n     * entity's data entirely, or a mutation function. The supplied mutation function will be called\n     * with a mutable copy of the entity's data. The mutations performed by that function will be\n     * reflected in the original entity instance (i.e. mutations applied in place).\n     */\n    mutate(mutation) {\n        if (!this.mutable) {\n            throw new Error('Entity is immutable.');\n        }\n        let newData;\n        // Using typeof instead of instanceof here, because apparently sometimes lambdas aren't an instance of Function... :-/\n        if (typeof mutation === 'function') {\n            newData = this.dataClone();\n            mutation(newData);\n        }\n        else {\n            newData = mutation;\n        }\n        // Note that this does *not* trigger the error in the Entity's Proxy 'set' trap, because we're\n        // applying the field updates directly to the original Entity instance (this.entity), not the\n        // Proxied version returned by the Entity constructor. Not confusing at all!\n        sanitizeAndApply(this.entity, newData, this.schema, this.context);\n        // TODO: Send mutations to data store.\n    }\n    toLiteral() {\n        return JSON.parse(JSON.stringify(this.entity));\n    }\n    dataClone() {\n        const clone = {};\n        const fieldTypes = this.schema.fields;\n        for (const name of Object.keys(fieldTypes)) {\n            if (this.entity[name] !== undefined) {\n                if (fieldTypes[name] && fieldTypes[name].kind === 'schema-reference') {\n                    if (this.entity[name]) {\n                        clone[name] = this.entity[name].dataClone();\n                    }\n                }\n                else if (fieldTypes[name] && fieldTypes[name].kind === 'schema-collection') {\n                    if (this.entity[name]) {\n                        clone[name] = [...this.entity[name]].map(a => a.dataClone());\n                    }\n                }\n                else {\n                    clone[name] = this.entity[name];\n                }\n            }\n        }\n        return clone;\n    }\n    serialize() {\n        return { id: this.id, rawData: this.dataClone() };\n    }\n    debugLog() {\n        // Here be dragons! Create a copy of the entity class but with an enumerable version of this\n        // internals object so it will appear in the log output, with a few tweaks for better display.\n        const original = this.entity;\n        // Strip the noisy-and-not-very-useful 'location' field from the schema.\n        const schema = JSON.parse(JSON.stringify(this.schema, (k, v) => (k !== 'location') ? v : undefined));\n        const copy = new EntityInternals(null, this.entityClass, schema, this.context, this.userIDComponent);\n        copy.id = this.id;\n        // Force 'entity' to show as '[Circular]'. The 'any' is required because 'entity' is readonly.\n        // tslint:disable-next-line: no-any\n        copy.entity = copy;\n        // Set up a class that looks the same as the real entity, copy the schema fields in, add an\n        // enumerable version of the copied internals, and use console.dir to show the full object.\n        // Node displays the name set up with defineProperty below, but Chrome uses the name of the\n        // class variable defined here, so we'll call that entity.\n        const entity = class extends Entity {\n            constructor() {\n                super();\n                Object.assign(this, original);\n                this[SYMBOL_INTERNALS] = copy;\n            }\n        };\n        Object.defineProperty(entity, 'name', { value: original.constructor.name });\n        console.dir(new entity(), { depth: null });\n    }\n}\nexport class Entity {\n    toString() {\n        const fields = Object.entries(this).map(([name, value]) => `${name}: ${JSON.stringify(value)}`);\n        return `${this.constructor.name} { ${fields.join(', ')} }`;\n    }\n    // TODO: remove ASAP, once we're satisfied there are no lingering direct accesses on these fields\n    // Note that this breaks any schemas that have an 'id' field (or rawData/dataClone).\n    get id() { throw new Error('entity.id is no longer valid; use Entity.id() or Particle.idFor()'); }\n    get rawData() { throw new Error('entity.rawData is no longer valid; use plain .field access or spread notation'); }\n    get dataClone() { throw new Error('entity.dataClone() is no longer valid; use use Entity.dataClone() or Particle.dataClone()'); }\n    // Dynamically constructs a new JS class for the entity type represented by the given schema.\n    // This creates a new class which extends the Entity base class and implements the required\n    // static properties, then returns a Proxy wrapping that to guard against incorrect field writes.\n    static createEntityClass(schema, context) {\n        const clazz = class extends Entity {\n            constructor(data, userIDComponent) {\n                super();\n                assert(data, `can't construct entity with null data`);\n                assert(!userIDComponent || userIDComponent.indexOf(':') === -1, `user IDs must not contain the ':' character`);\n                // We want the SYMBOL_INTERNALS property to be non-enumerable so any copies made of this\n                // entity (e.g. via Object.assign) pick up only the plain data fields from the schema, and\n                // not the EntityInternals object (which should be unique to this instance).\n                Object.defineProperty(this, SYMBOL_INTERNALS, {\n                    value: new EntityInternals(this, clazz, schema, context, userIDComponent),\n                    enumerable: false\n                });\n                sanitizeAndApply(this, data, schema, context);\n                // We don't want a 'get' trap here because JS accesses various fields as part of routine\n                // system behaviour, and making sure we special case all of them is going to be brittle.\n                // For example: when returning an object from an async function, JS needs to check if the\n                // object is a 'thenable' (so it knows whether to wrap it in a Promise or not), and it does\n                // this by checking for the existence of a 'then' method. Not trapping 'get' is ok because\n                // callers who try to read fields that aren't in the schema will just get 'undefined', which\n                // is idiomatic for JS anyway.\n                return new Proxy(this, {\n                    set: (target, name, value) => {\n                        throw new Error(`Tried to modify entity field '${name}'. Use the mutate method instead.`);\n                    }\n                });\n            }\n            static get type() {\n                // TODO: should the entity's key just be its type?\n                // Should it just be called type in that case?\n                return new EntityType(schema);\n            }\n            static get key() {\n                return { tag: 'entity', schema };\n            }\n            static get schema() {\n                return schema;\n            }\n        };\n        // Override the name property to use the name of the entity given in the schema.\n        Object.defineProperty(clazz, 'name', { value: schema.name });\n        return clazz;\n    }\n    static id(entity) {\n        return getInternals(entity).getId();\n    }\n    static entityClass(entity) {\n        return getInternals(entity).getEntityClass();\n    }\n    static isIdentified(entity) {\n        return getInternals(entity).isIdentified();\n    }\n    static identify(entity, identifier) {\n        getInternals(entity).identify(identifier);\n    }\n    static createIdentity(entity, parentId, idGenerator) {\n        getInternals(entity).createIdentity(parentId, idGenerator);\n    }\n    static isMutable(entity) {\n        return getInternals(entity).isMutable();\n    }\n    static makeImmutable(entity) {\n        getInternals(entity).makeImmutable();\n    }\n    static mutate(entity, mutation) {\n        getInternals(entity).mutate(mutation);\n    }\n    static toLiteral(entity) {\n        return getInternals(entity).toLiteral();\n    }\n    static dataClone(entity) {\n        return getInternals(entity).dataClone();\n    }\n    static serialize(entity) {\n        return getInternals(entity).serialize();\n    }\n    // Because the internals object is non-enumerable, console.log(entity) in Node only shows the\n    // schema-based fields; use this function to log a more complete record of the entity in tests.\n    // Chrome's console.log already shows the internals object so that's usually sufficient for\n    // debugging, but this function can still be useful for logging a snapshot of an entity that\n    // is later modified.\n    static debugLog(entity) {\n        getInternals(entity).debugLog();\n    }\n}\nfunction getInternals(entity) {\n    const internals = entity[SYMBOL_INTERNALS];\n    assert(internals !== undefined, 'SYMBOL_INTERNALS lookup on non-entity');\n    return internals;\n}\nfunction sanitizeAndApply(target, data, schema, context) {\n    for (const [name, value] of Object.entries(data)) {\n        const sanitizedValue = sanitizeEntry(schema.fields[name], value, name, context);\n        validateFieldAndTypes(name, sanitizedValue, schema);\n        target[name] = sanitizedValue;\n    }\n}\nfunction convertToJsType(primitiveType, schemaName) {\n    switch (primitiveType.type) {\n        case 'Text':\n            return 'string';\n        case 'URL':\n            return 'string';\n        case 'Number':\n            return 'number';\n        case 'Boolean':\n            return 'boolean';\n        case 'Bytes':\n            return 'Uint8Array';\n        case 'Object':\n            return 'object';\n        default:\n            throw new Error(`Unknown field type ${primitiveType.type} in schema ${schemaName}`);\n    }\n}\n// tslint:disable-next-line: no-any\nfunction validateFieldAndTypes(name, value, schema, fieldType) {\n    fieldType = fieldType || schema.fields[name];\n    if (fieldType === undefined) {\n        throw new Error(`Can't set field ${name}; not in schema ${schema.name}`);\n    }\n    if (value === undefined || value === null) {\n        return;\n    }\n    switch (fieldType.kind) {\n        case 'schema-primitive': {\n            const valueType = value.constructor.name === 'Uint8Array' ? 'Uint8Array' : typeof (value);\n            if (valueType !== convertToJsType(fieldType, schema.name)) {\n                throw new TypeError(`Type mismatch setting field ${name} (type ${fieldType.type}); ` +\n                    `value '${value}' is type ${typeof (value)}`);\n            }\n            break;\n        }\n        case 'schema-union':\n            // Value must be a primitive that matches one of the union types.\n            for (const innerType of fieldType.types) {\n                if (typeof (value) === convertToJsType(innerType, schema.name)) {\n                    return;\n                }\n            }\n            throw new TypeError(`Type mismatch setting field ${name} (union [${fieldType.types}]); ` +\n                `value '${value}' is type ${typeof (value)}`);\n        case 'schema-tuple':\n            // Value must be an array whose contents match each of the tuple types.\n            if (!Array.isArray(value)) {\n                throw new TypeError(`Cannot set tuple ${name} with non-array value '${value}'`);\n            }\n            if (value.length !== fieldType.types.length) {\n                throw new TypeError(`Length mismatch setting tuple ${name} ` +\n                    `[${fieldType.types}] with value '${value}'`);\n            }\n            fieldType.types.map((innerType, i) => {\n                if (value[i] !== undefined && value[i] !== null &&\n                    typeof (value[i]) !== convertToJsType(innerType, schema.name)) {\n                    throw new TypeError(`Type mismatch setting field ${name} (tuple [${fieldType.types}]); ` +\n                        `value '${value}' has type ${typeof (value[i])} at index ${i}`);\n                }\n            });\n            break;\n        case 'schema-reference':\n            if (!(value instanceof Reference)) {\n                throw new TypeError(`Cannot set reference ${name} with non-reference '${value}'`);\n            }\n            if (!TypeChecker.compareTypes({ type: value.type }, { type: new ReferenceType(fieldType.schema.model) })) {\n                throw new TypeError(`Cannot set reference ${name} with value '${value}' of mismatched type`);\n            }\n            break;\n        case 'schema-collection':\n            // WTF?! value instanceof Set is returning false sometimes here because the Set in\n            // this environment (a native code constructor) isn't equal to the Set that the value\n            // has been constructed with (another native code constructor)...\n            if (value.constructor.name !== 'Set') {\n                throw new TypeError(`Cannot set collection ${name} with non-Set '${value}'`);\n            }\n            for (const element of value) {\n                validateFieldAndTypes(name, element, schema, fieldType.schema);\n            }\n            break;\n        default:\n            throw new Error(`Unknown kind '${fieldType.kind}' for field ${name} in schema ${schema.name}`);\n    }\n}\nfunction sanitizeEntry(type, value, name, context) {\n    if (!type) {\n        // If there isn't a field type for this, the proxy will pick up\n        // that fact and report a meaningful error.\n        return value;\n    }\n    if (type.kind === 'schema-reference' && value) {\n        if (value instanceof Reference) {\n            // Setting value as Reference (Particle side). This will enforce that the type provided for\n            // the handle matches the type of the reference.\n            return value;\n        }\n        else if (value.id && value.storageKey) {\n            // Setting value from raw data (Channel side).\n            // TODO(shans): This can't enforce type safety here as there isn't any type data available.\n            // Maybe this is OK because there's type checking on the other side of the channel?\n            return new Reference(value, new ReferenceType(type.schema.model), context);\n        }\n        else {\n            throw new TypeError(`Cannot set reference ${name} with non-reference '${value}'`);\n        }\n    }\n    else if (type.kind === 'schema-collection' && value) {\n        // WTF?! value instanceof Set is returning false sometimes here because the Set in\n        // this environment (a native code constructor) isn't equal to the Set that the value\n        // has been constructed with (another native code constructor)...\n        if (value.constructor.name === 'Set') {\n            return value;\n        }\n        else if (value.length && value instanceof Object) {\n            return new Set(value.map(v => sanitizeEntry(type.schema, v, name, context)));\n        }\n        else {\n            throw new TypeError(`Cannot set collection ${name} with non-collection '${value}'`);\n        }\n    }\n    else {\n        return value;\n    }\n}\n//# sourceMappingURL=entity.js.map","/**\n * @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\nimport { handleFor } from './handle.js';\nimport { ReferenceType } from './type.js';\nimport { Entity } from './entity.js';\nimport { SYMBOL_INTERNALS } from './symbols.js';\nvar ReferenceMode;\n(function (ReferenceMode) {\n    ReferenceMode[ReferenceMode[\"Unstored\"] = 0] = \"Unstored\";\n    ReferenceMode[ReferenceMode[\"Stored\"] = 1] = \"Stored\";\n})(ReferenceMode || (ReferenceMode = {}));\nexport class Reference {\n    constructor(data, type, context) {\n        this.entity = null;\n        this.storageProxy = null;\n        this.handle = null;\n        this.id = data.id;\n        this.storageKey = data.storageKey;\n        this.context = context;\n        this.type = type;\n        this[SYMBOL_INTERNALS] = {\n            serialize: () => ({ id: this.id, rawData: this.dataClone() })\n        };\n    }\n    async ensureStorageProxy() {\n        if (this.storageProxy == null) {\n            this.storageProxy = await this.context.getStorageProxy(this.storageKey, this.type.referredType);\n            this.handle = handleFor(this.storageProxy, this.context.idGenerator);\n            if (this.storageKey) {\n                assert(this.storageKey === this.storageProxy.storageKey);\n            }\n            else {\n                this.storageKey = this.storageProxy.storageKey;\n            }\n        }\n    }\n    async dereference() {\n        assert(this.context, 'Must have context to dereference');\n        if (this.entity) {\n            return this.entity;\n        }\n        await this.ensureStorageProxy();\n        this.entity = await this.handle.get(this.id);\n        return this.entity;\n    }\n    dataClone() {\n        return { storageKey: this.storageKey, id: this.id };\n    }\n}\n/** A subclass of Reference that clients can create. */\nexport class ClientReference extends Reference {\n    /** Use the newClientReference factory method instead. */\n    constructor(entity, context) {\n        // TODO(shans): start carrying storageKey information around on Entity objects\n        super({ id: Entity.id(entity), storageKey: null }, new ReferenceType(Entity.entityClass(entity).type), context);\n        this.mode = ReferenceMode.Unstored;\n        this.entity = entity;\n        this.stored = new Promise(async (resolve, reject) => {\n            await this.storeReference(entity);\n            resolve();\n        });\n    }\n    async storeReference(entity) {\n        await this.ensureStorageProxy();\n        await this.handle.store(entity);\n        this.mode = ReferenceMode.Stored;\n    }\n    async dereference() {\n        if (this.mode === ReferenceMode.Unstored) {\n            return null;\n        }\n        return super.dereference();\n    }\n    isIdentified() {\n        return Entity.isIdentified(this.entity);\n    }\n    static newClientReference(context) {\n        return class extends ClientReference {\n            constructor(entity) {\n                super(entity, context);\n            }\n        };\n    }\n}\n//# sourceMappingURL=reference.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\nimport { SystemException, UserException } from './arc-exceptions.js';\nimport { ParticleSpec } from './particle-spec.js';\nimport { Reference } from './reference.js';\nimport { BigCollectionType, CollectionType, EntityType, InterfaceType, ReferenceType } from './type.js';\nimport { Entity } from './entity.js';\nimport { Id } from './id.js';\nimport { SYMBOL_INTERNALS } from './symbols.js';\n// TODO: This won't be needed once runtime is transferred between contexts.\nfunction cloneData(data) {\n    return data;\n    //return JSON.parse(JSON.stringify(data));\n}\nfunction restore(entry, entityClass) {\n    assert(entityClass, 'Handles need entity classes for deserialization');\n    const { id, rawData } = entry;\n    const entity = new entityClass(cloneData(rawData));\n    if (entry.id) {\n        Entity.identify(entity, entry.id);\n    }\n    // TODO some relation magic, somewhere, at some point.\n    return entity;\n}\n/**\n * Base class for Collections and Singletons.\n */\nexport class Handle {\n    // TODO type particleId, marked as string, but called with number\n    constructor(storage, idGenerator, name, particleId, canRead, canWrite) {\n        assert(!(storage instanceof Handle));\n        this.storage = storage;\n        this.idGenerator = idGenerator;\n        this.name = name || this.storage.name;\n        this.canRead = canRead;\n        this.canWrite = canWrite;\n        this._particleId = particleId;\n        this.options = {\n            keepSynced: true,\n            notifySync: true,\n            notifyUpdate: true,\n            notifyDesync: false,\n        };\n    }\n    reportUserExceptionInHost(exception, particle, method) {\n        this.storage.reportExceptionInHost(new UserException(exception, method, this._particleId, particle.spec.name));\n    }\n    reportSystemExceptionInHost(exception, method) {\n        this.storage.reportExceptionInHost(new SystemException(exception, method, this._particleId));\n    }\n    // `options` may contain any of:\n    // - keepSynced (bool): load full data on startup, maintain data in proxy and resync as required\n    // - notifySync (bool): if keepSynced is true, call onHandleSync when the full data is received\n    // - notifyUpdate (bool): call onHandleUpdate for every change event received\n    // - notifyDesync (bool): if keepSynced is true, call onHandleDesync when desync is detected\n    configure(options) {\n        assert(this.canRead, 'configure can only be called on readable Handles');\n        try {\n            const keys = Object.keys(this.options);\n            const badKeys = Object.keys(options).filter(o => !keys.includes(o));\n            if (badKeys.length > 0) {\n                throw new Error(`Invalid option in Handle.configure(): ${badKeys}`);\n            }\n            Object.assign(this.options, options);\n        }\n        catch (e) {\n            this.reportSystemExceptionInHost(e, 'Handle::configure');\n            throw e;\n        }\n    }\n    _serialize(entity) {\n        assert(entity, `can't serialize a null entity`);\n        if (entity instanceof Entity) {\n            if (!Entity.isIdentified(entity)) {\n                this.createIdentityFor(entity);\n            }\n        }\n        return entity[SYMBOL_INTERNALS].serialize();\n    }\n    createIdentityFor(entity) {\n        Entity.createIdentity(entity, Id.fromString(this._id), this.idGenerator);\n    }\n    get type() {\n        return this.storage.type;\n    }\n    get _id() {\n        return this.storage.id;\n    }\n    toManifestString() {\n        return `'${this._id}'`;\n    }\n    generateKey() {\n        return this.idGenerator.newChildId(Id.fromString(this._id), 'key').toString();\n    }\n}\n/**\n * A handle on a set of Entity data. Note that, as a set, a Collection can only\n * contain a single version of an Entity for each given ID. Further, no order is\n * implied by the set. A particle's manifest dictates the types of handles that\n * need to be connected to that particle, and the current recipe identifies\n * which handles are connected.\n */\nexport class Collection extends Handle {\n    async _notify(kind, particle, details) {\n        assert(this.canRead, '_notify should not be called for non-readable handles');\n        switch (kind) {\n            case 'sync':\n                await particle.callOnHandleSync(this, this._restore(details), e => this.reportUserExceptionInHost(e, particle, 'onHandleSync'));\n                return;\n            case 'update': {\n                // tslint:disable-next-line: no-any\n                const update = {};\n                if ('add' in details) {\n                    update.added = this._restore(details.add);\n                }\n                if ('remove' in details) {\n                    update.removed = this._restore(details.remove);\n                }\n                update.originator = details.originatorId === this._particleId;\n                await particle.callOnHandleUpdate(this, update, e => this.reportUserExceptionInHost(e, particle, 'onHandleUpdate'));\n                return;\n            }\n            case 'desync':\n                await particle.callOnHandleDesync(this, e => this.reportUserExceptionInHost(e, particle, 'onHandleUpdate'));\n                return;\n            default:\n                throw new Error('unsupported');\n        }\n    }\n    /**\n     * Returns the Entity specified by id contained by the handle, or null if this id is not\n     * contained by the handle.\n     * @throws {Error} if this handle is not configured as a readable handle (i.e. 'in' or 'inout')\n     * in the particle's manifest.\n     */\n    async get(id) {\n        if (!this.canRead) {\n            throw new Error('Handle not readable');\n        }\n        return this._restore([await this.storage.get(id)])[0];\n    }\n    /**\n     * @returns a list of the Entities contained by the handle.\n     * @throws {Error} if this handle is not configured as a readable handle (i.e. 'in' or 'inout')\n     * in the particle's manifest.\n     */\n    async toList() {\n        if (!this.canRead) {\n            throw new Error('Handle not readable');\n        }\n        return this._restore(await this.storage.toList());\n    }\n    _restore(list) {\n        return (list !== null) ? list.map(a => restore(a, this.entityClass)) : null;\n    }\n    /**\n     * Stores a new entity into the Handle.\n     * @throws {Error} if this handle is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async store(entity) {\n        if (!this.canWrite) {\n            throw new Error('Handle not writeable');\n        }\n        const serialization = this._serialize(entity);\n        const keys = [this.generateKey()];\n        return this.storage.store(serialization, keys, this._particleId);\n    }\n    /**\n     * Removes all known entities from the Handle.\n     * @throws {Error} if this handle is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async clear() {\n        if (!this.canWrite) {\n            throw new Error('Handle not writeable');\n        }\n        if (this.storage.clear) {\n            return this.storage.clear(this._particleId);\n        }\n        else {\n            throw new Error('clear not implemented by storage');\n        }\n    }\n    /**\n     * Removes an entity from the Handle.\n     * @throws {Error} if this handle is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async remove(entity) {\n        if (!this.canWrite) {\n            throw new Error('Handle not writeable');\n        }\n        const serialization = this._serialize(entity);\n        // Remove the keys that exist at storage/proxy.\n        const keys = [];\n        await this.storage.remove(serialization.id, keys, this._particleId);\n    }\n}\n/**\n * A handle on a single entity. A particle's manifest dictates\n * the types of handles that need to be connected to that particle, and\n * the current recipe identifies which handles are connected.\n */\nexport class Singleton extends Handle {\n    // Called by StorageProxy.\n    async _notify(kind, particle, details) {\n        assert(this.canRead, '_notify should not be called for non-readable handles');\n        switch (kind) {\n            case 'sync':\n                await particle.callOnHandleSync(this, this._restore(details), e => this.reportUserExceptionInHost(e, particle, 'onHandleSync'));\n                return;\n            case 'update': {\n                const data = this._restore(details.data);\n                const oldData = this._restore(details.oldData);\n                await particle.callOnHandleUpdate(this, { data, oldData }, e => this.reportUserExceptionInHost(e, particle, 'onHandleUpdate'));\n                return;\n            }\n            case 'desync':\n                await particle.callOnHandleDesync(this, e => this.reportUserExceptionInHost(e, particle, 'onHandleDesync'));\n                return;\n            default:\n                throw new Error('unsupported');\n        }\n    }\n    /**\n     * @returns the Entity contained by the Singleton, or undefined if the Singleton is cleared.\n     * @throws {Error} if this Singleton is not configured as a readable handle (i.e. 'in' or 'inout')\n     * in the particle's manifest.\n     */\n    async get() {\n        if (!this.canRead) {\n            throw new Error('Handle not readable');\n        }\n        const model = await this.storage.get();\n        return this._restore(model);\n    }\n    _restore(model) {\n        if (model == null) {\n            return null;\n        }\n        if (this.type instanceof EntityType) {\n            return restore(model, this.entityClass);\n        }\n        if (this.type instanceof InterfaceType) {\n            return ParticleSpec.fromLiteral(model);\n        }\n        if (this.type instanceof ReferenceType) {\n            return new Reference(model, this.type, this.storage.pec);\n        }\n        throw new Error(`Don't know how to deliver handle data of type ${this.type}`);\n    }\n    /**\n     * Stores a new entity into the Singleton, replacing any existing entity.\n     * @throws {Error} if this Singleton is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async set(entity) {\n        try {\n            if (!this.canWrite) {\n                throw new Error('Handle not writeable');\n            }\n            const serialization = this._serialize(entity);\n            return this.storage.set(serialization, this._particleId);\n        }\n        catch (e) {\n            this.reportSystemExceptionInHost(e, 'Handle::set');\n            throw e;\n        }\n    }\n    /**\n     * Clears any entity currently in the Singleton.\n     * @throws {Error} if this Singleton is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async clear() {\n        if (!this.canWrite) {\n            throw new Error('Handle not writeable');\n        }\n        return this.storage.clear(this._particleId);\n    }\n}\n/**\n * Provides paginated read access to a BigCollection. Conforms to the javascript iterator protocol\n * but is not marked as iterable because next() is async, which is currently not supported by\n * implicit iteration in Javascript.\n */\nclass Cursor {\n    constructor(parent, cursorId) {\n        this._parent = parent;\n        this._cursorId = cursorId;\n    }\n    /**\n     * Returns {value: [items], done: false} while there are items still available, or {done: true}\n     * when the cursor has completed reading the collection.\n     */\n    async next() {\n        const data = await this._parent.storage.cursorNext(this._cursorId);\n        if (!data.done) {\n            data.value = data.value.map(a => restore(a, this._parent.entityClass));\n        }\n        return data;\n    }\n    /**\n     * Terminates the streamed read. This must be called if a cursor is no longer needed but has not\n     * yet completed streaming (i.e. next() hasn't returned {done: true}).\n     */\n    close() {\n        this._parent.storage.cursorClose(this._cursorId);\n    }\n}\n/**\n * A handle on a large set of Entity data. Similar to Collection, except the complete set of\n * entities is not available directly; use stream() to read the full set. Particles wanting to\n * operate on BigCollections should do so in the setHandles() call, since BigCollections do not\n * trigger onHandleSync() or onHandleUpdate().\n */\nexport class BigCollection extends Handle {\n    configure(options) {\n        throw new Error('BigCollections do not support sync/update configuration');\n    }\n    async _notify(kind, particle, details) {\n        assert(this.canRead, '_notify should not be called for non-readable handles');\n        assert(kind === 'sync', 'BigCollection._notify only supports sync events');\n        await particle.callOnHandleSync(this, [], e => this.reportUserExceptionInHost(e, particle, 'onHandleSync'));\n    }\n    /**\n     * Stores a new entity into the Handle.\n     * @throws {Error} if this handle is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async store(entity) {\n        if (!this.canWrite) {\n            throw new Error('Handle not writeable');\n        }\n        const serialization = this._serialize(entity);\n        const keys = [this.generateKey()];\n        return this.storage.store(serialization, keys, this._particleId);\n    }\n    /**\n     * Removes an entity from the Handle.\n     * @throws {Error} if this handle is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async remove(entity) {\n        if (!this.canWrite) {\n            throw new Error('Handle not writeable');\n        }\n        const serialization = this._serialize(entity);\n        await this.storage.remove(serialization.id, [], this._particleId);\n    }\n    /**\n     * @returns a Cursor instance that iterates over the full set of entities, reading `pageSize`\n     * entities at a time. The cursor views a snapshot of the collection, locked to the version\n     * at which the cursor is created.\n     *\n     * By default items are returned in order of original insertion into the collection (with the\n     * caveat that items removed during a streamed read may be returned at the end). Set `forward`\n     * to false to return items in reverse insertion order.\n     *\n     * @throws {Error} if this Singleton is not configured as a readable handle (i.e. 'in' or 'inout')\n     * in the particle's manifest.\n     */\n    async stream({ pageSize, forward = true }) {\n        if (!this.canRead) {\n            throw new Error('Handle not readable');\n        }\n        if (isNaN(pageSize) || pageSize < 1) {\n            throw new Error('Streamed reads require a positive pageSize');\n        }\n        const cursorId = await this.storage.stream(pageSize, forward);\n        return new Cursor(this, cursorId);\n    }\n}\nexport function handleFor(storage, idGenerator, name = null, particleId = '', canRead = true, canWrite = true) {\n    let handle;\n    if (storage.type instanceof CollectionType) {\n        handle = new Collection(storage, idGenerator, name, particleId, canRead, canWrite);\n    }\n    else if (storage.type instanceof BigCollectionType) {\n        handle = new BigCollection(storage, idGenerator, name, particleId, canRead, canWrite);\n    }\n    else {\n        handle = new Singleton(storage, idGenerator, name, particleId, canRead, canWrite);\n    }\n    const type = storage.type.getContainedType() || storage.type;\n    if (type instanceof EntityType) {\n        handle.entityClass = type.entitySchema.entityClass(storage.pec);\n    }\n    return handle;\n}\n//# sourceMappingURL=handle.js.map","/** An exception that is to be propagated back to the host. */\nexport class PropagatedException extends Error {\n    constructor(cause, method, particleId, particleName) {\n        super();\n        this.cause = cause;\n        this.method = method;\n        this.particleId = particleId;\n        this.particleName = particleName;\n        this.stack += `\\nCaused by: ${this.cause.stack}`;\n    }\n    toLiteral() {\n        return {\n            exceptionType: this.constructor.name,\n            cause: {\n                name: this.cause.name,\n                message: this.cause.message,\n                stack: this.cause.stack,\n            },\n            method: this.method,\n            particleId: this.particleId,\n            particleName: this.particleName,\n            stack: this.stack,\n        };\n    }\n    static fromLiteral(literal) {\n        const cause = literal.cause;\n        let exception;\n        switch (literal.exceptionType) {\n            case SystemException.name:\n                exception = new SystemException(cause, literal.method, literal.particleId, literal.particleName);\n                break;\n            case UserException.name:\n                exception = new UserException(cause, literal.method, literal.particleId, literal.particleName);\n                break;\n            default:\n                throw new Error(`Unknown exception type: ${literal.exceptionType}`);\n        }\n        exception.stack = literal.stack;\n        return exception;\n    }\n}\n/** An exception thrown in Arcs runtime code. */\nexport class SystemException extends PropagatedException {\n    get message() {\n        const particleName = this.particleName ? this.particleName : this.particleId;\n        return `SystemException: exception ${this.cause.name} raised when invoking system function ${this.method} on behalf of particle ${particleName}: ${this.cause.message}`;\n    }\n}\n/** An exception thrown in the user particle code (as opposed to an error in the Arcs runtime). */\nexport class UserException extends PropagatedException {\n    get message() {\n        const particleName = this.particleName ? this.particleName : this.particleId;\n        return `UserException: exception ${this.cause.name} raised when invoking function ${this.method} on particle ${particleName}: ${this.cause.message}`;\n    }\n}\nconst systemHandlers = [];\nexport function reportSystemException(exception) {\n    for (const handler of systemHandlers) {\n        handler(exception);\n    }\n}\nexport function registerSystemExceptionHandler(handler) {\n    if (!systemHandlers.includes(handler)) {\n        systemHandlers.push(handler);\n    }\n}\nexport function removeSystemExceptionHandler(handler) {\n    const idx = systemHandlers.indexOf(handler);\n    if (idx > -1) {\n        systemHandlers.splice(idx, 1);\n    }\n}\nregisterSystemExceptionHandler((exception) => {\n    console.log(exception.method, exception.particleName);\n    throw exception;\n});\n//# sourceMappingURL=arc-exceptions.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { Random } from './random.js';\n/**\n * Generates new IDs which are rooted in the current session. Only one IdGenerator should be instantiated for each running Arc, and all of the\n * IDs created should be created using that same IdGenerator instance.\n */\nexport class IdGenerator {\n    /** Use the newSession factory method instead. */\n    constructor(currentSessionId) {\n        this._nextComponentId = 0;\n        this._currentSessionId = currentSessionId;\n    }\n    /** Generates a new random session ID to use when creating new IDs. */\n    static newSession() {\n        const sessionId = Math.floor(Random.next() * Math.pow(2, 50)) + '';\n        return new IdGenerator(sessionId);\n    }\n    /**\n     * Intended only for testing the IdGenerator class itself. Lets you specify the session ID manually. Prefer using the real\n     * IdGenerator.newSession() method when testing other classes.\n     */\n    static createWithSessionIdForTesting(sessionId) {\n        return new IdGenerator(sessionId);\n    }\n    newArcId(name) {\n        return ArcId._newArcIdInternal(this._currentSessionId, name);\n    }\n    /**\n     * Creates a new ID, as a child of the given parentId. The given subcomponent will be appended to the component hierarchy of the given ID, but\n     * the generator's random session ID will be used as the ID's root.\n     */\n    newChildId(parentId, subcomponent = '') {\n        // Append (and increment) a counter to the subcomponent, to ensure that it is unique.\n        subcomponent += this._nextComponentId++;\n        return Id._newIdInternal(this._currentSessionId, [...parentId.idTree, subcomponent]);\n    }\n    get currentSessionIdForTesting() {\n        return this._currentSessionId;\n    }\n}\n/**\n * An immutable object consisting of two components: a root, and an idTree. The root is the session ID from the particular session in which the\n * ID was constructed (see the IdGenerator class). The idTree is a list of subcomponents, forming a hierarchy of IDs (child IDs are created by\n * appending subcomponents to their parent ID's idTree).\n */\nexport class Id {\n    /** Protected constructor. Use IdGenerator to create new IDs instead. */\n    constructor(root, idTree = []) {\n        /** The components of the idTree. */\n        this.idTree = [];\n        this.root = root;\n        this.idTree = idTree;\n    }\n    /** Creates a new ID. Use IdGenerator to create new IDs instead. */\n    static _newIdInternal(root, idTree = []) {\n        return new Id(root, idTree);\n    }\n    /** Parses a string representation of an ID (see toString). */\n    static fromString(str) {\n        const bits = str.split(':');\n        if (bits[0].startsWith('!')) {\n            const root = bits[0].slice(1);\n            const idTree = bits.slice(1).filter(component => component.length > 0);\n            return new Id(root, idTree);\n        }\n        else {\n            return new Id('', bits);\n        }\n    }\n    /** Returns the full ID string. */\n    toString() {\n        return `!${this.root}:${this.idTree.join(':')}`;\n    }\n    /** Returns the idTree as as string (without the root). */\n    idTreeAsString() {\n        return this.idTree.join(':');\n    }\n    equal(id) {\n        if (id.root !== this.root || id.idTree.length !== this.idTree.length) {\n            return false;\n        }\n        for (let i = 0; i < id.idTree.length; i++) {\n            if (id.idTree[i] !== this.idTree[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n}\nexport class ArcId extends Id {\n    /** Creates a new Arc ID. Use IdGenerator to create new IDs instead. */\n    static _newArcIdInternal(root, name) {\n        return new ArcId(root, [name]);\n    }\n    /** Creates a new Arc ID with the given name. For convenience in unit testing only; otherwise use IdGenerator to create new IDs instead. */\n    static newForTest(id) {\n        return IdGenerator.newSession().newArcId(id);\n    }\n}\n//# sourceMappingURL=id.js.map","/**\n * @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nclass RNG {\n}\n/**\n * A basic random number generator using Math.random();\n */\nclass MathRandomRNG extends RNG {\n    next() {\n        return Math.random();\n    }\n}\n// Singleton Pattern\nconst random = new MathRandomRNG();\nexport class Random {\n    static next() {\n        return random.next();\n    }\n}\n//# sourceMappingURL=random.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n// TypeScript seems to lose the necessary type info if this symbol is wrapped in an object and then\n// used as an interface key (e.g. 'interface Foo { [Symbols.internals]: {...} }'), so we just have\n// to export it as a standard variable. See the EntityInternals class for the usage of this symbol.\nexport const SYMBOL_INTERNALS = Symbol('internals');\n//# sourceMappingURL=symbols.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nexport class SlotInfo {\n    constructor(formFactor, handle) {\n        this.formFactor = formFactor;\n        this.handle = handle;\n    }\n    toLiteral() {\n        return this;\n    }\n    static fromLiteral({ formFactor, handle }) {\n        return new SlotInfo(formFactor, handle);\n    }\n}\n//# sourceMappingURL=slot-info.js.map","/**\n * @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n// Equivalent to an Entity with Schema { serialization Text }\nexport class ArcInfo {\n    constructor(arcId, serialization) {\n        this.id = arcId.toString();\n        // TODO: remove the import-removal hack when import statements no longer appear\n        // in serialized manifests, or deal with them correctly if they end up staying\n        this.serialization = serialization.replace(/\\bimport .*\\n/g, '');\n    }\n    // Retrieves the serialized string from a stored instance of ArcInfo.\n    static extractSerialization(data) {\n        return data.serialization.replace(/\\bimport .*\\n/g, '');\n    }\n}\nexport class ArcHandle {\n    constructor(id, storageKey, type, tags) {\n        this.id = id;\n        this.storageKey = storageKey;\n        this.type = type;\n        this.tags = tags;\n    }\n}\n//# sourceMappingURL=synthetic-types.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\nimport { Schema } from './schema.js';\nimport { EntityType, SlotType, Type, TypeVariable } from './type.js';\nexport class TypeVariableInfo {\n    constructor(name, canWriteSuperset, canReadSubset) {\n        this.name = name;\n        this._canWriteSuperset = canWriteSuperset;\n        this._canReadSubset = canReadSubset;\n        this._resolution = null;\n    }\n    /**\n     * Merge both the read subset (upper bound) and write superset (lower bound) constraints\n     * of two variables together. Use this when two separate type variables need to resolve\n     * to the same value.\n     */\n    maybeMergeConstraints(variable) {\n        if (!this.maybeMergeCanReadSubset(variable.canReadSubset)) {\n            return false;\n        }\n        return this.maybeMergeCanWriteSuperset(variable.canWriteSuperset);\n    }\n    /**\n     * Merge a type variable's read subset (upper bound) constraints into this variable.\n     * This is used to accumulate read constraints when resolving a handle's type.\n     */\n    maybeMergeCanReadSubset(constraint) {\n        if (constraint == null) {\n            return true;\n        }\n        if (this.canReadSubset == null) {\n            this.canReadSubset = constraint;\n            return true;\n        }\n        if (this.canReadSubset instanceof SlotType && constraint instanceof SlotType) {\n            // TODO: formFactor compatibility, etc.\n            return true;\n        }\n        if (this.canReadSubset instanceof EntityType && constraint instanceof EntityType) {\n            const mergedSchema = Schema.intersect(this.canReadSubset.entitySchema, constraint.entitySchema);\n            if (!mergedSchema) {\n                return false;\n            }\n            this.canReadSubset = new EntityType(mergedSchema);\n            return true;\n        }\n        return false;\n    }\n    /**\n     * merge a type variable's write superset (lower bound) constraints into this variable.\n     * This is used to accumulate write constraints when resolving a handle's type.\n     */\n    maybeMergeCanWriteSuperset(constraint) {\n        if (constraint == null) {\n            return true;\n        }\n        if (this.canWriteSuperset == null) {\n            this.canWriteSuperset = constraint;\n            return true;\n        }\n        if (this.canWriteSuperset instanceof SlotType && constraint instanceof SlotType) {\n            // TODO: formFactor compatibility, etc.\n            return true;\n        }\n        if (this.canWriteSuperset instanceof EntityType && constraint instanceof EntityType) {\n            const mergedSchema = Schema.union(this.canWriteSuperset.entitySchema, constraint.entitySchema);\n            if (!mergedSchema) {\n                return false;\n            }\n            this.canWriteSuperset = new EntityType(mergedSchema);\n            return true;\n        }\n        return false;\n    }\n    isSatisfiedBy(type) {\n        const constraint = this._canWriteSuperset;\n        if (!constraint) {\n            return true;\n        }\n        if (!(constraint instanceof EntityType) || !(type instanceof EntityType)) {\n            throw new Error(`constraint checking not implemented for ${this} and ${type}`);\n        }\n        return type.getEntitySchema().isMoreSpecificThan(constraint.getEntitySchema());\n    }\n    get resolution() {\n        if (this._resolution) {\n            return this._resolution.resolvedType();\n        }\n        return null;\n    }\n    isValidResolutionCandidate(value) {\n        const elementType = value.resolvedType().getContainedType();\n        if (elementType instanceof TypeVariable && elementType.variable === this) {\n            return { result: false, detail: 'variable cannot resolve to collection of itself' };\n        }\n        return { result: true };\n    }\n    set resolution(value) {\n        assert(!this._resolution);\n        const isValid = this.isValidResolutionCandidate(value);\n        assert(isValid.result, isValid.detail);\n        let probe = value;\n        while (probe) {\n            if (!(probe instanceof TypeVariable)) {\n                break;\n            }\n            if (probe.variable === this) {\n                return;\n            }\n            probe = probe.variable.resolution;\n        }\n        this._resolution = value;\n        this._canWriteSuperset = null;\n        this._canReadSubset = null;\n    }\n    get canWriteSuperset() {\n        if (this._resolution) {\n            assert(!this._canWriteSuperset);\n            if (this._resolution instanceof TypeVariable) {\n                return this._resolution.variable.canWriteSuperset;\n            }\n            return null;\n        }\n        return this._canWriteSuperset;\n    }\n    set canWriteSuperset(value) {\n        assert(!this._resolution);\n        this._canWriteSuperset = value;\n    }\n    get canReadSubset() {\n        if (this._resolution) {\n            assert(!this._canReadSubset);\n            if (this._resolution instanceof TypeVariable) {\n                return this._resolution.variable.canReadSubset;\n            }\n            return null;\n        }\n        return this._canReadSubset;\n    }\n    set canReadSubset(value) {\n        assert(!this._resolution);\n        this._canReadSubset = value;\n    }\n    get hasConstraint() {\n        return this._canReadSubset !== null || this._canWriteSuperset !== null;\n    }\n    canEnsureResolved() {\n        if (this._resolution) {\n            return this._resolution.canEnsureResolved();\n        }\n        if (this._canWriteSuperset || this._canReadSubset) {\n            return true;\n        }\n        return false;\n    }\n    maybeEnsureResolved() {\n        if (this._resolution) {\n            return this._resolution.maybeEnsureResolved();\n        }\n        if (this._canWriteSuperset) {\n            this.resolution = this._canWriteSuperset;\n            return true;\n        }\n        if (this._canReadSubset) {\n            this.resolution = this._canReadSubset;\n            return true;\n        }\n        return false;\n    }\n    toLiteral() {\n        assert(this.resolution == null);\n        return this.toLiteralIgnoringResolutions();\n    }\n    toLiteralIgnoringResolutions() {\n        return {\n            name: this.name,\n            canWriteSuperset: this._canWriteSuperset && this._canWriteSuperset.toLiteral(),\n            canReadSubset: this._canReadSubset && this._canReadSubset.toLiteral()\n        };\n    }\n    static fromLiteral(data) {\n        return new TypeVariableInfo(data.name, data.canWriteSuperset ? Type.fromLiteral(data.canWriteSuperset) : null, data.canReadSubset ? Type.fromLiteral(data.canReadSubset) : null);\n    }\n    isResolved() {\n        return (this._resolution && this._resolution.isResolved());\n    }\n}\n//# sourceMappingURL=type-variable-info.js.map","/**\n * @license\n * Copyright 2019 Google LLC.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { HandleConnectionSpec } from './particle-spec.js';\nimport { assert } from '../platform/assert-web.js';\n/** The different types of trust checks that particles can make. */\nexport var CheckType;\n(function (CheckType) {\n    CheckType[\"HasTag\"] = \"has-tag\";\n    CheckType[\"IsFromHandle\"] = \"is-from-handle\";\n    CheckType[\"IsFromStore\"] = \"is-from-store\";\n})(CheckType || (CheckType = {}));\nexport class Check {\n    constructor(target, expression) {\n        this.target = target;\n        this.expression = expression;\n    }\n    toManifestString() {\n        let targetString;\n        if (this.target instanceof HandleConnectionSpec) {\n            targetString = this.target.name;\n        }\n        else {\n            targetString = `${this.target.name} data`;\n        }\n        return `check ${targetString} ${this.expression.toManifestString()}`;\n    }\n}\n/** A boolean expression inside a trust check. */\nexport class CheckBooleanExpression {\n    constructor(type, children) {\n        this.type = type;\n        this.children = children;\n    }\n    /**\n     * @inheritdoc\n     * @param requireParens Indicates whether to enclose the expression inside parentheses. All nested boolean expressions must have parentheses,\n     *     but a top-level expression doesn't need to.\n     */\n    toManifestString(requireParens = false) {\n        const str = this.children.map(child => child.toManifestString(/* requireParens= */ true)).join(` ${this.type} `);\n        return requireParens ? `(${str})` : str;\n    }\n}\n/** A check condition of the form 'check x is <tag>'. */\nexport class CheckHasTag {\n    constructor(tag) {\n        this.tag = tag;\n        this.type = CheckType.HasTag;\n    }\n    static fromASTNode(astNode) {\n        return new CheckHasTag(astNode.tag);\n    }\n    toManifestString() {\n        return `is ${this.tag}`;\n    }\n}\n/** A check condition of the form 'check x is from handle <handle>'. */\nexport class CheckIsFromHandle {\n    constructor(parentHandle) {\n        this.parentHandle = parentHandle;\n        this.type = CheckType.IsFromHandle;\n    }\n    static fromASTNode(astNode, handleConnectionMap) {\n        const parentHandle = handleConnectionMap.get(astNode.parentHandle);\n        if (!parentHandle) {\n            throw new Error(`Unknown \"check is from handle\" handle name: ${parentHandle}.`);\n        }\n        return new CheckIsFromHandle(parentHandle);\n    }\n    toManifestString() {\n        return `is from handle ${this.parentHandle.name}`;\n    }\n}\n/** A check condition of the form 'check x is from store <store reference>'. */\nexport class CheckIsFromStore {\n    constructor(storeRef) {\n        this.storeRef = storeRef;\n        this.type = CheckType.IsFromStore;\n    }\n    static fromASTNode(astNode) {\n        return new CheckIsFromStore({\n            type: astNode.storeRef.type,\n            store: astNode.storeRef.store,\n        });\n    }\n    toManifestString() {\n        let store = this.storeRef.store;\n        if (this.storeRef.type === 'id') {\n            // Put the ID inside single-quotes.\n            store = `'${store}'`;\n        }\n        return `is from store ${store}`;\n    }\n}\n/** Converts the given AST node into a CheckCondition object. */\nfunction createCheckCondition(astNode, handleConnectionMap) {\n    switch (astNode.checkType) {\n        case CheckType.HasTag:\n            return CheckHasTag.fromASTNode(astNode);\n        case CheckType.IsFromHandle:\n            return CheckIsFromHandle.fromASTNode(astNode, handleConnectionMap);\n        case CheckType.IsFromStore:\n            return CheckIsFromStore.fromASTNode(astNode);\n        default:\n            throw new Error('Unknown check type.');\n    }\n}\n/** Converts the given AST node into a CheckExpression object. */\nfunction createCheckExpression(astNode, handleConnectionMap) {\n    if (astNode.kind === 'particle-trust-check-boolean-expression') {\n        assert(astNode.children.length >= 2, 'Boolean check expressions must have at least two children.');\n        return new CheckBooleanExpression(astNode.operator, astNode.children.map(child => createCheckExpression(child, handleConnectionMap)));\n    }\n    else {\n        return createCheckCondition(astNode, handleConnectionMap);\n    }\n}\n/** Converts the given AST node into a Check object. */\nexport function createCheck(checkTarget, astNode, handleConnectionMap) {\n    const expression = createCheckExpression(astNode.expression, handleConnectionMap);\n    return new Check(checkTarget, expression);\n}\n//# sourceMappingURL=particle-check.js.map","/**\n * @license\n * Copyright 2019 Google LLC.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n/** The different types of trust claims that particles can make. */\nexport var ClaimType;\n(function (ClaimType) {\n    ClaimType[\"IsTag\"] = \"is-tag\";\n    ClaimType[\"DerivesFrom\"] = \"derives-from\";\n})(ClaimType || (ClaimType = {}));\nexport class Claim {\n    constructor(handle, expression) {\n        this.handle = handle;\n        this.expression = expression;\n    }\n    toManifestString() {\n        return `claim ${this.handle.name} ${this.expression.toManifestString()}`;\n    }\n}\nexport class ClaimIsTag {\n    constructor(isNot, tag) {\n        this.isNot = isNot;\n        this.tag = tag;\n        this.type = ClaimType.IsTag;\n    }\n    static fromASTNode(astNode) {\n        return new ClaimIsTag(astNode.isNot, astNode.tag);\n    }\n    toManifestString() {\n        return `is ${this.isNot ? 'not ' : ''}${this.tag}`;\n    }\n}\nexport class ClaimDerivesFrom {\n    constructor(parentHandles) {\n        this.parentHandles = parentHandles;\n        this.type = ClaimType.DerivesFrom;\n    }\n    static fromASTNode(astNode, handleConnectionMap) {\n        // Convert handle names into HandleConnectionSpec objects.\n        const parentHandles = astNode.parentHandles.map(parentHandleName => {\n            const parentHandle = handleConnectionMap.get(parentHandleName);\n            if (!parentHandle) {\n                throw new Error(`Unknown \"derives from\" handle name: ${parentHandle}.`);\n            }\n            return parentHandle;\n        });\n        return new ClaimDerivesFrom(parentHandles);\n    }\n    toManifestString() {\n        return `derives from ${this.parentHandles.map(h => h.name).join(' and ')}`;\n    }\n}\nexport function createClaim(handle, astNode, handleConnectionMap) {\n    let expression;\n    switch (astNode.expression.claimType) {\n        case ClaimType.IsTag:\n            expression = ClaimIsTag.fromASTNode(astNode.expression);\n            break;\n        case ClaimType.DerivesFrom:\n            expression = ClaimDerivesFrom.fromASTNode(astNode.expression, handleConnectionMap);\n            break;\n        default:\n            throw new Error('Unknown claim type.');\n    }\n    return new Claim(handle, expression);\n}\n//# sourceMappingURL=particle-claim.js.map","/**\n * @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\n/**\n * Returns the set delta between two lists based on direct object comparison.\n */\nexport function setDiff(from, to) {\n    const result = { add: [], remove: [] };\n    const items = new Set([...from, ...to]);\n    const fromSet = new Set(from);\n    const toSet = new Set(to);\n    for (const item of items) {\n        if (fromSet.has(item)) {\n            if (toSet.has(item)) {\n                continue;\n            }\n            result.remove.push(item);\n            continue;\n        }\n        assert(toSet.has(item));\n        result.add.push(item);\n    }\n    return result;\n}\n/**\n * Returns the set delta between two lists based on custom object comparison.\n * `keyFn` takes type T and returns the value by which items should be compared.\n */\nexport function setDiffCustom(from, to, keyFn) {\n    const result = { add: [], remove: [] };\n    const items = new Map();\n    const fromSet = new Map();\n    const toSet = new Map();\n    for (const item of from) {\n        const key = keyFn(item);\n        items.set(key, item);\n        fromSet.set(key, item);\n    }\n    for (const item of to) {\n        const key = keyFn(item);\n        items.set(key, item);\n        toSet.set(key, item);\n    }\n    for (const [key, item] of items) {\n        if (fromSet.has(key)) {\n            if (toSet.has(key)) {\n                continue;\n            }\n            result.remove.push(item);\n            continue;\n        }\n        assert(toSet.has(key));\n        result.add.push(item);\n    }\n    return result;\n}\n/**\n * A hack to ignore a floating promise and bypass the linter. Promises should very rarely be left floating, and when such behaviour is intended,\n * it should be clearly marked as such. See https://tsetse.info/must-use-promises.html for details.\n *\n * TODO: Remove all usages of this function and then delete it.\n */\nexport function floatingPromiseToAudit(promise) { }\n//# sourceMappingURL=util.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n/**\n * A representation of a consumed slot. Retrieved from a particle using\n * particle.getSlot(name)\n */\nexport class SlotProxy {\n    constructor(apiPort, particle, slotName, providedSlots) {\n        // eslint-disable-next-line func-call-spacing\n        this.handlers = new Map();\n        this.requestedContentTypes = new Set();\n        this._isRendered = false;\n        this.apiPort = apiPort;\n        this.slotName = slotName;\n        this.particle = particle;\n        this.providedSlots = providedSlots;\n    }\n    get isRendered() {\n        return this._isRendered;\n    }\n    /**\n     * renders content to the slot.\n     */\n    render(content) {\n        this.apiPort.Render(this.particle, this.slotName, content);\n        Object.keys(content).forEach(key => { this.requestedContentTypes.delete(key); });\n        // Slot is considered rendered, if a non-empty content was sent and all requested content types were fullfilled.\n        this._isRendered = this.requestedContentTypes.size === 0 && (Object.keys(content).length > 0);\n    }\n    /**\n     * registers a callback to be invoked when 'name' event happens.\n     */\n    registerEventHandler(name, f) {\n        if (!this.handlers.has(name)) {\n            this.handlers.set(name, []);\n        }\n        this.handlers.get(name).push(f);\n    }\n    clearEventHandlers(name) {\n        this.handlers.set(name, []);\n    }\n    fireEvent(event) {\n        for (const handler of this.handlers.get(event.handler) || []) {\n            handler(event);\n        }\n    }\n}\n//# sourceMappingURL=slot-proxy.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\nimport { mapStackTrace } from '../platform/sourcemapped-stacktrace-web.js';\nimport { SystemException } from './arc-exceptions.js';\nimport { CrdtCollectionModel } from './storage/crdt-collection-model.js';\nimport { BigCollectionType, CollectionType } from './type.js';\nimport { Id } from './id.js';\nvar SyncState;\n(function (SyncState) {\n    SyncState[SyncState[\"none\"] = 0] = \"none\";\n    SyncState[SyncState[\"pending\"] = 1] = \"pending\";\n    SyncState[SyncState[\"full\"] = 2] = \"full\";\n})(SyncState || (SyncState = {}));\n/**\n * Mediates between one or more Handles and the backing store outside the PEC.\n *\n * This can operate in two modes, based on how observing handles are configured:\n * - synchronized: the proxy maintains a copy of the full data held by the backing store, keeping\n *                 it in sync by listening to change events from the store.\n * - unsynchronized: the proxy simply passes through calls from Handles to the backing store.\n *\n * In synchronized mode we maintain a queue of sorted update events received from the backing store.\n * While events are received correctly - each update is one version ahead of our stored model - they\n * are processed immediately and observing handles are notified accordingly. If we receive an update\n * with a \"future\" version, the proxy is desynchronized:\n * - a request for the full data is sent to the backing store;\n * - any update events received after that (and before the response) are added to the queue;\n * - any new updates that can be applied will be (which may cause the proxy to \"catch up\" and resync\n *   before the full data response arrives);\n * - once the resync response is received, stale queued updates are discarded and any remaining ones\n *   are applied.\n */\nexport class StorageProxy {\n    constructor(id, type, port, pec, scheduler, name) {\n        this.version = undefined;\n        this.listenerAttached = false;\n        this.keepSynced = false;\n        this.synchronized = SyncState.none;\n        this.observers = [];\n        this.updates = [];\n        this.barrier = null;\n        this.id = id;\n        this.type = type;\n        this.port = port;\n        this.scheduler = scheduler;\n        this.name = name;\n        this.updates = [];\n        this.pec = pec;\n    }\n    static newProxy(id, type, port, pec, scheduler, name) {\n        if (type instanceof CollectionType) {\n            return new CollectionProxy(id, type, port, pec, scheduler, name);\n        }\n        if (type instanceof BigCollectionType) {\n            return new BigCollectionProxy(id, type, port, pec, scheduler, name);\n        }\n        return new SingletonProxy(id, type, port, pec, scheduler, name);\n    }\n    reportExceptionInHost(exception) {\n        // TODO: Encapsulate source-mapping of the stack trace once there are more users of the port.RaiseSystemException() call.\n        if (mapStackTrace) {\n            mapStackTrace(exception.cause.stack, mappedStack => {\n                exception.cause.stack = mappedStack;\n                this.port.ReportExceptionInHost(exception);\n            });\n        }\n        else {\n            this.port.ReportExceptionInHost(exception);\n        }\n    }\n    /**\n     *  Called by ParticleExecutionContext to associate (potentially multiple) particle/handle pairs with this proxy.\n     */\n    register(particle, handle) {\n        if (!handle.canRead) {\n            return;\n        }\n        this.observers.push({ particle, handle });\n        // Attach an event listener to the backing store when the first readable handle is registered.\n        if (!this.listenerAttached) {\n            this.port.InitializeProxy(this, x => this._onUpdate(x));\n            this.listenerAttached = true;\n        }\n        // Change to synchronized mode as soon as we get any handle configured with keepSynced and send\n        // a request to get the full model (once).\n        // TODO: drop back to non-sync mode if all handles re-configure to !keepSynced\n        if (handle.options.keepSynced) {\n            if (!this.keepSynced) {\n                this.port.SynchronizeProxy(this, x => this._onSynchronize(x));\n                this.keepSynced = true;\n            }\n            // If a handle configured for sync notifications registers after we've received the full\n            // model, notify it immediately.\n            if (handle.options.notifySync && this.synchronized === SyncState.full) {\n                const syncModel = this._getModelForSync();\n                this.scheduler.enqueue(particle, handle, ['sync', particle, syncModel]);\n            }\n        }\n    }\n    _onSynchronize({ version, model }) {\n        if (this.version !== undefined && version <= this.version) {\n            console.warn(`StorageProxy '${this.id}' received stale model version ${version}; ` +\n                `current is ${this.version}`);\n            return;\n        }\n        // Replace the stored data with the new one and notify handles that are configured for it.\n        if (!this._synchronizeModel(version, model)) {\n            return;\n        }\n        // We may have queued updates that were received after a desync; discard any that are stale\n        // with respect to the received model.\n        this.synchronized = SyncState.full;\n        while (this.updates.length > 0 && this.updates[0].version <= version) {\n            this.updates.shift();\n        }\n        const syncModel = this._getModelForSync();\n        this._notify('sync', syncModel, options => options.keepSynced && options.notifySync);\n        this._processUpdates();\n    }\n    _onUpdate(update) {\n        // Immediately notify any handles that are not configured with keepSynced but do want updates.\n        if (this.observers.find(({ handle }) => !handle.options.keepSynced && handle.options.notifyUpdate)) {\n            const handleUpdate = this._processUpdate(update, false);\n            this._notify('update', handleUpdate, options => !options.keepSynced && options.notifyUpdate);\n        }\n        // Bail if we're not in synchronized mode or this is a stale event.\n        if (!this.keepSynced) {\n            return;\n        }\n        if (update.version <= this.version) {\n            console.warn(`StorageProxy '${this.id}' received stale update version ${update.version}; ` +\n                `current is ${this.version}`);\n            return;\n        }\n        // Add the update to the queue and process. Most of the time the queue should be empty and\n        // _processUpdates will consume this event immediately.\n        this.updates.push(update);\n        this.updates.sort((a, b) => a.version - b.version);\n        this._processUpdates();\n    }\n    _notify(kind, details, predicate = (ignored) => true) {\n        for (const { handle, particle } of this.observers) {\n            if (predicate(handle.options)) {\n                this.scheduler.enqueue(particle, handle, [kind, particle, details]);\n            }\n        }\n    }\n    _processUpdates() {\n        const updateIsNext = update => {\n            if (update.version === this.version + 1) {\n                return true;\n            }\n            // Holy Layering Violation Batman\n            //\n            // If we are a singleton waiting for a barriered set response\n            // then that set response *is* the next thing we're waiting for,\n            // regardless of version numbers.\n            //\n            // TODO(shans): refactor this code so we don't need to layer-violate.\n            if (this.barrier && update.barrier === this.barrier) {\n                return true;\n            }\n            return false;\n        };\n        // Consume all queued updates whose versions are monotonically increasing from our stored one.\n        while (this.updates.length > 0 && updateIsNext(this.updates[0])) {\n            const update = this.updates.shift();\n            // Fold the update into our stored model.\n            const handleUpdate = this._processUpdate(update);\n            this.version = update.version;\n            // Notify handles configured with keepSynced and notifyUpdates (non-keepSynced handles are\n            // notified as updates are received).\n            if (handleUpdate) {\n                this._notify('update', handleUpdate, options => options.keepSynced && options.notifyUpdate);\n            }\n        }\n        // If we still have update events queued, we must have received a future version are are now\n        // desynchronized. Send a request for the full model and notify handles configured for it.\n        if (this.updates.length > 0) {\n            if (this.synchronized !== SyncState.none) {\n                this.synchronized = SyncState.none;\n                this.port.SynchronizeProxy(this, x => this._onSynchronize(x));\n                for (const { handle, particle } of this.observers) {\n                    if (handle.options.notifyDesync) {\n                        this.scheduler.enqueue(particle, handle, ['desync', particle, {}]);\n                    }\n                }\n            }\n        }\n        else if (this.synchronized !== SyncState.full) {\n            // If we were desynced but have now consumed all update events, we've caught up.\n            this.synchronized = SyncState.full;\n        }\n    }\n    generateBarrier() {\n        return this.pec.idGenerator.newChildId(Id.fromString(this.id), 'barrier').toString();\n    }\n}\n/**\n * Collections are synchronized in a CRDT Observed/Removed scheme.\n * Each value is identified by an ID and a set of membership keys.\n * Concurrent adds of the same value will specify the same ID but different\n * keys. A value is removed by removing all of the observed keys. A value\n * is considered to be removed if all of it's keys have been removed.\n *\n * In synchronized mode mutation takes place synchronously inside the proxy.\n * The proxy uses the originatorId to skip over redundant events sent back\n * by the storage object.\n *\n * In unsynchronized mode removal is not based on the keys observed at the\n * proxy, since the proxy does not remember the state, but instead the set\n * of keys that exist at the storage object at the time it receives the\n * request.\n */\nexport class CollectionProxy extends StorageProxy {\n    constructor() {\n        super(...arguments);\n        this.model = new CrdtCollectionModel();\n    }\n    _getModelForSync() {\n        return this.model.toList();\n    }\n    _synchronizeModel(version, model) {\n        this.version = version;\n        this.model = new CrdtCollectionModel(model);\n        return true;\n    }\n    _processUpdate(update, apply = true) {\n        if (this.synchronized === SyncState.full) {\n            // If we're synchronized, then any updates we sent have\n            // already been applied/notified.\n            for (const { handle } of this.observers) {\n                if (update.originatorId === handle._particleId) {\n                    return null;\n                }\n            }\n        }\n        const added = [];\n        const removed = [];\n        if ('add' in update) {\n            for (const { value, keys, effective } of update.add) {\n                if (apply && this.model.add(value.id, value, keys) || !apply && effective) {\n                    added.push(value);\n                }\n            }\n        }\n        else if ('remove' in update) {\n            for (const { value, keys, effective } of update.remove) {\n                const localValue = this.model.getValue(value.id);\n                if (apply && this.model.remove(value.id, keys) || !apply && effective) {\n                    removed.push(localValue);\n                }\n            }\n        }\n        else {\n            throw new Error(`StorageProxy received invalid update event: ${JSON.stringify(update)}`);\n        }\n        if (added.length || removed.length) {\n            const result = { originatorId: update.originatorId };\n            if (added.length)\n                result.add = added;\n            if (removed.length)\n                result.remove = removed;\n            return result;\n        }\n        return null;\n    }\n    // Read ops: if we're synchronized we can just return the local copy of the data.\n    // Otherwise, send a request to the backing store.\n    async toList() {\n        if (this.synchronized === SyncState.full) {\n            return Promise.resolve(this.model.toList());\n        }\n        else {\n            // TODO: in synchronized mode, this should integrate with SynchronizeProxy rather than\n            //       sending a parallel request\n            return new Promise(resolve => this.port.HandleToList(this, resolve));\n        }\n    }\n    async get(id) {\n        if (this.synchronized === SyncState.full) {\n            return Promise.resolve(this.model.getValue(id));\n        }\n        else {\n            return new Promise((resolve, reject) => this.port.HandleToList(this, r => resolve(r.find(entity => entity.id === id))));\n        }\n    }\n    // tslint:disable-next-line: no-any\n    async store(value, keys, particleId) {\n        const id = value.id;\n        const data = { value, keys };\n        this.port.HandleStore(this, () => { }, data, particleId);\n        if (this.synchronized !== SyncState.full) {\n            return Promise.resolve();\n        }\n        if (!this.model.add(id, value, keys)) {\n            return Promise.resolve();\n        }\n        const update = { originatorId: particleId, add: [value] };\n        this._notify('update', update, options => options.notifyUpdate);\n        return Promise.resolve();\n    }\n    async clear(particleId) {\n        if (this.synchronized !== SyncState.full) {\n            this.port.HandleRemoveMultiple(this, () => { }, [], particleId);\n        }\n        let items = this.model.toList().map(item => ({ id: item.id, keys: this.model.getKeys(item.id) }));\n        this.port.HandleRemoveMultiple(this, () => { }, items, particleId);\n        items = items.map(({ id, keys }) => ({ rawData: this.model.getValue(id).rawData, id, keys }));\n        items = items.filter(item => this.model.remove(item.id, item.keys));\n        if (items.length > 0) {\n            this._notify('update', { originatorId: particleId, remove: items }, options => options.notifyUpdate);\n        }\n        return Promise.resolve();\n    }\n    async remove(id, keys, particleId) {\n        if (this.synchronized !== SyncState.full) {\n            const data = { id, keys: [] };\n            this.port.HandleRemove(this, () => { }, data, particleId);\n            return Promise.resolve();\n        }\n        const value = this.model.getValue(id);\n        if (!value) {\n            return Promise.resolve();\n        }\n        if (keys.length === 0) {\n            keys = this.model.getKeys(id);\n        }\n        const data = { id, keys };\n        this.port.HandleRemove(this, () => { }, data, particleId);\n        if (!this.model.remove(id, keys)) {\n            return Promise.resolve();\n        }\n        const update = { originatorId: particleId, remove: [value] };\n        this._notify('update', update, options => options.notifyUpdate);\n        return Promise.resolve();\n    }\n}\n/**\n * Variables are synchronized in a 'last-writer-wins' scheme. When the\n * SingletonProxy mutates the model, it sets a barrier and expects to\n * receive the barrier value echoed back in a subsequent update event.\n * Between those two points in time updates are not applied or\n * notified about as these reflect concurrent writes that did not 'win'.\n */\nexport class SingletonProxy extends StorageProxy {\n    constructor() {\n        super(...arguments);\n        this.model = null;\n    }\n    _getModelForSync() {\n        return this.model;\n    }\n    _synchronizeModel(version, model) {\n        // If there's an active barrier then we shouldn't apply the model here, because\n        // there is a more recent write from the particle side that is still in flight.\n        if (this.barrier != null) {\n            return false;\n        }\n        this.version = version;\n        this.model = model.length === 0 ? null : model[0].value;\n        assert(this.model !== undefined);\n        return true;\n    }\n    _processUpdate(update, apply = true) {\n        assert('data' in update);\n        if (!apply) {\n            return update;\n        }\n        // If we have set a barrier, suppress updates until after\n        // we have seen the barrier return via an update.\n        if (this.barrier != null) {\n            if (update.barrier === this.barrier) {\n                this.barrier = null;\n                // HOLY LAYERING VIOLATION BATMAN\n                //\n                // We just cleared a barrier which means we are now synchronized. If we weren't\n                // synchronized already, then we need to tell the handles.\n                //\n                // TODO(shans): refactor this code so we don't need to layer-violate.\n                if (this.synchronized !== SyncState.full) {\n                    this.synchronized = SyncState.full;\n                    const syncModel = this._getModelForSync();\n                    this._notify('sync', syncModel, options => options.keepSynced && options.notifySync);\n                }\n            }\n            return null;\n        }\n        const oldData = this.model;\n        this.model = update.data;\n        return { ...update, oldData };\n    }\n    // Read ops: if we're synchronized we can just return the local copy of the data.\n    // Otherwise, send a request to the backing store.\n    // TODO: in synchronized mode, these should integrate with SynchronizeProxy rather than\n    //       sending a parallel request\n    async get() {\n        if (this.synchronized === SyncState.full) {\n            return Promise.resolve(this.model);\n        }\n        else {\n            return new Promise(resolve => this.port.HandleGet(this, resolve));\n        }\n    }\n    async set(entity, particleId) {\n        assert(entity !== undefined);\n        if (JSON.stringify(this.model) === JSON.stringify(entity)) {\n            return Promise.resolve();\n        }\n        let barrier;\n        // If we're setting to this handle but we aren't listening to firebase,\n        // then there's no point creating a barrier. In fact, if the response\n        // to the set comes back before a listener is registered then this proxy will\n        // end up locked waiting for a barrier that will never arrive.\n        if (this.listenerAttached) {\n            barrier = this.generateBarrier();\n        }\n        else {\n            barrier = null;\n        }\n        const oldData = this.model;\n        // TODO: is this already a clone?\n        this.model = JSON.parse(JSON.stringify(entity));\n        this.barrier = barrier;\n        this.port.HandleSet(this, entity, particleId, barrier);\n        const update = { originatorId: particleId, data: entity, oldData };\n        this._notify('update', update, options => options.notifyUpdate);\n        return Promise.resolve();\n    }\n    async clear(particleId) {\n        if (this.model == null) {\n            return Promise.resolve();\n        }\n        const barrier = this.generateBarrier();\n        const oldData = this.model;\n        this.model = null;\n        this.barrier = barrier;\n        this.port.HandleClear(this, particleId, barrier);\n        const update = { originatorId: particleId, data: null, oldData };\n        this._notify('update', update, options => options.notifyUpdate);\n        return Promise.resolve();\n    }\n}\n// BigCollections are never synchronized. No local state is held and all operations are passed\n// directly through to the backing store.\nexport class BigCollectionProxy extends StorageProxy {\n    register(particle, handle) {\n        if (handle.canRead) {\n            this.scheduler.enqueue(particle, handle, ['sync', particle, {}]);\n        }\n    }\n    _getModelForSync() {\n        throw new Error('_getModelForSync not implemented for BigCollectionProxy');\n    }\n    _processUpdate() {\n        throw new Error('_processUpdate not implemented for BigCollectionProxy');\n    }\n    _synchronizeModel() {\n        throw new Error('_synchronizeModel not implemented for BigCollectionProxy');\n    }\n    // TODO: surface get()\n    async get(id) {\n        throw new Error('unimplemented');\n    }\n    async store(value, keys, particleId) {\n        return new Promise(resolve => this.port.HandleStore(this, resolve, { value, keys }, particleId));\n    }\n    async remove(id, keys, particleId) {\n        return new Promise(resolve => this.port.HandleRemove(this, resolve, { id, keys: [] }, particleId));\n    }\n    async stream(pageSize, forward) {\n        return new Promise(resolve => this.port.HandleStream(this, resolve, pageSize, forward));\n    }\n    // tslint:disable-next-line: no-any\n    async cursorNext(cursorId) {\n        return new Promise(resolve => this.port.StreamCursorNext(this, resolve, cursorId));\n    }\n    async cursorClose(cursorId) {\n        this.port.StreamCursorClose(this, cursorId);\n        return Promise.resolve();\n    }\n}\nexport class StorageProxyScheduler {\n    constructor() {\n        this._scheduled = false;\n        this._queues = new Map();\n        this._idleResolver = null;\n        this._idle = null;\n        this._scheduled = false;\n        // Particle -> {Handle -> [Queue of events]}\n        this._queues = new Map();\n    }\n    // TODO: break apart args here, sync events should flush the queue.\n    enqueue(particle, handle, args) {\n        if (!this._queues.has(particle)) {\n            this._queues.set(particle, new Map());\n        }\n        const byHandle = this._queues.get(particle);\n        if (!byHandle.has(handle)) {\n            byHandle.set(handle, []);\n        }\n        const queue = byHandle.get(handle);\n        queue.push(args);\n        this._schedule();\n    }\n    get busy() {\n        return this._queues.size > 0;\n    }\n    _updateIdle() {\n        if (this._idleResolver && !this.busy) {\n            this._idleResolver();\n            this._idle = null;\n            this._idleResolver = null;\n        }\n    }\n    get idle() {\n        if (!this.busy) {\n            return Promise.resolve();\n        }\n        if (!this._idle) {\n            this._idle = new Promise(resolve => this._idleResolver = resolve);\n        }\n        return this._idle;\n    }\n    _schedule() {\n        if (this._scheduled) {\n            return;\n        }\n        this._scheduled = true;\n        setTimeout(() => {\n            this._scheduled = false;\n            this._dispatch();\n        }, 0);\n    }\n    _dispatch() {\n        // TODO: should we process just one particle per task?\n        while (this._queues.size > 0) {\n            const particle = [...this._queues.keys()][0];\n            const byHandle = this._queues.get(particle);\n            this._queues.delete(particle);\n            for (const [handle, queue] of byHandle.entries()) {\n                for (const args of queue) {\n                    try {\n                        handle._notify(...args);\n                    }\n                    catch (e) {\n                        console.error('Error dispatching to particle', e);\n                        handle.storage.reportExceptionInHost(new SystemException(e, handle._particleId, 'StorageProxyScheduler::_dispatch'));\n                    }\n                }\n            }\n        }\n        this._updateIdle();\n    }\n}\n//# sourceMappingURL=storage-proxy.js.map","/**\n * @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n// This is only relevant in the web devtools, but we need to\n// ensure that the stack trace is passed through on node\n// so that system exceptions are plumbed properly.\nexport const mapStackTrace = (x, f) => f([x]);\n//# sourceMappingURL=sourcemapped-stacktrace-node.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../../platform/assert-web.js';\nexport class CrdtCollectionModel {\n    constructor(model) {\n        // id => {value, Set[keys]}\n        this.items = new Map();\n        if (model) {\n            for (let { id, value, keys } of model) {\n                if (!keys) {\n                    keys = [];\n                }\n                this.items.set(id, { value, keys: new Set(keys) });\n            }\n        }\n    }\n    /**\n     * Adds membership, `keys`, of `value` indexed by `id` to this collection.\n     * Returns whether the change is effective (`id` is new to the collection,\n     * or `value` is different to the value previously stored).\n     */\n    add(id, value, keys) {\n        // Ensure that keys is actually an array, not a single string.\n        // TODO(shans): remove this when all callers are implemented in typeScript.\n        assert(keys.length > 0 && typeof keys === 'object', 'add requires a list of keys');\n        let item = this.items.get(id);\n        let effective = false;\n        if (!item) {\n            item = { value, keys: new Set(keys) };\n            this.items.set(id, item);\n            effective = true;\n        }\n        else {\n            let newKeys = false;\n            for (const key of keys) {\n                if (!item.keys.has(key)) {\n                    newKeys = true;\n                }\n                item.keys.add(key);\n            }\n            if (!this._equals(item.value, value)) {\n                assert(newKeys, 'cannot add without new keys. incoming=' + keys.join(',') + ' existing=' + [...item.keys].join(','));\n                item.value = value;\n                effective = true;\n            }\n        }\n        return effective;\n    }\n    _equals(value1, value2) {\n        if (Boolean(value1) !== Boolean(value2)) {\n            return false;\n        }\n        if (!value1) {\n            return true;\n        }\n        const type1 = typeof (value1);\n        if (type1 !== typeof (value2)) {\n            return false;\n        }\n        if (type1 === 'object') {\n            const keys = Object.keys(value1);\n            if (keys.length !== Object.keys(value2).length) {\n                return false;\n            }\n            return keys.every(key => this._equals(value1[key], value2[key]));\n        }\n        return JSON.stringify(value1) === JSON.stringify(value2);\n    }\n    /**\n     * Removes the membership, `keys`, of the value indexed by `id` from this collection.\n     * Returns whether the change is effective (the value is no longer present\n     * in the collection because all of the keys have been removed).\n     */\n    remove(id, keys) {\n        const item = this.items.get(id);\n        if (!item) {\n            return false;\n        }\n        for (const key of keys) {\n            item.keys.delete(key);\n        }\n        const effective = item.keys.size === 0;\n        if (effective) {\n            this.items.delete(id);\n        }\n        return effective;\n    }\n    toLiteral() {\n        const result = [];\n        for (const [id, { value, keys }] of this.items.entries()) {\n            result.push({ id, value, keys: [...keys] });\n        }\n        return result;\n    }\n    toList() {\n        return [...this.items.values()].map(item => item.value);\n    }\n    has(id) {\n        return this.items.has(id);\n    }\n    getKeys(id) {\n        const item = this.items.get(id);\n        return item ? [...item.keys] : [];\n    }\n    getValue(id) {\n        const item = this.items.get(id);\n        return item ? item.value : null;\n    }\n    get size() {\n        return this.items.size;\n    }\n}\n//# sourceMappingURL=crdt-collection-model.js.map","/**\n * @license\n * Copyright (c) 2019 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\nimport { Entity } from './entity.js';\nimport { Particle } from './particle.js';\nimport { Singleton } from './handle.js';\n// Encodes/decodes the wire format for transferring entities over the wasm boundary.\n// Note that entities must have an id before serializing for use in a wasm particle.\n//\n//  <singleton> = <id-length>:<id>|<name>:<value>|<name>:<value>| ... |\n//  <value> depends on the field type:\n//    Text       <name>:T<length>:<text>\n//    URL        <name>:U<length>:<text>\n//    Number     <name>:N<number>:\n//    Boolean    <name>:B<zero-or-one>\n//\n//  <collection> = <num-entities>:<length>:<encoded><length>:<encoded> ...\n//\n// Examples:\n//   Singleton:   4:id05|txt:T3:abc|lnk:U10:http://def|num:N37:|flg:B1|\n//   Collection:  3:29:4:id12|txt:T4:qwer|num:N9.2:|18:6:id2670|num:N-7:|15:5:id501|flg:B0|\n//\n// The encoder classes also support a \"Dictionary\" format of key:value string pairs:\n//   <size>:<key-len>:<key><value-len>:<value><key-len>:<key><value-len>:<value>...\nexport class EntityPackager {\n    constructor(schema) {\n        this.encoder = new StringEncoder();\n        this.decoder = new StringDecoder();\n        assert(schema.names.length > 0, 'At least one schema name is required for entity packaging');\n        this.schema = schema;\n    }\n    encodeSingleton(entity) {\n        return this.encoder.encodeSingleton(this.schema, entity);\n    }\n    encodeCollection(entities) {\n        return this.encoder.encodeCollection(this.schema, entities);\n    }\n    decodeSingleton(str) {\n        const { id, data } = this.decoder.decodeSingleton(str);\n        const entity = new (this.schema.entityClass())(data);\n        if (id !== '') {\n            Entity.identify(entity, id);\n        }\n        return entity;\n    }\n}\nclass StringEncoder {\n    encodeSingleton(schema, entity) {\n        const id = Entity.id(entity);\n        let encoded = id.length + ':' + id + '|';\n        for (const [name, value] of Object.entries(entity)) {\n            encoded += this.encodeField(schema.fields[name], name, value);\n        }\n        return encoded;\n    }\n    encodeCollection(schema, entities) {\n        let encoded = entities.length + ':';\n        for (const entity of entities) {\n            const str = this.encodeSingleton(schema, entity);\n            encoded += str.length + ':' + str;\n        }\n        return encoded;\n    }\n    static encodeDictionary(dict) {\n        const entries = Object.entries(dict);\n        let encoded = entries.length + ':';\n        for (const [key, value] of entries) {\n            encoded += key.length + ':' + key + value.length + ':' + value;\n        }\n        return encoded;\n    }\n    encodeField(field, name, value) {\n        switch (field.kind) {\n            case 'schema-primitive':\n                return name + ':' + field.type.substr(0, 1) + this.encodeValue(field.type, value) + '|';\n            case 'schema-collection':\n            case 'schema-union':\n            case 'schema-tuple':\n            case 'schema-reference':\n                throw new Error(`'${field.kind}' not yet supported for entity packaging`);\n            default:\n                throw new Error(`Unknown field kind '${field.kind}' in schema`);\n        }\n    }\n    encodeValue(type, value) {\n        switch (type) {\n            case 'Text':\n            case 'URL':\n                return value.length + ':' + value;\n            case 'Number':\n                return value + ':';\n            case 'Boolean':\n                return (value ? '1' : '0');\n            case 'Bytes':\n            case 'Object':\n                throw new Error(`'${type}' not yet supported for entity packaging`);\n            default:\n                throw new Error(`Unknown primitive value type '${type}' in schema`);\n        }\n    }\n}\nclass StringDecoder {\n    decodeSingleton(str) {\n        this.str = str;\n        const len = Number(this.upTo(':'));\n        const id = this.chomp(len);\n        this.validate('|');\n        const data = {};\n        while (this.str.length > 0) {\n            const name = this.upTo(':');\n            const typeChar = this.chomp(1);\n            data[name] = this.decodeValue(typeChar);\n            this.validate('|');\n        }\n        return { id, data };\n    }\n    decodeDictionary(str) {\n        this.str = str;\n        const dict = {};\n        let num = Number(this.upTo(':'));\n        while (num--) {\n            const klen = Number(this.upTo(':'));\n            const key = this.chomp(klen);\n            const vlen = Number(this.upTo(':'));\n            dict[key] = this.chomp(vlen);\n        }\n        return dict;\n    }\n    upTo(char) {\n        const i = this.str.indexOf(char);\n        if (i < 0) {\n            throw new Error(`Packaged entity decoding fail: expected '${char}' separator in '${this.str}'`);\n        }\n        const token = this.str.slice(0, i);\n        this.str = this.str.slice(i + 1);\n        return token;\n    }\n    chomp(len) {\n        if (len > this.str.length) {\n            throw new Error(`Packaged entity decoding fail: expected '${len}' chars to remain in '${this.str}'`);\n        }\n        const token = this.str.slice(0, len);\n        this.str = this.str.slice(len);\n        return token;\n    }\n    validate(token) {\n        if (this.chomp(token.length) !== token) {\n            throw new Error(`Packaged entity decoding fail: expected '${token}' at start of '${this.str}'`);\n        }\n    }\n    decodeValue(typeChar) {\n        switch (typeChar) {\n            case 'T':\n            case 'U': {\n                const len = Number(this.upTo(':'));\n                return this.chomp(len);\n            }\n            case 'N':\n                return Number(this.upTo(':'));\n            case 'B':\n                return Boolean(this.chomp(1) === '1');\n            default:\n                throw new Error(`Packaged entity decoding fail: unknown or unsupported primitive value type '${typeChar}'`);\n        }\n    }\n}\nclass EmscriptenWasmDriver {\n    constructor(customSection) {\n        // Records file and line for console logging in C++. This is set by the console/error macros in\n        // arcs.h and used immediately in the following printf call (implemented by sysWritev() below).\n        this.logInfo = null;\n        // Wasm modules built by emscripten require some external memory configuration by the caller,\n        // which is usually built into the glue code generated alongside the module. We're not using\n        // the glue code, but if we set the EMIT_EMSCRIPTEN_METADATA flag when building, emscripten\n        // will provide a custom section in the module itself with the required values.\n        const METADATA_SIZE = 10;\n        const METADATA_MAJOR = 0;\n        const METADATA_MINOR = 1;\n        const ABI_MAJOR = 0;\n        const ABI_MINOR = 3;\n        // The logic for reading metadata values here was copied from the emscripten source.\n        const buffer = new Uint8Array(customSection);\n        const metadata = [];\n        let offset = 0;\n        while (offset < buffer.byteLength) {\n            let result = 0;\n            let shift = 0;\n            while (1) {\n                const byte = buffer[offset++];\n                result |= (byte & 0x7f) << shift;\n                if (!(byte & 0x80)) {\n                    break;\n                }\n                shift += 7;\n            }\n            metadata.push(result);\n        }\n        // The specifics of the section are not published anywhere official (yet). The values here\n        // correspond to emscripten version 1.38.34:\n        //   https://github.com/emscripten-core/emscripten/blob/1.38.34/tools/shared.py#L3065\n        if (metadata.length !== METADATA_SIZE) {\n            throw new Error(`emscripten metadata section should have ${METADATA_SIZE} values; ` +\n                `got ${metadata.length}`);\n        }\n        if (metadata[0] !== METADATA_MAJOR || metadata[1] !== METADATA_MINOR) {\n            throw new Error(`emscripten metadata version should be ${METADATA_MAJOR}.${METADATA_MINOR}; ` +\n                `got ${metadata[0]}.${metadata[1]}`);\n        }\n        if (metadata[2] !== ABI_MAJOR || metadata[3] !== ABI_MINOR) {\n            throw new Error(`emscripten ABI version should be ${ABI_MAJOR}.${ABI_MINOR}; ` +\n                `got ${metadata[2]}.${metadata[3]}`);\n        }\n        // metadata[9] is 'tempdoublePtr'; appears to be related to pthreads and is not used here.\n        this.cfg = {\n            memSize: metadata[4],\n            tableSize: metadata[5],\n            globalBase: metadata[6],\n            dynamicBase: metadata[7],\n            dynamictopPtr: metadata[8],\n        };\n    }\n    configureEnvironment(module, container, env) {\n        container.memory = new WebAssembly.Memory({ initial: this.cfg.memSize, maximum: this.cfg.memSize });\n        container.heapU8 = new Uint8Array(container.memory.buffer);\n        container.heap32 = new Int32Array(container.memory.buffer);\n        // We need to poke the address of the heap base into the memory buffer prior to instantiating.\n        container.heap32[this.cfg.dynamictopPtr >> 2] = this.cfg.dynamicBase;\n        Object.assign(env, {\n            // Memory setup\n            memory: container.memory,\n            __memory_base: this.cfg.globalBase,\n            table: new WebAssembly.Table({ initial: this.cfg.tableSize, maximum: this.cfg.tableSize, element: 'anyfunc' }),\n            __table_base: 0,\n            DYNAMICTOP_PTR: this.cfg.dynamictopPtr,\n            // Heap management\n            _emscripten_get_heap_size: () => container.heapU8.length,\n            _emscripten_resize_heap: (size) => false,\n            _emscripten_memcpy_big: (dst, src, num) => container.heapU8.set(container.heapU8.subarray(src, src + num), dst),\n            // Error handling\n            _systemError: (msg) => { throw new Error(container.read(msg)); },\n            abortOnCannotGrowMemory: (size) => { throw new Error(`abortOnCannotGrowMemory(${size})`); },\n            // Logging\n            _setLogInfo: (file, line) => this.logInfo = [container.read(file), line],\n            ___syscall146: (which, varargs) => this.sysWritev(container, which, varargs),\n        });\n    }\n    initializeInstance(container, instance) {\n        // Emscripten doesn't need main() invoked\n    }\n    // C++ printf support cribbed from emscripten glue js - currently only supports ASCII\n    sysWritev(container, which, varargs) {\n        const get = () => {\n            varargs += 4;\n            return container.heap32[(((varargs) - (4)) >> 2)];\n        };\n        const output = (get() === 1) ? console.log : console.error;\n        const iov = get();\n        const iovcnt = get();\n        // TODO: does this need to be persistent across calls? (i.e. due to write buffering)\n        let str = this.logInfo ? `[${this.logInfo[0]}:${this.logInfo[1]}] ` : '';\n        let ret = 0;\n        for (let i = 0; i < iovcnt; i++) {\n            const ptr = container.heap32[(((iov) + (i * 8)) >> 2)];\n            const len = container.heap32[(((iov) + (i * 8 + 4)) >> 2)];\n            for (let j = 0; j < len; j++) {\n                const curr = container.heapU8[ptr + j];\n                if (curr === 0 || curr === 10) { // NUL or \\n\n                    output(str);\n                    str = '';\n                }\n                else {\n                    str += String.fromCharCode(curr);\n                }\n            }\n            ret += len;\n        }\n        this.logInfo = null;\n        return ret;\n    }\n}\nclass KotlinWasmDriver {\n    configureEnvironment(module, container, env) {\n        Object.assign(env, {\n            // These two are used by launcher.cpp\n            Konan_js_arg_size: (index) => 1,\n            Konan_js_fetch_arg: (index, ptr) => 'dummyArg',\n            // These two are imported, but never used\n            Konan_js_allocateArena: (array) => { },\n            Konan_js_freeArena: (arenaIndex) => { },\n            // These two are used by logging functions\n            write: (ptr) => console.log(container.read(ptr)),\n            flush: () => { },\n            // Apparently used by Kotlin Memory management\n            Konan_notify_memory_grow: () => this.updateMemoryViews(container),\n            // Kotlin's own glue for abort and exit\n            Konan_abort: (pointer) => { throw new Error('Konan_abort(' + container.read(pointer) + ')'); },\n            Konan_exit: (status) => { },\n            // Needed by some code that tries to get the current time in it's runtime\n            Konan_date_now: (pointer) => {\n                const now = Date.now();\n                const high = Math.floor(now / 0xffffffff);\n                const low = Math.floor(now % 0xffffffff);\n                container.heap32[pointer] = low;\n                container.heap32[pointer + 1] = high;\n            },\n        });\n    }\n    // Kotlin manages its own heap construction, as well as tables.\n    initializeInstance(container, instance) {\n        this.updateMemoryViews(container);\n        // Kotlin main() must be invoked before everything else.\n        instance.exports.Konan_js_main(1, 0);\n    }\n    updateMemoryViews(container) {\n        container.memory = container.exports.memory;\n        container.heapU8 = new Uint8Array(container.memory.buffer);\n        container.heap32 = new Int32Array(container.memory.buffer);\n    }\n}\n// Holds an instance of a running wasm module, which may contain multiple particles.\nexport class WasmContainer {\n    constructor() {\n        this.particleMap = new Map();\n    }\n    async initialize(buffer) {\n        // TODO: vet the imports/exports on 'module'\n        // TODO: use compileStreaming? requires passing the fetch() Response, not its ArrayBuffer\n        const module = await WebAssembly.compile(buffer);\n        const driver = this.driverForModule(module);\n        // Shared ENV between Emscripten and Kotlin\n        const env = {\n            abort: () => { throw new Error('Abort!'); },\n            // Inner particle API\n            // TODO: guard against null/empty args from the wasm side\n            _singletonSet: (p, handle, entity) => this.getParticle(p).singletonSet(handle, entity),\n            _singletonClear: (p, handle) => this.getParticle(p).singletonClear(handle),\n            _collectionStore: (p, handle, entity) => this.getParticle(p).collectionStore(handle, entity),\n            _collectionRemove: (p, handle, entity) => this.getParticle(p).collectionRemove(handle, entity),\n            _collectionClear: (p, handle) => this.getParticle(p).collectionClear(handle),\n            _render: (p, slotName, template, model) => this.getParticle(p).renderImpl(slotName, template, model),\n            _serviceRequest: (p, call, args, tag) => this.getParticle(p).serviceRequest(call, args, tag),\n        };\n        driver.configureEnvironment(module, this, env);\n        const global = { 'NaN': NaN, 'Infinity': Infinity };\n        this.wasm = await WebAssembly.instantiate(module, { env, global });\n        this.exports = this.wasm.exports;\n        driver.initializeInstance(this, this.wasm);\n    }\n    driverForModule(module) {\n        const customSections = WebAssembly.Module.customSections(module, 'emscripten_metadata');\n        if (customSections.length === 1) {\n            return new EmscriptenWasmDriver(customSections[0]);\n        }\n        return new KotlinWasmDriver();\n    }\n    getParticle(innerParticle) {\n        return this.particleMap.get(innerParticle);\n    }\n    register(particle, innerParticle) {\n        this.particleMap.set(innerParticle, particle);\n    }\n    // Allocates memory in the wasm container.\n    store(str) {\n        const p = this.exports._malloc(str.length + 1);\n        for (let i = 0; i < str.length; i++) {\n            this.heapU8[p + i] = str.charCodeAt(i);\n        }\n        this.heapU8[p + str.length] = 0;\n        return p;\n    }\n    // Convenience function for freeing one or more wasm memory allocations. Null pointers are ignored.\n    free(...ptrs) {\n        ptrs.forEach(p => p && this.exports._free(p));\n    }\n    // Currently only supports ASCII. TODO: unicode\n    read(idx) {\n        let str = '';\n        while (idx < this.heapU8.length && this.heapU8[idx] !== 0) {\n            str += String.fromCharCode(this.heapU8[idx++]);\n        }\n        return str;\n    }\n}\n// Creates and interfaces to a particle inside a WasmContainer's module.\nexport class WasmParticle extends Particle {\n    constructor(container) {\n        super();\n        this.handleMap = new Map();\n        this.revHandleMap = new Map();\n        this.converters = new Map();\n        this.container = container;\n        this.exports = container.exports;\n        this.innerParticle = this.exports[`_new${this.spec.name}`]();\n        container.register(this, this.innerParticle);\n    }\n    // TODO: for now we set up Handle objects with onDefineHandle and map them into the\n    // wasm container through this call, which creates corresponding Handle objects in there.\n    // That means entity transfer goes from the StorageProxy, deserializes at the outer Handle\n    // which then notifies this class (calling onHandle*), and we then serialize into the wasm\n    // transfer format. Obviously this can be improved.\n    async setHandles(handles) {\n        for (const [name, handle] of handles) {\n            const p = this.container.store(name);\n            const wasmHandle = this.exports._connectHandle(this.innerParticle, p, handle.canRead, handle.canWrite);\n            this.container.free(p);\n            if (wasmHandle === 0) {\n                throw new Error(`Wasm particle failed to connect handle '${name}'`);\n            }\n            this.handleMap.set(handle, wasmHandle);\n            this.revHandleMap.set(wasmHandle, handle);\n            this.converters.set(handle, new EntityPackager(handle.entityClass.schema));\n        }\n        this.exports._init(this.innerParticle);\n    }\n    async onHandleSync(handle, model) {\n        const wasmHandle = this.handleMap.get(handle);\n        if (!model) {\n            this.exports._syncHandle(this.innerParticle, wasmHandle, 0);\n            return;\n        }\n        const converter = this.converters.get(handle);\n        if (!converter) {\n            throw new Error('cannot find handle ' + handle.name);\n        }\n        let encoded;\n        if (handle instanceof Singleton) {\n            encoded = converter.encodeSingleton(model);\n        }\n        else {\n            encoded = converter.encodeCollection(model);\n        }\n        const p = this.container.store(encoded);\n        this.exports._syncHandle(this.innerParticle, wasmHandle, p);\n        this.container.free(p);\n    }\n    // tslint:disable-next-line: no-any\n    async onHandleUpdate(handle, update) {\n        if (update.originator) {\n            return;\n        }\n        const wasmHandle = this.handleMap.get(handle);\n        const converter = this.converters.get(handle);\n        if (!converter) {\n            throw new Error('cannot find handle ' + handle.name);\n        }\n        let p1 = 0;\n        let p2 = 0;\n        if (handle instanceof Singleton) {\n            if (update.data) {\n                p1 = this.container.store(converter.encodeSingleton(update.data));\n            }\n        }\n        else {\n            p1 = this.container.store(converter.encodeCollection(update.added || []));\n            p2 = this.container.store(converter.encodeCollection(update.removed || []));\n        }\n        this.exports._updateHandle(this.innerParticle, wasmHandle, p1, p2);\n        this.container.free(p1, p2);\n    }\n    // Ignored for wasm particles.\n    async onHandleDesync(handle) { }\n    // Store API.\n    //\n    // Each of these calls an async storage method, but we don't want to await them because returning\n    // a Promise to wasm doesn't work, and control (surprisingly) returns to the calling wasm function\n    // at the first await point anyway. However, our CRDTs make it safe to fire-and-forget the storage\n    // updates, and the wasm handles already have the updated version of the stored data, so it's safe\n    // to leave the promises floating.\n    // If the given entity doesn't have an id, this will create one for it and return the new id\n    // in allocated memory that the wasm particle must free. If the entity already has an id this\n    // returns 0 (nulltpr).\n    singletonSet(wasmHandle, entityPtr) {\n        const singleton = this.getHandle(wasmHandle);\n        const entity = this.decodeEntity(singleton, entityPtr);\n        const p = this.ensureIdentified(entity, singleton);\n        void singleton.set(entity);\n        return p;\n    }\n    singletonClear(wasmHandle) {\n        const singleton = this.getHandle(wasmHandle);\n        void singleton.clear();\n    }\n    // If the given entity doesn't have an id, this will create one for it and return the new id\n    // in allocated memory that the wasm particle must free. If the entity already has an id this\n    // returns 0 (nulltpr).\n    collectionStore(wasmHandle, entityPtr) {\n        const collection = this.getHandle(wasmHandle);\n        const entity = this.decodeEntity(collection, entityPtr);\n        const p = this.ensureIdentified(entity, collection);\n        void collection.store(entity);\n        return p;\n    }\n    collectionRemove(wasmHandle, entityPtr) {\n        const collection = this.getHandle(wasmHandle);\n        void collection.remove(this.decodeEntity(collection, entityPtr));\n    }\n    collectionClear(wasmHandle) {\n        const collection = this.getHandle(wasmHandle);\n        void collection.clear();\n    }\n    getHandle(wasmHandle) {\n        const handle = this.revHandleMap.get(wasmHandle);\n        if (!handle) {\n            throw new Error(`wasm particle '${this.spec.name}' attempted to write to unconnected handle`);\n        }\n        return handle;\n    }\n    decodeEntity(handle, entityPtr) {\n        const converter = this.converters.get(handle);\n        return converter.decodeSingleton(this.container.read(entityPtr));\n    }\n    ensureIdentified(entity, handle) {\n        let p = 0;\n        if (!Entity.isIdentified(entity)) {\n            handle.createIdentityFor(entity);\n            p = this.container.store(Entity.id(entity));\n        }\n        return p;\n    }\n    // Called by the shell to initiate rendering; the particle will call env._render in response.\n    renderSlot(slotName, contentTypes) {\n        const p = this.container.store(slotName);\n        const sendTemplate = contentTypes.includes('template');\n        const sendModel = contentTypes.includes('model');\n        this.exports._renderSlot(this.innerParticle, p, sendTemplate, sendModel);\n        this.container.free(p);\n    }\n    // TODO\n    renderHostedSlot(slotName, hostedSlotId, content) {\n        throw new Error('renderHostedSlot not implemented for wasm particles');\n    }\n    // Actually renders the slot. May be invoked due to an external request via renderSlot(),\n    // or directly from the wasm particle itself (e.g. in response to a data update).\n    // template is a string provided by the particle. model is an encoded Dictionary.\n    renderImpl(slotNamePtr, templatePtr, modelPtr) {\n        const slot = this.slotProxiesByName.get(this.container.read(slotNamePtr));\n        if (slot) {\n            const content = { templateName: 'default' };\n            if (templatePtr) {\n                content.template = this.container.read(templatePtr);\n                slot.requestedContentTypes.add('template');\n            }\n            if (modelPtr) {\n                content.model = new StringDecoder().decodeDictionary(this.container.read(modelPtr));\n                slot.requestedContentTypes.add('model');\n            }\n            slot.render(content);\n        }\n    }\n    // Wasm particles can request service calls with a Dictionary of arguments and an optional string\n    // tag to disambiguate different requests to the same service call.\n    async serviceRequest(callPtr, argsPtr, tagPtr) {\n        const call = this.container.read(callPtr);\n        const args = new StringDecoder().decodeDictionary(this.container.read(argsPtr));\n        const tag = this.container.read(tagPtr);\n        // tslint:disable-next-line: no-any\n        const response = await this.service({ call, ...args });\n        // Convert the arbitrary response object to key:value string pairs.\n        const dict = {};\n        if (typeof response === 'object') {\n            for (const entry of Object.entries(response)) {\n                // tslint:disable-next-line: no-any\n                const [key, value] = entry;\n                dict[key] = (typeof value === 'object') ? JSON.stringify(value) : (value + '');\n            }\n        }\n        else {\n            // Convert a plain value response to {value: 'string'}\n            dict['value'] = response + '';\n        }\n        // We can't re-use the string pointers passed in as args to this method, because the await\n        // point above means the call to internal::serviceRequest inside the wasm module will already\n        // have completed, and the memory for those args will have been freed.\n        const cp = this.container.store(call);\n        const rp = this.container.store(StringEncoder.encodeDictionary(dict));\n        const tp = this.container.store(tag);\n        this.exports._serviceResponse(this.innerParticle, cp, rp, tp);\n        this.container.free(cp, rp, tp);\n    }\n    fireEvent(slotName, event) {\n        const sp = this.container.store(slotName);\n        const hp = this.container.store(event.handler);\n        this.exports._fireEvent(this.innerParticle, sp, hp);\n        this.container.free(sp, hp);\n    }\n}\n//# sourceMappingURL=wasm.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { BigCollection } from './handle.js';\nimport { Collection } from './handle.js';\nimport { Entity } from './entity.js';\n/**\n * A basic particle. For particles that provide UI, you may like to\n * instead use DOMParticle.\n */\nexport class Particle {\n    constructor() {\n        this.relevances = [];\n        this._idle = Promise.resolve();\n        this._busy = 0;\n        this.slotProxiesByName = new Map();\n        // Typescript only sees this.constructor as a Function type.\n        // TODO(shans): move spec off the constructor\n        this.spec = this.constructor['spec'];\n        if (this.spec.inputs.length === 0) {\n            this.extraData = true;\n        }\n    }\n    /**\n     * This sets the capabilities for this particle.  This can only\n     * be called once.\n     */\n    setCapabilities(capabilities) {\n        if (this.capabilities) {\n            // Capabilities already set, throw an error.\n            throw new Error('capabilities should only be set once');\n        }\n        this.capabilities = capabilities || {};\n    }\n    async invokeSafely(fun, err) {\n        try {\n            this.startBusy();\n            await fun(this);\n        }\n        catch (e) {\n            err(e);\n        }\n        finally {\n            this.doneBusy();\n        }\n    }\n    async callSetHandles(handles, onException) {\n        await this.invokeSafely(async (p) => p.setHandles(handles), onException);\n    }\n    /**\n     * This method is invoked with a handle for each store this particle\n     * is registered to interact with, once those handles are ready for\n     * interaction. Override the method to register for events from\n     * the handles.\n     *\n     * @param handles a map from handle names to store handles.\n     */\n    async setHandles(handles) {\n    }\n    async callOnHandleSync(handle, model, onException) {\n        await this.invokeSafely(async (p) => p.onHandleSync(handle, model), onException);\n    }\n    /**\n     * Called for handles that are configured with both keepSynced and notifySync, when they are\n     * updated with the full model of their data. This will occur once after setHandles() and any time\n     * thereafter if the handle is resynchronized.\n     *\n     * @param handle The Handle instance that was updated.\n     * @param model For Singleton-backed Handles, the Entity data or null if the Singleton is not set.\n     *        For Collection-backed Handles, the Array of Entities, which may be empty.\n     */\n    async onHandleSync(handle, model) {\n    }\n    // tslint:disable-next-line: no-any\n    async callOnHandleUpdate(handle, update, onException) {\n        await this.invokeSafely(async (p) => p.onHandleUpdate(handle, update), onException);\n    }\n    /**\n     * Called for handles that are configued with notifyUpdate, when change events are received from\n     * the backing store. For handles also configured with keepSynced these events will be correctly\n     * ordered, with some potential skips if a desync occurs. For handles not configured with\n     * keepSynced, all change events will be passed through as they are received.\n     *\n     * @param handle The Handle instance that was updated.\n     * @param update An object containing one of the following fields:\n     *  - data: The full Entity for a Singleton-backed Handle.\n     *  - oldData: The previous value of a Singleton before it was updated.\n     *  - added: An Array of Entities added to a Collection-backed Handle.\n     *  - removed: An Array of Entities removed from a Collection-backed Handle.\n     */\n    // tslint:disable-next-line: no-any\n    async onHandleUpdate(handle, update) {\n    }\n    async callOnHandleDesync(handle, onException) {\n        await this.invokeSafely(async (p) => p.onHandleDesync(handle), onException);\n    }\n    /**\n     * Called for handles that are configured with both keepSynced and notifyDesync, when they are\n     * detected as being out-of-date against the backing store. For Singletons, the event that triggers\n     * this will also resync the data and thus this call may usually be ignored. For Collections, the\n     * underlying proxy will automatically request a full copy of the stored data to resynchronize.\n     * onHandleSync will be invoked when that is received.\n     *\n     * @param handle The Handle instance that was desynchronized.\n     */\n    async onHandleDesync(handle) {\n    }\n    async constructInnerArc() {\n        if (!this.capabilities.constructInnerArc) {\n            throw new Error('This particle is not allowed to construct inner arcs');\n        }\n        return this.capabilities.constructInnerArc(this);\n    }\n    get busy() {\n        return this._busy > 0;\n    }\n    get idle() {\n        return this._idle;\n    }\n    set relevance(r) {\n        this.relevances.push(r);\n    }\n    startBusy() {\n        if (this._busy === 0) {\n            this._idle = new Promise(resolve => this._idleResolver = () => resolve());\n        }\n        this._busy++;\n    }\n    doneBusy() {\n        this._busy--;\n        if (this._busy === 0) {\n            this._idleResolver();\n        }\n    }\n    inputs() {\n        return this.spec.inputs;\n    }\n    outputs() {\n        return this.spec.outputs;\n    }\n    hasSlotProxy(name) {\n        return this.slotProxiesByName.has(name);\n    }\n    addSlotProxy(slotlet) {\n        this.slotProxiesByName.set(slotlet.slotName, slotlet);\n    }\n    removeSlotProxy(name) {\n        this.slotProxiesByName.delete(name);\n    }\n    /**\n     * Request (outerPEC) service invocations.\n     */\n    // TODO(sjmiles): experimental services impl\n    async service(request) {\n        if (!this.capabilities.serviceRequest) {\n            console.warn(`${this.spec.name} has no service support.`);\n            return null;\n        }\n        return new Promise(resolve => {\n            this.capabilities.serviceRequest(this, request, response => resolve(response));\n        });\n    }\n    /**\n     * Returns the slot with provided name.\n     */\n    getSlot(name) {\n        return this.slotProxiesByName.get(name);\n    }\n    static buildManifest(strings, ...bits) {\n        const output = [];\n        for (let i = 0; i < bits.length; i++) {\n            const str = strings[i];\n            const indent = / *$/.exec(str)[0];\n            let bitStr;\n            if (typeof bits[i] === 'string') {\n                bitStr = bits[i];\n            }\n            else {\n                bitStr = bits[i].toManifestString();\n            }\n            bitStr = bitStr.replace(/(\\n)/g, '$1' + indent);\n            output.push(str);\n            output.push(bitStr);\n        }\n        if (strings.length > bits.length) {\n            output.push(strings[strings.length - 1]);\n        }\n        return output.join('');\n    }\n    async setParticleDescription(pattern) {\n        return this.setDescriptionPattern('pattern', pattern);\n    }\n    async setDescriptionPattern(connectionName, pattern) {\n        const descriptions = this.handles.get('descriptions');\n        if (descriptions) {\n            const entityClass = descriptions.entityClass;\n            if (descriptions instanceof Collection || descriptions instanceof BigCollection) {\n                await descriptions.store(new entityClass({ key: connectionName, value: pattern }, this.spec.name + '-' + connectionName));\n            }\n            return true;\n        }\n        throw new Error('A particle needs a description handle to set a decription pattern');\n    }\n    // Entity functions.\n    idFor(entity) {\n        return Entity.id(entity);\n    }\n    dataClone(entity) {\n        return Entity.dataClone(entity);\n    }\n    mutate(entity, mutation) {\n        Entity.mutate(entity, mutation);\n    }\n    // abstract\n    renderSlot(slotName, contentTypes) { }\n    renderHostedSlot(slotName, hostedSlotId, content) { }\n    fireEvent(slotName, event) { }\n}\n//# sourceMappingURL=particle.js.map","/**\n * @license\n * Copyright 2019 Google LLC.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { PlatformLoaderBase } from './loader-platform.js';\nimport { logFactory } from '../platform/log-web.js';\nconst log = logFactory('loader-web', 'green');\nconst warn = logFactory('loader-web', 'green', 'warn');\nconst error = logFactory('loader-web', 'green', 'error');\nexport class PlatformLoader extends PlatformLoaderBase {\n    flushCaches() {\n        // punt object urls?\n    }\n    async loadResource(url) {\n        // subclass impl differentiates paths and URLs,\n        // for browser env we can feed both kinds into _loadURL\n        return super._loadURL(this._resolve(url));\n    }\n    async loadBinary(url) {\n        return super.loadBinary(this._resolve(url));\n    }\n    async provisionObjectUrl(fileName) {\n        const raw = await this.loadResource(fileName);\n        const code = `${raw}\\n//# sourceURL=${fileName}`;\n        return URL.createObjectURL(new Blob([code], { type: 'application/javascript' }));\n    }\n    // Below here invoked from inside Worker\n    async loadParticleClass(spec) {\n        const clazz = await this.requireParticle(spec.implFile, spec.implBlobUrl);\n        if (clazz) {\n            clazz.spec = spec;\n        }\n        else {\n            warn(`[spec.implFile]::defineParticle() returned no particle.`);\n        }\n        return clazz;\n    }\n    async requireParticle(unresolvedPath, blobUrl) {\n        // inject path to this particle into the UrlMap,\n        // allows \"foo.js\" particle to invoke \"importScripts(resolver('foo/othermodule.js'))\"\n        this.mapParticleUrl(unresolvedPath);\n        // resolved target\n        const url = blobUrl || this._resolve(unresolvedPath);\n        // load wrapped particle\n        const particle = this.loadWrappedParticle(url);\n        // execute particle wrapper, if we have one\n        if (particle) {\n            const logger = this.provisionLogger(unresolvedPath);\n            return this.unwrapParticle(particle, logger);\n        }\n    }\n    provisionLogger(fileName) {\n        return logFactory(fileName.split('/').pop(), '#1faa00');\n    }\n    loadWrappedParticle(url) {\n        let result;\n        // MUST be synchronous from here until deletion\n        // of self.defineParticle because we share this\n        // scope with other particles\n        // TODO fix usage of quoted property\n        self['defineParticle'] = (particleWrapper) => {\n            if (result) {\n                warn('multiple particles not supported, last particle wins');\n            }\n            // multiple particles not supported: last particle wins\n            result = particleWrapper;\n        };\n        try {\n            // import (execute) particle code\n            importScripts(url);\n        }\n        catch (x) {\n            error(x);\n        }\n        // clean up\n        delete self['defineParticle'];\n        return result;\n    }\n}\n//# sourceMappingURL=loader-web.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { Loader } from '../runtime/loader.js';\nimport { Particle } from '../runtime/particle.js';\nimport { DomParticle } from '../runtime/dom-particle.js';\nimport { MultiplexerDomParticle } from '../runtime/multiplexer-dom-particle.js';\nimport { TransformationDomParticle } from '../runtime/transformation-dom-particle.js';\nconst html = (strings, ...values) => (strings[0] + values.map((v, i) => v + strings[i + 1]).join('')).trim();\nexport class PlatformLoaderBase extends Loader {\n    constructor(urlMap) {\n        super();\n        this._urlMap = urlMap || [];\n    }\n    async loadResource(name) {\n        const path = this._resolve(name);\n        return super.loadResource(path);\n    }\n    _resolve(path) {\n        let url = this._urlMap[path];\n        if (!url && path) {\n            // TODO(sjmiles): inefficient!\n            const macro = Object.keys(this._urlMap).sort((a, b) => b.length - a.length).find(k => path.slice(0, k.length) === k);\n            if (macro) {\n                url = this._urlMap[macro] + path.slice(macro.length);\n            }\n        }\n        url = this.normalizeDots(url || path);\n        return url;\n    }\n    mapParticleUrl(path) {\n        const parts = path.split('/');\n        const suffix = parts.pop();\n        const folder = parts.join('/');\n        const name = suffix.split('.').shift();\n        const resolved = this._resolve(folder);\n        this._urlMap[name] = resolved;\n        this._urlMap['$here'] = resolved;\n    }\n    unwrapParticle(particleWrapper, log) {\n        // TODO(sjmiles): regarding `resolver`:\n        //  _resolve method allows particles to request remapping of assets paths\n        //  for use in DOM\n        const resolver = this._resolve.bind(this);\n        return particleWrapper({\n            Particle,\n            DomParticle,\n            MultiplexerDomParticle,\n            SimpleParticle: DomParticle,\n            TransformationDomParticle,\n            resolver,\n            log: log || (() => { }),\n            html\n        });\n    }\n}\n//# sourceMappingURL=loader-platform.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\nimport { fetch } from '../platform/fetch-web.js';\nimport { fs } from '../platform/fs-web.js';\nimport { vm } from '../platform/vm-web.js';\nimport { JsonldToManifest } from './converters/jsonldToManifest.js';\nimport { DomParticle } from './dom-particle.js';\nimport { MultiplexerDomParticle } from './multiplexer-dom-particle.js';\nimport { Particle } from './particle.js';\nimport { ClientReference } from './reference.js';\nimport { TransformationDomParticle } from './transformation-dom-particle.js';\nconst html = (strings, ...values) => (strings[0] + values.map((v, i) => v + strings[i + 1]).join('')).trim();\nfunction schemaLocationFor(name) {\n    return `../entities/${name}.schema`;\n}\nexport class Loader {\n    path(fileName) {\n        return fileName.replace(/[/][^/]+$/, '/');\n    }\n    join(prefix, path) {\n        if (/^https?:\\/\\//.test(path)) {\n            return path;\n        }\n        // TODO: replace this with something that isn't hacky\n        if (path[0] === '/' || path[1] === ':') {\n            return path;\n        }\n        prefix = this.path(prefix);\n        path = this.normalizeDots(`${prefix}${path}`);\n        return path;\n    }\n    // convert `././foo/bar/../baz` to `./foo/baz`\n    normalizeDots(path) {\n        // only unix slashes\n        path = path.replace(/\\\\/g, '/');\n        // remove './'\n        path = path.replace(/\\/\\.\\//g, '/');\n        // remove 'foo/..'\n        const norm = s => s.replace(/(?:^|\\/)[^./]*\\/\\.\\./g, '');\n        for (let n = norm(path); n !== path; path = n, n = norm(path))\n            ;\n        // remove '//' except after `:`\n        path = path.replace(/([^:])(\\/\\/)/g, '$1/');\n        return path;\n    }\n    async loadResource(file) {\n        if (/^https?:\\/\\//.test(file)) {\n            return this._loadURL(file);\n        }\n        return this.loadFile(file, 'utf-8');\n    }\n    async loadBinary(file) {\n        if (/^https?:\\/\\//.test(file)) {\n            return fetch(file).then(res => res.arrayBuffer());\n        }\n        else {\n            return this.loadFile(file);\n        }\n    }\n    async loadFile(file, encoding) {\n        return new Promise((resolve, reject) => {\n            fs.readFile(file, { encoding }, (err, data) => {\n                if (err) {\n                    reject(err);\n                }\n                else {\n                    resolve(encoding ? data : data.buffer);\n                }\n            });\n        });\n    }\n    async _loadURL(url) {\n        if (/\\/\\/schema.org\\//.test(url)) {\n            if (url.endsWith('/Thing')) {\n                return fetch('https://schema.org/Product.jsonld').then(res => res.text()).then(data => JsonldToManifest.convert(data, { '@id': 'schema:Thing' }));\n            }\n            return fetch(url + '.jsonld').then(res => res.text()).then(data => JsonldToManifest.convert(data));\n        }\n        return fetch(url).then(res => res.text());\n    }\n    /**\n     * Returns a particle class implementation by loading and executing\n     * the code defined by a particle.  In the following example `x.js`\n     * will be loaded and executed:\n     *\n     * ```\n     * Particle foo in 'x.js'\n     * ```\n     */\n    async loadParticleClass(spec) {\n        const clazz = await this.requireParticle(spec.implFile);\n        clazz.spec = spec;\n        return clazz;\n    }\n    /**\n     * Loads a particle class from the given filename by loading the\n     * script contained in `fileName` and executing it as a script.\n     *\n     * Protected for use in tests.\n     */\n    async requireParticle(fileName) {\n        if (fileName === null)\n            fileName = '';\n        const src = await this.loadResource(fileName);\n        // Note. This is not real isolation.\n        const script = new vm.Script(src, { filename: fileName, displayErrors: true });\n        const result = [];\n        // TODO(lindner): restrict Math.random here.\n        const self = {\n            defineParticle(particleWrapper) {\n                result.push(particleWrapper);\n            },\n            console,\n            fetch,\n            setTimeout,\n            importScripts: s => null //console.log(`(skipping browser-space import for [${s}])`)\n        };\n        script.runInNewContext(self, { filename: fileName, displayErrors: true });\n        assert(result.length > 0 && typeof result[0] === 'function', `Error while instantiating particle implementation from ${fileName}`);\n        return this.unwrapParticle(result[0]);\n    }\n    setParticleExecutionContext(pec) {\n        this.pec = pec;\n    }\n    /**\n     * executes the defineParticle() code and returns the results which should be a class definition.\n     */\n    unwrapParticle(particleWrapper) {\n        assert(this.pec);\n        return particleWrapper({ Particle, DomParticle, TransformationDomParticle, MultiplexerDomParticle, Reference: ClientReference.newClientReference(this.pec), html });\n    }\n}\n//# sourceMappingURL=loader.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n// 'export default fetch' works because 'fetch' is evaluated as an expression, which finds the\n// appropriate global definition - but we don't want to use default exports.\n// 'export {fetch}' doesn't work because 'fetch' is just a name in that context and is not defined.\n// So we need to use an expression to find the global fetch function then map that for export.\nconst localFetch = fetch;\nexport { localFetch as fetch };\n//# sourceMappingURL=fetch-web.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n\nexport const fs = {};\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n\nexport const vm = {};\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nexport const supportedTypes = ['Text', 'URL', 'Number', 'Boolean'];\nexport class JsonldToManifest {\n    static convert(jsonld, theClass = undefined) {\n        const obj = JSON.parse(jsonld);\n        const classes = {};\n        const properties = {};\n        if (!obj['@graph']) {\n            obj['@graph'] = [obj];\n        }\n        for (const item of obj['@graph']) {\n            if (item['@type'] === 'rdf:Property') {\n                properties[item['@id']] = item;\n            }\n            else if (item['@type'] === 'rdfs:Class') {\n                classes[item['@id']] = item;\n                item['subclasses'] = [];\n                item['superclass'] = null;\n            }\n        }\n        for (const clazz of Object.values(classes)) {\n            if (clazz['rdfs:subClassOf'] !== undefined) {\n                if (clazz['rdfs:subClassOf'].length == undefined) {\n                    clazz['rdfs:subClassOf'] = [clazz['rdfs:subClassOf']];\n                }\n                for (const subClass of clazz['rdfs:subClassOf']) {\n                    const superclass = subClass['@id'];\n                    if (clazz['superclass'] == undefined) {\n                        clazz['superclass'] = [];\n                    }\n                    if (classes[superclass]) {\n                        classes[superclass].subclasses.push(clazz);\n                        clazz['superclass'].push(classes[superclass]);\n                    }\n                    else {\n                        clazz['superclass'].push({ '@id': superclass });\n                    }\n                }\n            }\n        }\n        for (const clazz of Object.values(classes)) {\n            if (clazz['subclasses'].length === 0 && theClass == undefined) {\n                theClass = clazz;\n            }\n        }\n        const relevantProperties = [];\n        for (const property of Object.values(properties)) {\n            let domains = property['schema:domainIncludes'];\n            if (!domains) {\n                domains = { '@id': theClass['@id'] };\n            }\n            if (!domains.length) {\n                domains = [domains];\n            }\n            domains = domains.map(a => a['@id']);\n            if (domains.includes(theClass['@id'])) {\n                const name = property['@id'].split(':')[1];\n                let type = property['schema:rangeIncludes'];\n                if (!type) {\n                    console.log(property);\n                }\n                if (!type.length) {\n                    type = [type];\n                }\n                type = type.map(a => a['@id'].split(':')[1]);\n                type = type.filter(type => supportedTypes.includes(type));\n                if (type.length > 0) {\n                    relevantProperties.push({ name, type });\n                }\n            }\n        }\n        const className = theClass['@id'].split(':')[1];\n        const superNames = theClass && theClass.superclass ? theClass.superclass.map(a => a['@id'].split(':')[1]) : [];\n        let s = '';\n        for (const superName of superNames) {\n            s += `import 'https://schema.org/${superName}'\\n\\n`;\n        }\n        s += `schema ${className}`;\n        if (superNames.length > 0) {\n            s += ` extends ${superNames.join(', ')}`;\n        }\n        if (relevantProperties.length > 0) {\n            for (const property of relevantProperties) {\n                let type;\n                if (property.type.length > 1) {\n                    type = '(' + property.type.join(' or ') + ')';\n                }\n                else {\n                    type = property.type[0];\n                }\n                s += `\\n  ${type} ${property.name}`;\n            }\n        }\n        s += '\\n';\n        return s;\n    }\n}\n//# sourceMappingURL=jsonldToManifest.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { XenStateMixin } from '../../modalities/dom/components/xen/xen-state.js';\nimport { DomParticleBase } from './dom-particle-base.js';\n/**\n * Particle that interoperates with DOM and uses a simple state system\n * to handle updates.\n */\nexport class DomParticle extends XenStateMixin(DomParticleBase) {\n    /**\n     * Override if necessary, to do things when props change.\n     */\n    willReceiveProps(...args) {\n    }\n    /**\n     * Override if necessary, to modify superclass config.\n     */\n    update(...args) {\n    }\n    /**\n     * Override to return false if the Particle won't use\n     * it's slot.\n     */\n    shouldRender(...args) {\n        return true;\n    }\n    /**\n     * Override to return a dictionary to map into the template.\n     */\n    render(...args) {\n        return {};\n    }\n    /**\n     * Copy values from `state` into the particle's internal state,\n     * triggering an update cycle unless currently updating.\n     */\n    setState(state) {\n        return this._setState(state);\n    }\n    /**\n     * Getters and setters for working with state/props.\n     */\n    get state() {\n        return this._state;\n    }\n    /**\n     * Syntactic sugar: `this.state = {state}` is equivalent to `this.setState(state)`.\n     */\n    set state(state) {\n        this.setState(state);\n    }\n    get props() {\n        return this._props;\n    }\n    /**\n     * Override if necessary, to modify superclass config.\n     */\n    get config() {\n        // TODO(sjmiles): getter that does work is a bad idea, this is temporary\n        return {\n            handleNames: this.spec.inputs.map(i => i.name),\n            // TODO(mmandlis): this.spec needs to be replaced with a particle-spec loaded from\n            // .manifest files, instead of .ptcl ones.\n            slotNames: [...this.spec.slotConnections.values()].map(s => s.name)\n        };\n    }\n    // affordances for aliasing methods to remove `_`\n    _willReceiveProps(...args) {\n        this.willReceiveProps(...args);\n    }\n    _update(...args) {\n        this.update(...args);\n        if (this.shouldRender(...args)) { // TODO: should shouldRender be slot specific?\n            this.relevance = 1; // TODO: improve relevance signal.\n        }\n        this.config.slotNames.forEach(s => this.renderSlot(s, ['model']));\n    }\n    _async(fn) {\n        // asynchrony in Particle code must be bookended with start/doneBusy\n        this.startBusy();\n        const done = () => {\n            try {\n                fn.call(this);\n            }\n            finally {\n                this.doneBusy();\n            }\n        };\n        // TODO(sjmiles): superclass uses Promise.resolve(),\n        // but here use a short timeout for a wider debounce\n        return setTimeout(done, 10);\n    }\n    async setHandles(handles) {\n        this.configureHandles(handles);\n        this.handles = handles;\n        // TODO(sjmiles): we must invalidate at least once, is there a way to know\n        // whether handleSync/update will be called?\n        this._invalidate();\n    }\n    /**\n     * This is called once during particle setup. Override to control sync and update\n     * configuration on specific handles (via their configure() method).\n     * `handles` is a map from names to handle instances.\n     */\n    configureHandles(handles) {\n        // Example: handles.get('foo').configure({keepSynced: false});\n    }\n    async onHandleSync(handle, model) {\n        this._setProperty(handle.name, model);\n    }\n    async onHandleUpdate({ name }, { data, added, removed }) {\n        if (data !== undefined) {\n            //console.log('update.data:', JSON.stringify(data, null, '  '));\n            this._setProps({ [name]: data });\n        }\n        if (added) {\n            //console.log('update.added:', JSON.stringify(added, null, '  '));\n            const prop = (this.props[name] || []).concat(added);\n            // TODO(sjmiles): generally improper to set `this._props` directly, this is a special case\n            this._props[name] = prop;\n            this._setProps({ [name]: prop });\n        }\n        if (removed) {\n            //console.log('update.removed:', JSON.stringify(removed, null, '  '));\n            const prop = this.props[name];\n            if (Array.isArray(prop)) {\n                removed.forEach(removed => {\n                    // TODO(sjmiles): linear search is inefficient\n                    const index = prop.findIndex(entry => this.idFor(entry) === this.idFor(removed));\n                    if (index >= 0) {\n                        prop.splice(index, 1);\n                    }\n                    else {\n                        console.warn(`dom-particle::onHandleUpdate: couldn't find item to remove`);\n                    }\n                });\n                this._setProps({ [name]: prop });\n            }\n        }\n    }\n    fireEvent(slotName, { handler, data }) {\n        if (this[handler]) {\n            // TODO(sjmiles): remove `this._state` parameter\n            this[handler]({ data }, this._state);\n        }\n    }\n    debounce(key, func, delay) {\n        const subkey = `_debounce_${key}`;\n        const state = this.state;\n        if (!state[subkey]) {\n            state[subkey] = true;\n            this.startBusy();\n        }\n        const idleThenFunc = () => {\n            this.doneBusy();\n            func();\n            state[subkey] = null;\n        };\n        // TODO(sjmiles): rewrite Xen debounce so caller has idle control\n        super._debounce(key, idleThenFunc, delay);\n    }\n}\n//# sourceMappingURL=dom-particle.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n\nconst nob = () => Object.create(null);\n\nconst debounce = (key, action, delay) => {\n  if (key) {\n    clearTimeout(key);\n  }\n  if (action && delay) {\n    return setTimeout(action, delay);\n  }\n};\n\nconst XenStateMixin = Base => class extends Base {\n  constructor() {\n    super();\n    this._pendingProps = nob();\n    this._props = this._getInitialProps() || nob();\n    this._lastProps = nob();\n    this._state = this._getInitialState() || nob();\n    this._lastState = nob();\n  }\n  _getInitialProps() {\n  }\n  _getInitialState() {\n  }\n  _getProperty(name) {\n    return this._pendingProps[name] || this._props[name];\n  }\n  _setProperty(name, value) {\n    // dirty checking opportunity\n    if (this._validator || this._wouldChangeProp(name, value)) {\n      this._pendingProps[name] = value;\n      this._invalidateProps();\n    }\n  }\n  _wouldChangeValue(map, name, value) {\n    // Important dirty-checking behavior controlled here,\n    // can be overridden.\n    // The default implementation will use strict reference checking.\n    // To modify structured values one must create a new Object to\n    // replace the old one.\n    return (map[name] !== value);\n    // an example of dirty-checking that instead simply punts on structured data\n    //return (typeof value === 'object') || (map[name] !== value);\n  }\n  _wouldChangeProp(name, value) {\n    return this._wouldChangeValue(this._props, name, value);\n  }\n  _wouldChangeState(name, value) {\n    return this._wouldChangeValue(this._state, name, value);\n  }\n  _setProps(props) {\n    // TODO(sjmiles): should be a replace instead of a merge?\n    Object.assign(this._pendingProps, props);\n    this._invalidateProps();\n  }\n  _invalidateProps() {\n    this._propsInvalid = true;\n    this._invalidate();\n  }\n  _setState(object) {\n    let dirty = false;\n    const state = this._state;\n    for (const property in object) {\n      const value = object[property];\n      if (this._wouldChangeState(property, value)) {\n        dirty = true;\n        state[property] = value;\n      }\n    }\n    if (dirty) {\n      this._invalidate();\n      return true;\n    }\n  }\n  _async(fn) {\n    return Promise.resolve().then(fn.bind(this));\n  }\n  _invalidate() {\n    if (!this._validator) {\n      this._validator = this._async(this._validate);\n    }\n  }\n  _getStateArgs() {\n    return [this._props, this._state, this._lastProps, this._lastState];\n  }\n  _validate() {\n    const stateArgs = this._getStateArgs();\n    // try..catch to ensure we nullify `validator` before return\n    try {\n      // TODO(sjmiles): should be a replace instead of a merge\n      Object.assign(this._props, this._pendingProps);\n      if (this._propsInvalid) {\n        // TODO(sjmiles): should/can have different timing from rendering?\n        this._willReceiveProps(...stateArgs);\n        this._propsInvalid = false;\n      }\n      if (this._shouldUpdate(...stateArgs)) {\n        // TODO(sjmiles): consider throttling update to rAF\n        this._ensureMount();\n        this._doUpdate(...stateArgs);\n      }\n    } catch (x) {\n      console.error(x);\n    }\n    // nullify validator _after_ methods so state changes don't reschedule validation\n    this._validator = null;\n    // save the old props and state\n    this._lastProps = Object.assign(nob(), this._props);\n    this._lastState = Object.assign(nob(), this._state);\n  }\n  _doUpdate(...stateArgs) {\n    this._update(...stateArgs);\n    this._didUpdate(...stateArgs);\n  }\n  _ensureMount() {\n  }\n  _willReceiveProps() {\n  }\n  _shouldUpdate() {\n    return true;\n  }\n  _update() {\n  }\n  _didUpdate() {\n  }\n  _debounce(key, func, delay) {\n    key = `_debounce_${key}`;\n    this._state[key] = debounce(this._state[key], func, delay != null ? delay : 16);\n  }\n};\n\nexport {XenStateMixin, nob, debounce};\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { BigCollection, Collection, Singleton } from './handle.js';\nimport { Particle } from './particle.js';\n/**\n * Particle that interoperates with DOM.\n */\nexport class DomParticleBase extends Particle {\n    /**\n     * Override to return a String defining primary markup.\n     */\n    get template() {\n        return '';\n    }\n    /**\n     * Override to return a String defining primary markup for the given slot name.\n     */\n    getTemplate(slotName) {\n        // TODO: only supports a single template for now. add multiple templates support.\n        return this.template;\n    }\n    /**\n     * Override to return a String defining the name of the template for the given slot name.\n     */\n    getTemplateName(slotName) {\n        // TODO: only supports a single template for now. add multiple templates support.\n        return `default`;\n    }\n    /**\n     * Override to return false if the Particle won't use it's slot.\n     */\n    shouldRender(stateArgs) {\n        return true;\n    }\n    /**\n     * Override to return a dictionary to map into the template.\n     */\n    render(stateArgs) {\n        return {};\n    }\n    renderSlot(slotName, contentTypes) {\n        const stateArgs = this._getStateArgs();\n        const slot = this.getSlot(slotName);\n        if (!slot) {\n            return; // didn't receive StartRender.\n        }\n        // Set this to support multiple slots consumed by a particle, without needing\n        // to pass slotName to particle's render method, where it useless in most cases.\n        this.currentSlotName = slotName;\n        contentTypes.forEach(ct => slot.requestedContentTypes.add(ct));\n        // TODO(sjmiles): redundant, same answer for every slot\n        if (this.shouldRender(...stateArgs)) {\n            const content = {};\n            if (slot.requestedContentTypes.has('template')) {\n                content.template = this.getTemplate(slot.slotName);\n            }\n            if (slot.requestedContentTypes.has('model')) {\n                content.model = this.render(...stateArgs);\n            }\n            content.templateName = this.getTemplateName(slot.slotName);\n            // Backwards-compatibility and convenience code:\n            //  - Rewrites slotid=\"slotName\" to slotid$=\"{{$slotName}}\" in templates.\n            //  - Enhances the model with `$slotName` fields.\n            if (slot.providedSlots.size > 0) {\n                if (content.template) {\n                    if (typeof content.template === 'string') {\n                        content.template = this.slotNamesToModelReferences(slot, content.template);\n                    }\n                    else {\n                        content.template = Object.entries(content.template).reduce((templateDictionary, [templateName, templateValue]) => {\n                            templateDictionary[templateName] = this.slotNamesToModelReferences(slot, templateValue);\n                            return templateDictionary;\n                        }, {});\n                    }\n                }\n                if (content.model) {\n                    const slotIDs = {};\n                    slot.providedSlots.forEach((slotId, slotName) => slotIDs[`$${slotName}`] = slotId);\n                    content.model = this.enhanceModelWithSlotIDs(content.model, slotIDs);\n                }\n            }\n            slot.render(content);\n        }\n        else if (slot.isRendered) {\n            // Send empty object, to clear rendered slot contents.\n            slot.render({});\n        }\n        this.currentSlotName = undefined;\n    }\n    slotNamesToModelReferences(slot, template) {\n        slot.providedSlots.forEach((slotId, slotName) => {\n            // TODO: This is a simple string replacement right now,\n            // ensuring that 'slotid' is an attribute on an HTML element would be an improvement.\n            // TODO(sjmiles): clone original id as `slotname` for human readability\n            template = template.replace(new RegExp(`slotid=\"${slotName}\"`, 'gi'), `slotname=\"${slotName}\" slotid$=\"{{$${slotName}}}\"`);\n        });\n        return template;\n    }\n    // We put slot IDs at the top-level of the model as well as in models for sub-templates.\n    // This is temporary and should go away when we move from sub-IDs to [(Entity, Slot)] constructs.\n    enhanceModelWithSlotIDs(model, slotIDs, topLevel = true) {\n        if (topLevel) {\n            model = { ...slotIDs, ...model };\n        }\n        if (model.hasOwnProperty('$template') && model.hasOwnProperty('models') && Array.isArray(model['models'])) {\n            model['models'] = model['models'].map(m => this.enhanceModelWithSlotIDs(m, slotIDs));\n        }\n        for (const [key, value] of Object.entries(model)) {\n            if (!!value && typeof value === 'object') {\n                model[key] = this.enhanceModelWithSlotIDs(value, slotIDs, false);\n            }\n        }\n        return model;\n    }\n    _getStateArgs() {\n        return [];\n    }\n    forceRenderTemplate(slotName = '') {\n        this.slotProxiesByName.forEach((slot, name) => {\n            if (!slotName || (name === slotName)) {\n                slot.requestedContentTypes.add('template');\n            }\n        });\n    }\n    fireEvent(slotName, { handler, data }) {\n        if (this[handler]) {\n            this[handler]({ data });\n        }\n    }\n    async setParticleDescription(pattern) {\n        if (typeof pattern === 'string') {\n            return super.setParticleDescription(pattern);\n        }\n        if (pattern.template && pattern.model) {\n            await super.setDescriptionPattern('_template_', pattern.template);\n            await super.setDescriptionPattern('_model_', JSON.stringify(pattern.model));\n            return undefined;\n        }\n        else {\n            throw new Error('Description pattern must either be string or have template and model');\n        }\n    }\n    /**\n     * Remove all entities from named handle.\n     */\n    async clearHandle(handleName) {\n        const handle = this.handles.get(handleName);\n        if (handle instanceof Singleton || handle instanceof Collection) {\n            await handle.clear();\n        }\n        else {\n            throw new Error('Singleton/Collection required');\n        }\n    }\n    /**\n     * Merge entities from Array into named handle.\n     */\n    async mergeEntitiesToHandle(handleName, entities) {\n        const idMap = {};\n        const handle = this.handles.get(handleName);\n        if (handle instanceof Collection) {\n            const handleEntities = await handle.toList();\n            handleEntities.forEach(entity => idMap[entity.id] = entity);\n            for (const entity of entities) {\n                if (!idMap[this.idFor(entity)]) {\n                    await handle.store(entity);\n                }\n            }\n        }\n        else {\n            throw new Error('Collection required');\n        }\n    }\n    /**\n     * Append entities from Array to named handle.\n     */\n    async appendEntitiesToHandle(handleName, entities) {\n        const handle = this.handles.get(handleName);\n        if (handle) {\n            if (handle instanceof Collection || handle instanceof BigCollection) {\n                await Promise.all(entities.map(entity => handle.store(entity)));\n            }\n            else {\n                throw new Error('Collection required');\n            }\n        }\n    }\n    /**\n     * Create an entity from each rawData, and append to named handle.\n     */\n    async appendRawDataToHandle(handleName, rawDataArray) {\n        const handle = this.handles.get(handleName);\n        if (handle && handle.entityClass) {\n            if (handle instanceof Collection || handle instanceof BigCollection) {\n                const entityClass = handle.entityClass;\n                await Promise.all(rawDataArray.map(raw => handle.store(new entityClass(raw))));\n            }\n            else {\n                throw new Error('Collection required');\n            }\n        }\n    }\n    /**\n     * Modify value of named handle. A new entity is created\n     * from `rawData` (`new [EntityClass](rawData)`).\n     */\n    async updateSingleton(handleName, rawData) {\n        const handle = this.handles.get(handleName);\n        if (handle && handle.entityClass) {\n            if (handle instanceof Singleton) {\n                const entity = new handle.entityClass(rawData);\n                await handle.set(entity);\n                return entity;\n            }\n            else {\n                throw new Error('Singleton required');\n            }\n        }\n        return undefined;\n    }\n    /**\n     * Modify or insert `entity` into named handle.\n     * Modification is done by removing the old entity and reinserting the new one.\n     */\n    async updateCollection(handleName, entity) {\n        // Set the entity into the right place in the set. If we find it\n        // already present replace it, otherwise, add it.\n        // TODO(dstockwell): Replace this with happy entity mutation approach.\n        const handle = this.handles.get(handleName);\n        if (handle) {\n            if (handle instanceof Collection || handle instanceof BigCollection) {\n                await handle.remove(entity);\n                await handle.store(entity);\n            }\n            else {\n                throw new Error('Collection required');\n            }\n        }\n    }\n    /**\n     * Return array of Entities dereferenced from array of Share-Type Entities\n     */\n    async derefShares(shares) {\n        let entities = [];\n        this.startBusy();\n        try {\n            const derefPromises = shares.map(async (share) => share.ref.dereference());\n            entities = await Promise.all(derefPromises);\n        }\n        finally {\n            this.doneBusy();\n        }\n        return entities;\n    }\n    /**\n     * Returns array of Entities found in BOXED data `box` that are owned by `userid`\n     */\n    async boxQuery(box, userid) {\n        if (!box) {\n            return [];\n        }\n        else {\n            const matches = box.filter(item => userid === item.fromKey);\n            return await this.derefShares(matches);\n        }\n    }\n}\n//# sourceMappingURL=dom-particle-base.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../platform/assert-web.js';\nimport { ParticleSpec } from './particle-spec.js';\nimport { TransformationDomParticle } from './transformation-dom-particle.js';\nimport { Entity } from './entity.js';\nexport class MultiplexerDomParticle extends TransformationDomParticle {\n    constructor() {\n        super(...arguments);\n        this._itemSubIdByHostedSlotId = new Map();\n        this._connByHostedConn = new Map();\n    }\n    async _mapParticleConnections(listHandleName, particleHandleName, hostedParticle, handles, arc) {\n        const otherMappedHandles = [];\n        const otherConnections = [];\n        let index = 2;\n        const skipConnectionNames = [listHandleName, particleHandleName];\n        for (const [connectionName, otherHandle] of handles) {\n            if (skipConnectionNames.includes(connectionName)) {\n                continue;\n            }\n            // TODO(wkorman): For items with embedded recipes we may need a map\n            // (perhaps id to index) to make sure we don't map a handle into the inner\n            // arc multiple times unnecessarily.\n            // TODO(lindner): type erasure to avoid mismatch of Store vs Handle in arc.mapHandle\n            // tslint:disable-next-line: no-any\n            const otherHandleStore = otherHandle.storage;\n            otherMappedHandles.push(`use '${await arc.mapHandle(otherHandleStore)}' as v${index}`);\n            const hostedOtherConnection = hostedParticle.handleConnections.find(conn => conn.isCompatibleType(otherHandle.type));\n            if (hostedOtherConnection) {\n                otherConnections.push(`${hostedOtherConnection.name} = v${index++}`);\n                // TODO(wkorman): For items with embedded recipes where we may have a\n                // different particle rendering each item, we need to track\n                // |connByHostedConn| keyed on the particle type.\n                this._connByHostedConn.set(hostedOtherConnection.name, connectionName);\n            }\n        }\n        return [otherMappedHandles, otherConnections];\n    }\n    async setHandles(handles) {\n        this.handleIds = {};\n        const arc = await this.constructInnerArc();\n        const listHandleName = 'list';\n        const particleHandleName = 'hostedParticle';\n        const particleHandle = handles.get(particleHandleName);\n        let hostedParticle = null;\n        let otherMappedHandles = [];\n        let otherConnections = [];\n        if (particleHandle) {\n            // Typecast to any; the get() method doesn't exist on raw Handles.\n            // tslint:disable-next-line: no-any\n            hostedParticle = await particleHandle.get();\n            if (hostedParticle) {\n                [otherMappedHandles, otherConnections] =\n                    await this._mapParticleConnections(listHandleName, particleHandleName, hostedParticle, handles, arc);\n            }\n        }\n        this.setState({\n            arc,\n            type: handles.get(listHandleName).type,\n            hostedParticle,\n            otherMappedHandles,\n            otherConnections\n        });\n        await super.setHandles(handles);\n    }\n    async update({ list }, { arc, type, hostedParticle, otherMappedHandles, otherConnections }, oldProps, oldState) {\n        //console.warn(`[${this.spec.name}]::update`, list, arc);\n        if (!list || !arc) {\n            return;\n        }\n        if (oldProps.list === list && oldState.arc === arc) {\n            return;\n        }\n        if (list.length > 0) {\n            this.relevance = 0.1;\n        }\n        for (const [index, item] of this.getListEntries(list)) {\n            let resolvedHostedParticle = hostedParticle;\n            const id = Entity.id(item);\n            if (this.handleIds[id]) {\n                const itemHandle = await this.handleIds[id];\n                // tslint:disable-next-line: no-any\n                itemHandle.set(item);\n                continue;\n            }\n            const itemHandlePromise = arc.createHandle(type.getContainedType(), `item${index}`);\n            this.handleIds[id] = itemHandlePromise;\n            const itemHandle = await itemHandlePromise;\n            if (!resolvedHostedParticle) {\n                // If we're muxing on behalf of an item with an embedded recipe, the\n                // hosted particle should be retrievable from the item itself. Else we\n                // just skip this item.\n                if (!item.renderParticleSpec) {\n                    continue;\n                }\n                resolvedHostedParticle =\n                    ParticleSpec.fromLiteral(JSON.parse(item.renderParticleSpec));\n                // Re-map compatible handles and compute the connections specific\n                // to this item's render particle.\n                const listHandleName = 'list';\n                const particleHandleName = 'renderParticle';\n                [otherMappedHandles, otherConnections] =\n                    await this._mapParticleConnections(listHandleName, particleHandleName, resolvedHostedParticle, this.handles, arc);\n            }\n            const hostedSlotName = [...resolvedHostedParticle.slotConnections.keys()][0];\n            const slotName = [...this.spec.slotConnections.values()][0].name;\n            const slotId = await arc.createSlot(this, slotName, itemHandle._id);\n            if (!slotId) {\n                continue;\n            }\n            this._itemSubIdByHostedSlotId.set(slotId, id);\n            try {\n                const recipe = this.constructInnerRecipe(resolvedHostedParticle, item, itemHandle, { name: hostedSlotName, id: slotId }, { connections: otherConnections, handles: otherMappedHandles });\n                await arc.loadRecipe(recipe);\n                // tslint:disable-next-line: no-any\n                itemHandle.set(item);\n            }\n            catch (e) {\n                console.log(e);\n            }\n        }\n    }\n    combineHostedModel(slotName, hostedSlotId, content) {\n        const subId = this._itemSubIdByHostedSlotId.get(hostedSlotId);\n        if (!subId) {\n            return;\n        }\n        const items = this._state.renderModel ? this._state.renderModel.items : [];\n        const listIndex = items.findIndex(item => item.subId === subId);\n        const item = { ...content.model, subId };\n        if (listIndex >= 0 && listIndex < items.length) {\n            items[listIndex] = item;\n        }\n        else {\n            items.push(item);\n        }\n        this.setState({ renderModel: { items } });\n    }\n    combineHostedTemplate(slotName, hostedSlotId, content) {\n        const subId = this._itemSubIdByHostedSlotId.get(hostedSlotId);\n        if (!subId) {\n            return;\n        }\n        assert(content.templateName, `Template name is missing for slot '${slotName}' (hosted slot ID: '${hostedSlotId}')`);\n        const templateName = { ...this._state.templateName, [subId]: `${content.templateName}` };\n        this.setState({ templateName });\n        if (content.template) {\n            let template = content.template;\n            // Append subid$={{subid}} attribute to all provided slots, to make it usable for the transformation particle.\n            template = template.replace(new RegExp('slotid=\"[a-z]+\"', 'gi'), '$& subid$=\"{{subId}}\"');\n            // Replace hosted particle connection in template with the corresponding particle connection names.\n            // TODO: make this generic!\n            this._connByHostedConn.forEach((conn, hostedConn) => {\n                template = template.replace(new RegExp(`{{${hostedConn}.description}}`, 'g'), `{{${conn}.description}}`);\n            });\n            this.setState({ template: { ...this._state.template, [content.templateName]: template } });\n            this.forceRenderTemplate();\n        }\n    }\n    // Called with the list of items and by default returns the direct result of\n    // `Array.entries()`. Subclasses can override this method to alter the item\n    // order or otherwise permute the items as desired before their slots are\n    // created and contents are rendered.\n    // tslint:disable-next-line: no-any\n    getListEntries(list) {\n        return list.entries();\n    }\n}\n//# sourceMappingURL=multiplexer-dom-particle.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { DomParticle } from './dom-particle.js';\nimport { Entity } from './entity.js';\n// Regex to separate style and template.\nconst re = /<style>((?:.|[\\r\\n])*)<\\/style>((?:.|[\\r\\n])*)/;\n/**\n * Particle that does transformation stuff with DOM.\n */\nexport class TransformationDomParticle extends DomParticle {\n    getTemplate(slotName) {\n        // TODO: add support for multiple slots.\n        return this._state.template;\n    }\n    getTemplateName(slotName) {\n        // TODO: add support for multiple slots.\n        return this._state.templateName;\n    }\n    render(props, state) {\n        return state.renderModel;\n    }\n    shouldRender(props, state) {\n        return Boolean((state.template || state.templateName) && state.renderModel);\n    }\n    renderHostedSlot(slotName, hostedSlotId, content) {\n        this.combineHostedTemplate(slotName, hostedSlotId, content);\n        this.combineHostedModel(slotName, hostedSlotId, content);\n    }\n    // abstract\n    combineHostedTemplate(slotName, hostedSlotId, content) {\n    }\n    combineHostedModel(slotName, hostedSlotId, content) {\n    }\n    // Helper methods that may be reused in transformation particles to combine hosted content.\n    static propsToItems(propsValues) {\n        return propsValues ? propsValues.map(e => ({ subId: Entity.id(e), ...e })) : [];\n    }\n}\n//# sourceMappingURL=transformation-dom-particle.js.map","/**\n * @license\n * Copyright 2019 Google LLC.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nconst _factory = (preamble, color, log = 'log') =>\n  console[log].bind(\n    console,\n    `%c${preamble}`,\n    `background: ${color || 'gray'}; color: white; padding: 1px 6px 2px 7px; border-radius: 6px;`\n  );\n\n// don't spam the console for workers\nif (typeof window !== 'undefined') {\n  console.log(`log-web: binding logFactory to level [${window.logLevel}]`);\n}\n\nexport const logFactory = (...args) => {\n  // could be running in worker\n  const g = (typeof window !== 'undefined') ? window : global;\n  // use specified logLevel otherwise 0\n  const logLevel = ('logLevel' in g) ? g['logLevel'] : 0;\n  // modulate factory based on logLevel\n  const factory = logLevel > 0 ? _factory : () => () => {};\n  return factory(...args);\n};\n"],"sourceRoot":""}