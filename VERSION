commit fca21ff71ec3435fc9cf381e715afce9a13d75f4
Author: Alex Rosengarten <alxr@google.com>
Date:   Thu Jun 13 15:35:53 2019 -0700

    Granular Image Classification Recipes (#3180)
    
    * image schema: blob + url subtypes
    
    * updating lock sha
    
    * oop tf service prototype
    
    * types. Have dummy tensor2Output fn
    
    * idea: let resource mgr handle dispose for tf objects.
    
    * added a needed await
    
    * refinement of tfjs srvc. Prototype modular img classifier
    
    * experiment: tfjs --> lazy + eager load
    
    * experiment: web--> relative import
    
    * experiment: ... rel path to dist/...js
    
    * using tf core as tfjs
    
    * quick fix to bad fn call
    
    * workaround: check for sub-library versions
    
    * added preprocess service + srvc adjustments
    
    * WIP: generic img classifier particle
    
    * depending on dynamic load
    
    * - using input references
    - cleanup
    
    * particle: load then classify. ++logs
    
    * adding preproc services
    
    * cleaning up normalize fn
    
    * cleaning up api
    
    * Got first iteration of modular classifier to work!
    
    * added postprocessor + using mobilnet v1 + moved interface
    
    * Added labels as asset
    
    * have messy, but working example particle. Using mobilenet v1
    
    * Added model warmup -- got it to work
    
    * Added doc for warmUp
    
    * documented + cleaned up tfjs service
    
    * Fixed dynamic load caching check
    
    * rm messy log statement
    
    * typo: fixed spelling
    
    * move + revision of image schema
    
    * whitespace
    
    * Modeled parts of ML process with schemas
    - model for inference results
    - model for MlModels
    - model for Ml resources (i.e. tensors)
    
    * First micro particle: image to tensor converter
    
    * breaking up classifying and labeling
    
    * prototype of toLabels particle
    
    * logits --> yHat
    
    * rename: correcting minor mistake
    
    * Drafted model loading
    - created alias in the tfjs service for layers models
    - added two particles for loading each kind of model.
    - TODO: unify model loading at the service level.
    - Updated the schema for MLModels to include TFHub flag
    
    * fix: changed to updateSingleton
    
    * whitespace
    
    * updated ml schemas -- labels + options
    
    * updated labels based on schema
    
    * Renamed labels particle
    
    * attempt a label parse particle
    
    * round of particle grooming
    
    * Following inline schema pattern
    
    * simplified ml model schema
    
    * Service calls: * --> tf.*
    
    * correct call to predict
    
    * added dispose particle
    
    * simple normalize particle
    
    * defensive method: get reference
    
    * quick impl of reshape
    
    * quick expand dims
    
    * quick resize bilinear
    
    * rename: * --> apply
    
    * rm `consume root`
    
    * correcting inline particle syntax
    
    * updating to better schemas
    
    * added log stmts, rm state
    
    * rm state
    
    * rm state
    
    * update param names; rm state
    
    * only need to import 1 particle + 1 schema
    
    * WIP: img classifier recipe
    
    * revert aml-language-server
    
    * stable: 2tensor + norm + resize
    
    * added resize op
    
    * Volatile + added ML model store
    
    * loading ml model
    
    * added classifier
    
    * Classifier --> Classify
    
    * ... forgot a rename
    
    * updated parse labels particle
    
    * Updates ML Model schema
    
    * Added model label url
    
    * clever use of inline schemas. Thanks Maria
    
    * added labels parsing
    
    * ToLabels --> TopLabels
    
    * Making k an optional handle
    
    * Getting top labels from prediction
    
    * Add image selector particle
    
    * View in dev shell working!
    
    * quick present label view
    
    * Pointing to existing asset
    
    * Hooked up ui endpoints
    
    * making a simpler MlModel
    
    * fixed problem, don't need slot
    
    * added description
    
    * Downloaded tf hub asset locally
    
    * exposing img classifier in webshell
    
    * fix: accessing img url, not entity
    
    * added model shards
    
    * Updating collection properly (Thanks Maria)
    
    * CORS fix
    
    * Fixed model loading particles
    
    * Fixed issues that broke pipeline
    
    * fix: lack of capitalization
    
    * fix: accessing correct field
    
    * Adding log statements: why is getTopK so slow?
    
    * proper update of collections
    
    * correct update for handles, thanks Scott
    
    * labels, predictions are now volatile
    
    * Better UI for presenting labels
    
    * rm logs from tfjs service
    
    * rm extra import ... don't know how that got here
    
    * rm accidental export
    
    * rm whitespace
    
    * Simplifying schemas
    
    * Simplfying PresentLabel particle
    
    * fix whitespace
    
    * mv model to it's own directory
    
    * quick model selector particle
    
    * added labels input to model selector
    
    * fix: schema uses term "location"
    
    * Got granular inference working!
    
    * provide a results view slot
    
    * good enough slot handling
    
    * comment out old ml classification srvcs
    
    * dependenct slot approach
    
    * rename model artifact path
    
    * fixed: english
    
    * Added MobileNet v2 assets
    
    * Added MobNet v2 recipe
    
    * Classify --> Infer
