{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///./devtools/shared/devtools-broker.js","webpack:///./node_modules/process/browser.js","webpack:///./node_modules/sourcemapped-stacktrace/node_modules/source-map/lib/array-set.js","webpack:///./node_modules/sourcemapped-stacktrace/node_modules/source-map/lib/base64-vlq.js","webpack:///./node_modules/sourcemapped-stacktrace/node_modules/source-map/lib/base64.js","webpack:///./node_modules/sourcemapped-stacktrace/node_modules/source-map/lib/binary-search.js","webpack:///./node_modules/sourcemapped-stacktrace/node_modules/source-map/lib/quick-sort.js","webpack:///./node_modules/sourcemapped-stacktrace/node_modules/source-map/lib/source-map-consumer.js","webpack:///./node_modules/sourcemapped-stacktrace/node_modules/source-map/lib/util.js","webpack:///./node_modules/sourcemapped-stacktrace/sourcemapped-stacktrace.js","webpack:///(webpack)/buildin/global.js","webpack:///./platform/assert-web.js","webpack:///./platform/devtools-channel-web.js","webpack:///./platform/fs-web.js","webpack:///./platform/sourcemapped-stacktrace-web.js","webpack:///./platform/vm-web.js","webpack:///./runtime/api-channel.js","webpack:///./runtime/debug/abstract-devtools-channel.js","webpack:///./runtime/debug/devtools-connection.js","webpack:///./runtime/debug/outer-port-attachment.js","webpack:///./runtime/debug/testing/devtools-channel-stub.js","webpack:///./runtime/dom-particle-base.js","webpack:///./runtime/dom-particle.js","webpack:///./runtime/fetch-web.js","webpack:///./runtime/multiplexer-dom-particle.js","webpack:///./runtime/particle-execution-context.js","webpack:///./runtime/particle.js","webpack:///./runtime/storage-proxy.js","webpack:///./runtime/transformation-dom-particle.js","webpack:///./runtime/ts-build/converters/jsonldToManifest.js","webpack:///./runtime/ts-build/entity.js","webpack:///./runtime/ts-build/handle.js","webpack:///./runtime/ts-build/loader.js","webpack:///./runtime/ts-build/particle-spec.js","webpack:///./runtime/ts-build/recipe/type-checker.js","webpack:///./runtime/ts-build/reference.js","webpack:///./runtime/ts-build/schema.js","webpack:///./runtime/ts-build/shape.js","webpack:///./runtime/ts-build/storage/crdt-collection-model.js","webpack:///./runtime/ts-build/symbols.js","webpack:///./runtime/ts-build/tuple-fields.js","webpack:///./runtime/ts-build/type-variable.js","webpack:///./runtime/ts-build/type.js","webpack:///./shell/components/xen/xen-state.js","webpack:///./shell/source/browser-loader.js","webpack:///./shell/source/worker-entry.js","webpack:///./tracelib/trace.js"],"names":[],"mappings":";AAAA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,kDAA0C,gCAAgC;AAC1E;AACA;;AAEA;AACA;AACA;AACA,gEAAwD,kBAAkB;AAC1E;AACA,yDAAiD,cAAc;AAC/D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAyC,iCAAiC;AAC1E,wHAAgH,mBAAmB,EAAE;AACrI;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;;AAGA;AACA;;;;;;;;;;;;;AClFA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;;;;;;;;;;;;;AChCA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;;;AAIA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,uBAAuB,sBAAsB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qCAAqC;;AAErC;AACA;AACA;;AAEA,2BAA2B;AAC3B;AACA;AACA;AACA,4BAA4B,UAAU;;;;;;;;;;;;ACvLtC,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA;;AAEA,WAAW,mBAAO,CAAC,0FAAQ;AAC3B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,sCAAsC,SAAS;AAC/C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;;;;;ACvGA,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D;AAC3D,oBAAoB;AACpB;AACA;AACA;AACA;;AAEA,aAAa,mBAAO,CAAC,8FAAU;;AAE/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;;;;;;;;;;;;AC3IA,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB,gBAAgB;;AAEhB,mBAAmB;AACnB,oBAAoB;;AAEpB,gBAAgB;AAChB,gBAAgB;;AAEhB,gBAAgB;AAChB,iBAAiB;;AAEjB;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;;;;;AClEA,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;;;;;;;;;;AC9GA,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,MAAM;AACjB;AACA,WAAW,OAAO;AAClB;AACA,WAAW,OAAO;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,OAAO;AAClB;AACA,WAAW,OAAO;AAClB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,MAAM;AACjB;AACA,WAAW,SAAS;AACpB;AACA,WAAW,OAAO;AAClB;AACA,WAAW,OAAO;AAClB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,OAAO;AAC1B;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,MAAM;AACjB;AACA,WAAW,SAAS;AACpB;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACjHA,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA;;AAEA,WAAW,mBAAO,CAAC,0FAAQ;AAC3B,mBAAmB,mBAAO,CAAC,4GAAiB;AAC5C,eAAe,mBAAO,CAAC,oGAAa;AACpC,gBAAgB,mBAAO,CAAC,sGAAc;AACtC,gBAAgB,mBAAO,CAAC,sGAAc;;AAEtC;AACA;AACA;AACA,sDAAsD;AACtD;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA,mBAAmB;AACnB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;;AAEX;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;;AAEX;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,MAAM;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD;AACtD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,sDAAsD,YAAY;AAClE;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,yBAAyB,cAAc;AACvC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,wCAAwC;AAC/D;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,mBAAmB,EAAE;AACpE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,oBAAoB;AACrC;AACA;AACA;AACA;AACA;AACA,6BAA6B,MAAM;AACnC;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD;AACtD;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,GAAG;AACH;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2BAA2B;AAC9C,qBAAqB,+CAA+C;AACpE;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2BAA2B;AAC9C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2BAA2B;AAC9C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2BAA2B;AAC9C;AACA;AACA,qBAAqB,4BAA4B;AACjD;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;;;;;;;;;;;ACzjCA,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,8CAA8C,QAAQ;AACtD;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,2BAA2B,QAAQ;AACnC;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;;;;;AChaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,iCAAO,CAAC,0JAAoC,CAAC,mCAC7C;;AAEA;;AAEA;AACA;AACA;AACA,aAAa,MAAM;AACnB;AACA;AACA,aAAa,SAAS;AACtB;AACA;AACA,aAAa,OAAO;AACpB,aAAa,SAAS;AACtB;AACA,aAAa,QAAQ;AACrB,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;;AAEA,iBAAiB,kBAAkB;AACnC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA,I;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,2CAA2C,MAAM,EAAE;AACnD;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oEAAoE,YAAY,GAAG;;AAEnF;AACA;AACA;AACA,SAAS;AACT;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,kBAAkB;AACnC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa,6BAA6B;AAC1C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAc,6BAA6B;AAC3C,cAAc,4CAA4C;AAC1D,cAAc,4CAA4C;AAC1D,cAAc;AACd;;AAEA;AACA;AACA,mBAAmB,0BAA0B;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AAAA,oGAAC;;;;;;;;;;;;AClRF;;AAEA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;;AAEA;AACA;AACA,4CAA4C;;AAE5C;;;;;;;;;;;;;ACnBA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA,aAAa;AACb;AACA;AACA;;;;;;;;;;;;;ACZA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEyE;;AAE/E,8BAA8B,mGAAuB;AAC5D;AACA;AACA;AACA;;AAEA;AACA,8DAA8D,iBAAiB;AAC/E;AACA;;;;;;;;;;;;;ACtBA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEO;;;;;;;;;;;;;ACPP;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,aAAa,mBAAO,CAAC,6HAAoD;AAClE;;;;;;;;;;;;;ACTP;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEO;;;;;;;;;;;;;ACPP;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEoC;AACQ;AACjB;AAC6B;AACH;;AAElE;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,IAAI,sEAAM;AACV;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA,IAAI,sEAAM,0BAA0B,sGAAsG,GAAG,GAAG;AAChJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,sEAAM;AACZ;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,IAAI,sEAAM,kDAAkD,MAAM;AAClE;AACA;;AAEA;AACA,IAAI,sEAAM,qCAAqC,GAAG;AAClD;AACA;AACA;;;AAGO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,IAAI,sEAAM;;AAEV;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL,yDAAyD,mBAAmB;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,sEAAM,wCAAwC,YAAY;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,sEAAM;AACZ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,gCAAgC,oBAAoB;AACpD;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;;AAEA,gCAAgC;AAChC,uDAAuD,qBAAqB,sDAAI,qBAAqB;AACrG;AACA,OAAO,sCAAsC,uEAAY,+CAA+C;;AAExG,kCAAkC,iEAAiE;AACnG,yCAAyC,yCAAyC;AAClF,oCAAoC,qBAAqB;AACzD,sCAAsC,mFAAmF;AACzH,qCAAqC,6CAA6C;;AAElF,oCAAoC,mEAAmE;AACvG,6CAA6C,2CAA2C;AACxF,8CAA8C,2CAA2C;AACzF,uCAAuC,oEAAoE;AAC3G,0CAA0C,oEAAoE;AAC9G,uCAAuC,sFAAsF;AAC7H,yCAAyC,mEAAmE;AAC5G,yCAAyC,uFAAuF;AAChI,0CAA0C,uFAAuF;AACjI,kDAAkD,uFAAuF;AACzI,0CAA0C,wFAAwF;AAClI,8CAA8C,kEAAkE;AAChH,+CAA+C,2CAA2C;;AAE1F,kCAAkC,oEAAoE;;AAEtG,6CAA6C,qEAAqE,sDAAI,EAAE;AACxH,yDAAyD,4CAA4C,sDAAI,+DAA+D;;AAExK,+CAA+C,6CAA6C;AAC5F,+CAA+C,6CAA6C;;AAE5F,6CAA6C,mEAAmE,sDAAI,qBAAqB;AACzI,sDAAsD,4CAA4C,sDAAI,sCAAsC;AAC5I,0CAA0C,kEAAkE;AAC5G,mDAAmD,uCAAuC;AAC1F;AACA,OAAO,4MAA4M;AACnN,oDAAoD,iDAAiD;AACrG,yCAAyC,0HAA0H;;AAEnK,2CAA2C,kEAAkE;;AAE7G,kDAAkD,yEAAyE;;AAE3H,IAAI,gFAAkB;AACtB,qDAAqD,mFAAmB;AACxE;AACA;;AAEO;AACP;AACA;;AAEA,mCAAmC;AACnC,qDAAqD,qBAAqB,sDAAI,qBAAqB;AACnG;AACA,OAAO,sCAAsC,uEAAY,+CAA+C;;AAExG,qCAAqC,iEAAiE;AACtG,4CAA4C,8CAA8C;AAC1F,uCAAuC,qBAAqB;AAC5D,yCAAyC,mFAAmF;AAC5H,wCAAwC,6CAA6C;;AAErF,iCAAiC,mEAAmE;AACpG,0CAA0C,gDAAgD;AAC1F,2CAA2C,gDAAgD;AAC3F,oCAAoC,yEAAyE;AAC7G,uCAAuC,yEAAyE;AAChH,oCAAoC,sFAAsF;AAC1H,sCAAsC,mEAAmE;AACzG,sCAAsC,4FAA4F;AAClI,uCAAuC,4FAA4F;AACnI,+CAA+C,4FAA4F;AAC3I,uCAAuC,6FAA6F;AACpI,2CAA2C,uEAAuE;AAClH,4CAA4C,2CAA2C;;AAEvF,+BAA+B,oEAAoE;;AAEnG,0CAA0C,0EAA0E,sDAAI,EAAE;AAC1H,gEAAgE,iDAAiD,sDAAI,+DAA+D;;AAEpL,4CAA4C,kDAAkD;AAC9F,kDAAkD,6CAA6C;;AAE/F,0CAA0C,mEAAmE,sDAAI,qBAAqB;AACtI,6DAA6D,iDAAiD,sDAAI,sCAAsC;AACxJ,uCAAuC,kEAAkE;AACzG,0DAA0D,4CAA4C;AACtG;AACA,OAAO,4MAA4M;AACnN,2DAA2D,sDAAsD;AACjH,4CAA4C,0HAA0H;;AAEtK,wCAAwC,kEAAkE;;AAE1G,+CAA+C,yEAAyE;AACxH;AACA;;;;;;;;;;;;;AC9VA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEuC;;AAE7C;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA,IAAI,sEAAM;AACV,IAAI,sEAAM;AACV;AACA,mBAAmB,MAAM,GAAG,YAAY;AACxC;AACA;AACA;AACA;;AAEA;AACA,mDAAmD,UAAU,GAAG,gBAAgB;AAChF;AACA,6CAA6C,gBAAgB;AAC7D,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;ACtDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEoD;AACmB;AACA;AACC;;AAExE;AACA;AACA;AACA;;AAEA,kFAAc;AACd;AACA;AACA;AACA,CAAC;;AAEM;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,iFAAe;AAC/C;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA,IAAI,sEAAM;AACV,kBAAkB,qFAAmB;AACrC;AACA;AACA;AACA;AACA,IAAI,sEAAM;AACV;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC1DA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAE+D;;AAErE;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM,8FAAa;AACnB;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,EAAE;AAChC;;AAEA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,yCAAyC,eAAe;AACxD;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,IAAI,WAAW;AACtB;;AAEA;AACA;AACA,oBAAoB,2DAA2D;AAC/E,KAAK;AACL;;AAEA,iCAAiC,kBAAkB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA,kBAAkB,eAAe;AACjC;AACA;AACA;AACA,gDAAgD;AAChD;AACA;;AAEA,qBAAqB,iBAAiB;AACtC;AACA,OAAO,+BAA+B;AACtC;;AAEA,sBAAsB,iBAAiB;AACvC;AACA,OAAO,gCAAgC;AACvC;;AAEA,eAAe,6BAA6B;AAC5C;AACA,OAAO,qCAAqC;AAC5C;;AAEA,kBAAkB,6BAA6B;AAC/C;AACA,OAAO,wCAAwC;AAC/C;;AAEA,eAAe,kCAAkC;AACjD,yBAAyB,2CAA2C;AACpE;;AAEA,iBAAiB,yBAAyB;AAC1C,yBAAyB,6CAA6C;AACtE;;AAEA,iBAAiB,4BAA4B;AAC7C,yBAAyB,uCAAuC;AAChE;;AAEA,kBAAkB,yBAAyB;AAC3C,yBAAyB,8CAA8C;AACvE;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,gCAAgC,qCAAqC;AACrE;;AAEA,uBAAuB,8BAA8B;AACrD;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,0CAA0C;AAClF;AACA,6BAA6B,eAAe,GAAG,0CAA0C;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC7MA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,0CAA0C;;AAE1C;AACA;AACA;AACA;;;;;;;;;;;;;AC5BA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEoC;AACV;;AAEvC;AACA;AACA;AACO,8BAA8B,qDAAQ;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,uBAAuB,cAAc;AACrC;AACA,qBAAqB,KAAK;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,sEAAM;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC7LA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEsD;AACZ;;AAEvD;AACA;AACA;AACA;AACO,0BAA0B,wFAAa,CAAC,qEAAe;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,kBAAkB;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,eAAe;AAC5C;AACA;AACA;AACA,6BAA6B,eAAe;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,uBAAuB,cAAc;AACrC;AACA;AACA,qBAAqB,KAAK;AAC1B;AACA;AACA;AACA,gCAAgC,IAAI;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACzKA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,YAAY,MAAM;AAClB;;AAEA;AAC8B;;;;;;;;;;;;;ACb9B;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEoC;AACQ;AACkB;;AAEpE,qCAAqC,yFAAyB;AACrE;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,wCAAwC,QAAQ,MAAM;AACxE;AACA;AACA;AACA,iCAAiC,2BAA2B,MAAM,QAAQ;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA,OAAO,KAAK;AACZ,OAAO,gEAAgE;AACvE;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,uEAAY;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,WAAW,iCAAiC;AAC5C,WAAW;AACX;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,kBAAkB,MAAM;AACzD;AACA;AACA,KAAK;AACL;AACA;AACA,oBAAoB,cAAc,OAAO;AACzC;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI,sEAAM,6DAA6D,SAAS,sBAAsB,aAAa;AACnH,oBAAoB,0DAA0D,GAAG,YAAY,qBAAqB,EAAE,EAAE;;AAEtH;AACA;AACA,yBAAyB,OAAO;AAChC,qFAAqF,OAAO;;AAE5F;AACA;AACA;AACA;AACA,0BAA0B,EAAE,WAAW,cAAc;AACrD,eAAe,EAAE,KAAK,cAAc;AACpC,OAAO;AACP,sBAAsB,kDAAkD,GAAG,iCAAiC,EAAE;;AAE9G;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AChNA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEkC;AACE;AACH;AACyB;;AAEhE;AACP;AACA,wBAAwB,4DAAY;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,uEAAqB;AAC/C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,uBAAuB;AAC5D,iBAAiB,8DAAY;AAC7B;;AAEA,gDAAgD,qCAAqC;AACrF,wBAAwB,8DAAY;AACpC;AACA;AACA;;;AAGA,6CAA6C,yBAAyB;AACtE,wBAAwB,8DAAY;AACpC;AACA;;AAEA,0CAA0C,aAAa;AACvD;AACA;;AAEA,2CAA2C,uBAAuB;AAClE;AACA;;AAEA,uCAAuC,sEAAsE;AAC7G;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,QAAQ,kBAAkB;;AAE1B,uCAAuC,eAAe;;AAEtD,6CAA6C,cAAc;;AAE3D,kCAAkC,QAAQ;AAC1C;AACA;AACA;AACA,0BAA0B,qBAAqB,mCAAmC,EAAE,EAAE;AACtF,OAAO;;AAEP,gCAAgC,0BAA0B;;AAE1D,oCAAoC,iCAAiC;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,uBAAuB;AAC/C,wBAAwB,uBAAuB;AAC/C,0BAA0B,yBAAyB;AACnD;AACA;AACA;AACA;AACA,qCAAqC,4BAA4B;;AAEjE,+CAA+C,yCAAyC,EAAE;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,mCAAmC,mBAAmB;AACtD,MAAM,sEAAM;AACZ,2CAA2C,cAAc,QAAQ,SAAS;AAC1E;AACA;AACA;;AAEA;AACA,YAAY;AACZ;;AAEA;AACA,cAAc,aAAa,GAAG,oBAAoB;AAClD;;AAEA;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACxC,2BAA2B,qEAAS;AACpC;AACA;AACA;AACA;AACA,YAAY;AACZ,OAAO;AACP;AACA;AACA,qCAAqC;AACrC;AACA,YAAY;AACZ,OAAO;AACP;AACA,kGAAkG;AAClG;AACA;AACA,sCAAsC;AACtC;AACA,YAAY;AACZ,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA,0C;AACA;AACA,uCAAuC;AACvC;AACA;AACA,UAAU;AACV,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,2CAA2C,oBAAoB,kDAAkD,WAAW;AAC5H;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,qBAAqB,qEAAS;AAC9B;;AAEA;AACA;AACA,yBAAyB,wBAAwB;AACjD,KAAK;;AAEL;AACA;AACA,6BAA6B,wBAAwB;AACrD;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;ACvRA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEgC;AACI;;AAEjD;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,oCAAoC;AAC3F;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACvKA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEoC;AAC+B;;AAEhF,mBAAmB;;AAEnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,qCAAqC,YAAY,yEAAyE,yBAAyB;AACnJ;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,iBAAiB;;AAE3C;AACA;AACA,kCAAkC,+CAA+C;AACjF;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,qCAAqC,oDAAoD;AACzF;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,kBAAkB,eAAe;AACjC;AACA,oCAAoC,SAAS,iCAAiC,SAAS;AACvF,iCAAiC,cAAc;AAC/C;AACA;;AAEA;AACA;AACA;AACA;;AAEA,oEAAoE;AACpE;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,+BAA+B,OAAO;AACtC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,oCAAoC,SAAS,kCAAkC,gBAAgB;AAC/F,iCAAiC,cAAc;AAC/C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,gBAAgB,iBAAiB;AACjC;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,qCAAqC,oDAAoD;AACzF,oBAAoB,iBAAiB;AACrC;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA,cAAc,mBAAmB,GAAG,yBAAyB;AAC7D;;AAEA;AACA,YAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,8FAAmB;AACzC;;AAEA;AACA;AACA;;AAEA;AACA;AACA,sBAAsB,8FAAmB;AACzC;AACA;;AAEA;AACA;AACA;AACA;AACA,kBAAkB,OAAO;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,uBAAuB;AACzC;AACA;AACA;AACA;AACA,KAAK;AACL,kBAAkB,uBAAuB;AACzC;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,qEAAqE,uBAAuB;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,iCAAiC,4CAA4C;AAC7E;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA,iCAAiC,qFAAqF;AACtH;AACA;;AAEA;AACA;AACA,kBAAkB;AAClB,4BAA4B,gCAAgC,mBAAmB;;AAE/E;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;;AAEA;AACA;AACA,uCAAuC,gCAAgC,uBAAuB;AAC9F;;AAEA,mDAAmD,gDAAgD;AACnG,qCAAqC,gCAAgC,0BAA0B;;AAE/F,wBAAwB,SAAS,OAAO,oDAAoD;AAC5F;AACA;AACA,8BAA8B,wCAAwC;AACtE;AACA;;AAEA;AACA;AACA,oBAAoB;AACpB,+BAA+B,gCAAgC,mBAAmB;AAClF;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB,6BAA6B,gCAAgC,mBAAmB;;AAEhF;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,sEAAM;AACV;AACA;;AAEA;AACA,IAAI,sEAAM;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,8BAA8B,4CAA4C;AAC1E;AACA;;AAEA;AACA,IAAI,sEAAM;AACV;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,0BAA0B,gDAAgD;AAC1E,oBAAoB;AACpB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,kCAAkC;AAC9D,oBAAoB;AACpB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,qEAAqE;AACrE;AACA;;AAEA;;AAEA;AACA;AACA,8BAA8B,wCAAwC,YAAY,aAAa;AAC/F;;AAEA;AACA;AACA,+BAA+B,wCAAwC,aAAa,aAAa;AACjG;;AAEA;AACA;AACA,+BAA+B,mDAAmD;AAClF;;AAEA;AACA;AACA,mCAAmC,0CAA0C;AAC7E;;AAEA;AACA,kCAAkC,uBAAuB;AACzD;AACA;;AAEO;AACP;AACA;AACA,oBAAoB;AACpB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;;;;;;ACplBA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEiC;;AAE9C;AACA;;AAEA;AACA;AACA;AACO,wCAAwC,4DAAW;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,2CAA2C,YAAY,qBAAqB,YAAY,UAAU;AAClG;AACA;;;;;;;;;;;;;AChDA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,oBAAoB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,aAAa;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,UAAU;AACzD;AACA,uBAAuB,UAAU;AACjC;AACA,6BAA6B,sBAAsB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,KAAK,GAAG,cAAc;AAClD;AACA;AACA;AACA;AACA;AACA;AACA,4C;;;;;;;;;;;;ACzGA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACsD;AACf;AAChC;AACP;AACA,QAAQ,sEAAM;AACd,aAAa,mDAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,mDAAO;AAC3B;AACA;AACA;AACA,QAAQ,sEAAM;AACd,oBAAoB,mDAAO;AAC3B;AACA;AACA,QAAQ,sEAAM;AACd,aAAa,mDAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA,oBAAoB,gBAAgB,OAAO,qBAAqB;AAChE;AACA;AACA,oBAAoB,gBAAgB,GAAG,uBAAuB;AAC9D;AACA,aAAa,mDAAO;AACpB;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;ACpDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAC2C;AACJ;AACe;AACJ;AAClD;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,sEAAM;AACV,WAAW,cAAc;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA,yEAAyE,QAAQ;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA,0BAA0B,mDAAO;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,SAAS;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,cAAc;AAClE;AACA;AACA;AACA;AACA,yDAAyD,oCAAoC;AAC7F;AACA;AACA,oDAAoD,cAAc;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,cAAc;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,8DAAY;AAC/B;AACA;AACA,uBAAuB,uDAAS;AAChC;AACA,QAAQ,sEAAM,yDAAyD,UAAU;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4BAA4B,4CAA4C;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,WAAW;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,kBAAkB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,2BAA2B;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;AC3YA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAC8C;AACA;AACN;AACc;AACZ;AACO;AACuB;AACpB;AAC0B;AACV;AACpE;AACA;AACA,0BAA0B,KAAK;AAC/B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,OAAO,EAAE,KAAK;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,YAAY;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sDAAE;AACd;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA,uBAAuB,2DAAK,2EAA2E,gFAAgB,gBAAgB,wBAAwB;AAC/J;AACA,mBAAmB,2DAAK,uDAAuD,gFAAgB;AAC/F;AACA,eAAe,2DAAK;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,sDAAE,cAAc,0CAA0C;AACrF;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,YAAY,0DAAK;AACjB;AACA,0FAA0F,EAAE;AAC5F;AACA,sCAAsC,0CAA0C;AAChF,QAAQ,sEAAM,iHAAiH,SAAS;AACxI;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd,gCAAgC,CAAC,+DAAQ,EAAE,yEAAW,EAAE,oHAAyB,EAAE,2GAAsB,aAAa,wEAAkB,kBAAkB;AAC1J;AACA;AACA,kC;;;;;;;;;;;;AChHA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACiC;AACsB;AACpB;AACmB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,mEAAW,eAAe,OAAO,GAAG,6CAA6C;AAChG;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,+CAA+C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,+CAA+C;AAC/C;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,sEAAM;AAC9C,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,8DAA8D;AAC7E,sCAAsC,0DAA0D,OAAO,2HAA2H;AAClO;AACA,gBAAgB;AAChB;AACA;AACA,aAAa,8DAA8D;AAC3E,wCAAwC,0DAA0D,OAAO,OAAO,6CAAI,oJAAoJ;AACxQ;AACA,iCAAiC,2EAA2E;AAC5G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sEAAM,yGAAyG,EAAE;AAC7H,SAAS;AACT;AACA;AACA,eAAe,6CAAI;AACnB;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA,mBAAmB,+CAAK;AACxB;AACA;AACA;AACA;AACA;AACA,qDAAqD,KAAK;AAC1D;AACA,iCAAiC,UAAU,EAAE,MAAM,OAAO,cAAc;AACxE;AACA;AACA,4BAA4B,OAAO,EAAE,qBAAqB,GAAG,2BAA2B,EAAE,iCAAiC,GAAG,gBAAgB;AAC9I;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4FAA4F,EAAE;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,EAAE;AACnD;AACA,8BAA8B,kBAAkB;AAChD;AACA,+CAA+C,aAAa;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,EAAE;AACxD;AACA,oCAAoC,kBAAkB;AACtD;AACA,qDAAqD,cAAc;AACnE;AACA,0EAA0E,OAAO;AACjF,aAAa;AACb,SAAS;AACT;AACA;AACA,4CAA4C,aAAa;AACzD;AACA;AACA,wCAAwC,QAAQ,KAAK,WAAW;AAChE;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;AC9OA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACkC;AACiB;AAC5C;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,8DAAY;AACpD;AACA;AACA;AACA,4BAA4B,6CAAI;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,6CAAI;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,6CAAI;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,kBAAkB;AAC/D,6DAA6D,6CAAI;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,6CAAI,iBAAiB,8DAAY;AAChE;AACA,2DAA2D,6CAAI,oEAAoE,6CAAI,4BAA4B,6CAAI;AACvK,+BAA+B,6CAAI;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,sCAAsC,6CAAI;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,6CAAI;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;;;;;;ACpQA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACsD;AACrB;AACO;AACjC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA,0BAA0B,4DAAS;AACnC;AACA,gBAAgB,sEAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AAChC;AACP;AACA;AACA;AACA,mBAAmB,kCAAkC,EAAE,6CAAI;AAC3D;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;AChFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACsD;AACrB;AACsB;AAClB;AACM;AACpC;AACP;AACA;AACA;AACA;AACA;AACA,YAAY,sEAAM;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,sBAAsB,sCAAsC,kBAAkB;AACjH;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oCAAoC,qDAAqD;AACjH;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oCAAoC,2BAA2B,6CAAI,4BAA4B;AACvH;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,4BAA4B;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sEAAM;AAClB;AACA;AACA;AACA;AACA,2BAA2B,wBAAwB;AACnD;AACA,2BAA2B,sBAAsB;AACjD;AACA,oCAAoC,gCAAgC;AACpE;AACA;AACA;AACA;AACA,2BAA2B,gCAAgC;AAC3D;AACA,qDAAqD,UAAU,aAAa,UAAU;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,6CAAI;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,UAAU,aAAa,UAAU;AAC3F;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,GAAG,SAAS,MAAM,iBAAiB,UAAU;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,GAAG,aAAa,KAAK,SAAS,UAAU,EAAE;AACnG,kCAAkC,MAAM,YAAY,eAAe;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,GAAG,aAAa,KAAK,WAAW,gBAAgB,GAAG;AAC5G,kCAAkC,MAAM,YAAY,eAAe;AACnE;AACA;AACA;AACA,sDAAsD,GAAG,SAAS,KAAK,yBAAyB,MAAM;AACtG;AACA;AACA,+DAA+D,GAAG,aAAa,KAAK;AACpF,gCAAgC,gBAAgB,gBAAgB,MAAM;AACtE;AACA;AACA;AACA;AACA,iEAAiE,GAAG,aAAa,KAAK,WAAW,gBAAgB,GAAG;AACpH,0CAA0C,MAAM,aAAa,kBAAkB,YAAY,EAAE;AAC7F;AACA,qBAAqB;AACrB;AACA;AACA,2CAA2C,uDAAS;AACpD,sDAAsD,GAAG,aAAa,KAAK,uBAAuB,MAAM;AACxG;AACA,yBAAyB,mEAAW,eAAe,mBAAmB,GAAG,OAAO,6CAAI,uCAAuC;AAC3H,sDAAsD,GAAG,aAAa,KAAK,eAAe,MAAM;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,GAAG,cAAc,KAAK,iBAAiB,MAAM;AACnG;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,eAAe,aAAa,UAAU;AAC1F;AACA;AACA,oCAAoC,iDAAM;AAC1C;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,gBAAgB,sEAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,uDAAS;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,uDAAS,QAAQ,6CAAI;AACxD;AACA;AACA,oEAAoE,KAAK,uBAAuB,MAAM;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,KAAK,wBAAwB,MAAM;AACxG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,6CAAI;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,mBAAmB;AACjE,8CAA8C,mBAAmB;AACjE;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,4EAA4E,yBAAyB,GAAG,KAAK;AAC7G,kBAAkB,MAAM,EAAE,EAAE,qEAAqE;AACjG;AACA;AACA;AACA,+BAA+B,qBAAqB;AACpD,+EAA+E,yBAAyB,GAAG,KAAK;AAChH;AACA,4CAA4C,yBAAyB;AACrE;AACA;AACA,wCAAwC,KAAK,KAAK,uBAAuB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;AC3ZA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACsD;AACtD,gBAAgB;AAChB,SAAS;AACT;AACA;AACA,eAAe,6CAAI;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,sEAAM;AACd,QAAQ,sEAAM;AACd,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,wBAAwB;AAChE;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,sBAAsB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,gBAAgB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,0BAA0B;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,+CAA+C,EAAE,gBAAgB,GAAG,gCAAgC;AAC5H,SAAS;AACT;AACA;AACA;AACA;AACA,8BAA8B,eAAe,GAAG,4BAA4B,EAAE,iCAAiC;AAC/G;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB,EAAE;AACF,EAAE;AACF;AACA;AACA;AACA,qDAAqD,8GAA8G;AACnK,+CAA+C,qJAAqJ;AACpM;AACA;AACA;AACA,qDAAqD,wGAAwG;AAC7J,+CAA+C,6IAA6I;AAC5L,gBAAgB;AAChB;AACA;AACA,2CAA2C,wBAAwB,OAAO,oEAAoE;AAC9I,uCAAuC,qCAAqC,OAAO,qCAAqC;AACxH;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,wBAAwB,OAAO,oFAAoF;AAC9J,uCAAuC,qCAAqC,OAAO,qCAAqC;AACxH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,0GAA0G;AAClL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,mEAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,gHAAgH;AAC7I;AACA,uCAAuC,qCAAqC,OAAO,qCAAqC;AACxH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,6CAAI;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,6CAAI;AAClC;AACA,qBAAqB,4DAA4D;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sGAAsG,oEAAoE;AAC1K;AACA;AACA;AACA,gCAAgC,gHAAgH;AAChJ;AACA,oCAAoC,8FAA8F;AAClI,aAAa;AACb,SAAS;AACT;AACA,2EAA2E,4BAA4B;AACvG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,mEAAW;AAChC;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACiC;AACsB;AACvD,iC;;;;;;;;;;;;ACvWA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACyD;AAClD;AACP;AACA,kBAAkB;AAClB;AACA;AACA,sBAAsB,kBAAkB;AACxC;AACA;AACA;AACA,oCAAoC,6BAA6B;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sEAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,oBAAoB;AAC7B;AACA;AACA,yBAAyB,cAAc;AACvC,yBAAyB,6BAA6B;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iD;;;;;;;;;;;;ACtHA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,iBAAiB;AACxB,mC;;;;;;;;;;;;ACTA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACiC;AAC1B;AACP;AACA;AACA;AACA;AACA,gDAAgD,6CAAI;AACpD;AACA;AACA;AACA;AACA;AACA,iEAAiE;AACjE;AACA;AACA;AACA;AACA;AACA,uBAAuB,2BAA2B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;;;;;;ACnCA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACiC;AACqB;AACjB;AAC9B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,iDAAM;AACnC;AACA;AACA;AACA,6BAA6B,6CAAI;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,iDAAM;AACnC;AACA;AACA;AACA,gCAAgC,6CAAI;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,KAAK,OAAO,KAAK;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA,YAAY,sEAAM;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sEAAM;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA,YAAY,sEAAM;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,6CAAI,iEAAiE,6CAAI;AAC5I;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;ACtLA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACsD;AACtD;AACA;AACA;AACA,6CAA6C,UAAU,EAAE,SAAS;AAClE;AACA,2BAA2B,KAAK;AAChC,gBAAgB,sEAAM,WAAW,KAAK,MAAM,EAAE,SAAS,IAAI,WAAW,kBAAkB,KAAK;AAC7F;AACA;AACA;AACA,KAAK;AACL,+CAA+C,KAAK;AACpD;AACA;AACA;AACA,KAAK;AACL;AACO;AACP;AACA,QAAQ,sEAAM;AACd,QAAQ,sEAAM;AACd;AACA,YAAY,sEAAM,iBAAiB,iDAAM;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,8DAAY;AAC9C;AACA;AACA,2BAA2B,8DAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sEAAM;AACd,QAAQ,sEAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,mEAAW,eAAe,aAAa,GAAG,OAAO;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,KAAK;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,KAAK;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,KAAK;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iDAAM;AAC7B;AACA,4FAA4F,wBAAwB;AACpH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iDAAM;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,8DAAY;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,8DAAY;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,+CAAK;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D,+CAAK,yBAAyB,iDAAM;AAClG,iCAAiC,8DAAY;AAC7C,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,+CAAK;AAC5B;AACA,uBAAuB,iDAAM;AAC7B;AACA;AACA;AACA;AACA,uBAAuB,4DAAW;AAClC;AACA,uBAAuB,8DAAY;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,sCAAsC;AAC7D;AACA;AACA,oCAAoC,yCAAyC;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,mBAAmB;AAC1C;AACA;AACA;AACA;AACA;AACA,mCAAmC,IAAI,GAAG,eAAe;AACzD;AACA;AACA;AACA;AACA,kCAAkC,EAAE,mBAAmB;AACvD;AACA,0BAA0B,aAAa;AACvC;AACA;AACA;AACA;AACA,4DAA4D,qBAAqB;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,qCAAqC;AAC3D;AACA;AACA,oCAAoC,wCAAwC;AAC5E;AACA;AACA,4FAA4F,mBAAmB;AAC/G;AACA;AACA;AACA;AACA;AACA,mCAAmC,IAAI,GAAG,eAAe;AACzD;AACA;AACA;AACA;AACA,kCAAkC,EAAE,mBAAmB;AACvD;AACA,0BAA0B,aAAa;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACmC;AACE;AACa;AACF;AACO;AACvD,gC;;;;;;;;;;;;ACphBA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,IAAI;AAC3B;AACA;AACA;;AAEsC;;;;;;;;;;;;;AC7JtC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEwD;AACL;AACO;AACuB;AACM;;AAEvF,mFAAmF,SAAS,6BAA6B,OAAO,cAAc,0BAA0B,oBAAoB;AAC5L;;AAEA;;AAEO,4BAA4B,kEAAM;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,IAAI;AAC9B,0BAA0B,SAAS;AACnC,0BAA0B,SAAS;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,KAAK,MAAM,IAAI;AAC5D;AACA;AACA;AACA;AACA,sCAAsC,KAAK;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,uEAAQ;AACd,MAAM,iFAAW;AACjB,MAAM,mHAAsB;AAC5B,sBAAsB,oEAAW;AACjC,MAAM,4HAAyB;AAC/B;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;;;;;;;;;;;;ACjGA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEqF;AACnC;;AAElD,6EAA6E,cAAc,0BAA0B,oBAAoB;;AAEzI;AACA;AACA,SAAS,SAAS;AAClB;AACA,MAAM,+FAAwB,qBAAqB,gEAAa;AAChE;;;;;;;;;;;;;AClBA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,oBAAoB;AACtC;AACA;AACA,KAAK;AACL;;AAEA,gBAAgB;AACT;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC,OAAO;AACP,gCAAgC;AAChC;AACA;AACA,yCAAyC;AACzC;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,kBAAkB;AACrD,SAAS;AACT,sBAAsB,gBAAgB;AACtC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,oBAAoB,kBAAkB;AACtC;AACA,OAAO;AACP;AACA,uCAAuC;AACvC;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS,OAAO;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,oBAAoB;AACjD;AACA;AACA;AACA;AACA;AACA;;AAEA","file":"shell/build/worker-entry.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = \"./shell/source/worker-entry.js\");\n","/**\n * @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n\n// Debugging is initialized either by /devtools/src/run-mark-connected.js, which is\n// injected by the devtools extension content script in the browser env,\n// or used directly when debugging nodeJS.\n\n// Data needs to be referenced via a global object, otherwise extension and\n// Arcs have different instances.\nconst root = typeof window === 'object' ? window : global;\n\nif (!root._arcDebugPromise) {\n  root._arcDebugPromise = new Promise(resolve => {\n    root._arcDebugPromiseResolve = resolve;\n  });\n}\n\nexport class DevtoolsBroker {\n  static get onceConnected() {\n    return root._arcDebugPromise;\n  }\n  static markConnected() {\n    root._arcDebugPromiseResolve();\n    return {preExistingArcs: !!root.arc};\n  }\n}\n","// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\nvar has = Object.prototype.hasOwnProperty;\n\n/**\n * A data structure which is a combination of an array and a set. Adding a new\n * member is O(1), testing for membership is O(1), and finding the index of an\n * element is O(1). Removing elements from the set is not supported. Only\n * strings are supported for membership.\n */\nfunction ArraySet() {\n  this._array = [];\n  this._set = Object.create(null);\n}\n\n/**\n * Static method for creating ArraySet instances from an existing array.\n */\nArraySet.fromArray = function ArraySet_fromArray(aArray, aAllowDuplicates) {\n  var set = new ArraySet();\n  for (var i = 0, len = aArray.length; i < len; i++) {\n    set.add(aArray[i], aAllowDuplicates);\n  }\n  return set;\n};\n\n/**\n * Return how many unique items are in this ArraySet. If duplicates have been\n * added, than those do not count towards the size.\n *\n * @returns Number\n */\nArraySet.prototype.size = function ArraySet_size() {\n  return Object.getOwnPropertyNames(this._set).length;\n};\n\n/**\n * Add the given string to this set.\n *\n * @param String aStr\n */\nArraySet.prototype.add = function ArraySet_add(aStr, aAllowDuplicates) {\n  var sStr = util.toSetString(aStr);\n  var isDuplicate = has.call(this._set, sStr);\n  var idx = this._array.length;\n  if (!isDuplicate || aAllowDuplicates) {\n    this._array.push(aStr);\n  }\n  if (!isDuplicate) {\n    this._set[sStr] = idx;\n  }\n};\n\n/**\n * Is the given string a member of this set?\n *\n * @param String aStr\n */\nArraySet.prototype.has = function ArraySet_has(aStr) {\n  var sStr = util.toSetString(aStr);\n  return has.call(this._set, sStr);\n};\n\n/**\n * What is the index of the given string in the array?\n *\n * @param String aStr\n */\nArraySet.prototype.indexOf = function ArraySet_indexOf(aStr) {\n  var sStr = util.toSetString(aStr);\n  if (has.call(this._set, sStr)) {\n    return this._set[sStr];\n  }\n  throw new Error('\"' + aStr + '\" is not in the set.');\n};\n\n/**\n * What is the element at the given index?\n *\n * @param Number aIdx\n */\nArraySet.prototype.at = function ArraySet_at(aIdx) {\n  if (aIdx >= 0 && aIdx < this._array.length) {\n    return this._array[aIdx];\n  }\n  throw new Error('No element indexed by ' + aIdx);\n};\n\n/**\n * Returns the array representation of this set (which has the proper indices\n * indicated by indexOf). Note that this is a copy of the internal array used\n * for storing the members so that no one can mess with internal state.\n */\nArraySet.prototype.toArray = function ArraySet_toArray() {\n  return this._array.slice();\n};\n\nexports.ArraySet = ArraySet;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n *\n * Based on the Base 64 VLQ implementation in Closure Compiler:\n * https://code.google.com/p/closure-compiler/source/browse/trunk/src/com/google/debugging/sourcemap/Base64VLQ.java\n *\n * Copyright 2011 The Closure Compiler Authors. All rights reserved.\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are\n * met:\n *\n *  * Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n *  * Redistributions in binary form must reproduce the above\n *    copyright notice, this list of conditions and the following\n *    disclaimer in the documentation and/or other materials provided\n *    with the distribution.\n *  * Neither the name of Google Inc. nor the names of its\n *    contributors may be used to endorse or promote products derived\n *    from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\nvar base64 = require('./base64');\n\n// A single base 64 digit can contain 6 bits of data. For the base 64 variable\n// length quantities we use in the source map spec, the first bit is the sign,\n// the next four bits are the actual value, and the 6th bit is the\n// continuation bit. The continuation bit tells us whether there are more\n// digits in this value following this digit.\n//\n//   Continuation\n//   |    Sign\n//   |    |\n//   V    V\n//   101011\n\nvar VLQ_BASE_SHIFT = 5;\n\n// binary: 100000\nvar VLQ_BASE = 1 << VLQ_BASE_SHIFT;\n\n// binary: 011111\nvar VLQ_BASE_MASK = VLQ_BASE - 1;\n\n// binary: 100000\nvar VLQ_CONTINUATION_BIT = VLQ_BASE;\n\n/**\n * Converts from a two-complement value to a value where the sign bit is\n * placed in the least significant bit.  For example, as decimals:\n *   1 becomes 2 (10 binary), -1 becomes 3 (11 binary)\n *   2 becomes 4 (100 binary), -2 becomes 5 (101 binary)\n */\nfunction toVLQSigned(aValue) {\n  return aValue < 0\n    ? ((-aValue) << 1) + 1\n    : (aValue << 1) + 0;\n}\n\n/**\n * Converts to a two-complement value from a value where the sign bit is\n * placed in the least significant bit.  For example, as decimals:\n *   2 (10 binary) becomes 1, 3 (11 binary) becomes -1\n *   4 (100 binary) becomes 2, 5 (101 binary) becomes -2\n */\nfunction fromVLQSigned(aValue) {\n  var isNegative = (aValue & 1) === 1;\n  var shifted = aValue >> 1;\n  return isNegative\n    ? -shifted\n    : shifted;\n}\n\n/**\n * Returns the base 64 VLQ encoded value.\n */\nexports.encode = function base64VLQ_encode(aValue) {\n  var encoded = \"\";\n  var digit;\n\n  var vlq = toVLQSigned(aValue);\n\n  do {\n    digit = vlq & VLQ_BASE_MASK;\n    vlq >>>= VLQ_BASE_SHIFT;\n    if (vlq > 0) {\n      // There are still more digits in this value, so we must make sure the\n      // continuation bit is marked.\n      digit |= VLQ_CONTINUATION_BIT;\n    }\n    encoded += base64.encode(digit);\n  } while (vlq > 0);\n\n  return encoded;\n};\n\n/**\n * Decodes the next base 64 VLQ value from the given string and returns the\n * value and the rest of the string via the out parameter.\n */\nexports.decode = function base64VLQ_decode(aStr, aIndex, aOutParam) {\n  var strLen = aStr.length;\n  var result = 0;\n  var shift = 0;\n  var continuation, digit;\n\n  do {\n    if (aIndex >= strLen) {\n      throw new Error(\"Expected more digits in base 64 VLQ value.\");\n    }\n\n    digit = base64.decode(aStr.charCodeAt(aIndex++));\n    if (digit === -1) {\n      throw new Error(\"Invalid base64 digit: \" + aStr.charAt(aIndex - 1));\n    }\n\n    continuation = !!(digit & VLQ_CONTINUATION_BIT);\n    digit &= VLQ_BASE_MASK;\n    result = result + (digit << shift);\n    shift += VLQ_BASE_SHIFT;\n  } while (continuation);\n\n  aOutParam.value = fromVLQSigned(result);\n  aOutParam.rest = aIndex;\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar intToCharMap = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'.split('');\n\n/**\n * Encode an integer in the range of 0 to 63 to a single base 64 digit.\n */\nexports.encode = function (number) {\n  if (0 <= number && number < intToCharMap.length) {\n    return intToCharMap[number];\n  }\n  throw new TypeError(\"Must be between 0 and 63: \" + number);\n};\n\n/**\n * Decode a single base 64 character code digit to an integer. Returns -1 on\n * failure.\n */\nexports.decode = function (charCode) {\n  var bigA = 65;     // 'A'\n  var bigZ = 90;     // 'Z'\n\n  var littleA = 97;  // 'a'\n  var littleZ = 122; // 'z'\n\n  var zero = 48;     // '0'\n  var nine = 57;     // '9'\n\n  var plus = 43;     // '+'\n  var slash = 47;    // '/'\n\n  var littleOffset = 26;\n  var numberOffset = 52;\n\n  // 0 - 25: ABCDEFGHIJKLMNOPQRSTUVWXYZ\n  if (bigA <= charCode && charCode <= bigZ) {\n    return (charCode - bigA);\n  }\n\n  // 26 - 51: abcdefghijklmnopqrstuvwxyz\n  if (littleA <= charCode && charCode <= littleZ) {\n    return (charCode - littleA + littleOffset);\n  }\n\n  // 52 - 61: 0123456789\n  if (zero <= charCode && charCode <= nine) {\n    return (charCode - zero + numberOffset);\n  }\n\n  // 62: +\n  if (charCode == plus) {\n    return 62;\n  }\n\n  // 63: /\n  if (charCode == slash) {\n    return 63;\n  }\n\n  // Invalid base64 digit.\n  return -1;\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nexports.GREATEST_LOWER_BOUND = 1;\nexports.LEAST_UPPER_BOUND = 2;\n\n/**\n * Recursive implementation of binary search.\n *\n * @param aLow Indices here and lower do not contain the needle.\n * @param aHigh Indices here and higher do not contain the needle.\n * @param aNeedle The element being searched for.\n * @param aHaystack The non-empty array being searched.\n * @param aCompare Function which takes two elements and returns -1, 0, or 1.\n * @param aBias Either 'binarySearch.GREATEST_LOWER_BOUND' or\n *     'binarySearch.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n */\nfunction recursiveSearch(aLow, aHigh, aNeedle, aHaystack, aCompare, aBias) {\n  // This function terminates when one of the following is true:\n  //\n  //   1. We find the exact element we are looking for.\n  //\n  //   2. We did not find the exact element, but we can return the index of\n  //      the next-closest element.\n  //\n  //   3. We did not find the exact element, and there is no next-closest\n  //      element than the one we are searching for, so we return -1.\n  var mid = Math.floor((aHigh - aLow) / 2) + aLow;\n  var cmp = aCompare(aNeedle, aHaystack[mid], true);\n  if (cmp === 0) {\n    // Found the element we are looking for.\n    return mid;\n  }\n  else if (cmp > 0) {\n    // Our needle is greater than aHaystack[mid].\n    if (aHigh - mid > 1) {\n      // The element is in the upper half.\n      return recursiveSearch(mid, aHigh, aNeedle, aHaystack, aCompare, aBias);\n    }\n\n    // The exact needle element was not found in this haystack. Determine if\n    // we are in termination case (3) or (2) and return the appropriate thing.\n    if (aBias == exports.LEAST_UPPER_BOUND) {\n      return aHigh < aHaystack.length ? aHigh : -1;\n    } else {\n      return mid;\n    }\n  }\n  else {\n    // Our needle is less than aHaystack[mid].\n    if (mid - aLow > 1) {\n      // The element is in the lower half.\n      return recursiveSearch(aLow, mid, aNeedle, aHaystack, aCompare, aBias);\n    }\n\n    // we are in termination case (3) or (2) and return the appropriate thing.\n    if (aBias == exports.LEAST_UPPER_BOUND) {\n      return mid;\n    } else {\n      return aLow < 0 ? -1 : aLow;\n    }\n  }\n}\n\n/**\n * This is an implementation of binary search which will always try and return\n * the index of the closest element if there is no exact hit. This is because\n * mappings between original and generated line/col pairs are single points,\n * and there is an implicit region between each of them, so a miss just means\n * that you aren't on the very start of a region.\n *\n * @param aNeedle The element you are looking for.\n * @param aHaystack The array that is being searched.\n * @param aCompare A function which takes the needle and an element in the\n *     array and returns -1, 0, or 1 depending on whether the needle is less\n *     than, equal to, or greater than the element, respectively.\n * @param aBias Either 'binarySearch.GREATEST_LOWER_BOUND' or\n *     'binarySearch.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'binarySearch.GREATEST_LOWER_BOUND'.\n */\nexports.search = function search(aNeedle, aHaystack, aCompare, aBias) {\n  if (aHaystack.length === 0) {\n    return -1;\n  }\n\n  var index = recursiveSearch(-1, aHaystack.length, aNeedle, aHaystack,\n                              aCompare, aBias || exports.GREATEST_LOWER_BOUND);\n  if (index < 0) {\n    return -1;\n  }\n\n  // We have found either the exact element, or the next-closest element than\n  // the one we are searching for. However, there may be more than one such\n  // element. Make sure we always return the smallest of these.\n  while (index - 1 >= 0) {\n    if (aCompare(aHaystack[index], aHaystack[index - 1], true) !== 0) {\n      break;\n    }\n    --index;\n  }\n\n  return index;\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n// It turns out that some (most?) JavaScript engines don't self-host\n// `Array.prototype.sort`. This makes sense because C++ will likely remain\n// faster than JS when doing raw CPU-intensive sorting. However, when using a\n// custom comparator function, calling back and forth between the VM's C++ and\n// JIT'd JS is rather slow *and* loses JIT type information, resulting in\n// worse generated code for the comparator function than would be optimal. In\n// fact, when sorting with a comparator, these costs outweigh the benefits of\n// sorting in C++. By using our own JS-implemented Quick Sort (below), we get\n// a ~3500ms mean speed-up in `bench/bench.html`.\n\n/**\n * Swap the elements indexed by `x` and `y` in the array `ary`.\n *\n * @param {Array} ary\n *        The array.\n * @param {Number} x\n *        The index of the first item.\n * @param {Number} y\n *        The index of the second item.\n */\nfunction swap(ary, x, y) {\n  var temp = ary[x];\n  ary[x] = ary[y];\n  ary[y] = temp;\n}\n\n/**\n * Returns a random integer within the range `low .. high` inclusive.\n *\n * @param {Number} low\n *        The lower bound on the range.\n * @param {Number} high\n *        The upper bound on the range.\n */\nfunction randomIntInRange(low, high) {\n  return Math.round(low + (Math.random() * (high - low)));\n}\n\n/**\n * The Quick Sort algorithm.\n *\n * @param {Array} ary\n *        An array to sort.\n * @param {function} comparator\n *        Function to use to compare two items.\n * @param {Number} p\n *        Start index of the array\n * @param {Number} r\n *        End index of the array\n */\nfunction doQuickSort(ary, comparator, p, r) {\n  // If our lower bound is less than our upper bound, we (1) partition the\n  // array into two pieces and (2) recurse on each half. If it is not, this is\n  // the empty array and our base case.\n\n  if (p < r) {\n    // (1) Partitioning.\n    //\n    // The partitioning chooses a pivot between `p` and `r` and moves all\n    // elements that are less than or equal to the pivot to the before it, and\n    // all the elements that are greater than it after it. The effect is that\n    // once partition is done, the pivot is in the exact place it will be when\n    // the array is put in sorted order, and it will not need to be moved\n    // again. This runs in O(n) time.\n\n    // Always choose a random pivot so that an input array which is reverse\n    // sorted does not cause O(n^2) running time.\n    var pivotIndex = randomIntInRange(p, r);\n    var i = p - 1;\n\n    swap(ary, pivotIndex, r);\n    var pivot = ary[r];\n\n    // Immediately after `j` is incremented in this loop, the following hold\n    // true:\n    //\n    //   * Every element in `ary[p .. i]` is less than or equal to the pivot.\n    //\n    //   * Every element in `ary[i+1 .. j-1]` is greater than the pivot.\n    for (var j = p; j < r; j++) {\n      if (comparator(ary[j], pivot) <= 0) {\n        i += 1;\n        swap(ary, i, j);\n      }\n    }\n\n    swap(ary, i + 1, j);\n    var q = i + 1;\n\n    // (2) Recurse on each half.\n\n    doQuickSort(ary, comparator, p, q - 1);\n    doQuickSort(ary, comparator, q + 1, r);\n  }\n}\n\n/**\n * Sort the given array in-place with the given comparator function.\n *\n * @param {Array} ary\n *        An array to sort.\n * @param {function} comparator\n *        Function to use to compare two items.\n */\nexports.quickSort = function (ary, comparator) {\n  doQuickSort(ary, comparator, 0, ary.length - 1);\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\nvar binarySearch = require('./binary-search');\nvar ArraySet = require('./array-set').ArraySet;\nvar base64VLQ = require('./base64-vlq');\nvar quickSort = require('./quick-sort').quickSort;\n\nfunction SourceMapConsumer(aSourceMap) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = JSON.parse(aSourceMap.replace(/^\\)\\]\\}'/, ''));\n  }\n\n  return sourceMap.sections != null\n    ? new IndexedSourceMapConsumer(sourceMap)\n    : new BasicSourceMapConsumer(sourceMap);\n}\n\nSourceMapConsumer.fromSourceMap = function(aSourceMap) {\n  return BasicSourceMapConsumer.fromSourceMap(aSourceMap);\n}\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nSourceMapConsumer.prototype._version = 3;\n\n// `__generatedMappings` and `__originalMappings` are arrays that hold the\n// parsed mapping coordinates from the source map's \"mappings\" attribute. They\n// are lazily instantiated, accessed via the `_generatedMappings` and\n// `_originalMappings` getters respectively, and we only parse the mappings\n// and create these arrays once queried for a source location. We jump through\n// these hoops because there can be many thousands of mappings, and parsing\n// them is expensive, so we only want to do it if we must.\n//\n// Each object in the arrays is of the form:\n//\n//     {\n//       generatedLine: The line number in the generated code,\n//       generatedColumn: The column number in the generated code,\n//       source: The path to the original source file that generated this\n//               chunk of code,\n//       originalLine: The line number in the original source that\n//                     corresponds to this chunk of generated code,\n//       originalColumn: The column number in the original source that\n//                       corresponds to this chunk of generated code,\n//       name: The name of the original symbol which generated this chunk of\n//             code.\n//     }\n//\n// All properties except for `generatedLine` and `generatedColumn` can be\n// `null`.\n//\n// `_generatedMappings` is ordered by the generated positions.\n//\n// `_originalMappings` is ordered by the original positions.\n\nSourceMapConsumer.prototype.__generatedMappings = null;\nObject.defineProperty(SourceMapConsumer.prototype, '_generatedMappings', {\n  get: function () {\n    if (!this.__generatedMappings) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this.__generatedMappings;\n  }\n});\n\nSourceMapConsumer.prototype.__originalMappings = null;\nObject.defineProperty(SourceMapConsumer.prototype, '_originalMappings', {\n  get: function () {\n    if (!this.__originalMappings) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this.__originalMappings;\n  }\n});\n\nSourceMapConsumer.prototype._charIsMappingSeparator =\n  function SourceMapConsumer_charIsMappingSeparator(aStr, index) {\n    var c = aStr.charAt(index);\n    return c === \";\" || c === \",\";\n  };\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nSourceMapConsumer.prototype._parseMappings =\n  function SourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    throw new Error(\"Subclasses must implement _parseMappings\");\n  };\n\nSourceMapConsumer.GENERATED_ORDER = 1;\nSourceMapConsumer.ORIGINAL_ORDER = 2;\n\nSourceMapConsumer.GREATEST_LOWER_BOUND = 1;\nSourceMapConsumer.LEAST_UPPER_BOUND = 2;\n\n/**\n * Iterate over each mapping between an original source/line/column and a\n * generated line/column in this source map.\n *\n * @param Function aCallback\n *        The function that is called with each mapping.\n * @param Object aContext\n *        Optional. If specified, this object will be the value of `this` every\n *        time that `aCallback` is called.\n * @param aOrder\n *        Either `SourceMapConsumer.GENERATED_ORDER` or\n *        `SourceMapConsumer.ORIGINAL_ORDER`. Specifies whether you want to\n *        iterate over the mappings sorted by the generated file's line/column\n *        order or the original's source/line/column order, respectively. Defaults to\n *        `SourceMapConsumer.GENERATED_ORDER`.\n */\nSourceMapConsumer.prototype.eachMapping =\n  function SourceMapConsumer_eachMapping(aCallback, aContext, aOrder) {\n    var context = aContext || null;\n    var order = aOrder || SourceMapConsumer.GENERATED_ORDER;\n\n    var mappings;\n    switch (order) {\n    case SourceMapConsumer.GENERATED_ORDER:\n      mappings = this._generatedMappings;\n      break;\n    case SourceMapConsumer.ORIGINAL_ORDER:\n      mappings = this._originalMappings;\n      break;\n    default:\n      throw new Error(\"Unknown order of iteration.\");\n    }\n\n    var sourceRoot = this.sourceRoot;\n    mappings.map(function (mapping) {\n      var source = mapping.source === null ? null : this._sources.at(mapping.source);\n      if (source != null && sourceRoot != null) {\n        source = util.join(sourceRoot, source);\n      }\n      return {\n        source: source,\n        generatedLine: mapping.generatedLine,\n        generatedColumn: mapping.generatedColumn,\n        originalLine: mapping.originalLine,\n        originalColumn: mapping.originalColumn,\n        name: mapping.name === null ? null : this._names.at(mapping.name)\n      };\n    }, this).forEach(aCallback, context);\n  };\n\n/**\n * Returns all generated line and column information for the original source,\n * line, and column provided. If no column is provided, returns all mappings\n * corresponding to a either the line we are searching for or the next\n * closest line that has any mappings. Otherwise, returns all mappings\n * corresponding to the given line and either the column we are searching for\n * or the next closest column that has any offsets.\n *\n * The only argument is an object with the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.\n *   - column: Optional. the column number in the original source.\n *\n * and an array of objects is returned, each with the following properties:\n *\n *   - line: The line number in the generated source, or null.\n *   - column: The column number in the generated source, or null.\n */\nSourceMapConsumer.prototype.allGeneratedPositionsFor =\n  function SourceMapConsumer_allGeneratedPositionsFor(aArgs) {\n    var line = util.getArg(aArgs, 'line');\n\n    // When there is no exact match, BasicSourceMapConsumer.prototype._findMapping\n    // returns the index of the closest mapping less than the needle. By\n    // setting needle.originalColumn to 0, we thus find the last mapping for\n    // the given line, provided such a mapping exists.\n    var needle = {\n      source: util.getArg(aArgs, 'source'),\n      originalLine: line,\n      originalColumn: util.getArg(aArgs, 'column', 0)\n    };\n\n    if (this.sourceRoot != null) {\n      needle.source = util.relative(this.sourceRoot, needle.source);\n    }\n    if (!this._sources.has(needle.source)) {\n      return [];\n    }\n    needle.source = this._sources.indexOf(needle.source);\n\n    var mappings = [];\n\n    var index = this._findMapping(needle,\n                                  this._originalMappings,\n                                  \"originalLine\",\n                                  \"originalColumn\",\n                                  util.compareByOriginalPositions,\n                                  binarySearch.LEAST_UPPER_BOUND);\n    if (index >= 0) {\n      var mapping = this._originalMappings[index];\n\n      if (aArgs.column === undefined) {\n        var originalLine = mapping.originalLine;\n\n        // Iterate until either we run out of mappings, or we run into\n        // a mapping for a different line than the one we found. Since\n        // mappings are sorted, this is guaranteed to find all mappings for\n        // the line we found.\n        while (mapping && mapping.originalLine === originalLine) {\n          mappings.push({\n            line: util.getArg(mapping, 'generatedLine', null),\n            column: util.getArg(mapping, 'generatedColumn', null),\n            lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n          });\n\n          mapping = this._originalMappings[++index];\n        }\n      } else {\n        var originalColumn = mapping.originalColumn;\n\n        // Iterate until either we run out of mappings, or we run into\n        // a mapping for a different line than the one we were searching for.\n        // Since mappings are sorted, this is guaranteed to find all mappings for\n        // the line we are searching for.\n        while (mapping &&\n               mapping.originalLine === line &&\n               mapping.originalColumn == originalColumn) {\n          mappings.push({\n            line: util.getArg(mapping, 'generatedLine', null),\n            column: util.getArg(mapping, 'generatedColumn', null),\n            lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n          });\n\n          mapping = this._originalMappings[++index];\n        }\n      }\n    }\n\n    return mappings;\n  };\n\nexports.SourceMapConsumer = SourceMapConsumer;\n\n/**\n * A BasicSourceMapConsumer instance represents a parsed source map which we can\n * query for information about the original file positions by giving it a file\n * position in the generated source.\n *\n * The only parameter is the raw source map (either as a JSON string, or\n * already parsed to an object). According to the spec, source maps have the\n * following attributes:\n *\n *   - version: Which version of the source map spec this map is following.\n *   - sources: An array of URLs to the original source files.\n *   - names: An array of identifiers which can be referrenced by individual mappings.\n *   - sourceRoot: Optional. The URL root from which all sources are relative.\n *   - sourcesContent: Optional. An array of contents of the original source files.\n *   - mappings: A string of base64 VLQs which contain the actual mappings.\n *   - file: Optional. The generated file this source map is associated with.\n *\n * Here is an example source map, taken from the source map spec[0]:\n *\n *     {\n *       version : 3,\n *       file: \"out.js\",\n *       sourceRoot : \"\",\n *       sources: [\"foo.js\", \"bar.js\"],\n *       names: [\"src\", \"maps\", \"are\", \"fun\"],\n *       mappings: \"AA,AB;;ABCDE;\"\n *     }\n *\n * [0]: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit?pli=1#\n */\nfunction BasicSourceMapConsumer(aSourceMap) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = JSON.parse(aSourceMap.replace(/^\\)\\]\\}'/, ''));\n  }\n\n  var version = util.getArg(sourceMap, 'version');\n  var sources = util.getArg(sourceMap, 'sources');\n  // Sass 3.3 leaves out the 'names' array, so we deviate from the spec (which\n  // requires the array) to play nice here.\n  var names = util.getArg(sourceMap, 'names', []);\n  var sourceRoot = util.getArg(sourceMap, 'sourceRoot', null);\n  var sourcesContent = util.getArg(sourceMap, 'sourcesContent', null);\n  var mappings = util.getArg(sourceMap, 'mappings');\n  var file = util.getArg(sourceMap, 'file', null);\n\n  // Once again, Sass deviates from the spec and supplies the version as a\n  // string rather than a number, so we use loose equality checking here.\n  if (version != this._version) {\n    throw new Error('Unsupported version: ' + version);\n  }\n\n  sources = sources\n    .map(String)\n    // Some source maps produce relative source paths like \"./foo.js\" instead of\n    // \"foo.js\".  Normalize these first so that future comparisons will succeed.\n    // See bugzil.la/1090768.\n    .map(util.normalize)\n    // Always ensure that absolute sources are internally stored relative to\n    // the source root, if the source root is absolute. Not doing this would\n    // be particularly problematic when the source root is a prefix of the\n    // source (valid, but why??). See github issue #199 and bugzil.la/1188982.\n    .map(function (source) {\n      return sourceRoot && util.isAbsolute(sourceRoot) && util.isAbsolute(source)\n        ? util.relative(sourceRoot, source)\n        : source;\n    });\n\n  // Pass `true` below to allow duplicate names and sources. While source maps\n  // are intended to be compressed and deduplicated, the TypeScript compiler\n  // sometimes generates source maps with duplicates in them. See Github issue\n  // #72 and bugzil.la/889492.\n  this._names = ArraySet.fromArray(names.map(String), true);\n  this._sources = ArraySet.fromArray(sources, true);\n\n  this.sourceRoot = sourceRoot;\n  this.sourcesContent = sourcesContent;\n  this._mappings = mappings;\n  this.file = file;\n}\n\nBasicSourceMapConsumer.prototype = Object.create(SourceMapConsumer.prototype);\nBasicSourceMapConsumer.prototype.consumer = SourceMapConsumer;\n\n/**\n * Create a BasicSourceMapConsumer from a SourceMapGenerator.\n *\n * @param SourceMapGenerator aSourceMap\n *        The source map that will be consumed.\n * @returns BasicSourceMapConsumer\n */\nBasicSourceMapConsumer.fromSourceMap =\n  function SourceMapConsumer_fromSourceMap(aSourceMap) {\n    var smc = Object.create(BasicSourceMapConsumer.prototype);\n\n    var names = smc._names = ArraySet.fromArray(aSourceMap._names.toArray(), true);\n    var sources = smc._sources = ArraySet.fromArray(aSourceMap._sources.toArray(), true);\n    smc.sourceRoot = aSourceMap._sourceRoot;\n    smc.sourcesContent = aSourceMap._generateSourcesContent(smc._sources.toArray(),\n                                                            smc.sourceRoot);\n    smc.file = aSourceMap._file;\n\n    // Because we are modifying the entries (by converting string sources and\n    // names to indices into the sources and names ArraySets), we have to make\n    // a copy of the entry or else bad things happen. Shared mutable state\n    // strikes again! See github issue #191.\n\n    var generatedMappings = aSourceMap._mappings.toArray().slice();\n    var destGeneratedMappings = smc.__generatedMappings = [];\n    var destOriginalMappings = smc.__originalMappings = [];\n\n    for (var i = 0, length = generatedMappings.length; i < length; i++) {\n      var srcMapping = generatedMappings[i];\n      var destMapping = new Mapping;\n      destMapping.generatedLine = srcMapping.generatedLine;\n      destMapping.generatedColumn = srcMapping.generatedColumn;\n\n      if (srcMapping.source) {\n        destMapping.source = sources.indexOf(srcMapping.source);\n        destMapping.originalLine = srcMapping.originalLine;\n        destMapping.originalColumn = srcMapping.originalColumn;\n\n        if (srcMapping.name) {\n          destMapping.name = names.indexOf(srcMapping.name);\n        }\n\n        destOriginalMappings.push(destMapping);\n      }\n\n      destGeneratedMappings.push(destMapping);\n    }\n\n    quickSort(smc.__originalMappings, util.compareByOriginalPositions);\n\n    return smc;\n  };\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nBasicSourceMapConsumer.prototype._version = 3;\n\n/**\n * The list of original sources.\n */\nObject.defineProperty(BasicSourceMapConsumer.prototype, 'sources', {\n  get: function () {\n    return this._sources.toArray().map(function (s) {\n      return this.sourceRoot != null ? util.join(this.sourceRoot, s) : s;\n    }, this);\n  }\n});\n\n/**\n * Provide the JIT with a nice shape / hidden class.\n */\nfunction Mapping() {\n  this.generatedLine = 0;\n  this.generatedColumn = 0;\n  this.source = null;\n  this.originalLine = null;\n  this.originalColumn = null;\n  this.name = null;\n}\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nBasicSourceMapConsumer.prototype._parseMappings =\n  function SourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    var generatedLine = 1;\n    var previousGeneratedColumn = 0;\n    var previousOriginalLine = 0;\n    var previousOriginalColumn = 0;\n    var previousSource = 0;\n    var previousName = 0;\n    var length = aStr.length;\n    var index = 0;\n    var cachedSegments = {};\n    var temp = {};\n    var originalMappings = [];\n    var generatedMappings = [];\n    var mapping, str, segment, end, value;\n\n    while (index < length) {\n      if (aStr.charAt(index) === ';') {\n        generatedLine++;\n        index++;\n        previousGeneratedColumn = 0;\n      }\n      else if (aStr.charAt(index) === ',') {\n        index++;\n      }\n      else {\n        mapping = new Mapping();\n        mapping.generatedLine = generatedLine;\n\n        // Because each offset is encoded relative to the previous one,\n        // many segments often have the same encoding. We can exploit this\n        // fact by caching the parsed variable length fields of each segment,\n        // allowing us to avoid a second parse if we encounter the same\n        // segment again.\n        for (end = index; end < length; end++) {\n          if (this._charIsMappingSeparator(aStr, end)) {\n            break;\n          }\n        }\n        str = aStr.slice(index, end);\n\n        segment = cachedSegments[str];\n        if (segment) {\n          index += str.length;\n        } else {\n          segment = [];\n          while (index < end) {\n            base64VLQ.decode(aStr, index, temp);\n            value = temp.value;\n            index = temp.rest;\n            segment.push(value);\n          }\n\n          if (segment.length === 2) {\n            throw new Error('Found a source, but no line and column');\n          }\n\n          if (segment.length === 3) {\n            throw new Error('Found a source and line, but no column');\n          }\n\n          cachedSegments[str] = segment;\n        }\n\n        // Generated column.\n        mapping.generatedColumn = previousGeneratedColumn + segment[0];\n        previousGeneratedColumn = mapping.generatedColumn;\n\n        if (segment.length > 1) {\n          // Original source.\n          mapping.source = previousSource + segment[1];\n          previousSource += segment[1];\n\n          // Original line.\n          mapping.originalLine = previousOriginalLine + segment[2];\n          previousOriginalLine = mapping.originalLine;\n          // Lines are stored 0-based\n          mapping.originalLine += 1;\n\n          // Original column.\n          mapping.originalColumn = previousOriginalColumn + segment[3];\n          previousOriginalColumn = mapping.originalColumn;\n\n          if (segment.length > 4) {\n            // Original name.\n            mapping.name = previousName + segment[4];\n            previousName += segment[4];\n          }\n        }\n\n        generatedMappings.push(mapping);\n        if (typeof mapping.originalLine === 'number') {\n          originalMappings.push(mapping);\n        }\n      }\n    }\n\n    quickSort(generatedMappings, util.compareByGeneratedPositionsDeflated);\n    this.__generatedMappings = generatedMappings;\n\n    quickSort(originalMappings, util.compareByOriginalPositions);\n    this.__originalMappings = originalMappings;\n  };\n\n/**\n * Find the mapping that best matches the hypothetical \"needle\" mapping that\n * we are searching for in the given \"haystack\" of mappings.\n */\nBasicSourceMapConsumer.prototype._findMapping =\n  function SourceMapConsumer_findMapping(aNeedle, aMappings, aLineName,\n                                         aColumnName, aComparator, aBias) {\n    // To return the position we are searching for, we must first find the\n    // mapping for the given position and then return the opposite position it\n    // points to. Because the mappings are sorted, we can use binary search to\n    // find the best mapping.\n\n    if (aNeedle[aLineName] <= 0) {\n      throw new TypeError('Line must be greater than or equal to 1, got '\n                          + aNeedle[aLineName]);\n    }\n    if (aNeedle[aColumnName] < 0) {\n      throw new TypeError('Column must be greater than or equal to 0, got '\n                          + aNeedle[aColumnName]);\n    }\n\n    return binarySearch.search(aNeedle, aMappings, aComparator, aBias);\n  };\n\n/**\n * Compute the last column for each generated mapping. The last column is\n * inclusive.\n */\nBasicSourceMapConsumer.prototype.computeColumnSpans =\n  function SourceMapConsumer_computeColumnSpans() {\n    for (var index = 0; index < this._generatedMappings.length; ++index) {\n      var mapping = this._generatedMappings[index];\n\n      // Mappings do not contain a field for the last generated columnt. We\n      // can come up with an optimistic estimate, however, by assuming that\n      // mappings are contiguous (i.e. given two consecutive mappings, the\n      // first mapping ends where the second one starts).\n      if (index + 1 < this._generatedMappings.length) {\n        var nextMapping = this._generatedMappings[index + 1];\n\n        if (mapping.generatedLine === nextMapping.generatedLine) {\n          mapping.lastGeneratedColumn = nextMapping.generatedColumn - 1;\n          continue;\n        }\n      }\n\n      // The last mapping for each line spans the entire line.\n      mapping.lastGeneratedColumn = Infinity;\n    }\n  };\n\n/**\n * Returns the original source, line, and column information for the generated\n * source's line and column positions provided. The only argument is an object\n * with the following properties:\n *\n *   - line: The line number in the generated source.\n *   - column: The column number in the generated source.\n *   - bias: Either 'SourceMapConsumer.GREATEST_LOWER_BOUND' or\n *     'SourceMapConsumer.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'SourceMapConsumer.GREATEST_LOWER_BOUND'.\n *\n * and an object is returned with the following properties:\n *\n *   - source: The original source file, or null.\n *   - line: The line number in the original source, or null.\n *   - column: The column number in the original source, or null.\n *   - name: The original identifier, or null.\n */\nBasicSourceMapConsumer.prototype.originalPositionFor =\n  function SourceMapConsumer_originalPositionFor(aArgs) {\n    var needle = {\n      generatedLine: util.getArg(aArgs, 'line'),\n      generatedColumn: util.getArg(aArgs, 'column')\n    };\n\n    var index = this._findMapping(\n      needle,\n      this._generatedMappings,\n      \"generatedLine\",\n      \"generatedColumn\",\n      util.compareByGeneratedPositionsDeflated,\n      util.getArg(aArgs, 'bias', SourceMapConsumer.GREATEST_LOWER_BOUND)\n    );\n\n    if (index >= 0) {\n      var mapping = this._generatedMappings[index];\n\n      if (mapping.generatedLine === needle.generatedLine) {\n        var source = util.getArg(mapping, 'source', null);\n        if (source !== null) {\n          source = this._sources.at(source);\n          if (this.sourceRoot != null) {\n            source = util.join(this.sourceRoot, source);\n          }\n        }\n        var name = util.getArg(mapping, 'name', null);\n        if (name !== null) {\n          name = this._names.at(name);\n        }\n        return {\n          source: source,\n          line: util.getArg(mapping, 'originalLine', null),\n          column: util.getArg(mapping, 'originalColumn', null),\n          name: name\n        };\n      }\n    }\n\n    return {\n      source: null,\n      line: null,\n      column: null,\n      name: null\n    };\n  };\n\n/**\n * Return true if we have the source content for every source in the source\n * map, false otherwise.\n */\nBasicSourceMapConsumer.prototype.hasContentsOfAllSources =\n  function BasicSourceMapConsumer_hasContentsOfAllSources() {\n    if (!this.sourcesContent) {\n      return false;\n    }\n    return this.sourcesContent.length >= this._sources.size() &&\n      !this.sourcesContent.some(function (sc) { return sc == null; });\n  };\n\n/**\n * Returns the original source content. The only argument is the url of the\n * original source file. Returns null if no original source content is\n * available.\n */\nBasicSourceMapConsumer.prototype.sourceContentFor =\n  function SourceMapConsumer_sourceContentFor(aSource, nullOnMissing) {\n    if (!this.sourcesContent) {\n      return null;\n    }\n\n    if (this.sourceRoot != null) {\n      aSource = util.relative(this.sourceRoot, aSource);\n    }\n\n    if (this._sources.has(aSource)) {\n      return this.sourcesContent[this._sources.indexOf(aSource)];\n    }\n\n    var url;\n    if (this.sourceRoot != null\n        && (url = util.urlParse(this.sourceRoot))) {\n      // XXX: file:// URIs and absolute paths lead to unexpected behavior for\n      // many users. We can help them out when they expect file:// URIs to\n      // behave like it would if they were running a local HTTP server. See\n      // https://bugzilla.mozilla.org/show_bug.cgi?id=885597.\n      var fileUriAbsPath = aSource.replace(/^file:\\/\\//, \"\");\n      if (url.scheme == \"file\"\n          && this._sources.has(fileUriAbsPath)) {\n        return this.sourcesContent[this._sources.indexOf(fileUriAbsPath)]\n      }\n\n      if ((!url.path || url.path == \"/\")\n          && this._sources.has(\"/\" + aSource)) {\n        return this.sourcesContent[this._sources.indexOf(\"/\" + aSource)];\n      }\n    }\n\n    // This function is used recursively from\n    // IndexedSourceMapConsumer.prototype.sourceContentFor. In that case, we\n    // don't want to throw if we can't find the source - we just want to\n    // return null, so we provide a flag to exit gracefully.\n    if (nullOnMissing) {\n      return null;\n    }\n    else {\n      throw new Error('\"' + aSource + '\" is not in the SourceMap.');\n    }\n  };\n\n/**\n * Returns the generated line and column information for the original source,\n * line, and column positions provided. The only argument is an object with\n * the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.\n *   - column: The column number in the original source.\n *   - bias: Either 'SourceMapConsumer.GREATEST_LOWER_BOUND' or\n *     'SourceMapConsumer.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'SourceMapConsumer.GREATEST_LOWER_BOUND'.\n *\n * and an object is returned with the following properties:\n *\n *   - line: The line number in the generated source, or null.\n *   - column: The column number in the generated source, or null.\n */\nBasicSourceMapConsumer.prototype.generatedPositionFor =\n  function SourceMapConsumer_generatedPositionFor(aArgs) {\n    var source = util.getArg(aArgs, 'source');\n    if (this.sourceRoot != null) {\n      source = util.relative(this.sourceRoot, source);\n    }\n    if (!this._sources.has(source)) {\n      return {\n        line: null,\n        column: null,\n        lastColumn: null\n      };\n    }\n    source = this._sources.indexOf(source);\n\n    var needle = {\n      source: source,\n      originalLine: util.getArg(aArgs, 'line'),\n      originalColumn: util.getArg(aArgs, 'column')\n    };\n\n    var index = this._findMapping(\n      needle,\n      this._originalMappings,\n      \"originalLine\",\n      \"originalColumn\",\n      util.compareByOriginalPositions,\n      util.getArg(aArgs, 'bias', SourceMapConsumer.GREATEST_LOWER_BOUND)\n    );\n\n    if (index >= 0) {\n      var mapping = this._originalMappings[index];\n\n      if (mapping.source === needle.source) {\n        return {\n          line: util.getArg(mapping, 'generatedLine', null),\n          column: util.getArg(mapping, 'generatedColumn', null),\n          lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n        };\n      }\n    }\n\n    return {\n      line: null,\n      column: null,\n      lastColumn: null\n    };\n  };\n\nexports.BasicSourceMapConsumer = BasicSourceMapConsumer;\n\n/**\n * An IndexedSourceMapConsumer instance represents a parsed source map which\n * we can query for information. It differs from BasicSourceMapConsumer in\n * that it takes \"indexed\" source maps (i.e. ones with a \"sections\" field) as\n * input.\n *\n * The only parameter is a raw source map (either as a JSON string, or already\n * parsed to an object). According to the spec for indexed source maps, they\n * have the following attributes:\n *\n *   - version: Which version of the source map spec this map is following.\n *   - file: Optional. The generated file this source map is associated with.\n *   - sections: A list of section definitions.\n *\n * Each value under the \"sections\" field has two fields:\n *   - offset: The offset into the original specified at which this section\n *       begins to apply, defined as an object with a \"line\" and \"column\"\n *       field.\n *   - map: A source map definition. This source map could also be indexed,\n *       but doesn't have to be.\n *\n * Instead of the \"map\" field, it's also possible to have a \"url\" field\n * specifying a URL to retrieve a source map from, but that's currently\n * unsupported.\n *\n * Here's an example source map, taken from the source map spec[0], but\n * modified to omit a section which uses the \"url\" field.\n *\n *  {\n *    version : 3,\n *    file: \"app.js\",\n *    sections: [{\n *      offset: {line:100, column:10},\n *      map: {\n *        version : 3,\n *        file: \"section.js\",\n *        sources: [\"foo.js\", \"bar.js\"],\n *        names: [\"src\", \"maps\", \"are\", \"fun\"],\n *        mappings: \"AAAA,E;;ABCDE;\"\n *      }\n *    }],\n *  }\n *\n * [0]: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit#heading=h.535es3xeprgt\n */\nfunction IndexedSourceMapConsumer(aSourceMap) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = JSON.parse(aSourceMap.replace(/^\\)\\]\\}'/, ''));\n  }\n\n  var version = util.getArg(sourceMap, 'version');\n  var sections = util.getArg(sourceMap, 'sections');\n\n  if (version != this._version) {\n    throw new Error('Unsupported version: ' + version);\n  }\n\n  this._sources = new ArraySet();\n  this._names = new ArraySet();\n\n  var lastOffset = {\n    line: -1,\n    column: 0\n  };\n  this._sections = sections.map(function (s) {\n    if (s.url) {\n      // The url field will require support for asynchronicity.\n      // See https://github.com/mozilla/source-map/issues/16\n      throw new Error('Support for url field in sections not implemented.');\n    }\n    var offset = util.getArg(s, 'offset');\n    var offsetLine = util.getArg(offset, 'line');\n    var offsetColumn = util.getArg(offset, 'column');\n\n    if (offsetLine < lastOffset.line ||\n        (offsetLine === lastOffset.line && offsetColumn < lastOffset.column)) {\n      throw new Error('Section offsets must be ordered and non-overlapping.');\n    }\n    lastOffset = offset;\n\n    return {\n      generatedOffset: {\n        // The offset fields are 0-based, but we use 1-based indices when\n        // encoding/decoding from VLQ.\n        generatedLine: offsetLine + 1,\n        generatedColumn: offsetColumn + 1\n      },\n      consumer: new SourceMapConsumer(util.getArg(s, 'map'))\n    }\n  });\n}\n\nIndexedSourceMapConsumer.prototype = Object.create(SourceMapConsumer.prototype);\nIndexedSourceMapConsumer.prototype.constructor = SourceMapConsumer;\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nIndexedSourceMapConsumer.prototype._version = 3;\n\n/**\n * The list of original sources.\n */\nObject.defineProperty(IndexedSourceMapConsumer.prototype, 'sources', {\n  get: function () {\n    var sources = [];\n    for (var i = 0; i < this._sections.length; i++) {\n      for (var j = 0; j < this._sections[i].consumer.sources.length; j++) {\n        sources.push(this._sections[i].consumer.sources[j]);\n      }\n    }\n    return sources;\n  }\n});\n\n/**\n * Returns the original source, line, and column information for the generated\n * source's line and column positions provided. The only argument is an object\n * with the following properties:\n *\n *   - line: The line number in the generated source.\n *   - column: The column number in the generated source.\n *\n * and an object is returned with the following properties:\n *\n *   - source: The original source file, or null.\n *   - line: The line number in the original source, or null.\n *   - column: The column number in the original source, or null.\n *   - name: The original identifier, or null.\n */\nIndexedSourceMapConsumer.prototype.originalPositionFor =\n  function IndexedSourceMapConsumer_originalPositionFor(aArgs) {\n    var needle = {\n      generatedLine: util.getArg(aArgs, 'line'),\n      generatedColumn: util.getArg(aArgs, 'column')\n    };\n\n    // Find the section containing the generated position we're trying to map\n    // to an original position.\n    var sectionIndex = binarySearch.search(needle, this._sections,\n      function(needle, section) {\n        var cmp = needle.generatedLine - section.generatedOffset.generatedLine;\n        if (cmp) {\n          return cmp;\n        }\n\n        return (needle.generatedColumn -\n                section.generatedOffset.generatedColumn);\n      });\n    var section = this._sections[sectionIndex];\n\n    if (!section) {\n      return {\n        source: null,\n        line: null,\n        column: null,\n        name: null\n      };\n    }\n\n    return section.consumer.originalPositionFor({\n      line: needle.generatedLine -\n        (section.generatedOffset.generatedLine - 1),\n      column: needle.generatedColumn -\n        (section.generatedOffset.generatedLine === needle.generatedLine\n         ? section.generatedOffset.generatedColumn - 1\n         : 0),\n      bias: aArgs.bias\n    });\n  };\n\n/**\n * Return true if we have the source content for every source in the source\n * map, false otherwise.\n */\nIndexedSourceMapConsumer.prototype.hasContentsOfAllSources =\n  function IndexedSourceMapConsumer_hasContentsOfAllSources() {\n    return this._sections.every(function (s) {\n      return s.consumer.hasContentsOfAllSources();\n    });\n  };\n\n/**\n * Returns the original source content. The only argument is the url of the\n * original source file. Returns null if no original source content is\n * available.\n */\nIndexedSourceMapConsumer.prototype.sourceContentFor =\n  function IndexedSourceMapConsumer_sourceContentFor(aSource, nullOnMissing) {\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n\n      var content = section.consumer.sourceContentFor(aSource, true);\n      if (content) {\n        return content;\n      }\n    }\n    if (nullOnMissing) {\n      return null;\n    }\n    else {\n      throw new Error('\"' + aSource + '\" is not in the SourceMap.');\n    }\n  };\n\n/**\n * Returns the generated line and column information for the original source,\n * line, and column positions provided. The only argument is an object with\n * the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.\n *   - column: The column number in the original source.\n *\n * and an object is returned with the following properties:\n *\n *   - line: The line number in the generated source, or null.\n *   - column: The column number in the generated source, or null.\n */\nIndexedSourceMapConsumer.prototype.generatedPositionFor =\n  function IndexedSourceMapConsumer_generatedPositionFor(aArgs) {\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n\n      // Only consider this section if the requested source is in the list of\n      // sources of the consumer.\n      if (section.consumer.sources.indexOf(util.getArg(aArgs, 'source')) === -1) {\n        continue;\n      }\n      var generatedPosition = section.consumer.generatedPositionFor(aArgs);\n      if (generatedPosition) {\n        var ret = {\n          line: generatedPosition.line +\n            (section.generatedOffset.generatedLine - 1),\n          column: generatedPosition.column +\n            (section.generatedOffset.generatedLine === generatedPosition.line\n             ? section.generatedOffset.generatedColumn - 1\n             : 0)\n        };\n        return ret;\n      }\n    }\n\n    return {\n      line: null,\n      column: null\n    };\n  };\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nIndexedSourceMapConsumer.prototype._parseMappings =\n  function IndexedSourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    this.__generatedMappings = [];\n    this.__originalMappings = [];\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n      var sectionMappings = section.consumer._generatedMappings;\n      for (var j = 0; j < sectionMappings.length; j++) {\n        var mapping = sectionMappings[j];\n\n        var source = section.consumer._sources.at(mapping.source);\n        if (section.consumer.sourceRoot !== null) {\n          source = util.join(section.consumer.sourceRoot, source);\n        }\n        this._sources.add(source);\n        source = this._sources.indexOf(source);\n\n        var name = section.consumer._names.at(mapping.name);\n        this._names.add(name);\n        name = this._names.indexOf(name);\n\n        // The mappings coming from the consumer for the section have\n        // generated positions relative to the start of the section, so we\n        // need to offset them to be relative to the start of the concatenated\n        // generated file.\n        var adjustedMapping = {\n          source: source,\n          generatedLine: mapping.generatedLine +\n            (section.generatedOffset.generatedLine - 1),\n          generatedColumn: mapping.generatedColumn +\n            (section.generatedOffset.generatedLine === mapping.generatedLine\n            ? section.generatedOffset.generatedColumn - 1\n            : 0),\n          originalLine: mapping.originalLine,\n          originalColumn: mapping.originalColumn,\n          name: name\n        };\n\n        this.__generatedMappings.push(adjustedMapping);\n        if (typeof adjustedMapping.originalLine === 'number') {\n          this.__originalMappings.push(adjustedMapping);\n        }\n      }\n    }\n\n    quickSort(this.__generatedMappings, util.compareByGeneratedPositionsDeflated);\n    quickSort(this.__originalMappings, util.compareByOriginalPositions);\n  };\n\nexports.IndexedSourceMapConsumer = IndexedSourceMapConsumer;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n/**\n * This is a helper function for getting values from parameter/options\n * objects.\n *\n * @param args The object we are extracting values from\n * @param name The name of the property we are getting.\n * @param defaultValue An optional value to return if the property is missing\n * from the object. If this is not specified and the property is missing, an\n * error will be thrown.\n */\nfunction getArg(aArgs, aName, aDefaultValue) {\n  if (aName in aArgs) {\n    return aArgs[aName];\n  } else if (arguments.length === 3) {\n    return aDefaultValue;\n  } else {\n    throw new Error('\"' + aName + '\" is a required argument.');\n  }\n}\nexports.getArg = getArg;\n\nvar urlRegexp = /^(?:([\\w+\\-.]+):)?\\/\\/(?:(\\w+:\\w+)@)?([\\w.]*)(?::(\\d+))?(\\S*)$/;\nvar dataUrlRegexp = /^data:.+\\,.+$/;\n\nfunction urlParse(aUrl) {\n  var match = aUrl.match(urlRegexp);\n  if (!match) {\n    return null;\n  }\n  return {\n    scheme: match[1],\n    auth: match[2],\n    host: match[3],\n    port: match[4],\n    path: match[5]\n  };\n}\nexports.urlParse = urlParse;\n\nfunction urlGenerate(aParsedUrl) {\n  var url = '';\n  if (aParsedUrl.scheme) {\n    url += aParsedUrl.scheme + ':';\n  }\n  url += '//';\n  if (aParsedUrl.auth) {\n    url += aParsedUrl.auth + '@';\n  }\n  if (aParsedUrl.host) {\n    url += aParsedUrl.host;\n  }\n  if (aParsedUrl.port) {\n    url += \":\" + aParsedUrl.port\n  }\n  if (aParsedUrl.path) {\n    url += aParsedUrl.path;\n  }\n  return url;\n}\nexports.urlGenerate = urlGenerate;\n\n/**\n * Normalizes a path, or the path portion of a URL:\n *\n * - Replaces consecutive slashes with one slash.\n * - Removes unnecessary '.' parts.\n * - Removes unnecessary '<dir>/..' parts.\n *\n * Based on code in the Node.js 'path' core module.\n *\n * @param aPath The path or url to normalize.\n */\nfunction normalize(aPath) {\n  var path = aPath;\n  var url = urlParse(aPath);\n  if (url) {\n    if (!url.path) {\n      return aPath;\n    }\n    path = url.path;\n  }\n  var isAbsolute = exports.isAbsolute(path);\n\n  var parts = path.split(/\\/+/);\n  for (var part, up = 0, i = parts.length - 1; i >= 0; i--) {\n    part = parts[i];\n    if (part === '.') {\n      parts.splice(i, 1);\n    } else if (part === '..') {\n      up++;\n    } else if (up > 0) {\n      if (part === '') {\n        // The first part is blank if the path is absolute. Trying to go\n        // above the root is a no-op. Therefore we can remove all '..' parts\n        // directly after the root.\n        parts.splice(i + 1, up);\n        up = 0;\n      } else {\n        parts.splice(i, 2);\n        up--;\n      }\n    }\n  }\n  path = parts.join('/');\n\n  if (path === '') {\n    path = isAbsolute ? '/' : '.';\n  }\n\n  if (url) {\n    url.path = path;\n    return urlGenerate(url);\n  }\n  return path;\n}\nexports.normalize = normalize;\n\n/**\n * Joins two paths/URLs.\n *\n * @param aRoot The root path or URL.\n * @param aPath The path or URL to be joined with the root.\n *\n * - If aPath is a URL or a data URI, aPath is returned, unless aPath is a\n *   scheme-relative URL: Then the scheme of aRoot, if any, is prepended\n *   first.\n * - Otherwise aPath is a path. If aRoot is a URL, then its path portion\n *   is updated with the result and aRoot is returned. Otherwise the result\n *   is returned.\n *   - If aPath is absolute, the result is aPath.\n *   - Otherwise the two paths are joined with a slash.\n * - Joining for example 'http://' and 'www.example.com' is also supported.\n */\nfunction join(aRoot, aPath) {\n  if (aRoot === \"\") {\n    aRoot = \".\";\n  }\n  if (aPath === \"\") {\n    aPath = \".\";\n  }\n  var aPathUrl = urlParse(aPath);\n  var aRootUrl = urlParse(aRoot);\n  if (aRootUrl) {\n    aRoot = aRootUrl.path || '/';\n  }\n\n  // `join(foo, '//www.example.org')`\n  if (aPathUrl && !aPathUrl.scheme) {\n    if (aRootUrl) {\n      aPathUrl.scheme = aRootUrl.scheme;\n    }\n    return urlGenerate(aPathUrl);\n  }\n\n  if (aPathUrl || aPath.match(dataUrlRegexp)) {\n    return aPath;\n  }\n\n  // `join('http://', 'www.example.com')`\n  if (aRootUrl && !aRootUrl.host && !aRootUrl.path) {\n    aRootUrl.host = aPath;\n    return urlGenerate(aRootUrl);\n  }\n\n  var joined = aPath.charAt(0) === '/'\n    ? aPath\n    : normalize(aRoot.replace(/\\/+$/, '') + '/' + aPath);\n\n  if (aRootUrl) {\n    aRootUrl.path = joined;\n    return urlGenerate(aRootUrl);\n  }\n  return joined;\n}\nexports.join = join;\n\nexports.isAbsolute = function (aPath) {\n  return aPath.charAt(0) === '/' || !!aPath.match(urlRegexp);\n};\n\n/**\n * Make a path relative to a URL or another path.\n *\n * @param aRoot The root path or URL.\n * @param aPath The path or URL to be made relative to aRoot.\n */\nfunction relative(aRoot, aPath) {\n  if (aRoot === \"\") {\n    aRoot = \".\";\n  }\n\n  aRoot = aRoot.replace(/\\/$/, '');\n\n  // It is possible for the path to be above the root. In this case, simply\n  // checking whether the root is a prefix of the path won't work. Instead, we\n  // need to remove components from the root one by one, until either we find\n  // a prefix that fits, or we run out of components to remove.\n  var level = 0;\n  while (aPath.indexOf(aRoot + '/') !== 0) {\n    var index = aRoot.lastIndexOf(\"/\");\n    if (index < 0) {\n      return aPath;\n    }\n\n    // If the only part of the root that is left is the scheme (i.e. http://,\n    // file:///, etc.), one or more slashes (/), or simply nothing at all, we\n    // have exhausted all components, so the path is not relative to the root.\n    aRoot = aRoot.slice(0, index);\n    if (aRoot.match(/^([^\\/]+:\\/)?\\/*$/)) {\n      return aPath;\n    }\n\n    ++level;\n  }\n\n  // Make sure we add a \"../\" for each component we removed from the root.\n  return Array(level + 1).join(\"../\") + aPath.substr(aRoot.length + 1);\n}\nexports.relative = relative;\n\nvar supportsNullProto = (function () {\n  var obj = Object.create(null);\n  return !('__proto__' in obj);\n}());\n\nfunction identity (s) {\n  return s;\n}\n\n/**\n * Because behavior goes wacky when you set `__proto__` on objects, we\n * have to prefix all the strings in our set with an arbitrary character.\n *\n * See https://github.com/mozilla/source-map/pull/31 and\n * https://github.com/mozilla/source-map/issues/30\n *\n * @param String aStr\n */\nfunction toSetString(aStr) {\n  if (isProtoString(aStr)) {\n    return '$' + aStr;\n  }\n\n  return aStr;\n}\nexports.toSetString = supportsNullProto ? identity : toSetString;\n\nfunction fromSetString(aStr) {\n  if (isProtoString(aStr)) {\n    return aStr.slice(1);\n  }\n\n  return aStr;\n}\nexports.fromSetString = supportsNullProto ? identity : fromSetString;\n\nfunction isProtoString(s) {\n  if (!s) {\n    return false;\n  }\n\n  var length = s.length;\n\n  if (length < 9 /* \"__proto__\".length */) {\n    return false;\n  }\n\n  if (s.charCodeAt(length - 1) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 2) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 3) !== 111 /* 'o' */ ||\n      s.charCodeAt(length - 4) !== 116 /* 't' */ ||\n      s.charCodeAt(length - 5) !== 111 /* 'o' */ ||\n      s.charCodeAt(length - 6) !== 114 /* 'r' */ ||\n      s.charCodeAt(length - 7) !== 112 /* 'p' */ ||\n      s.charCodeAt(length - 8) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 9) !== 95  /* '_' */) {\n    return false;\n  }\n\n  for (var i = length - 10; i >= 0; i--) {\n    if (s.charCodeAt(i) !== 36 /* '$' */) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * Comparator between two mappings where the original positions are compared.\n *\n * Optionally pass in `true` as `onlyCompareGenerated` to consider two\n * mappings with the same original source/line/column, but different generated\n * line and column the same. Useful when searching for a mapping with a\n * stubbed out mapping.\n */\nfunction compareByOriginalPositions(mappingA, mappingB, onlyCompareOriginal) {\n  var cmp = mappingA.source - mappingB.source;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0 || onlyCompareOriginal) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return mappingA.name - mappingB.name;\n}\nexports.compareByOriginalPositions = compareByOriginalPositions;\n\n/**\n * Comparator between two mappings with deflated source and name indices where\n * the generated positions are compared.\n *\n * Optionally pass in `true` as `onlyCompareGenerated` to consider two\n * mappings with the same generated line and column, but different\n * source/name/original line and column the same. Useful when searching for a\n * mapping with a stubbed out mapping.\n */\nfunction compareByGeneratedPositionsDeflated(mappingA, mappingB, onlyCompareGenerated) {\n  var cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0 || onlyCompareGenerated) {\n    return cmp;\n  }\n\n  cmp = mappingA.source - mappingB.source;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return mappingA.name - mappingB.name;\n}\nexports.compareByGeneratedPositionsDeflated = compareByGeneratedPositionsDeflated;\n\nfunction strcmp(aStr1, aStr2) {\n  if (aStr1 === aStr2) {\n    return 0;\n  }\n\n  if (aStr1 > aStr2) {\n    return 1;\n  }\n\n  return -1;\n}\n\n/**\n * Comparator between two mappings with inflated source and name strings where\n * the generated positions are compared.\n */\nfunction compareByGeneratedPositionsInflated(mappingA, mappingB) {\n  var cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = strcmp(mappingA.source, mappingB.source);\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return strcmp(mappingA.name, mappingB.name);\n}\nexports.compareByGeneratedPositionsInflated = compareByGeneratedPositionsInflated;\n","/*\n * sourcemapped-stacktrace.js\n * created by James Salter <iteration@gmail.com> (2014)\n *\n * https://github.com/novocaine/sourcemapped-stacktrace\n *\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n/*global define */\n\n// note we only include source-map-consumer, not the whole source-map library,\n// which includes gear for generating source maps that we don't need\ndefine(['source-map/lib/source-map-consumer'],\nfunction(source_map_consumer) {\n\n  var global_mapForUri = {};\n\n  /**\n   * Re-map entries in a stacktrace using sourcemaps if available.\n   *\n   * @param {Array} stack - Array of strings from the browser's stack\n   *                        representation. Currently only Chrome\n   *                        format is supported.\n   * @param {function} done - Callback invoked with the transformed stacktrace\n   *                          (an Array of Strings) passed as the first\n   *                          argument\n   * @param {Object} [opts] - Optional options object.\n   * @param {Function} [opts.filter] - Filter function applied to each stackTrace line.\n   *                                   Lines which do not pass the filter won't be processesd.\n   * @param {boolean} [opts.cacheGlobally] - Whether to cache sourcemaps globally across multiple calls.\n   * @param {boolean} [opts.sync] - Whether to use synchronous ajax to load the sourcemaps.\n   */\n  var mapStackTrace = function(stack, done, opts) {\n    var lines;\n    var line;\n    var mapForUri = {};\n    var rows = {};\n    var fields;\n    var uri;\n    var expected_fields;\n    var regex;\n    var skip_lines;\n\n    var fetcher = new Fetcher(opts);\n\n    if (isChromeOrEdge() || isIE11Plus()) {\n      regex = /^ +at.+\\((.*):([0-9]+):([0-9]+)/;\n      expected_fields = 4;\n      // (skip first line containing exception message)\n      skip_lines = 1;\n    } else if (isFirefox() || isSafari()) {\n      regex = /@(.*):([0-9]+):([0-9]+)/;\n      expected_fields = 4;\n      skip_lines = 0;\n    } else {\n      throw new Error(\"unknown browser :(\");\n    }\n\n    lines = stack.split(\"\\n\").slice(skip_lines);\n\n    for (var i=0; i < lines.length; i++) {\n      line = lines[i];\n      if ( opts && opts.filter && !opts.filter(line) ) continue;\n      \n      fields = line.match(regex);\n      if (fields && fields.length === expected_fields) {\n        rows[i] = fields;\n        uri = fields[1];\n        if (!uri.match(/<anonymous>/)) {\n          fetcher.fetchScript(uri);\n        }\n      }\n    }\n\n    fetcher.sem.whenReady(function() {\n      var result = processSourceMaps(lines, rows, fetcher.mapForUri);\n      done(result);\n    });\n  };\n\n  var isChromeOrEdge = function() {\n    return navigator.userAgent.toLowerCase().indexOf('chrome') > -1;\n  };\n\n  var isFirefox = function() {\n    return navigator.userAgent.toLowerCase().indexOf('firefox') > -1;\n  };  \n\n  var isSafari = function() {\n    return navigator.userAgent.toLowerCase().indexOf('safari') > -1;\n  };\n\t\t\n  var isIE11Plus = function() {\n   \treturn document.documentMode && document.documentMode >= 11;\n  };\n\n\n  var Semaphore = function() {\n    this.count = 0;\n    this.pending = [];\n  };\n\n  Semaphore.prototype.incr = function() {\n    this.count++;\n  };\n\n  Semaphore.prototype.decr = function() {\n    this.count--;\n    this.flush();\n  };\n\n  Semaphore.prototype.whenReady = function(fn) {\n    this.pending.push(fn);\n    this.flush();\n  };\n\n  Semaphore.prototype.flush = function() {\n    if (this.count === 0) {\n        this.pending.forEach(function(fn) { fn(); });\n        this.pending = [];\n    }\n  };\n\n\n  var Fetcher = function(opts) {\n    this.sem = new Semaphore();\n    this.sync = opts && opts.sync;\n    this.mapForUri = opts && opts.cacheGlobally ? global_mapForUri : {};\n  };\n\n  Fetcher.prototype.ajax = function(uri, callback) {\n    var xhr = createXMLHTTPObject();\n    var that = this;\n    xhr.onreadystatechange = function() {\n      if (xhr.readyState == 4) {\n        callback.call(that, xhr, uri);\n      }\n    };\n    xhr.open(\"GET\", uri, !this.sync);\n    xhr.send();\n  }\n\n  Fetcher.prototype.fetchScript = function(uri) {\n    if (!(uri in this.mapForUri)) {\n      this.sem.incr();\n      this.mapForUri[uri] = null;\n    } else {\n      return;\n    }\n\n    this.ajax(uri, this.onScriptLoad);\n  };\n\n  var absUrlRegex = new RegExp('^(?:[a-z]+:)?//', 'i');\n\n  Fetcher.prototype.onScriptLoad = function(xhr, uri) {\n    if (xhr.status === 200 || (uri.slice(0, 7) === \"file://\" && xhr.status === 0)) {\n      // find .map in file.\n      //\n      // attempt to find it at the very end of the file, but tolerate trailing\n      // whitespace inserted by some packers.\n      var match = xhr.responseText.match(\"//# [s]ourceMappingURL=(.*)[\\\\s]*$\", \"m\");\n      if (match && match.length === 2) {\n        // get the map\n        var mapUri = match[1];\n\n        var embeddedSourceMap = mapUri.match(\"data:application/json;(charset=[^;]+;)?base64,(.*)\");\n\n        if (embeddedSourceMap && embeddedSourceMap[2]) {\n          this.mapForUri[uri] = new source_map_consumer.SourceMapConsumer(atob(embeddedSourceMap[2]));\n          this.sem.decr();\n        } else {\n          if (!absUrlRegex.test(mapUri)) {\n            // relative url; according to sourcemaps spec is 'source origin'\n            var origin;\n            var lastSlash = uri.lastIndexOf('/');\n            if (lastSlash !== -1) {\n              origin = uri.slice(0, lastSlash + 1);\n              mapUri = origin + mapUri;\n              // note if lastSlash === -1, actual script uri has no slash\n              // somehow, so no way to use it as a prefix... we give up and try\n              // as absolute\n            }\n          }\n\n          this.ajax(mapUri, function(xhr) {\n            if (xhr.status === 200 || (mapUri.slice(0, 7) === \"file://\" && xhr.status === 0)) {\n              this.mapForUri[uri] = new source_map_consumer.SourceMapConsumer(xhr.responseText);\n            }\n            this.sem.decr();\n          });\n        }\n      } else {\n        // no map\n        this.sem.decr();\n      }\n    } else {\n      // HTTP error fetching uri of the script\n      this.sem.decr();\n    }\n  };\n\n  var processSourceMaps = function(lines, rows, mapForUri) {\n    var result = [];\n    var map;\n    for (var i=0; i < lines.length; i++) {\n      var row = rows[i];\n      if (row) {\n        var uri = row[1];\n        var line = parseInt(row[2], 10);\n        var column = parseInt(row[3], 10);\n        map = mapForUri[uri];\n\n        if (map) {\n          // we think we have a map for that uri. call source-map library\n          var origPos = map.originalPositionFor(\n            { line: line, column: column });\n          result.push(formatOriginalPosition(origPos.source,\n            origPos.line, origPos.column, origPos.name || origName(lines[i])));\n        } else {\n          // we can't find a map for that url, but we parsed the row.\n          // reformat unchanged line for consistency with the sourcemapped\n          // lines.\n          result.push(formatOriginalPosition(uri, line, column, origName(lines[i])));\n        }\n      } else {\n        // we weren't able to parse the row, push back what we were given\n        result.push(lines[i]);\n      }\n    }\n\n    return result;\n  };\n\n  function origName(origLine) {\n    var match = String(origLine).match((isChromeOrEdge() || isIE11Plus()) ?\n      / +at +([^ ]*).*/ :\n      /([^@]*)@.*/);\n    return match && match[1];\n  }\n\n  var formatOriginalPosition = function(source, line, column, name) {\n    // mimic chrome's format\n    return \"    at \" + (name ? name : \"(unknown)\") +\n      \" (\" + source + \":\" + line + \":\" + column + \")\";\n  };\n\n  // xmlhttprequest boilerplate\n  var XMLHttpFactories = [\n\tfunction () {return new XMLHttpRequest();},\n\tfunction () {return new ActiveXObject(\"Msxml2.XMLHTTP\");},\n\tfunction () {return new ActiveXObject(\"Msxml3.XMLHTTP\");},\n\tfunction () {return new ActiveXObject(\"Microsoft.XMLHTTP\");}\n  ];\n\n  function createXMLHTTPObject() {\n      var xmlhttp = false;\n      for (var i=0;i<XMLHttpFactories.length;i++) {\n          try {\n              xmlhttp = XMLHttpFactories[i]();\n          }\n          catch (e) {\n              continue;\n          }\n          break;\n      }\n      return xmlhttp;\n  }\n\n  return {\n    mapStackTrace: mapStackTrace\n  }\n});\n","var g;\n\n// This works in non-strict mode\ng = (function() {\n\treturn this;\n})();\n\ntry {\n\t// This works if eval is allowed (see CSP)\n\tg = g || Function(\"return this\")() || (1, eval)(\"this\");\n} catch (e) {\n\t// This works if the window reference is available\n\tif (typeof window === \"object\") g = window;\n}\n\n// g can still be undefined, but nothing to do about it...\n// We return undefined, instead of nothing here, so it's\n// easier to handle this case. if(!global) { ...}\n\nmodule.exports = g;\n","// Copyright (c) 2017 Google Inc. All rights reserved.\n// This code may only be used under the BSD style license found at\n// http://polymer.github.io/LICENSE.txt\n// Code distributed by Google as part of this project is also\n// subject to an additional IP rights grant found at\n// http://polymer.github.io/PATENTS.txt\n\nexport function assert(test, message) {\n  if (!test) {\n    debugger; // eslint-disable-line no-debugger\n    throw new Error(message);\n  }\n}\n","/**\n * @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n'use strict';\n\nimport {AbstractDevtoolsChannel} from '../runtime/debug/abstract-devtools-channel.js';\n\nexport class DevtoolsChannel extends AbstractDevtoolsChannel {\n  constructor() {\n    super();\n    document.addEventListener('arcs-debug-in', e => this._handleMessage(e.detail));\n  }\n\n  _flush(messages) {\n    document.dispatchEvent(new CustomEvent('arcs-debug-out', {detail: messages}));\n  }\n}\n","// Copyright (c) 2017 Google Inc. All rights reserved.\n// This code may only be used under the BSD style license found at\n// http://polymer.github.io/LICENSE.txt\n// Code distributed by Google as part of this project is also\n// subject to an additional IP rights grant found at\n// http://polymer.github.io/PATENTS.txt\n\nexport const fs = {};\n","// Copyright (c) 2018 Google Inc. All rights reserved.\n// This code may only be used under the BSD style license found at\n// http://polymer.github.io/LICENSE.txt\n// Code distributed by Google as part of this project is also\n// subject to an additional IP rights grant found at\n// http://polymer.github.io/PATENTS.txt\n\n// \"Convert\" old-style module to ES6.\nconst smst = require('sourcemapped-stacktrace/sourcemapped-stacktrace.js');\nexport const mapStackTrace = smst.mapStackTrace;\n","// Copyright (c) 2017 Google Inc. All rights reserved.\n// This code may only be used under the BSD style license found at\n// http://polymer.github.io/LICENSE.txt\n// Code distributed by Google as part of this project is also\n// subject to an additional IP rights grant found at\n// http://polymer.github.io/PATENTS.txt\n\nexport const vm = {};\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n'use strict';\n\nimport {assert} from '../platform/assert-web.js';\nimport {ParticleSpec} from './ts-build/particle-spec.js';\nimport {Type} from './ts-build/type.js';\nimport {OuterPortAttachment} from './debug/outer-port-attachment.js';\nimport {DevtoolsConnection} from './debug/devtools-connection.js';\n\nclass ThingMapper {\n  constructor(prefix) {\n    this._prefix = prefix;\n    this._nextIdentifier = 0;\n    this._idMap = new Map();\n    this._reverseIdMap = new Map();\n  }\n\n  _newIdentifier() {\n    return this._prefix + (this._nextIdentifier++);\n  }\n\n  createMappingForThing(thing, requestedId) {\n    assert(!this._reverseIdMap.has(thing));\n    let id;\n    if (requestedId) {\n      id = requestedId;\n    } else if (thing.apiChannelMappingId) {\n      id = thing.apiChannelMappingId;\n    } else {\n      id = this._newIdentifier();\n    }\n    assert(!this._idMap.has(id), `${requestedId ? 'requestedId' : (thing.apiChannelMappingId ? 'apiChannelMappingId' : 'newIdentifier()')} ${id} already in use`);\n    this.establishThingMapping(id, thing);\n    return id;\n  }\n\n  maybeCreateMappingForThing(thing) {\n    if (this.hasMappingForThing(thing)) {\n      return this.identifierForThing(thing);\n    }\n    return this.createMappingForThing(thing);\n  }\n\n  async establishThingMapping(id, thing) {\n    let continuation;\n    if (Array.isArray(thing)) {\n      [thing, continuation] = thing;\n    }\n    this._idMap.set(id, thing);\n    if (thing instanceof Promise) {\n      assert(continuation == null);\n      await this.establishThingMapping(id, await thing);\n    } else {\n      this._reverseIdMap.set(thing, id);\n      if (continuation) {\n        await continuation();\n      }\n    }\n  }\n\n  hasMappingForThing(thing) {\n    return this._reverseIdMap.has(thing);\n  }\n\n  identifierForThing(thing) {\n    assert(this._reverseIdMap.has(thing), `Missing thing [${thing}]`);\n    return this._reverseIdMap.get(thing);\n  }\n\n  thingForIdentifier(id) {\n    assert(this._idMap.has(id), `Missing id: ${id}`);\n    return this._idMap.get(id);\n  }\n}\n\n\nexport class APIPort {\n  constructor(messagePort, prefix) {\n    this._port = messagePort;\n    this._mapper = new ThingMapper(prefix);\n    this._messageMap = new Map();\n    this._port.onmessage = async e => this._processMessage(e);\n    this._debugAttachment = null;\n    this.messageCount = 0;\n\n    this.Direct = {\n      convert: a => a,\n      unconvert: a => a\n    };\n\n    this.LocalMapped = {\n      convert: a => this._mapper.maybeCreateMappingForThing(a),\n      unconvert: a => this._mapper.thingForIdentifier(a)\n    };\n\n    this.Mapped = {\n      convert: a => this._mapper.identifierForThing(a),\n      unconvert: a => this._mapper.thingForIdentifier(a)\n    };\n\n    this.Map = function(keyprimitive, valueprimitive) {\n      return {\n        convert: a => {\n          const r = {};\n          a.forEach((value, key) => r[keyprimitive.convert(key)] = valueprimitive.convert(value));\n          return r;\n        },\n        unconvert: a => {\n          const r = new Map();\n          for (const key in a) {\n            r.set(\n                keyprimitive.unconvert(key), valueprimitive.unconvert(a[key]));\n          }\n          return r;\n        }\n      };\n    };\n\n    this.List = function(primitive) {\n      return {\n        convert: a => a.map(v => primitive.convert(v)),\n        unconvert: a => a.map(v => primitive.unconvert(v))\n      };\n    };\n\n    this.ByLiteral = function(clazz) {\n      return {\n        convert: a => a.toLiteral(),\n        unconvert: a => clazz.fromLiteral(a)\n      };\n    };\n\n    this._testingHook();\n  }\n\n  // Overridden by unit tests.\n  _testingHook() {\n  }\n\n  close() {\n    this._port.close();\n  }\n\n  async _processMessage(e) {\n    assert(this._messageMap.has(e.data.messageType));\n\n    this.messageCount++;\n\n    const handler = this._messageMap.get(e.data.messageType);\n    let args;\n    try {\n      args = this._unprocessArguments(handler.args, e.data.messageBody);\n    } catch (exc) {\n      console.error(`Exception during unmarshaling for ${e.data.messageType}`);\n      throw exc;\n    }\n    // If any of the converted arguments are still pending promises\n    // wait for them to complete before processing the message.\n    for (const arg of Object.values(args)) {\n      if (arg instanceof Promise) {\n        arg.then(() => this._processMessage(e));\n        return;\n      }\n    }\n    const handlerName = 'on' + e.data.messageType;\n    assert(this[handlerName], `no handler named ${handlerName}`);\n    if (this._debugAttachment) {\n      if (this._debugAttachment[handlerName]) this._debugAttachment[handlerName](args);\n      this._debugAttachment.handlePecMessage(handlerName, e.data.messageBody, true /* isReceiver */);\n    }\n    const result = this[handlerName](args);\n    if (handler.isInitializer) {\n      assert(args.identifier);\n      await this._mapper.establishThingMapping(args.identifier, result);\n    }\n  }\n\n  _processArguments(argumentTypes, args) {\n    const messageBody = {};\n    for (const argument in argumentTypes) {\n      messageBody[argument] = argumentTypes[argument].convert(args[argument]);\n    }\n    return messageBody;\n  }\n\n  _unprocessArguments(argumentTypes, args) {\n    const messageBody = {};\n    for (const argument in argumentTypes) {\n      messageBody[argument] = argumentTypes[argument].unconvert(args[argument]);\n    }\n    return messageBody;\n  }\n\n  registerCall(name, argumentTypes) {\n    this[name] = args => {\n      const call = {messageType: name, messageBody: this._processArguments(argumentTypes, args)};\n      this.messageCount++;\n      this._port.postMessage(call);\n      if (this._debugAttachment) {\n        if (this._debugAttachment[name]) this._debugAttachment[name](args);\n        this._debugAttachment.handlePecMessage(name, call.messageBody, false /* isReceiver */);\n      }\n    };\n  }\n\n  registerHandler(name, argumentTypes) {\n    this._messageMap.set(name, {args: argumentTypes});\n  }\n\n  registerInitializerHandler(name, argumentTypes) {\n    argumentTypes.identifier = this.Direct;\n    this._messageMap.set(name, {\n      isInitializer: true,\n      args: argumentTypes,\n    });\n  }\n\n  registerRedundantInitializer(name, argumentTypes, mappingIdArg) {\n    this.registerInitializer(name, argumentTypes, mappingIdArg, true /* redundant */);\n  }\n\n  registerInitializer(name, argumentTypes, mappingIdArg = null, redundant = false) {\n    this[name] = (thing, args) => {\n      if (redundant && this._mapper.hasMappingForThing(thing)) return;\n      const call = {messageType: name, messageBody: this._processArguments(argumentTypes, args)};\n      const requestedId = mappingIdArg && args[mappingIdArg];\n      call.messageBody.identifier = this._mapper.createMappingForThing(thing, requestedId);\n      this.messageCount++;\n      this._port.postMessage(call);\n      if (this._debugAttachment) {\n        if (this._debugAttachment[name]) this._debugAttachment[name](thing, args);\n        this._debugAttachment.handlePecMessage(name, call.messageBody, false /* isReceiver */);\n      }\n    };\n  }\n}\n\nexport class PECOuterPort extends APIPort {\n  constructor(messagePort, arc) {\n    super(messagePort, 'o');\n\n    this.registerCall('Stop', {});\n    this.registerRedundantInitializer('DefineHandle', {type: this.ByLiteral(Type), name: this.Direct});\n    this.registerInitializer('InstantiateParticle',\n      {id: this.Direct, spec: this.ByLiteral(ParticleSpec), handles: this.Map(this.Direct, this.Mapped)}, 'id');\n\n    this.registerCall('UIEvent', {particle: this.Mapped, slotName: this.Direct, event: this.Direct});\n    this.registerCall('SimpleCallback', {callback: this.Direct, data: this.Direct});\n    this.registerCall('AwaitIdle', {version: this.Direct});\n    this.registerCall('StartRender', {particle: this.Mapped, slotName: this.Direct, contentTypes: this.List(this.Direct)});\n    this.registerCall('StopRender', {particle: this.Mapped, slotName: this.Direct});\n\n    this.registerHandler('Render', {particle: this.Mapped, slotName: this.Direct, content: this.Direct});\n    this.registerHandler('InitializeProxy', {handle: this.Mapped, callback: this.Direct});\n    this.registerHandler('SynchronizeProxy', {handle: this.Mapped, callback: this.Direct});\n    this.registerHandler('HandleGet', {handle: this.Mapped, callback: this.Direct, particleId: this.Direct});\n    this.registerHandler('HandleToList', {handle: this.Mapped, callback: this.Direct, particleId: this.Direct});\n    this.registerHandler('HandleSet', {handle: this.Mapped, data: this.Direct, particleId: this.Direct, barrier: this.Direct});\n    this.registerHandler('HandleClear', {handle: this.Mapped, particleId: this.Direct, barrier: this.Direct});\n    this.registerHandler('HandleStore', {handle: this.Mapped, callback: this.Direct, data: this.Direct, particleId: this.Direct});\n    this.registerHandler('HandleRemove', {handle: this.Mapped, callback: this.Direct, data: this.Direct, particleId: this.Direct});\n    this.registerHandler('HandleRemoveMultiple', {handle: this.Mapped, callback: this.Direct, data: this.Direct, particleId: this.Direct});\n    this.registerHandler('HandleStream', {handle: this.Mapped, callback: this.Direct, pageSize: this.Direct, forward: this.Direct});\n    this.registerHandler('StreamCursorNext', {handle: this.Mapped, callback: this.Direct, cursorId: this.Direct});\n    this.registerHandler('StreamCursorClose', {handle: this.Mapped, cursorId: this.Direct});\n\n    this.registerHandler('Idle', {version: this.Direct, relevance: this.Map(this.Mapped, this.Direct)});\n\n    this.registerHandler('GetBackingStore', {callback: this.Direct, storageKey: this.Direct, type: this.ByLiteral(Type)});\n    this.registerInitializer('GetBackingStoreCallback', {callback: this.Direct, type: this.ByLiteral(Type), name: this.Direct, id: this.Direct, storageKey: this.Direct});\n\n    this.registerHandler('ConstructInnerArc', {callback: this.Direct, particle: this.Mapped});\n    this.registerCall('ConstructArcCallback', {callback: this.Direct, arc: this.LocalMapped});\n\n    this.registerHandler('ArcCreateHandle', {callback: this.Direct, arc: this.LocalMapped, type: this.ByLiteral(Type), name: this.Direct});\n    this.registerInitializer('CreateHandleCallback', {callback: this.Direct, type: this.ByLiteral(Type), name: this.Direct, id: this.Direct});\n    this.registerHandler('ArcMapHandle', {callback: this.Direct, arc: this.LocalMapped, handle: this.Mapped});\n    this.registerInitializer('MapHandleCallback', {callback: this.Direct, id: this.Direct});\n    this.registerHandler('ArcCreateSlot',\n      {callback: this.Direct, arc: this.LocalMapped, transformationParticle: this.Mapped, transformationSlotName: this.Direct, hostedParticleName: this.Direct, hostedSlotName: this.Direct, handleId: this.Direct});\n    this.registerInitializer('CreateSlotCallback', {callback: this.Direct, hostedSlotId: this.Direct});\n    this.registerCall('InnerArcRender', {transformationParticle: this.Mapped, transformationSlotName: this.Direct, hostedSlotId: this.Direct, content: this.Direct});\n\n    this.registerHandler('ArcLoadRecipe', {arc: this.LocalMapped, recipe: this.Direct, callback: this.Direct});\n\n    this.registerHandler('RaiseSystemException', {exception: this.Direct, methodName: this.Direct, particleId: this.Direct});\n\n    DevtoolsConnection.onceConnected.then(\n      devtoolsChannel => this._debugAttachment = new OuterPortAttachment(arc, devtoolsChannel));\n  }\n}\n\nexport class PECInnerPort extends APIPort {\n  constructor(messagePort) {\n    super(messagePort, 'i');\n\n    this.registerHandler('Stop', {});\n    this.registerInitializerHandler('DefineHandle', {type: this.ByLiteral(Type), name: this.Direct});\n    this.registerInitializerHandler('InstantiateParticle',\n      {id: this.Direct, spec: this.ByLiteral(ParticleSpec), handles: this.Map(this.Direct, this.Mapped)});\n\n    this.registerHandler('UIEvent', {particle: this.Mapped, slotName: this.Direct, event: this.Direct});\n    this.registerHandler('SimpleCallback', {callback: this.LocalMapped, data: this.Direct});\n    this.registerHandler('AwaitIdle', {version: this.Direct});\n    this.registerHandler('StartRender', {particle: this.Mapped, slotName: this.Direct, contentTypes: this.List(this.Direct)});\n    this.registerHandler('StopRender', {particle: this.Mapped, slotName: this.Direct});\n\n    this.registerCall('Render', {particle: this.Mapped, slotName: this.Direct, content: this.Direct});\n    this.registerCall('InitializeProxy', {handle: this.Mapped, callback: this.LocalMapped});\n    this.registerCall('SynchronizeProxy', {handle: this.Mapped, callback: this.LocalMapped});\n    this.registerCall('HandleGet', {handle: this.Mapped, callback: this.LocalMapped, particleId: this.Direct});\n    this.registerCall('HandleToList', {handle: this.Mapped, callback: this.LocalMapped, particleId: this.Direct});\n    this.registerCall('HandleSet', {handle: this.Mapped, data: this.Direct, particleId: this.Direct, barrier: this.Direct});\n    this.registerCall('HandleClear', {handle: this.Mapped, particleId: this.Direct, barrier: this.Direct});\n    this.registerCall('HandleStore', {handle: this.Mapped, callback: this.LocalMapped, data: this.Direct, particleId: this.Direct});\n    this.registerCall('HandleRemove', {handle: this.Mapped, callback: this.LocalMapped, data: this.Direct, particleId: this.Direct});\n    this.registerCall('HandleRemoveMultiple', {handle: this.Mapped, callback: this.LocalMapped, data: this.Direct, particleId: this.Direct});\n    this.registerCall('HandleStream', {handle: this.Mapped, callback: this.LocalMapped, pageSize: this.Direct, forward: this.Direct});\n    this.registerCall('StreamCursorNext', {handle: this.Mapped, callback: this.LocalMapped, cursorId: this.Direct});\n    this.registerCall('StreamCursorClose', {handle: this.Mapped, cursorId: this.Direct});\n\n    this.registerCall('Idle', {version: this.Direct, relevance: this.Map(this.Mapped, this.Direct)});\n\n    this.registerCall('GetBackingStore', {callback: this.LocalMapped, storageKey: this.Direct, type: this.ByLiteral(Type)});\n    this.registerInitializerHandler('GetBackingStoreCallback', {callback: this.LocalMapped, type: this.ByLiteral(Type), name: this.Direct, id: this.Direct, storageKey: this.Direct});\n\n    this.registerCall('ConstructInnerArc', {callback: this.LocalMapped, particle: this.Mapped});\n    this.registerHandler('ConstructArcCallback', {callback: this.LocalMapped, arc: this.Direct});\n\n    this.registerCall('ArcCreateHandle', {callback: this.LocalMapped, arc: this.Direct, type: this.ByLiteral(Type), name: this.Direct});\n    this.registerInitializerHandler('CreateHandleCallback', {callback: this.LocalMapped, type: this.ByLiteral(Type), name: this.Direct, id: this.Direct});\n    this.registerCall('ArcMapHandle', {callback: this.LocalMapped, arc: this.Direct, handle: this.Mapped});\n    this.registerInitializerHandler('MapHandleCallback', {callback: this.LocalMapped, id: this.Direct});\n    this.registerCall('ArcCreateSlot',\n      {callback: this.LocalMapped, arc: this.Direct, transformationParticle: this.Mapped, transformationSlotName: this.Direct, hostedParticleName: this.Direct, hostedSlotName: this.Direct, handleId: this.Direct});\n    this.registerInitializerHandler('CreateSlotCallback', {callback: this.LocalMapped, hostedSlotId: this.Direct});\n    this.registerHandler('InnerArcRender', {transformationParticle: this.Mapped, transformationSlotName: this.Direct, hostedSlotId: this.Direct, content: this.Direct});\n\n    this.registerCall('ArcLoadRecipe', {arc: this.Direct, recipe: this.Direct, callback: this.LocalMapped});\n\n    this.registerCall('RaiseSystemException', {exception: this.Direct, methodName: this.Direct, particleId: this.Direct});\n  }\n}\n","/**\n * @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n'use strict';\n\nimport {assert} from '../../platform/assert-web.js';\n\nexport class AbstractDevtoolsChannel {\n  constructor() {\n    this.debouncedMessages = [];\n    this.debouncing = false;\n    this.messageListeners = new Map();\n  }\n\n  send(message) {\n    this.debouncedMessages.push(message);\n    if (!this.debouncing) {\n      this.debouncing = true;\n      setTimeout(() => {\n        this._flush(this.debouncedMessages);\n        this.debouncedMessages = [];\n        this.debouncing = false;\n      }, 100);\n    }\n  }\n\n  listen(arcOrId, messageType, callback) {\n    assert(messageType);\n    assert(arcOrId);\n    const arcId = typeof arcOrId === 'string' ? arcOrId : arcOrId.id.toString();\n    const key = `${arcId}/${messageType}`;\n    let listeners = this.messageListeners.get(key);\n    if (!listeners) this.messageListeners.set(key, listeners = []);\n    listeners.push(callback);\n  }\n\n  _handleMessage(msg) {\n    const listeners = this.messageListeners.get(`${msg.arcId}/${msg.messageType}`);\n    if (!listeners) {\n      console.warn(`No one is listening to ${msg.messageType} message`);\n    } else {\n      for (const listener of listeners) listener(msg);\n    }\n  }\n\n  _flush(messages) {\n    throw 'Not implemented in an abstract class';\n  }\n}\n","/**\n * @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n\nimport {assert} from '../../platform/assert-web.js';\nimport {DevtoolsChannel} from '../../platform/devtools-channel-web.js';\nimport {DevtoolsChannelStub} from './testing/devtools-channel-stub.js';\nimport {DevtoolsBroker} from '../../devtools/shared/devtools-broker.js';\n\nlet channel = null;\nlet isConnected = false;\nlet onceConnectedResolve = null;\nlet onceConnected = new Promise(resolve => onceConnectedResolve = resolve);\n\nDevtoolsBroker.onceConnected.then(() => {\n  DevtoolsConnection.ensure();\n  onceConnectedResolve(channel);\n  isConnected = true;\n});\n\nexport class DevtoolsConnection {\n  static get isConnected() {\n    return isConnected;\n  }\n  static get onceConnected() {\n    return onceConnected;\n  }\n  static get() {\n    return channel;\n  }\n  static ensure() {\n    if (!channel) channel = new DevtoolsChannel();\n  }\n}\n\nexport class DevtoolsForTests {\n  static get channel() {\n    return channel;\n  }\n  static ensureStub() {\n    assert(!channel);\n    channel = new DevtoolsChannelStub();\n    onceConnectedResolve(channel);\n    isConnected = true;\n  }\n  static reset() {\n    assert(channel);\n    isConnected = false;\n    onceConnectedResolve = null;\n    onceConnected = new Promise(resolve => onceConnectedResolve = resolve);\n    channel = null;\n  }\n}\n","/**\n * @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n'use strict';\n\nimport {mapStackTrace} from '../../platform/sourcemapped-stacktrace-web.js';\n\nexport class OuterPortAttachment {\n  constructor(arc, devtoolsChannel) {\n    this._devtoolsChannel = devtoolsChannel;\n    this._arcIdString = arc.id.toString();\n    this._speculative = arc.isSpeculative;\n    this._callbackRegistry = {};\n    this._particleRegistry = {};\n  }\n\n  handlePecMessage(name, pecMsgBody, isReceiver) {\n    // Skip speculative and pipes arcs for now.\n    if (this._arcIdString.endsWith('-pipes') || this._speculative) return;\n\n    const stack = [];\n    if (!isReceiver) {\n      // The slice discards the first two stack frames corresponding to this\n      // function and the API channel function, which is already being displayed\n      // in the log entry.\n      mapStackTrace(new Error().stack, mapped => mapped.slice(2).map(f => {\n        // Each frame has the form '    at function (source:line:column)'.\n        // Extract the function name and source:line:column text, then set up\n        // a frame object with the following fields:\n        //   location: text to display as the source in devtools Arcs panel\n        //   target: URL to open in devtools Sources panel\n        //   targetClass: CSS class specifier to attach to the location text\n        const m = f.match(/^ {4}at (.*) \\((.*)\\)$/);\n        if (m === null) return;\n\n        const frame = {method: m[1]};\n        const source = m[2].replace(/:[0-9]+$/, '');\n        if (source.startsWith('http')) {\n          // 'http://<url>/arcs.*/shell/file.js:150'\n          // -> location: 'shell/file.js:150', target: same as source\n          frame.location = source.replace(/^http.*\\/arcs[^/]*\\//, '');\n          frame.target = source;\n          frame.targetClass = 'link';\n        } else if (source.startsWith('webpack')) {\n          // 'webpack:///runtime/sub/file.js:18'\n          // -> location: 'runtime/sub/file.js:18', target: 'webpack:///./runtime/sub/file.js:18'\n          frame.location = source.slice(11);\n          frame.target = `webpack:///./${frame.location}`;\n          frame.targetClass = 'link';\n        } else {\n          // '<anonymous>' (or similar)\n          frame.location = source;\n          frame.target = null;\n          frame.targetClass = 'noLink';\n        }\n        stack.push(frame);\n      }), {sync: true});\n    }\n\n    this._devtoolsChannel.send({\n      messageType: 'PecLog',\n      messageBody: {name, isReceiver, pecMsgBody, timestamp: Date.now(), stack},\n    });\n  }\n\n  InstantiateParticle(particle, {id, spec, handles}) {\n    this._particleRegistry[id] = spec;\n    this._devtoolsChannel.send({\n      messageType: 'InstantiateParticle',\n      messageBody: Object.assign(\n        this._arcMetadata(),\n        this._trimParticleSpec(id, spec, handles)\n      )\n    });\n  }\n\n  SimpleCallback({callback, data}) {\n    const callbackDetails = this._callbackRegistry[callback];\n    if (callbackDetails) {\n      // Copying callback data, as the callback can be used multiple times.\n      this._sendDataflowMessage(Object.assign({}, callbackDetails), data);\n    }\n  }\n\n  onInitializeProxy({handle, callback}) {\n    this._callbackRegistry[callback] = this._describeHandleCall(\n      {operation: 'on-change', handle});\n  }\n\n  onSynchronizeProxy({handle, callback}) {\n    this._callbackRegistry[callback] = this._describeHandleCall(\n      {operation: 'sync-model', handle});\n  }\n\n  onHandleGet({handle, callback, particleId}) {\n    this._callbackRegistry[callback] = this._describeHandleCall(\n      {operation: 'get', handle, particleId});\n  }\n\n  onHandleToList({handle, callback, particleId}) {\n    this._callbackRegistry[callback] = this._describeHandleCall(\n      {operation: 'toList', handle, particleId});\n  }\n\n  onHandleSet({handle, data, particleId, barrier}) {\n    this._logHandleCall({operation: 'set', handle, data, particleId});\n  }\n\n  onHandleStore({handle, data, particleId}) {\n    this._logHandleCall({operation: 'store', handle, data, particleId});\n  }\n\n  onHandleClear({handle, particleId, barrier}) {\n    this._logHandleCall({operation: 'clear', handle, particleId});\n  }\n\n  onHandleRemove({handle, data, particleId}) {\n    this._logHandleCall({operation: 'remove', handle, data, particleId});\n  }\n\n  // TODO: add BigCollection stream APIs?\n\n  _logHandleCall(args) {\n    this._sendDataflowMessage(this._describeHandleCall(args), args.data);\n  }\n\n  _sendDataflowMessage(messageBody, data) {\n    messageBody.data = JSON.stringify(data);\n    messageBody.timestamp = Date.now();\n    this._devtoolsChannel.send({messageType: 'dataflow', messageBody});\n  }\n\n  _describeHandleCall({operation, handle, particleId}) {\n    const metadata = Object.assign(this._arcMetadata(), {\n      operation,\n      handle: this._describeHandle(handle)\n    });\n    if (particleId) metadata.particle = this._describeParticle(particleId);\n    return metadata;\n  }\n\n  _arcMetadata() {\n    return {\n      arcId: this._arcIdString,\n      speculative: this._speculative\n    };\n  }\n\n  _trimParticleSpec(id, spec, handles) {\n    const connections = {};\n    spec.connectionMap.forEach((value, key) => {\n      connections[key] = Object.assign({\n        direction: value.direction\n      }, this._describeHandle(handles.get(key)));\n    });\n    return {\n      id,\n      name: spec.name,\n      connections,\n      implFile: spec.implFile\n    };\n  }\n\n  _describeParticle(id) {\n    const particleSpec = this._particleRegistry[id];\n    return {\n      id,\n      name: particleSpec && particleSpec.name\n      // TODO: Send entire spec only once and refer to it by ID in the tool.\n    };\n  }\n\n  _describeHandle(handle) {\n    return {\n      id: handle.id,\n      storageKey: handle._storageKey,\n      name: handle.name,\n      description: handle.description,\n      type: this._describeHandleType(handle._type)\n    };\n  }\n\n  // TODO: This is fragile and incomplete. Change this into sending entire\n  //       handle object once and refer back to it via its ID in the tool.\n  _describeHandleType(handleType) {\n    switch (handleType.constructor.name) {\n      case 'Type':\n        switch (handleType.tag) {\n          case 'Collection': return `[${this._describeHandleType(handleType.data)}]`;\n          case 'Entity': return this._describeHandleType(handleType.data);\n          default: return `${handleType.tag} ${this._describeHandleType(handleType.data)}`;\n        }\n      case 'Schema':\n        return handleType.name;\n      case 'Shape':\n        return 'Shape';\n    }\n    return '';\n  }\n}\n","/**\n * @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n\nexport class DevtoolsChannelStub {\n  constructor() {\n    this._messages = [];\n  }\n\n  get messages() {\n    return this._messages;\n  }\n\n  send(message) {\n    this._messages.push(JSON.parse(JSON.stringify(message)));\n  }\n\n  listen(arcOrId, messageType, callback) { /* No-op */ }\n\n  clear() {\n    this._messages.length = 0;\n  }\n}\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n'use strict';\n\nimport {assert} from '../platform/assert-web.js';\nimport {Particle} from './particle.js';\n\n/** @class DomParticleBase\n * Particle that interoperates with DOM.\n */\nexport class DomParticleBase extends Particle {\n  constructor() {\n    super();\n  }\n  /** @method get template()\n   * Override to return a String defining primary markup.\n   */\n  get template() {\n    return '';\n  }\n  /** @method getTemplate(slotName)\n   * Override to return a String defining primary markup for the given slot name.\n   */\n  getTemplate(slotName) {\n    // TODO: only supports a single template for now. add multiple templates support.\n    return this.template;\n  }\n  /** @method getTemplateName(slotName)\n   * Override to return a String defining the name of the template for the given slot name.\n   */\n  getTemplateName(slotName) {\n    // TODO: only supports a single template for now. add multiple templates support.\n    return `default`;\n  }\n  /** @method shouldRender()\n   * Override to return false if the Particle won't use\n   * it's slot.\n   */\n  shouldRender() {\n    return true;\n  }\n  /** @method render()\n   * Override to return a dictionary to map into the template.\n   */\n  render() {\n    return {};\n  }\n  renderSlot(slotName, contentTypes) {\n    const stateArgs = this._getStateArgs();\n    const slot = this.getSlot(slotName);\n    if (!slot) {\n      return; // didn't receive StartRender.\n    }\n    // Set this to support multiple slots consumed by a particle, without needing\n    // to pass slotName to particle's render method, where it useless in most cases.\n    this.currentSlotName = slotName;\n    contentTypes.forEach(ct => slot._requestedContentTypes.add(ct));\n    // TODO(sjmiles): redundant, same answer for every slot\n    if (this.shouldRender(...stateArgs)) {\n      const content = {};\n      if (slot._requestedContentTypes.has('template')) {\n        content.template = this.getTemplate(slot.slotName);\n      }\n      if (slot._requestedContentTypes.has('model')) {\n        content.model = this.render(...stateArgs);\n      }\n      content.templateName = this.getTemplateName(slot.slotName);\n      slot.render(content);\n    } else if (slot.isRendered) {\n      // Send empty object, to clear rendered slot contents.\n      slot.render({});\n    }\n    this.currentSlotName = undefined;\n  }\n  _getStateArgs() {\n    return [];\n  }\n  forceRenderTemplate(slotName) {\n    this._slotByName.forEach((slot, name) => {\n      if (!slotName || (name == slotName)) {\n        slot._requestedContentTypes.add('template');\n      }\n    });\n  }\n  fireEvent(slotName, {handler, data}) {\n    if (this[handler]) {\n      this[handler]({data});\n    }\n  }\n  setParticleDescription(pattern) {\n    if (typeof pattern === 'string') {\n      return super.setParticleDescription(pattern);\n    }\n    assert(!!pattern.template && !!pattern.model, 'Description pattern must either be string or have template and model');\n    super.setDescriptionPattern('_template_', pattern.template);\n    super.setDescriptionPattern('_model_', JSON.stringify(pattern.model));\n  }\n  /** @method clearHandle(handleName)\n   * Remove entities from named handle.\n   */\n  async clearHandle(handleName) {\n    const handle = this.handles.get(handleName);\n    if (handle.clear) {\n      handle.clear();\n    } else {\n      const entities = await handle.toList();\n      if (entities) {\n        return Promise.all(entities.map(entity => handle.remove(entity)));\n      }\n    }\n  }\n  /** @method mergeEntitiesToHandle(handleName, entityArray)\n   * Merge entities from Array into named handle.\n   */\n  async mergeEntitiesToHandle(handleName, entities) {\n    const idMap = {};\n    const handle = this.handles.get(handleName);\n    const handleEntities = await handle.toList();\n    handleEntities.forEach(entity => idMap[entity.id] = entity);\n    for (const entity of entities) {\n      if (!idMap[entity.id]) {\n        handle.store(entity);\n      }\n    }\n    //Promise.all(entities.map(entity => !idMap[entity.id] && handle.store(entity)));\n    //Promise.all(entities.map(entity => handle.store(entity)));\n  }\n  /** @method appendEntitiesToHandle(handleName, entityArray)\n   * Append entities from Array to named handle.\n   */\n  async appendEntitiesToHandle(handleName, entities) {\n    const handle = this.handles.get(handleName);\n    if (handle) {\n      Promise.all(entities.map(entity => handle.store(entity)));\n    }\n  }\n  /** @method appendRawDataToHandle(handleName, rawDataArray)\n   * Create an entity from each rawData, and append to named handle.\n   */\n  async appendRawDataToHandle(handleName, rawDataArray) {\n    const handle = this.handles.get(handleName);\n    if (handle) {\n      Promise.all(rawDataArray.map(raw => handle.store(new (handle.entityClass)(raw))));\n    }\n  }\n  /** @method updateVariable(handleName, rawData)\n   * Modify value of named handle. A new entity is created\n   * from `rawData` (`new [EntityClass](rawData)`).\n   */\n  updateVariable(handleName, rawData) {\n    const handle = this.handles.get(handleName);\n    if (handle) {\n      const entity = new (handle.entityClass)(rawData);\n      handle.set(entity);\n      return entity;\n    }\n  }\n  /** @method updateSet(handleName, entity)\n   * Modify or insert `entity` into named handle.\n   * Modification is done by removing the old entity and reinserting the new one.\n   */\n  async updateSet(handleName, entity) {\n    // Set the entity into the right place in the set. If we find it\n    // already present replace it, otherwise, add it.\n    // TODO(dstockwell): Replace this with happy entity mutation approach.\n    const handle = this.handles.get(handleName);\n    if (handle) {\n      // const entities = await handle.toList();\n      // const target = entities.find(r => r.id === entity.id);\n      // if (target) {\n      //   handle.remove(target);\n      // }\n      handle.remove(entity);\n      handle.store(entity);\n    }\n  }\n  /** @method boxQuery(box, userid)\n   * Returns array of Entities found in BOXED data `box` that are owned by `userid`\n   */\n  boxQuery(box, userid) {\n    return box.filter(item => userid === item.getUserID().split('|')[0]);\n  }\n}\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n'use strict';\n\nimport {XenStateMixin} from '../shell/components/xen/xen-state.js';\nimport {DomParticleBase} from './dom-particle-base.js';\n\n/** @class DomParticle\n * Particle that interoperates with DOM and uses a simple state system\n * to handle updates.\n */\nexport class DomParticle extends XenStateMixin(DomParticleBase) {\n  constructor() {\n    super();\n    // alias properties to remove `_`\n    this.state = this._state;\n    this.props = this._props;\n  }\n  /** @method willReceiveProps(props, state, oldProps, oldState)\n   * Override if necessary, to do things when props change.\n   */\n  willReceiveProps() {\n  }\n  /** @method update(props, state, oldProps, oldState)\n   * Override if necessary, to modify superclass config.\n   */\n  update() {\n  }\n  /** @method shouldRender(props, state, oldProps, oldState)\n   * Override to return false if the Particle won't use\n   * it's slot.\n   */\n  shouldRender() {\n    return true;\n  }\n  /** @method render(props, state, oldProps, oldState)\n   * Override to return a dictionary to map into the template.\n   */\n  render() {\n    return {};\n  }\n  /** @method setState(state)\n   * Copy values from `state` into the particle's internal state,\n   * triggering an update cycle unless currently updating.\n   */\n  setState(state) {\n    return this._setState(state);\n  }\n  // TODO(sjmiles): deprecated, just use setState\n  setIfDirty(state) {\n    console.warn('DomParticle: `setIfDirty` is deprecated, please use `setState` instead');\n    return this._setState(state);\n  }\n  /** @method configureHandles(handles)\n   * This is called once during particle setup. Override to control sync and update\n   * configuration on specific handles (via their configure() method).\n   * `handles` is a map from names to handle instances.\n   */\n  configureHandles(handles) {\n    // Example: handles.get('foo').configure({keepSynced: false});\n  }\n  /** @method get config()\n   * Override if necessary, to modify superclass config.\n   */\n  get config() {\n    // TODO(sjmiles): getter that does work is a bad idea, this is temporary\n    return {\n      handleNames: this.spec.inputs.map(i => i.name),\n      // TODO(mmandlis): this.spec needs to be replaced with a particle-spec loaded from\n      // .manifest files, instead of .ptcl ones.\n      slotNames: [...this.spec.slots.values()].map(s => s.name)\n    };\n  }\n  // affordances for aliasing methods to remove `_`\n  _willReceiveProps(...args) {\n    this.willReceiveProps(...args);\n  }\n  _update(...args) {\n    this.update(...args);\n    if (this.shouldRender(...args)) { // TODO: should shouldRender be slot specific?\n      this.relevance = 1; // TODO: improve relevance signal.\n    }\n    this.config.slotNames.forEach(s => this.renderSlot(s, ['model']));\n  }\n  //\n  // deprecated\n  get _views() {\n    console.warn(`Particle ${this.spec.name} uses deprecated _views getter.`);\n    return this.handles;\n  }\n  async setViews(views) {\n    console.warn(`Particle ${this.spec.name} uses deprecated setViews method.`);\n    return this.setHandles(views);\n  }\n  // end deprecated\n  //\n  async setHandles(handles) {\n    this.configureHandles(handles);\n    this.handles = handles;\n    this._handlesToSync = new Set();\n    for (const name of this.config.handleNames) {\n      const handle = handles.get(name);\n      if (handle && handle.options.keepSynced && handle.options.notifySync) {\n        this._handlesToSync.add(name);\n      }\n    }\n    // make sure we invalidate once, even if there are no incoming handles\n    setTimeout(() => !this._hasProps && this._invalidate(), 200);\n    //this._invalidate();\n  }\n  async onHandleSync(handle, model) {\n    this._handlesToSync.delete(handle.name);\n    if (this._handlesToSync.size == 0) {\n      await this._handlesToProps();\n    }\n  }\n  async onHandleUpdate(handle, update) {\n    // TODO(sjmiles): debounce handles updates\n    const work = () => {\n      //console.warn(handle, update);\n      this._handlesToProps();\n    };\n    this._debounce('handleUpdateDebounce', work, 100);\n  }\n  async _handlesToProps() {\n    const config = this.config;\n    // acquire (async) list data from handles; BigCollections map to the handle itself\n    const data = await Promise.all(\n      config.handleNames\n      .map(name => this.handles.get(name))\n      .map(handle => {\n        if (handle.toList) return handle.toList();\n        if (handle.get) return handle.get();\n        return handle;\n      })\n    );\n    // convert handle data (array) into props (dictionary)\n    const props = Object.create(null);\n    config.handleNames.forEach((name, i) => {\n      props[name] = data[i];\n    });\n    this._hasProps = true;\n    this._setProps(props);\n  }\n  fireEvent(slotName, {handler, data}) {\n    if (this[handler]) {\n      // TODO(sjmiles): remove `this._state` parameter\n      this[handler]({data}, this._state);\n    }\n  }\n  _debounce(key, func, delay) {\n    const subkey = `_debounce_${key}`;\n    if (!this._state[subkey]) {\n      this.startBusy();\n    }\n    const idleThenFunc = () => {\n      this.doneBusy();\n      func();\n      this._state[subkey] = null;\n    };\n    super._debounce(key, idleThenFunc, delay);\n  }\n}\n","// Copyright (c) 2017 Google Inc. All rights reserved.\n// This code may only be used under the BSD style license found at\n// http://polymer.github.io/LICENSE.txt\n// Code distributed by Google as part of this project is also\n// subject to an additional IP rights grant found at\n// http://polymer.github.io/PATENTS.txt\n\n// 'export default fetch' works because 'fetch' is evaluated as an expression, which finds the\n// appropriate global definition - but we don't want to use default exports.\n// 'export {fetch}' doesn't work because 'fetch' is just a name in that context and is not defined.\n// So we need to use an expression to find the global fetch function then map that for export.\n\nconst local_fetch = fetch;\nexport {local_fetch as fetch};\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n'use strict';\n\nimport {assert} from '../platform/assert-web.js';\nimport {ParticleSpec} from './ts-build/particle-spec.js';\nimport {TransformationDomParticle} from './transformation-dom-particle.js';\n\nexport class MultiplexerDomParticle extends TransformationDomParticle {\n  constructor() {\n    super();\n    this._itemSubIdByHostedSlotId = new Map();\n    this._connByHostedConn = new Map();\n  }\n\n  async _mapParticleConnections(\n      listHandleName,\n      particleHandleName,\n      hostedParticle,\n      handles,\n      arc) {\n    const otherMappedHandles = [];\n    const otherConnections = [];\n    let index = 2;\n    const skipConnectionNames = [listHandleName, particleHandleName];\n    for (const [connectionName, otherHandle] of handles) {\n      if (skipConnectionNames.includes(connectionName)) {\n        continue;\n      }\n      // TODO(wkorman): For items with embedded recipes we may need a map\n      // (perhaps id to index) to make sure we don't map a handle into the inner\n      // arc multiple times unnecessarily.\n      otherMappedHandles.push(\n          `use '${await arc.mapHandle(otherHandle._proxy)}' as v${index}`);\n      const hostedOtherConnection = hostedParticle.connections.find(\n          conn => conn.isCompatibleType(otherHandle.type));\n      if (hostedOtherConnection) {\n        otherConnections.push(`${hostedOtherConnection.name} = v${index++}`);\n        // TODO(wkorman): For items with embedded recipes where we may have a\n        // different particle rendering each item, we need to track\n        // |connByHostedConn| keyed on the particle type.\n        this._connByHostedConn.set(hostedOtherConnection.name, connectionName);\n      }\n    }\n    return [otherMappedHandles, otherConnections];\n  }\n\n  async setHandles(handles) {\n    this.handleIds = {};\n    const arc = await this.constructInnerArc();\n    const listHandleName = 'list';\n    const particleHandleName = 'hostedParticle';\n    const particleHandle = handles.get(particleHandleName);\n    let hostedParticle = null;\n    let otherMappedHandles = [];\n    let otherConnections = [];\n    if (particleHandle) {\n      hostedParticle = await particleHandle.get();\n      if (hostedParticle) {\n        [otherMappedHandles, otherConnections] =\n            await this._mapParticleConnections(\n                listHandleName, particleHandleName, hostedParticle, handles, arc);\n      }\n    }\n    this.setState({\n      arc,\n      type: handles.get(listHandleName).type,\n      hostedParticle,\n      otherMappedHandles,\n      otherConnections\n    });\n\n    super.setHandles(handles);\n  }\n\n  async willReceiveProps(\n      {list},\n      {arc, type, hostedParticle, otherMappedHandles, otherConnections}) {\n    if (list.length > 0) {\n      this.relevance = 0.1;\n    }\n\n    for (const [index, item] of this.getListEntries(list)) {\n      let resolvedHostedParticle = hostedParticle;\n      if (this.handleIds[item.id]) {\n        const itemHandle = await this.handleIds[item.id];\n        itemHandle.set(item);\n        continue;\n      }\n\n      const itemHandlePromise =\n          arc.createHandle(type.primitiveType(), 'item' + index);\n      this.handleIds[item.id] = itemHandlePromise;\n\n      const itemHandle = await itemHandlePromise;\n\n      if (!resolvedHostedParticle) {\n        // If we're muxing on behalf of an item with an embedded recipe, the\n        // hosted particle should be retrievable from the item itself. Else we\n        // just skip this item.\n        if (!item.renderParticleSpec) {\n          continue;\n        }\n        resolvedHostedParticle =\n            ParticleSpec.fromLiteral(JSON.parse(item.renderParticleSpec));\n        // Re-map compatible handles and compute the connections specific\n        // to this item's render particle.\n        const listHandleName = 'list';\n        const particleHandleName = 'renderParticle';\n        [otherMappedHandles, otherConnections] =\n            await this._mapParticleConnections(\n                listHandleName,\n                particleHandleName,\n                resolvedHostedParticle,\n                this.handles,\n                arc);\n      }\n      const hostedSlotName = [...resolvedHostedParticle.slots.keys()][0];\n      const slotName = [...this.spec.slots.values()][0].name;\n      const slotId = await arc.createSlot(\n          this, slotName, resolvedHostedParticle.name, hostedSlotName, itemHandle._id);\n\n      if (!slotId) {\n        continue;\n      }\n\n      this._itemSubIdByHostedSlotId.set(slotId, item.id);\n\n      try {\n        const recipe = this.constructInnerRecipe(\n          resolvedHostedParticle,\n          item,\n          itemHandle,\n          {name: hostedSlotName, id: slotId},\n          {connections: otherConnections, handles: otherMappedHandles}\n        );\n        await arc.loadRecipe(recipe, this);\n        itemHandle.set(item);\n      } catch (e) {\n        console.log(e);\n      }\n    }\n  }\n\n  combineHostedModel(slotName, hostedSlotId, content) {\n    const subId = this._itemSubIdByHostedSlotId.get(hostedSlotId);\n    if (!subId) {\n      return;\n    }\n    const items = this._state.renderModel ? this._state.renderModel.items : [];\n    const listIndex = items.findIndex(item => item.subId == subId);\n    const item = Object.assign({}, content.model, {subId});\n    if (listIndex >= 0 && listIndex < items.length) {\n      items[listIndex] = item;\n    } else {\n      items.push(item);\n    }\n    this._setState({renderModel: {items}});\n  }\n\n  combineHostedTemplate(slotName, hostedSlotId, content) {\n    const subId = this._itemSubIdByHostedSlotId.get(hostedSlotId);\n    if (!subId) {\n      return;\n    }\n    assert(content.templateName, `Template name is missing for slot '${slotName}' (hosted slot ID: '${hostedSlotId}')`);\n    this._setState({templateName: Object.assign(this._state.templateName || {}, {[subId]: `${content.templateName}`})});\n\n    if (content.template) {\n      let template = content.template;\n      // Append subid$={{subid}} attribute to all provided slots, to make it usable for the transformation particle.\n      template = template.replace(new RegExp('slotid=\"[a-z]+\"', 'gi'), '$& subid$=\"{{subId}}\"');\n\n      // Replace hosted particle connection in template with the corresponding particle connection names.\n      // TODO: make this generic!\n      this._connByHostedConn.forEach((conn, hostedConn) => {\n        template = template.replace(\n            new RegExp(`{{${hostedConn}.description}}`, 'g'),\n            `{{${conn}.description}}`);\n      });\n      this._setState({template: Object.assign(this._state.template || {}, {[content.templateName]: template})});\n\n      this.forceRenderTemplate();\n    }\n  }\n\n  // Abstract methods below.\n\n  // Called to produce a full interpolated recipe for loading into an inner\n  // arc for each item. Subclasses should override this method as by default\n  // it does nothing and so no recipe will be returned and content will not\n  // be loaded successfully into the inner arc.\n  constructInnerRecipe(hostedParticle, item, itemHandle, slot, other) {}\n\n  // Called with the list of items and by default returns the direct result of\n  // `Array.entries()`. Subclasses can override this method to alter the item\n  // order or otherwise permute the items as desired before their slots are\n  // created and contents are rendered.\n  getListEntries(list) {\n    return list.entries();\n  }\n}\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n'use strict';\n\nimport {handleFor} from './ts-build/handle.js';\nimport {assert} from '../platform/assert-web.js';\nimport {PECInnerPort} from './api-channel.js';\nimport {StorageProxy, StorageProxyScheduler} from './storage-proxy.js';\n\nexport class ParticleExecutionContext {\n  constructor(port, idBase, loader) {\n    this._apiPort = new PECInnerPort(port);\n    this._particles = [];\n    this._idBase = idBase;\n    this._nextLocalID = 0;\n    this._loader = loader;\n    loader.setParticleExecutionContext(this);\n    this._pendingLoads = [];\n    this._scheduler = new StorageProxyScheduler();\n    this._keyedProxies = {};\n\n    /*\n     * This code ensures that the relevant types are known\n     * in the scope object, because otherwise we can't do\n     * particleSpec resolution, which is currently a necessary\n     * part of particle construction.\n     *\n     * Possibly we should eventually consider having particle\n     * specifications separated from particle classes - and\n     * only keeping type information on the arc side.\n     */\n    this._apiPort.onDefineHandle = ({type, identifier, name}) => {\n      return new StorageProxy(identifier, type, this._apiPort, this, this._scheduler, name);\n    };\n\n    this._apiPort.onGetBackingStoreCallback = ({type, id, name, callback, storageKey}) => {\n      const proxy = new StorageProxy(id, type, this._apiPort, this, this._scheduler, name);\n      proxy.storageKey = storageKey;\n      return [proxy, () => callback(proxy, storageKey)];\n    };\n\n\n    this._apiPort.onCreateHandleCallback = ({type, id, name, callback}) => {\n      const proxy = new StorageProxy(id, type, this._apiPort, this, this._scheduler, name);\n      return [proxy, () => callback(proxy)];\n    };\n\n    this._apiPort.onMapHandleCallback = ({id, callback}) => {\n      return [id, () => callback(id)];\n    };\n\n    this._apiPort.onCreateSlotCallback = ({hostedSlotId, callback}) => {\n      return [hostedSlotId, () => callback(hostedSlotId)];\n    };\n\n    this._apiPort.onInnerArcRender = ({transformationParticle, transformationSlotName, hostedSlotId, content}) => {\n      transformationParticle.renderHostedSlot(transformationSlotName, hostedSlotId, content);\n    };\n\n    this._apiPort.onStop = () => {\n      if (global.close) {\n        global.close();\n      }\n    };\n\n    this._apiPort.onInstantiateParticle =\n      ({id, spec, handles}) => this._instantiateParticle(id, spec, handles);\n\n    this._apiPort.onSimpleCallback = ({callback, data}) => callback(data);\n\n    this._apiPort.onConstructArcCallback = ({callback, arc}) => callback(arc);\n\n    this._apiPort.onAwaitIdle = ({version}) =>\n      this.idle.then(a => {\n        // TODO: dom-particles update is async, this is a workaround to allow dom-particles to\n        // update relevance, after handles are updated. Needs better idle signal.\n        setTimeout(() => { this._apiPort.Idle({version, relevance: this.relevance}); }, 0);\n      });\n\n    this._apiPort.onUIEvent = ({particle, slotName, event}) => particle.fireEvent(slotName, event);\n\n    this._apiPort.onStartRender = ({particle, slotName, contentTypes}) => {\n      /** @class Slot\n       * A representation of a consumed slot. Retrieved from a particle using\n       * particle.getSlot(name)\n       */\n      class Slotlet {\n        constructor(pec, particle, slotName) {\n          this._slotName = slotName;\n          this._particle = particle;\n          this._handlers = new Map();\n          this._pec = pec;\n          this._requestedContentTypes = new Set();\n        }\n        get particle() { return this._particle; }\n        get slotName() { return this._slotName; }\n        get isRendered() { return this._isRendered; }\n        /** @method render(content)\n         * renders content to the slot.\n         */\n        render(content) {\n          this._pec._apiPort.Render({particle, slotName, content});\n\n          Object.keys(content).forEach(key => { this._requestedContentTypes.delete(key); });\n          // Slot is considered rendered, if a non-empty content was sent and all requested content types were fullfilled.\n          this._isRendered = this._requestedContentTypes.size == 0 && (Object.keys(content).length > 0);\n        }\n        /** @method registerEventHandler(name, f)\n         * registers a callback to be invoked when 'name' event happens.\n         */\n        registerEventHandler(name, f) {\n          if (!this._handlers.has(name)) {\n            this._handlers.set(name, []);\n          }\n          this._handlers.get(name).push(f);\n        }\n        clearEventHandlers(name) {\n          this._handlers.set(name, []);\n        }\n        fireEvent(event) {\n          for (const handler of this._handlers.get(event.handler) || []) {\n            handler(event);\n          }\n        }\n      }\n\n      particle._slotByName.set(slotName, new Slotlet(this, particle, slotName));\n      particle.renderSlot(slotName, contentTypes);\n    };\n\n    this._apiPort.onStopRender = ({particle, slotName}) => {\n      assert(particle._slotByName.has(slotName),\n        `Stop render called for particle ${particle.name} slot ${slotName} without start render being called.`);\n      particle._slotByName.delete(slotName);\n    };\n  }\n\n  generateIDComponents() {\n    return {base: this._idBase, component: () => this._nextLocalID++};\n  }\n\n  generateID() {\n    return `${this._idBase}:${this._nextLocalID++}`;\n  }\n\n  innerArcHandle(arcId, particleId) {\n    const pec = this;\n    return {\n      createHandle: function(type, name, hostParticle) {\n        return new Promise((resolve, reject) =>\n          pec._apiPort.ArcCreateHandle({arc: arcId, type, name, callback: proxy => {\n            const handle = handleFor(proxy, name, particleId);\n            resolve(handle);\n            if (hostParticle) {\n              proxy.register(hostParticle, handle);\n            }\n          }}));\n      },\n      mapHandle: function(handle) {\n        return new Promise((resolve, reject) =>\n          pec._apiPort.ArcMapHandle({arc: arcId, handle, callback: id => {\n            resolve(id);\n          }}));\n      },\n      createSlot: function(transformationParticle, transformationSlotName, hostedParticleName, hostedSlotName, handleId) {\n        // handleId: the ID of a handle (returned by `createHandle` above) this slot is rendering; null - if not applicable.\n        // TODO: support multiple handle IDs.\n        return new Promise((resolve, reject) =>\n          pec._apiPort.ArcCreateSlot({arc: arcId, transformationParticle, transformationSlotName, hostedParticleName, hostedSlotName, handleId, callback: hostedSlotId => {\n            resolve(hostedSlotId);\n          }}));\n      },\n      loadRecipe: function(recipe) {\n        // TODO: do we want to return a promise on completion?\n        return new Promise((resolve, reject) => pec._apiPort.ArcLoadRecipe({\n          arc: arcId,\n          recipe,\n          callback: a => {\n            if (a == undefined) {\n              resolve();\n            } else {\n              reject(a);\n            }\n          }\n        }));\n      }\n    };\n  }\n\n  getStorageProxy(storageKey, type) {\n    if (!this._keyedProxies[storageKey]) {      \n      this._keyedProxies[storageKey] = new Promise((resolve, reject) => {\n        this._apiPort.GetBackingStore({storageKey, type, callback: (proxy, storageKey) => {\n          this._keyedProxies[storageKey] = proxy;\n          resolve(proxy);\n        }});\n      });\n    }\n    return this._keyedProxies[storageKey];\n  }\n\n  defaultCapabilitySet() {\n    return {\n      constructInnerArc: particle => {\n        return new Promise((resolve, reject) =>\n          this._apiPort.ConstructInnerArc({callback: arcId => {resolve(this.innerArcHandle(arcId, particle.id));}, particle}));\n      }\n    };\n  }\n\n  async _instantiateParticle(id, spec, proxies) {\n    const name = spec.name;\n    let resolve = null;\n    const p = new Promise(res => resolve = res);\n    this._pendingLoads.push(p);\n    const clazz = await this._loader.loadParticleClass(spec);\n    const capabilities = this.defaultCapabilitySet();\n    const particle = new clazz(); // TODO: how can i add an argument to DomParticle ctor?\n    particle.id = id;\n    particle.capabilities = capabilities;\n    this._particles.push(particle);\n\n    const handleMap = new Map();\n    const registerList = [];\n    proxies.forEach((proxy, name) => {\n      const connSpec = spec.connectionMap.get(name);\n      const handle = handleFor(proxy, name, id, connSpec.isInput, connSpec.isOutput);\n      handleMap.set(name, handle);\n\n      // Defer registration of handles with proxies until after particles have a chance to\n      // configure them in setHandles.\n      registerList.push({proxy, particle, handle});\n    });\n\n    return [particle, async () => {\n      await particle.setHandles(handleMap);\n      registerList.forEach(({proxy, particle, handle}) => proxy.register(particle, handle));\n      const idx = this._pendingLoads.indexOf(p);\n      this._pendingLoads.splice(idx, 1);\n      resolve();\n    }];\n  }\n\n  get relevance() {\n    const rMap = new Map();\n    this._particles.forEach(p => {\n      if (p.relevances.length == 0) {\n        return;\n      }\n      rMap.set(p, p.relevances);\n      p.relevances = [];\n    });\n    return rMap;\n  }\n\n  get busy() {\n    if (this._pendingLoads.length > 0 || this._scheduler.busy) {\n      return true;\n    }\n    if (this._particles.filter(particle => particle.busy).length > 0) {\n      return true;\n    }\n    return false;\n  }\n\n  get idle() {\n    if (!this.busy) {\n      return Promise.resolve();\n    }\n    const busyParticlePromises = this._particles.filter(particle => particle.busy).map(particle => particle.idle);\n    return Promise.all([this._scheduler.idle, ...this._pendingLoads, ...busyParticlePromises]).then(() => this.idle);\n  }\n}\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n'use strict';\n\nimport {Tracing} from '../tracelib/trace.js';\nimport {assert} from '../platform/assert-web.js';\n\n/** @class Particle\n * A basic particle. For particles that provide UI, you may like to\n * instead use DOMParticle.\n */\nexport class Particle {\n  constructor(capabilities) {\n    this.spec = this.constructor.spec;\n    if (this.spec.inputs.length == 0) {\n      this.extraData = true;\n    }\n    this.relevances = [];\n    this._idle = Promise.resolve();\n    this._busy = 0;\n    this._slotByName = new Map();\n    this.capabilities = capabilities || {};\n  }\n\n  /** @method setHandles(handles)\n   * This method is invoked with a handle for each store this particle\n   * is registered to interact with, once those handles are ready for\n   * interaction. Override the method to register for events from\n   * the handles.\n   *\n   * Handles is a map from handle names to store handles.\n   */\n  setHandles(handles) {\n  }\n  \n  /** @method setViews(views)\n   * This method is deprecated. Use setHandles instead.\n   */\n  setViews(views) {\n  }\n\n  /** @method onHandleSync(handle, model)\n   * Called for handles that are configured with both keepSynced and notifySync, when they are\n   * updated with the full model of their data. This will occur once after setHandles() and any time\n   * thereafter if the handle is resynchronized.\n   *\n   * handle: The Handle instance that was updated.\n   * model: For Variable-backed Handles, the Entity data or null if the Variable is not set.\n   *        For Collection-backed Handles, the Array of Entities, which may be empty.\n   */\n  onHandleSync(handle, model) {\n  }\n\n  /** @method onHandleUpdate(handle, update)\n   * Called for handles that are configued with notifyUpdate, when change events are received from\n   * the backing store. For handles also configured with keepSynced these events will be correctly\n   * ordered, with some potential skips if a desync occurs. For handles not configured with\n   * keepSynced, all change events will be passed through as they are received.\n   *\n   * handle: The Handle instance that was updated.\n   * update: An object containing one of the following fields:\n   *    data: The full Entity for a Variable-backed Handle.\n   *    added: An Array of Entities added to a Collection-backed Handle.\n   *    removed: An Array of Entities removed from a Collection-backed Handle.\n   */\n  onHandleUpdate(handle, update) {\n  }\n\n  /** @method onHandleDesync(handle)\n   * Called for handles that are configured with both keepSynced and notifyDesync, when they are\n   * detected as being out-of-date against the backing store. For Variables, the event that triggers\n   * this will also resync the data and thus this call may usually be ignored. For Collections, the\n   * underlying proxy will automatically request a full copy of the stored data to resynchronize.\n   * onHandleSync will be invoked when that is received.\n   *\n   * handle: The Handle instance that was desynchronized.\n   */\n  onHandleDesync(handle) {\n  }\n\n  constructInnerArc() {\n    if (!this.capabilities.constructInnerArc) {\n      throw new Error('This particle is not allowed to construct inner arcs');\n    }\n    return this.capabilities.constructInnerArc(this);\n  }\n\n  get busy() {\n    return this._busy > 0;\n  }\n\n  get idle() {\n    return this._idle;\n  }\n\n  set relevance(r) {\n    this.relevances.push(r);\n  }\n\n  startBusy() {\n    if (this._busy == 0) {\n      this._idle = new Promise(resolve => this._idleResolver = resolve);\n    }\n    this._busy++;\n  }\n  \n  doneBusy() {\n    this._busy--;\n    if (this._busy == 0) {\n      this._idleResolver();\n    }\n  }\n\n  inputs() {\n    return this.spec.inputs;\n  }\n\n  outputs() {\n    return this.spec.outputs;\n  }\n\n  /** @method getSlot(name)\n   * Returns the slot with provided name.\n   */\n  getSlot(name) {\n    return this._slotByName.get(name);\n  }\n\n  static buildManifest(strings, ...bits) {\n    const output = [];\n    for (let i = 0; i < bits.length; i++) {\n        const str = strings[i];\n        const indent = / *$/.exec(str)[0];\n        let bitStr;\n        if (typeof bits[i] == 'string') {\n          bitStr = bits[i];\n        } else {\n          bitStr = bits[i].toManifestString();\n        }\n        bitStr = bitStr.replace(/(\\n)/g, '$1' + indent);\n        output.push(str);\n        output.push(bitStr);\n    }\n    if (strings.length > bits.length) {\n      output.push(strings[strings.length - 1]);\n    }\n    return output.join('');\n  }\n\n  setParticleDescription(pattern) {\n    return this.setDescriptionPattern('pattern', pattern);\n  }\n  setDescriptionPattern(connectionName, pattern) {\n    const descriptions = this.handles.get('descriptions');\n    if (descriptions) {\n      descriptions.store(new descriptions.entityClass({key: connectionName, value: pattern}, this.spec.name + '-' + connectionName));\n      return true;\n    }\n    throw new Error('A particle needs a description handle to set a decription pattern');\n  }\n}\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n'use strict';\n\nimport {assert} from '../platform/assert-web.js';\nimport {CrdtCollectionModel} from './ts-build/storage/crdt-collection-model.js';\n\nconst SyncState = {none: 0, pending: 1, full: 2};\n\n/** @class StorageProxy\n * Mediates between one or more Handles and the backing store outside the PEC.\n *\n * This can operate in two modes, based on how observing handles are configured:\n * - synchronized: the proxy maintains a copy of the full data held by the backing store, keeping\n *                 it in sync by listening to change events from the store.\n * - unsynchronized: the proxy simply passes through calls from Handles to the backing store.\n *\n * In synchronized mode we maintain a queue of sorted update events received from the backing store.\n * While events are received correctly - each update is one version ahead of our stored model - they\n * are processed immediately and observing handles are notified accordingly. If we receive an update\n * with a \"future\" version, the proxy is desynchronized:\n * - a request for the full data is sent to the backing store;\n * - any update events received after that (and before the response) are added to the queue;\n * - any new updates that can be applied will be (which may cause the proxy to \"catch up\" and resync\n *   before the full data response arrives);\n * - once the resync response is received, stale queued updates are discarded and any remaining ones\n *   are applied.\n */\nexport class StorageProxy {\n  constructor(id, type, port, pec, scheduler, name) {\n    if (type.isCollection) {\n      return new CollectionProxy(id, type, port, pec, scheduler, name);\n    }\n    if (type.isBigCollection) {\n      return new BigCollectionProxy(id, type, port, pec, scheduler, name);\n    }\n    return new VariableProxy(id, type, port, pec, scheduler, name);\n  }\n}\n\nclass StorageProxyBase {\n  constructor(id, type, port, pec, scheduler, name) {\n    this._id = id;\n    this._type = type;\n    this._port = port;\n    this._scheduler = scheduler;\n    this.name = name;\n    this._baseForNewID = pec.generateID();\n    this._localIDComponent = 0;\n\n    this._version = undefined;\n    this._listenerAttached = false;\n    this._keepSynced = false;\n    this._synchronized = SyncState.none;\n    this._observers = [];\n    this._updates = [];\n\n    this.pec = pec;\n  }\n\n  raiseSystemException(exception, methodName, particleId) {\n    this._port.RaiseSystemException({exception: {message: exception.message, stack: exception.stack, name: exception.name}, methodName, particleId});\n  }\n\n  get id() {\n    return this._id;\n  }\n\n  get type() {\n    return this._type;\n  }\n\n  /**\n   *  Called by ParticleExecutionContext to associate (potentially multiple) particle/handle pairs with this proxy.\n   */\n  register(particle, handle) {\n    if (!handle.canRead) {\n      return;\n    }\n    this._observers.push({particle, handle});\n\n    // Attach an event listener to the backing store when the first readable handle is registered.\n    if (!this._listenerAttached) {\n      this._port.InitializeProxy({handle: this, callback: x => this._onUpdate(x)});\n      this._listenerAttached = true;\n    }\n\n    // Change to synchronized mode as soon as we get any handle configured with keepSynced and send\n    // a request to get the full model (once).\n    // TODO: drop back to non-sync mode if all handles re-configure to !keepSynced\n    if (handle.options.keepSynced) {\n      if (!this._keepSynced) {\n        this._port.SynchronizeProxy({handle: this, callback: x => this._onSynchronize(x)});\n        this._keepSynced = true;\n      }\n\n      // If a handle configured for sync notifications registers after we've received the full\n      // model, notify it immediately.\n      if (handle.options.notifySync && this._synchronized == SyncState.full) {\n        const syncModel = this._getModelForSync();\n        this._scheduler.enqueue(particle, handle, ['sync', particle, syncModel]);\n      }\n    }\n  }\n\n  _onSynchronize({version, model}) {\n    if (this._version !== undefined && version <= this._version) {\n      console.warn(`StorageProxy '${this._id}' received stale model version ${version}; ` +\n                   `current is ${this._version}`);\n      return;\n    }\n\n    // Replace the stored data with the new one and notify handles that are configured for it.\n    if (!this._synchronizeModel(version, model)) {\n      return;\n    }\n\n    // We may have queued updates that were received after a desync; discard any that are stale\n    // with respect to the received model.\n    this._synchronized = SyncState.full;\n    while (this._updates.length > 0 && this._updates[0].version <= version) {\n      this._updates.shift();\n    }\n\n    const syncModel = this._getModelForSync();\n    this._notify('sync', syncModel, options => options.keepSynced && options.notifySync);\n    this._processUpdates();\n  }\n\n  _onUpdate(update) {\n    // Immediately notify any handles that are not configured with keepSynced but do want updates.\n    if (this._observers.find(({handle}) => !handle.options.keepSynced && handle.options.notifyUpdate)) {\n      const handleUpdate = this._processUpdate(update, false);\n      this._notify('update', handleUpdate, options => !options.keepSynced && options.notifyUpdate);\n    }\n\n    // Bail if we're not in synchronized mode or this is a stale event.\n    if (!this._keepSynced) {\n      return;\n    }\n    if (update.version <= this._version) {\n      console.warn(`StorageProxy '${this._id}' received stale update version ${update.version}; ` +\n                   `current is ${this._version}`);\n      return;\n    }\n\n    // Add the update to the queue and process. Most of the time the queue should be empty and\n    // _processUpdates will consume this event immediately.\n    this._updates.push(update);\n    this._updates.sort((a, b) => a.version - b.version);\n    this._processUpdates();\n  }\n\n  _notify(kind, details, predicate=() => true) {\n    for (const {handle, particle} of this._observers) {\n      if (predicate(handle.options)) {\n        this._scheduler.enqueue(particle, handle, [kind, particle, details]);\n      }\n    }\n  }\n\n  _processUpdates() {\n\n    const updateIsNext = update => {\n      if (update.version == this._version + 1) {\n        return true;\n      }\n      // Holy Layering Violation Batman\n      // \n      // If we are a variable waiting for a barriered set response\n      // then that set response *is* the next thing we're waiting for,\n      // regardless of version numbers.\n      //\n      // TODO(shans): refactor this code so we don't need to layer-violate. \n      if (this._barrier && update.barrier == this._barrier) {\n        return true;\n      }\n      return false;\n    };\n\n    // Consume all queued updates whose versions are monotonically increasing from our stored one.\n    while (this._updates.length > 0 && updateIsNext(this._updates[0])) {\n      const update = this._updates.shift();\n\n      // Fold the update into our stored model.\n      const handleUpdate = this._processUpdate(update);\n      this._version = update.version;\n\n      // Notify handles configured with keepSynced and notifyUpdates (non-keepSynced handles are\n      // notified as updates are received).\n      if (handleUpdate) {\n        this._notify('update', handleUpdate, options => options.keepSynced && options.notifyUpdate);\n      }\n    }\n\n    // If we still have update events queued, we must have received a future version are are now\n    // desynchronized. Send a request for the full model and notify handles configured for it.\n    if (this._updates.length > 0) {\n      if (this._synchronized != SyncState.none) {\n        this._synchronized = SyncState.none;\n        this._port.SynchronizeProxy({handle: this, callback: x => this._onSynchronize(x)});\n        for (const {handle, particle} of this._observers) {\n          if (handle.options.notifyDesync) {\n            this._scheduler.enqueue(particle, handle, ['desync', particle]);\n          }\n        }\n      }\n    } else if (this._synchronized != SyncState.full) {\n      // If we were desynced but have now consumed all update events, we've caught up.\n      this._synchronized = SyncState.full;\n    }\n  }\n\n  generateID() {\n    return `${this._baseForNewID}:${this._localIDComponent++}`;\n  }\n\n  generateIDComponents() {\n    return {base: this._baseForNewID, component: () => this._localIDComponent++};\n  }\n}\n\n/**\n * Collections are synchronized in a CRDT Observed/Removed scheme.\n * Each value is identified by an ID and a set of membership keys.\n * Concurrent adds of the same value will specify the same ID but different\n * keys. A value is removed by removing all of the observed keys. A value\n * is considered to be removed if all of it's keys have been removed.\n *\n * In synchronized mode mutation takes place synchronously inside the proxy.\n * The proxy uses the originatorId to skip over redundant events sent back\n * by the storage object.\n *\n * In unsynchronized mode removal is not based on the keys observed at the\n * proxy, since the proxy does not remember the state, but instead the set\n * of keys that exist at the storage object at the time it receives the\n * request.\n */\nclass CollectionProxy extends StorageProxyBase {\n  constructor(...args) {\n    super(...args);\n    this._model = new CrdtCollectionModel();\n  }\n\n  _getModelForSync() {\n    return this._model.toList();\n  }\n\n  _synchronizeModel(version, model) {\n    this._version = version;\n    this._model = new CrdtCollectionModel(model);\n    return true;\n  }\n\n  _processUpdate(update, apply=true) {\n    if (this._synchronized == SyncState.full) {\n      // If we're synchronized, then any updates we sent have\n      // already been applied/notified.\n      for (const {handle} of this._observers) {\n        if (update.originatorId == handle._particleId) {\n          return null;\n        }\n      }\n    }\n    const added = [];\n    const removed = [];\n    if ('add' in update) {\n      for (const {value, keys, effective} of update.add) {\n        if (apply && this._model.add(value.id, value, keys) || !apply && effective) {\n          added.push(value);\n        }\n      }\n    } else if ('remove' in update) {\n      for (const {value, keys, effective} of update.remove) {\n        const localValue = this._model.getValue(value.id);\n        if (apply && this._model.remove(value.id, keys) || !apply && effective) {\n          removed.push(localValue);\n        }\n      }\n    } else {\n      throw new Error(`StorageProxy received invalid update event: ${JSON.stringify(update)}`);\n    }\n    if (added.length || removed.length) {\n      const result = {};\n      if (added.length) result.add = added;\n      if (removed.length) result.remove = removed;\n      result.originatorId = update.originatorId;\n      return result;\n    }\n    return null;\n  }\n\n  // Read ops: if we're synchronized we can just return the local copy of the data.\n  // Otherwise, send a request to the backing store.\n  toList(particleId) {\n    if (this._synchronized == SyncState.full) {\n      return Promise.resolve(this._model.toList());\n    } else {\n      // TODO: in synchronized mode, this should integrate with SynchronizeProxy rather than\n      //       sending a parallel request\n      return new Promise(resolve =>\n        this._port.HandleToList({callback: resolve, handle: this, particleId}));\n    }\n  }\n\n  get(id, particleId) {\n    if (this._synchronized == SyncState.full) {\n      return Promise.resolve(this._model.getValue(id));\n    } else {\n      return new Promise((resolve, reject) =>\n        this._port.HandleToList({callback: r => resolve(r.find(entity => entity.id === id)), handle: this, particleId}));\n    }\n  }\n\n  store(value, keys, particleId) {\n    const id = value.id;\n    const data = {value, keys};\n    this._port.HandleStore({handle: this, callback: () => {}, data, particleId});\n\n    if (this._synchronized != SyncState.full) {\n      return;\n    }\n    if (!this._model.add(id, value, keys)) {\n      return;\n    }\n    const update = {originatorId: particleId, add: [value]};\n    this._notify('update', update, options => options.notifyUpdate);\n  }\n\n  clear(particleId) {\n    if (this._synchronized != SyncState.full) {\n      this._port.HandleRemoveMultiple({handle: this, callback: () => {}, data: [], particleId});\n    }\n\n    let items = this._model.toList().map(item => ({id: item.id, keys: this._model.getKeys(item.id)}));\n    this._port.HandleRemoveMultiple({handle: this, callback: () => {}, data: items, particleId});\n\n    items = items.map(({id, keys}) => ({rawData: this._model.getValue(id).rawData, id, keys}));\n    items = items.filter(item => this._model.remove(item.id, item.keys));\n    if (items.length > 0) {\n      this._notify('update', {originatorId: particleId, remove: items}, options => options.notifyUpdate);\n    }\n  }\n\n  remove(id, keys, particleId) {\n    if (this._synchronized != SyncState.full) {\n      const data = {id, keys: []};\n      this._port.HandleRemove({handle: this, callback: () => {}, data, particleId});\n      return;\n    }\n\n    const value = this._model.getValue(id);\n    if (!value) {\n      return;\n    }\n    if (keys.length == 0) {\n      keys = this._model.getKeys(id);\n    }\n    const data = {id, keys};\n    this._port.HandleRemove({handle: this, callback: () => {}, data, particleId});\n\n    if (!this._model.remove(id, keys)) {\n      return;\n    }\n    const update = {originatorId: particleId, remove: [value]};\n    this._notify('update', update, options => options.notifyUpdate);\n  }\n}\n\n/**\n * Variables are synchronized in a 'last-writer-wins' scheme. When the\n * VariableProxy mutates the model, it sets a barrier and expects to\n * receive the barrier value echoed back in a subsequent update event.\n * Between those two points in time updates are not applied or\n * notified about as these reflect concurrent writes that did not 'win'.\n */\nclass VariableProxy extends StorageProxyBase {\n  constructor(...args) {\n    super(...args);\n    this._model = null;\n    this._barrier = null;\n  }\n\n  _getModelForSync() {\n    return this._model;\n  }\n\n  _synchronizeModel(version, model) {\n    // If there's an active barrier then we shouldn't apply the model here, because\n    // there is a more recent write from the particle side that is still in flight.\n    if (this._barrier != null) {\n      return false;\n    }\n    this._version = version;\n    this._model = model.length == 0 ? null : model[0].value;\n    assert(this._model !== undefined);\n    return true;\n  }\n\n  _processUpdate(update, apply=true) {\n    assert('data' in update);\n    if (!apply) {\n      return update;\n    }\n    // If we have set a barrier, suppress updates until after\n    // we have seen the barrier return via an update.\n    if (this._barrier != null) {\n      if (update.barrier == this._barrier) {\n        this._barrier = null;\n\n        // HOLY LAYERING VIOLATION BATMAN\n        //\n        // We just cleared a barrier which means we are now synchronized. If we weren't\n        // synchronized already, then we need to tell the handles.\n        //\n        // TODO(shans): refactor this code so we don't need to layer-violate. \n        if (this._synchronized !== SyncState.full) {\n          this._synchronized = SyncState.full;\n          const syncModel = this._getModelForSync();\n          this._notify('sync', syncModel, options => options.keepSynced && options.notifySync);\n\n        }\n      }\n      return null;\n    }\n    this._model = update.data;\n    return update;\n  }\n\n  // Read ops: if we're synchronized we can just return the local copy of the data.\n  // Otherwise, send a request to the backing store.\n  // TODO: in synchronized mode, these should integrate with SynchronizeProxy rather than\n  //       sending a parallel request\n  get(particleId) {\n    if (this._synchronized == SyncState.full) {\n      return Promise.resolve(this._model);\n    } else {\n      return new Promise(resolve =>\n        this._port.HandleGet({callback: resolve, handle: this, particleId}));\n    }\n  }\n\n  set(entity, particleId) {\n    assert(entity !== undefined);\n    if (JSON.stringify(this._model) == JSON.stringify(entity)) {\n      return;\n    }\n    let barrier;\n\n    // If we're setting to this handle but we aren't listening to firebase, \n    // then there's no point creating a barrier. In fact, if the response \n    // to the set comes back before a listener is registered then this proxy will\n    // end up locked waiting for a barrier that will never arrive.\n    if (this._listenerAttached) {\n      barrier = this.generateID('barrier');\n    } else {\n      barrier = null;\n    }\n    // TODO: is this already a clone?\n    this._model = JSON.parse(JSON.stringify(entity));\n    this._barrier = barrier;\n    this._port.HandleSet({data: entity, handle: this, particleId, barrier});\n    const update = {originatorId: particleId, data: entity};\n    this._notify('update', update, options => options.notifyUpdate);\n  }\n\n  clear(particleId) {\n    if (this._model == null) {\n      return;\n    }\n    const barrier = this.generateID('barrier');\n    this._model = null;\n    this._barrier = barrier;\n    this._port.HandleClear({handle: this, particleId, barrier});\n    const update = {originatorId: particleId, data: null};\n    this._notify('update', update, options => options.notifyUpdate);\n  }\n}\n\n// BigCollections are never synchronized. No local state is held and all operations are passed\n// directly through to the backing store.\nclass BigCollectionProxy extends StorageProxyBase {\n  register(particle, handle) {\n    if (handle.canRead) {\n      this._scheduler.enqueue(particle, handle, ['sync', particle, {}]);\n    }\n  }\n\n  // TODO: surface get()\n\n  async store(value, keys, particleId) {\n    return new Promise(resolve =>\n      this._port.HandleStore({handle: this, callback: resolve, data: {value, keys}, particleId}));\n  }\n\n  async remove(id, particleId) {\n    return new Promise(resolve =>\n      this._port.HandleRemove({handle: this, callback: resolve, data: {id, keys: []}, particleId}));\n  }\n\n  async stream(pageSize, forward) {\n    return new Promise(resolve =>\n      this._port.HandleStream({handle: this, callback: resolve, pageSize, forward}));\n  }\n\n  async cursorNext(cursorId) {\n    return new Promise(resolve =>\n      this._port.StreamCursorNext({handle: this, callback: resolve, cursorId}));\n  }\n\n  cursorClose(cursorId) {\n    this._port.StreamCursorClose({handle: this, cursorId});\n  }\n}\n\nexport class StorageProxyScheduler {\n  constructor() {\n    this._scheduled = false;\n    // Particle -> {Handle -> [Queue of events]}\n    this._queues = new Map();\n  }\n\n  // TODO: break apart args here, sync events should flush the queue.\n  enqueue(particle, handle, args) {\n    if (!this._queues.has(particle)) {\n      this._queues.set(particle, new Map());\n    }\n    const byHandle = this._queues.get(particle);\n    if (!byHandle.has(handle)) {\n      byHandle.set(handle, []);\n    }\n    const queue = byHandle.get(handle);\n    queue.push(args);\n    this._schedule();\n  }\n\n  get busy() {\n    return this._queues.size > 0;\n  }\n\n  _updateIdle() {\n    if (this._idleResolver && !this.busy) {\n      this._idleResolver();\n      this._idle = null;\n      this._idleResolver = null;\n    }\n  }\n\n  get idle() {\n    if (!this.busy) {\n      return Promise.resolve();\n    }\n    if (!this._idle) {\n      this._idle = new Promise(resolve => this._idleResolver = resolve);\n    }\n    return this._idle;\n  }\n\n  _schedule() {\n    if (this._scheduled) {\n      return;\n    }\n    this._scheduled = true;\n    setTimeout(() => {\n      this._scheduled = false;\n      this._dispatch();\n    }, 0);\n  }\n\n  _dispatch() {\n    // TODO: should we process just one particle per task?\n    while (this._queues.size > 0) {\n      const particle = [...this._queues.keys()][0];\n      const byHandle = this._queues.get(particle);\n      this._queues.delete(particle);\n      for (const [handle, queue] of byHandle.entries()) {\n        for (const args of queue) {\n          try {\n            handle._notify(...args);\n          } catch (e) {\n            console.error('Error dispatching to particle', e);\n            handle._proxy.raiseSystemException(e, 'StorageProxyScheduler::_dispatch', particle.id);\n          }\n        }\n      }\n    }\n\n    this._updateIdle();\n  }\n}\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n'use strict';\n\nimport {DomParticle} from './dom-particle.js';\n\n// Regex to separate style and template.\nconst re = /<style>((?:.|[\\r\\n])*)<\\/style>((?:.|[\\r\\n])*)/;\n\n/** @class TransformationDomParticle\n * Particle that does transformation stuff with DOM.\n */\nexport class TransformationDomParticle extends DomParticle {\n  getTemplate(slotName) {\n    // TODO: add support for multiple slots.\n    return this._state.template;\n  }\n  getTemplateName(slotName) {\n    // TODO: add support for multiple slots.\n    return this._state.templateName;\n  }\n  render(props, state) {\n    return state.renderModel;\n  }\n  shouldRender(props, state) {\n    return Boolean((state.template || state.templateName) && state.renderModel);\n  }\n\n  renderHostedSlot(slotName, hostedSlotId, content) {\n    this.combineHostedTemplate(slotName, hostedSlotId, content);\n    this.combineHostedModel(slotName, hostedSlotId, content);\n  }\n\n  // abstract\n  combineHostedTemplate(slotName, hostedSlotId, content) {}\n  combineHostedModel(slotName, hostedSlotId, content) {}\n\n  // Helper methods that may be reused in transformation particles to combine hosted content.\n  static propsToItems(propsValues) {\n    return propsValues ? propsValues.map(({rawData, id}) => Object.assign({}, rawData, {subId: id})) : [];\n  }\n}\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nconst supportedTypes = ['Text', 'URL', 'Number', 'Boolean'];\nexport class JsonldToManifest {\n    static convert(jsonld, theClass = undefined) {\n        const obj = JSON.parse(jsonld);\n        const classes = {};\n        const properties = {};\n        if (!obj['@graph']) {\n            obj['@graph'] = [obj];\n        }\n        for (const item of obj['@graph']) {\n            if (item['@type'] === 'rdf:Property') {\n                properties[item['@id']] = item;\n            }\n            else if (item['@type'] === 'rdfs:Class') {\n                classes[item['@id']] = item;\n                item['subclasses'] = [];\n                item['superclass'] = null;\n            }\n        }\n        for (const clazz of Object.values(classes)) {\n            if (clazz['rdfs:subClassOf'] !== undefined) {\n                if (clazz['rdfs:subClassOf'].length == undefined) {\n                    clazz['rdfs:subClassOf'] = [clazz['rdfs:subClassOf']];\n                }\n                for (const subClass of clazz['rdfs:subClassOf']) {\n                    const superclass = subClass['@id'];\n                    if (clazz['superclass'] == undefined) {\n                        clazz['superclass'] = [];\n                    }\n                    if (classes[superclass]) {\n                        classes[superclass].subclasses.push(clazz);\n                        clazz['superclass'].push(classes[superclass]);\n                    }\n                    else {\n                        clazz['superclass'].push({ '@id': superclass });\n                    }\n                }\n            }\n        }\n        for (const clazz of Object.values(classes)) {\n            if (clazz['subclasses'].length === 0 && theClass == undefined) {\n                theClass = clazz;\n            }\n        }\n        const relevantProperties = [];\n        for (const property of Object.values(properties)) {\n            let domains = property['schema:domainIncludes'];\n            if (!domains) {\n                domains = { '@id': theClass['@id'] };\n            }\n            if (!domains.length) {\n                domains = [domains];\n            }\n            domains = domains.map(a => a['@id']);\n            if (domains.includes(theClass['@id'])) {\n                const name = property['@id'].split(':')[1];\n                let type = property['schema:rangeIncludes'];\n                if (!type) {\n                    console.log(property);\n                }\n                if (!type.length) {\n                    type = [type];\n                }\n                type = type.map(a => a['@id'].split(':')[1]);\n                type = type.filter(type => supportedTypes.includes(type));\n                if (type.length > 0) {\n                    relevantProperties.push({ name, type });\n                }\n            }\n        }\n        const className = theClass['@id'].split(':')[1];\n        const superNames = theClass && theClass.superclass ? theClass.superclass.map(a => a['@id'].split(':')[1]) : [];\n        let s = '';\n        for (const superName of superNames) {\n            s += `import 'https://schema.org/${superName}'\\n\\n`;\n        }\n        s += `schema ${className}`;\n        if (superNames.length > 0) {\n            s += ` extends ${superNames.join(', ')}`;\n        }\n        if (relevantProperties.length > 0) {\n            for (const property of relevantProperties) {\n                let type;\n                if (property.type.length > 1) {\n                    type = '(' + property.type.join(' or ') + ')';\n                }\n                else {\n                    type = property.type[0];\n                }\n                s += `\\n  ${type} ${property.name}`;\n            }\n        }\n        s += '\\n';\n        return s;\n    }\n}\n//# sourceMappingURL=jsonldToManifest.js.map","// @license\n// Copyright (c) 2017 Google Inc. All rights reserved.\n// This code may only be used under the BSD style license found at\n// http://polymer.github.io/LICENSE.txt\n// Code distributed by Google as part of this project is also\n// subject to an additional IP rights grant found at\n// http://polymer.github.io/PATENTS.txt\nimport { assert } from '../../platform/assert-web.js';\nimport { Symbols } from './symbols.js';\nexport class Entity {\n    constructor(userIDComponent) {\n        assert(!userIDComponent || userIDComponent.indexOf(':') === -1, 'user IDs must not contain the \\':\\' character');\n        this[Symbols.identifier] = undefined;\n        this.userIDComponent = userIDComponent;\n    }\n    get data() {\n        return undefined;\n    }\n    getUserID() {\n        return this.userIDComponent;\n    }\n    isIdentified() {\n        return this[Symbols.identifier] !== undefined;\n    }\n    // TODO: entity should not be exposing its IDs.\n    get id() {\n        assert(!!this.isIdentified());\n        return this[Symbols.identifier];\n    }\n    identify(identifier) {\n        assert(!this.isIdentified());\n        this[Symbols.identifier] = identifier;\n        const components = identifier.split(':');\n        if (components[components.length - 2] === 'uid') {\n            this.userIDComponent = components[components.length - 1];\n        }\n    }\n    createIdentity(components) {\n        assert(!this.isIdentified());\n        let id;\n        if (this.userIDComponent) {\n            id = `${components.base}:uid:${this.userIDComponent}`;\n        }\n        else {\n            id = `${components.base}:${components.component()}`;\n        }\n        this[Symbols.identifier] = id;\n    }\n    toLiteral() {\n        return this.rawData;\n    }\n}\n//# sourceMappingURL=entity.js.map","/** @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { Reference } from './reference.js';\nimport { Symbols } from './symbols.js';\nimport { assert } from '../../platform/assert-web.js';\nimport { ParticleSpec } from './particle-spec.js';\n// TODO: This won't be needed once runtime is transferred between contexts.\nfunction cloneData(data) {\n    return data;\n    //return JSON.parse(JSON.stringify(data));\n}\nfunction restore(entry, entityClass) {\n    assert(entityClass, 'Handles need entity classes for deserialization');\n    const { id, rawData } = entry;\n    const entity = new entityClass(cloneData(rawData));\n    if (entry.id) {\n        entity.identify(entry.id);\n    }\n    // TODO some relation magic, somewhere, at some point.\n    return entity;\n}\n/** @class Handle\n * Base class for Collections and Variables.\n */\nexport class Handle {\n    constructor(proxy, name, particleId, canRead, canWrite) {\n        assert(!(proxy instanceof Handle));\n        this._proxy = proxy;\n        this.name = name || this._proxy.name;\n        this.canRead = canRead;\n        this.canWrite = canWrite;\n        this._particleId = particleId;\n        this.options = {\n            keepSynced: true,\n            notifySync: true,\n            notifyUpdate: true,\n            notifyDesync: false,\n        };\n    }\n    raiseSystemException(exception, method) {\n        this._proxy.raiseSystemException(exception, method, this._particleId);\n    }\n    // `options` may contain any of:\n    // - keepSynced (bool): load full data on startup, maintain data in proxy and resync as required\n    // - notifySync (bool): if keepSynced is true, call onHandleSync when the full data is received\n    // - notifyUpdate (bool): call onHandleUpdate for every change event received\n    // - notifyDesync (bool): if keepSynced is true, call onHandleDesync when desync is detected\n    configure(options) {\n        assert(this.canRead, 'configure can only be called on readable Handles');\n        try {\n            const keys = Object.keys(this.options);\n            const badKeys = Object.keys(options).filter(o => !keys.includes(o));\n            if (badKeys.length > 0) {\n                throw new Error(`Invalid option in Handle.configure(): ${badKeys}`);\n            }\n            Object.assign(this.options, options);\n        }\n        catch (e) {\n            this.raiseSystemException(e, 'Handle::configure');\n            throw e;\n        }\n    }\n    _serialize(entity) {\n        assert(entity, 'can\\'t serialize a null entity');\n        if (!entity.isIdentified()) {\n            entity.createIdentity(this._proxy.generateIDComponents());\n        }\n        const id = entity[Symbols.identifier];\n        const rawData = entity.dataClone();\n        return {\n            id,\n            rawData\n        };\n    }\n    get type() {\n        return this._proxy._type;\n    }\n    get _id() {\n        return this._proxy._id;\n    }\n    toManifestString() {\n        return `'${this._id}'`;\n    }\n}\n/** @class Collection\n * A handle on a set of Entity data. Note that, as a set, a Collection can only\n * contain a single version of an Entity for each given ID. Further, no order is\n * implied by the set. A particle's manifest dictates the types of handles that\n * need to be connected to that particle, and the current recipe identifies\n * which handles are connected.\n */\nclass Collection extends Handle {\n    // Called by StorageProxy.\n    _notify(kind, particle, details) {\n        assert(this.canRead, '_notify should not be called for non-readable handles');\n        switch (kind) {\n            case 'sync':\n                particle.onHandleSync(this, this._restore(details));\n                return;\n            case 'update': {\n                // tslint:disable-next-line: no-any\n                const update = {};\n                if ('add' in details) {\n                    update.added = this._restore(details.add);\n                }\n                if ('remove' in details) {\n                    update.removed = this._restore(details.remove);\n                }\n                update.originator = details.originatorId === this._particleId;\n                particle.onHandleUpdate(this, update);\n                return;\n            }\n            case 'desync':\n                particle.onHandleDesync(this);\n                return;\n            default:\n                throw new Error('unsupported');\n        }\n    }\n    /** @method async get(id)\n     * Returns the Entity specified by id contained by the handle, or null if this id is not\n     * contained by the handle.\n     * throws: Error if this handle is not configured as a readable handle (i.e. 'in' or 'inout')\n     * in the particle's manifest.\n     */\n    async get(id) {\n        if (!this.canRead) {\n            throw new Error('Handle not readable');\n        }\n        return this._restore([await this._proxy.get(id, this._particleId)])[0];\n    }\n    /** @method async toList()\n     * Returns a list of the Entities contained by the handle.\n     * throws: Error if this handle is not configured as a readable handle (i.e. 'in' or 'inout')\n     * in the particle's manifest.\n     */\n    async toList() {\n        if (!this.canRead) {\n            throw new Error('Handle not readable');\n        }\n        return this._restore(await this._proxy.toList(this._particleId));\n    }\n    _restore(list) {\n        return (list !== null) ? list.map(a => restore(a, this.entityClass)) : null;\n    }\n    /** @method store(entity)\n     * Stores a new entity into the Handle.\n     * throws: Error if this handle is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async store(entity) {\n        if (!this.canWrite) {\n            throw new Error('Handle not writeable');\n        }\n        const serialization = this._serialize(entity);\n        const keys = [this._proxy.generateID() + 'key'];\n        return this._proxy.store(serialization, keys, this._particleId);\n    }\n    /** @method clear()\n     * Removes all known entities from the Handle.\n     * throws: Error if this handle is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async clear() {\n        if (!this.canWrite) {\n            throw new Error('Handle not writeable');\n        }\n        return this._proxy.clear();\n    }\n    /** @method remove(entity)\n     * Removes an entity from the Handle.\n     * throws: Error if this handle is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async remove(entity) {\n        if (!this.canWrite) {\n            throw new Error('Handle not writeable');\n        }\n        const serialization = this._serialize(entity);\n        // Remove the keys that exist at storage/proxy.\n        const keys = [];\n        return this._proxy.remove(serialization.id, keys, this._particleId);\n    }\n}\n/** @class Variable\n * A handle on a single entity. A particle's manifest dictates\n * the types of handles that need to be connected to that particle, and\n * the current recipe identifies which handles are connected.\n */\nclass Variable extends Handle {\n    // Called by StorageProxy.\n    async _notify(kind, particle, details) {\n        assert(this.canRead, '_notify should not be called for non-readable handles');\n        switch (kind) {\n            case 'sync':\n                try {\n                    await particle.onHandleSync(this, this._restore(details));\n                }\n                catch (e) {\n                    this.raiseSystemException(e, `${particle.name}::onHandleSync`);\n                }\n                return;\n            case 'update': {\n                try {\n                    await particle.onHandleUpdate(this, { data: this._restore(details.data) });\n                }\n                catch (e) {\n                    this.raiseSystemException(e, `${particle.name}::onHandleUpdate`);\n                }\n                return;\n            }\n            case 'desync':\n                try {\n                    await particle.onHandleDesync(this);\n                }\n                catch (e) {\n                    this.raiseSystemException(e, `${particle.name}::onHandleDesync`);\n                }\n                return;\n            default:\n                throw new Error('unsupported');\n        }\n    }\n    /** @method async get()\n     * Returns the Entity contained by the Variable, or undefined if the Variable\n     * is cleared.\n     * throws: Error if this variable is not configured as a readable handle (i.e. 'in' or 'inout')\n     * in the particle's manifest.\n     */\n    async get() {\n        if (!this.canRead) {\n            throw new Error('Handle not readable');\n        }\n        const model = await this._proxy.get(this._particleId);\n        return this._restore(model);\n    }\n    _restore(model) {\n        if (model === null) {\n            return null;\n        }\n        if (this.type.isEntity) {\n            return restore(model, this.entityClass);\n        }\n        if (this.type.isInterface) {\n            return ParticleSpec.fromLiteral(model);\n        }\n        if (this.type.isReference) {\n            return new Reference(model, this.type, this._proxy.pec);\n        }\n        assert(false, `Don't know how to deliver handle data of type ${this.type}`);\n    }\n    /** @method set(entity)\n     * Stores a new entity into the Variable, replacing any existing entity.\n     * throws: Error if this variable is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async set(entity) {\n        try {\n            if (!this.canWrite) {\n                throw new Error('Handle not writeable');\n            }\n            return this._proxy.set(this._serialize(entity), this._particleId);\n        }\n        catch (e) {\n            this.raiseSystemException(e, 'Handle::set');\n            throw e;\n        }\n    }\n    /** @method clear()\n     * Clears any entity currently in the Variable.\n     * throws: Error if this variable is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async clear() {\n        if (!this.canWrite) {\n            throw new Error('Handle not writeable');\n        }\n        return this._proxy.clear(this._particleId);\n    }\n}\n/** @class Cursor\n * Provides paginated read access to a BigCollection. Conforms to the javascript iterator protocol\n * but is not marked as iterable because next() is async, which is currently not supported by\n * implicit iteration in Javascript.\n */\nclass Cursor {\n    constructor(parent, cursorId) {\n        this._parent = parent;\n        this._cursorId = cursorId;\n    }\n    /** @method next()\n     * Returns {value: [items], done: false} while there are items still available, or {done: true}\n     * when the cursor has completed reading the collection.\n     */\n    async next() {\n        const data = await this._parent._proxy.cursorNext(this._cursorId);\n        if (!data.done) {\n            data.value = data.value.map(a => restore(a, this._parent.entityClass));\n        }\n        return data;\n    }\n    /** @method close()\n     * Terminates the streamed read. This must be called if a cursor is no longer needed but has not\n     * yet completed streaming (i.e. next() hasn't returned {done: true}).\n     */\n    close() {\n        this._parent._proxy.cursorClose(this._cursorId);\n    }\n}\n/** @class BigCollection\n * A handle on a large set of Entity data. Similar to Collection, except the complete set of\n * entities is not available directly; use stream() to read the full set. Particles wanting to\n * operate on BigCollections should do so in the setHandles() call, since BigCollections do not\n * trigger onHandleSync() or onHandleUpdate().\n */\nclass BigCollection extends Handle {\n    configure(options) {\n        throw new Error('BigCollections do not support sync/update configuration');\n    }\n    async _notify(kind, particle, details) {\n        assert(this.canRead, '_notify should not be called for non-readable handles');\n        assert(kind === 'sync', 'BigCollection._notify only supports sync events');\n        await particle.onHandleSync(this, []);\n    }\n    /** @method store(entity)\n     * Stores a new entity into the Handle.\n     * throws: Error if this handle is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async store(entity) {\n        if (!this.canWrite) {\n            throw new Error('Handle not writeable');\n        }\n        const serialization = this._serialize(entity);\n        const keys = [this._proxy.generateID() + 'key'];\n        return this._proxy.store(serialization, keys, this._particleId);\n    }\n    /** @method remove(entity)\n     * Removes an entity from the Handle.\n     * throws: Error if this handle is not configured as a writeable handle (i.e. 'out' or 'inout')\n     * in the particle's manifest.\n     */\n    async remove(entity) {\n        if (!this.canWrite) {\n            throw new Error('Handle not writeable');\n        }\n        const serialization = this._serialize(entity);\n        return this._proxy.remove(serialization.id, [], this._particleId);\n    }\n    /** @method stream({pageSize, forward})\n     * Returns a Cursor instance that iterates over the full set of entities, reading `pageSize`\n     * entities at a time. The cursor views a snapshot of the collection, locked to the version\n     * at which the cursor is created.\n     *\n     * By default items are returned in order of original insertion into the collection (with the\n     * caveat that items removed during a streamed read may be returned at the end). Set `forward`\n     * to false to return items in reverse insertion order.\n     *\n     * throws: Error if this variable is not configured as a readable handle (i.e. 'in' or 'inout')\n     * in the particle's manifest.\n     */\n    async stream({ pageSize, forward = true }) {\n        if (!this.canRead) {\n            throw new Error('Handle not readable');\n        }\n        if (isNaN(pageSize) || pageSize < 1) {\n            throw new Error('Streamed reads require a positive pageSize');\n        }\n        const cursorId = await this._proxy.stream(pageSize, forward);\n        return new Cursor(this, cursorId);\n    }\n}\nexport function handleFor(proxy, name = null, particleId = 0, canRead = true, canWrite = true) {\n    let handle;\n    if (proxy.type.isCollection) {\n        handle = new Collection(proxy, name, particleId, canRead, canWrite);\n    }\n    else if (proxy.type.isBigCollection) {\n        handle = new BigCollection(proxy, name, particleId, canRead, canWrite);\n    }\n    else {\n        handle = new Variable(proxy, name, particleId, canRead, canWrite);\n    }\n    const type = proxy.type.getContainedType() || proxy.type;\n    if (type.isEntity) {\n        handle.entityClass = type.entitySchema.entityClass(proxy.pec);\n    }\n    return handle;\n}\n//# sourceMappingURL=handle.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { fs } from '../../platform/fs-web.js';\nimport { vm } from '../../platform/vm-web.js';\nimport { fetch } from '../fetch-web.js';\nimport { assert } from '../../platform/assert-web.js';\nimport { Particle } from '../particle.js';\nimport { DomParticle } from '../dom-particle.js';\nimport { MultiplexerDomParticle } from '../multiplexer-dom-particle.js';\nimport { newClientReference } from './reference.js';\nimport { TransformationDomParticle } from '../transformation-dom-particle.js';\nimport { JsonldToManifest } from './converters/jsonldToManifest.js';\nconst html = (strings, ...values) => (strings[0] + values.map((v, i) => v + strings[i + 1]).join('')).trim();\nfunction schemaLocationFor(name) {\n    return `../entities/${name}.schema`;\n}\nexport class Loader {\n    path(fileName) {\n        const path = fileName.replace(/[/][^/]+$/, '/');\n        return path;\n    }\n    join(prefix, path) {\n        if (/^https?:\\/\\//.test(path)) {\n            return path;\n        }\n        // TODO: replace this with something that isn't hacky\n        if (path[0] === '/' || path[1] === ':') {\n            return path;\n        }\n        prefix = this.path(prefix);\n        path = this.normalizeDots(`${prefix}${path}`);\n        return path;\n    }\n    // convert `././foo/bar/../baz` to `./foo/baz`\n    normalizeDots(path) {\n        // only unix slashes\n        path = path.replace(/\\\\/g, '/');\n        // remove './'\n        path = path.replace(/\\/\\.\\//g, '/');\n        // remove 'foo/..'\n        const norm = s => s.replace(/(?:^|\\/)[^./]*\\/\\.\\./g, '');\n        for (let n = norm(path); n !== path; path = n, n = norm(path))\n            ;\n        return path;\n    }\n    loadResource(file) {\n        if (/^https?:\\/\\//.test(file)) {\n            return this._loadURL(file);\n        }\n        return this._loadFile(file);\n    }\n    _loadFile(file) {\n        return new Promise((resolve, reject) => {\n            fs.readFile(file, (err, data) => {\n                if (err) {\n                    reject(err);\n                }\n                else {\n                    resolve(data.toString('utf-8'));\n                }\n            });\n        });\n    }\n    _loadURL(url) {\n        if (/\\/\\/schema.org\\//.test(url)) {\n            if (url.endsWith('/Thing')) {\n                return fetch('https://schema.org/Product.jsonld').then(res => res.text()).then(data => JsonldToManifest.convert(data, { '@id': 'schema:Thing' }));\n            }\n            return fetch(url + '.jsonld').then(res => res.text()).then(data => JsonldToManifest.convert(data));\n        }\n        return fetch(url).then(res => res.text());\n    }\n    async loadParticleClass(spec) {\n        const clazz = await this.requireParticle(spec.implFile);\n        clazz.spec = spec;\n        return clazz;\n    }\n    async requireParticle(fileName) {\n        if (fileName === null)\n            fileName = '';\n        const src = await this.loadResource(fileName);\n        // Note. This is not real isolation.\n        const script = new vm.Script(src, { filename: fileName, displayErrors: true });\n        const result = [];\n        const self = {\n            defineParticle(particleWrapper) {\n                result.push(particleWrapper);\n            },\n            console,\n            fetch,\n            setTimeout,\n            importScripts: s => null //console.log(`(skipping browser-space import for [${s}])`)\n        };\n        script.runInNewContext(self, { filename: fileName, displayErrors: true });\n        assert(result.length > 0 && typeof result[0] === 'function', `Error while instantiating particle implementation from ${fileName}`);\n        return this.unwrapParticle(result[0]);\n    }\n    setParticleExecutionContext(pec) {\n        this.pec = pec;\n    }\n    unwrapParticle(particleWrapper) {\n        assert(this.pec);\n        return particleWrapper({ Particle, DomParticle, TransformationDomParticle, MultiplexerDomParticle, Reference: newClientReference(this.pec), html });\n    }\n}\n//# sourceMappingURL=loader.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { Type } from './type.js';\nimport { TypeChecker } from './recipe/type-checker.js';\nimport { Shape } from './shape.js';\nimport { assert } from '../../platform/assert-web.js';\nclass ConnectionSpec {\n    constructor(rawData, typeVarMap) {\n        this.parentConnection = null;\n        this.rawData = rawData;\n        this.direction = rawData.direction;\n        this.name = rawData.name;\n        this.type = rawData.type.mergeTypeVariablesByName(typeVarMap);\n        this.isOptional = rawData.isOptional;\n        this.tags = rawData.tags || [];\n        this.dependentConnections = [];\n    }\n    instantiateDependentConnections(particle, typeVarMap) {\n        for (const dependentArg of this.rawData.dependentConnections) {\n            const dependentConnection = particle.createConnection(dependentArg, typeVarMap);\n            dependentConnection.parentConnection = this;\n            this.dependentConnections.push(dependentConnection);\n        }\n    }\n    get isInput() {\n        // TODO: we probably don't really want host to be here.\n        return this.direction === 'in' || this.direction === 'inout' || this.direction === 'host';\n    }\n    get isOutput() {\n        return this.direction === 'out' || this.direction === 'inout';\n    }\n    isCompatibleType(type) {\n        return TypeChecker.compareTypes({ type }, { type: this.type, direction: this.direction });\n    }\n}\nexport class SlotSpec {\n    constructor(slotModel) {\n        this.name = slotModel.name;\n        this.isRequired = slotModel.isRequired;\n        this.isSet = slotModel.isSet;\n        this.tags = slotModel.tags || [];\n        this.formFactor = slotModel.formFactor; // TODO: deprecate form factors?\n        this.providedSlots = [];\n        if (!slotModel.providedSlots) {\n            return;\n        }\n        slotModel.providedSlots.forEach(ps => {\n            this.providedSlots.push(new ProvidedSlotSpec(ps));\n        });\n    }\n    getProvidedSlotSpec(name) {\n        return this.providedSlots.find(ps => ps.name === name);\n    }\n}\nexport class ProvidedSlotSpec {\n    constructor(slotModel) {\n        this.name = slotModel.name;\n        this.isRequired = slotModel.isRequired || false;\n        this.isSet = slotModel.isSet || false;\n        this.tags = slotModel.tags || [];\n        this.formFactor = slotModel.formFactor; // TODO: deprecate form factors?\n        this.handles = slotModel.handles || [];\n    }\n}\nexport class ParticleSpec {\n    constructor(model) {\n        this.model = model;\n        this.name = model.name;\n        this.verbs = model.verbs;\n        const typeVarMap = new Map();\n        this.connections = [];\n        model.args.forEach(arg => this.createConnection(arg, typeVarMap));\n        this.connectionMap = new Map();\n        this.connections.forEach(a => this.connectionMap.set(a.name, a));\n        this.inputs = this.connections.filter(a => a.isInput);\n        this.outputs = this.connections.filter(a => a.isOutput);\n        // initialize descriptions patterns.\n        model.description = model.description || {};\n        this.validateDescription(model.description);\n        this.pattern = model.description['pattern'];\n        this.connections.forEach(connectionSpec => {\n            connectionSpec.pattern = model.description[connectionSpec.name];\n        });\n        this.implFile = model.implFile;\n        this.affordance = model.affordance;\n        this.slots = new Map();\n        if (model.slots) {\n            model.slots.forEach(s => this.slots.set(s.name, new SlotSpec(s)));\n        }\n        // Verify provided slots use valid handle connection names.\n        this.slots.forEach(slot => {\n            slot.providedSlots.forEach(ps => {\n                ps.handles.forEach(v => assert(this.connectionMap.has(v), 'Cannot provide slot for nonexistent handle constraint ', v));\n            });\n        });\n    }\n    createConnection(arg, typeVarMap) {\n        const connection = new ConnectionSpec(arg, typeVarMap);\n        this.connections.push(connection);\n        connection.instantiateDependentConnections(this, typeVarMap);\n        return connection;\n    }\n    isInput(param) {\n        for (const input of this.inputs)\n            if (input.name === param)\n                return true;\n        return false;\n    }\n    isOutput(param) {\n        for (const outputs of this.outputs)\n            if (outputs.name === param)\n                return true;\n        return false;\n    }\n    getSlotSpec(slotName) {\n        return this.slots.get(slotName);\n    }\n    get primaryVerb() {\n        return (this.verbs.length > 0) ? this.verbs[0] : undefined;\n    }\n    matchAffordance(affordance) {\n        return this.slots.size <= 0 || this.affordance.includes(affordance);\n    }\n    toLiteral() {\n        const { args, name, verbs, description, implFile, affordance, slots } = this.model;\n        const connectionToLiteral = ({ type, direction, name, isOptional, dependentConnections }) => ({ type: type.toLiteral(), direction, name, isOptional, dependentConnections: dependentConnections.map(connectionToLiteral) });\n        const argsLiteral = args.map(a => connectionToLiteral(a));\n        return { args: argsLiteral, name, verbs, description, implFile, affordance, slots };\n    }\n    static fromLiteral(literal) {\n        let { args, name, verbs, description, implFile, affordance, slots } = literal;\n        const connectionFromLiteral = ({ type, direction, name, isOptional, dependentConnections }) => ({ type: Type.fromLiteral(type), direction, name, isOptional, dependentConnections: dependentConnections ? dependentConnections.map(connectionFromLiteral) : [] });\n        args = args.map(connectionFromLiteral);\n        return new ParticleSpec({ args, name, verbs: verbs || [], description, implFile, affordance, slots });\n    }\n    clone() {\n        return ParticleSpec.fromLiteral(this.toLiteral());\n    }\n    equals(other) {\n        return JSON.stringify(this.toLiteral()) === JSON.stringify(other.toLiteral());\n    }\n    validateDescription(description) {\n        Object.keys(description || []).forEach(d => {\n            assert(['kind', 'location', 'pattern'].includes(d) || this.connectionMap.has(d), `Unexpected description for ${d}`);\n        });\n    }\n    toInterface() {\n        return Type.newInterface(this._toShape());\n    }\n    _toShape() {\n        const handles = this.model.args;\n        // TODO: wat do?\n        assert(!this.slots.size, 'please implement slots toShape');\n        const slots = [];\n        return new Shape(this.name, handles, slots);\n    }\n    toString() {\n        const results = [];\n        let verbs = '';\n        if (this.verbs.length > 0) {\n            verbs = ' ' + this.verbs.map(verb => `&${verb}`).join(' ');\n        }\n        results.push(`particle ${this.name}${verbs} in '${this.implFile}'`.trim());\n        const indent = '  ';\n        const writeConnection = (connection, indent) => {\n            results.push(`${indent}${connection.direction} ${connection.type.toString()}${connection.isOptional ? '?' : ''} ${connection.name}`);\n            for (const dependent of connection.dependentConnections) {\n                writeConnection(dependent, indent + '  ');\n            }\n        };\n        for (const connection of this.connections) {\n            if (connection.parentConnection) {\n                continue;\n            }\n            writeConnection(connection, indent);\n        }\n        this.affordance.filter(a => a !== 'mock').forEach(a => results.push(`  affordance ${a}`));\n        this.slots.forEach(s => {\n            // Consume slot.\n            const consume = [];\n            if (s.isRequired) {\n                consume.push('must');\n            }\n            consume.push('consume');\n            if (s.isSet) {\n                consume.push('set of');\n            }\n            consume.push(s.name);\n            if (s.tags.length > 0) {\n                consume.push(s.tags.map(a => `#${a}`).join(' '));\n            }\n            results.push(`  ${consume.join(' ')}`);\n            if (s.formFactor) {\n                results.push(`    formFactor ${s.formFactor}`);\n            }\n            // Provided slots.\n            s.providedSlots.forEach(ps => {\n                const provide = [];\n                if (ps.isRequired) {\n                    provide.push('must');\n                }\n                provide.push('provide');\n                if (ps.isSet) {\n                    provide.push('set of');\n                }\n                provide.push(ps.name);\n                if (ps.tags.length > 0) {\n                    provide.push(ps.tags.map(a => `#${a}`).join(' '));\n                }\n                results.push(`    ${provide.join(' ')}`);\n                if (ps.formFactor) {\n                    results.push(`      formFactor ${ps.formFactor}`);\n                }\n                ps.handles.forEach(handle => results.push(`      handle ${handle}`));\n            });\n        });\n        // Description\n        if (this.pattern) {\n            results.push(`  description \\`${this.pattern}\\``);\n            this.connections.forEach(cs => {\n                if (cs.pattern) {\n                    results.push(`    ${cs.name} \\`${cs.pattern}\\``);\n                }\n            });\n        }\n        return results.join('\\n');\n    }\n    toManifestString() {\n        return this.toString();\n    }\n}\n//# sourceMappingURL=particle-spec.js.map","// Copyright (c) 2017 Google Inc. All rights reserved.\n// This code may only be used under the BSD style license found at\n// http://polymer.github.io/LICENSE.txt\n// Code distributed by Google as part of this project is also\n// subject to an additional IP rights grant found at\n// http://polymer.github.io/PATENTS.txt\nimport { Type } from '../type.js';\nimport { TypeVariable } from '../type-variable.js';\nexport class TypeChecker {\n    // resolve a list of handleConnection types against a handle\n    // base type. This is the core type resolution mechanism, but should only\n    // be used when types can actually be associated with each other / constrained.\n    //\n    // By design this function is called exactly once per handle in a recipe during\n    // normalization, and should provide the same final answers regardless of the\n    // ordering of handles within that recipe\n    //\n    // NOTE: you probably don't want to call this function, if you think you\n    // do, talk to shans@.\n    static processTypeList(baseType, list) {\n        const newBaseTypeVariable = new TypeVariable('', null, null);\n        if (baseType) {\n            newBaseTypeVariable.resolution = baseType;\n        }\n        const newBaseType = Type.newVariable(newBaseTypeVariable);\n        baseType = newBaseType;\n        const concreteTypes = [];\n        // baseType might be a variable (and is definitely a variable if no baseType was available).\n        // Some of the list might contain variables too.\n        // First attempt to merge all the variables into the baseType\n        //\n        // If the baseType is a variable then this results in a single place to manipulate the constraints\n        // of all the other connected variables at the same time.\n        for (const item of list) {\n            if (item.type.resolvedType().hasVariable) {\n                baseType = TypeChecker._tryMergeTypeVariable(baseType, item.type);\n                if (baseType == null) {\n                    return null;\n                }\n            }\n            else {\n                concreteTypes.push(item);\n            }\n        }\n        for (const item of concreteTypes) {\n            if (!TypeChecker._tryMergeConstraints(baseType, item)) {\n                return null;\n            }\n        }\n        const getResolution = candidate => {\n            if (candidate.isVariable === false) {\n                return candidate;\n            }\n            if (candidate.canReadSubset == null || candidate.canWriteSuperset == null) {\n                return candidate;\n            }\n            if (candidate.canReadSubset.isMoreSpecificThan(candidate.canWriteSuperset)) {\n                if (candidate.canWriteSuperset.isMoreSpecificThan(candidate.canReadSubset)) {\n                    candidate.variable.resolution = candidate.canReadSubset;\n                }\n                return candidate;\n            }\n            return null;\n        };\n        const candidate = baseType.resolvedType();\n        if (candidate.isCollection) {\n            const resolution = getResolution(candidate.collectionType);\n            return (resolution !== null) ? resolution.collectionOf() : null;\n        }\n        if (candidate.isBigCollection) {\n            const resolution = getResolution(candidate.bigCollectionType);\n            return (resolution !== null) ? resolution.bigCollectionOf() : null;\n        }\n        return getResolution(candidate);\n    }\n    static _tryMergeTypeVariable(base, onto) {\n        const [primitiveBase, primitiveOnto] = Type.unwrapPair(base.resolvedType(), onto.resolvedType());\n        if (primitiveBase.isVariable) {\n            if (primitiveOnto.isVariable) {\n                // base, onto both variables.\n                const result = primitiveBase.variable.maybeMergeConstraints(primitiveOnto.variable);\n                if (result === false) {\n                    return null;\n                }\n                // Here onto grows, one level at a time,\n                // as we assign new resolution to primitiveOnto, which is a leaf.\n                primitiveOnto.variable.resolution = primitiveBase;\n            }\n            else {\n                // base variable, onto not.\n                primitiveBase.variable.resolution = primitiveOnto;\n            }\n            return base;\n        }\n        else if (primitiveOnto.isVariable) {\n            // onto variable, base not.\n            primitiveOnto.variable.resolution = primitiveBase;\n            return onto;\n        }\n        else if (primitiveBase.isInterface && primitiveOnto.isInterface) {\n            const result = primitiveBase.interfaceShape.tryMergeTypeVariablesWith(primitiveOnto.interfaceShape);\n            if (result == null) {\n                return null;\n            }\n            return Type.newInterface(result);\n        }\n        else if ((primitiveBase.isTypeContainer() && primitiveBase.hasVariable)\n            || (primitiveOnto.isTypeContainer() && primitiveOnto.hasVariable)) {\n            // Cannot merge [~a] with a type that is not a variable and not a collection.\n            return null;\n        }\n        throw new Error('tryMergeTypeVariable shouldn\\'t be called on two types without any type variables');\n    }\n    static _tryMergeConstraints(handleType, { type, direction }) {\n        let [primitiveHandleType, primitiveConnectionType] = Type.unwrapPair(handleType.resolvedType(), type.resolvedType());\n        if (primitiveHandleType.isVariable) {\n            while (primitiveConnectionType.isTypeContainer()) {\n                if (primitiveHandleType.variable.resolution != null\n                    || primitiveHandleType.variable.canReadSubset != null\n                    || primitiveHandleType.variable.canWriteSuperset != null) {\n                    // Resolved and/or constrained variables can only represent Entities, not sets.\n                    return false;\n                }\n                // If this is an undifferentiated variable then we need to create structure to match against. That's\n                // allowed because this variable could represent anything, and it needs to represent this structure\n                // in order for type resolution to succeed.\n                const newVar = Type.newVariable(new TypeVariable('a', null, null));\n                primitiveHandleType.variable.resolution =\n                    primitiveConnectionType.isCollection ? Type.newCollection(newVar) : (primitiveConnectionType.isBigCollection ? Type.newBigCollection(newVar) : Type.newReference(newVar));\n                const unwrap = Type.unwrapPair(primitiveHandleType.resolvedType(), primitiveConnectionType);\n                [primitiveHandleType, primitiveConnectionType] = unwrap;\n            }\n            if (direction === 'out' || direction === 'inout' || direction === '`provide') {\n                // the canReadSubset of the handle represents the maximal type that can be read from the\n                // handle, so we need to intersect out any type that is more specific than the maximal type\n                // that could be written.\n                if (!primitiveHandleType.variable.maybeMergeCanReadSubset(primitiveConnectionType.canWriteSuperset)) {\n                    return false;\n                }\n            }\n            if (direction === 'in' || direction === 'inout' || direction === '`consume') {\n                // the canWriteSuperset of the handle represents the maximum lower-bound type that is read from the handle,\n                // so we need to union it with the type that wants to be read here.\n                if (!primitiveHandleType.variable.maybeMergeCanWriteSuperset(primitiveConnectionType.canReadSubset)) {\n                    return false;\n                }\n            }\n        }\n        else {\n            if (primitiveConnectionType.tag !== primitiveHandleType.tag) {\n                return false;\n            }\n            if (direction === 'out' || direction === 'inout') {\n                if (!TypeChecker._writeConstraintsApply(primitiveHandleType, primitiveConnectionType)) {\n                    return false;\n                }\n            }\n            if (direction === 'in' || direction === 'inout') {\n                if (!TypeChecker._readConstraintsApply(primitiveHandleType, primitiveConnectionType)) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    }\n    static _writeConstraintsApply(handleType, connectionType) {\n        // this connection wants to write to this handle. If the written type is\n        // more specific than the canReadSubset then it isn't violating the maximal type\n        // that can be read.\n        const writtenType = connectionType.canWriteSuperset;\n        if (writtenType == null || handleType.canReadSubset == null) {\n            return true;\n        }\n        if (writtenType.isMoreSpecificThan(handleType.canReadSubset)) {\n            return true;\n        }\n        return false;\n    }\n    static _readConstraintsApply(handleType, connectionType) {\n        // this connection wants to read from this handle. If the read type\n        // is less specific than the canWriteSuperset, then it isn't violating\n        // the maximum lower-bound read type.\n        const readType = connectionType.canReadSubset;\n        if (readType == null || handleType.canWriteSuperset == null) {\n            return true;\n        }\n        if (handleType.canWriteSuperset.isMoreSpecificThan(readType)) {\n            return true;\n        }\n        return false;\n    }\n    // Compare two types to see if they could be potentially resolved (in the absence of other\n    // information). This is used as a filter when selecting compatible handles or checking\n    // validity of recipes. This function returning true never implies that full type resolution\n    // will succeed, but if the function returns false for a pair of types that are associated\n    // then type resolution is guaranteed to fail.\n    //\n    // left, right: {type, direction, connection}\n    static compareTypes(left, right) {\n        const resolvedLeft = left.type.resolvedType();\n        const resolvedRight = right.type.resolvedType();\n        const [leftType, rightType] = Type.unwrapPair(resolvedLeft, resolvedRight);\n        // a variable is compatible with a set only if it is unconstrained.\n        if (leftType.isVariable && rightType.isTypeContainer()) {\n            return !(leftType.variable.canReadSubset || leftType.variable.canWriteSuperset);\n        }\n        if (rightType.isVariable && leftType.isTypeContainer()) {\n            return !(rightType.variable.canReadSubset || rightType.variable.canWriteSuperset);\n        }\n        if (leftType.isVariable || rightType.isVariable) {\n            // TODO: everything should use this, eventually. Need to implement the\n            // right functionality in Shapes first, though.\n            return Type.canMergeConstraints(leftType, rightType);\n        }\n        if ((leftType === undefined) !== (rightType === undefined)) {\n            return false;\n        }\n        if (leftType === rightType) {\n            return true;\n        }\n        if (leftType.tag !== rightType.tag) {\n            return false;\n        }\n        if (leftType.isSlot) {\n            return true;\n        }\n        // TODO: we need a generic way to evaluate type compatibility\n        //       shapes + entities + etc\n        if (leftType.isInterface && rightType.isInterface) {\n            if (leftType.interfaceShape.equals(rightType.interfaceShape)) {\n                return true;\n            }\n        }\n        if (!leftType.isEntity || !rightType.isEntity) {\n            return false;\n        }\n        const leftIsSub = leftType.entitySchema.isMoreSpecificThan(rightType.entitySchema);\n        const leftIsSuper = rightType.entitySchema.isMoreSpecificThan(leftType.entitySchema);\n        if (leftIsSuper && leftIsSub) {\n            return true;\n        }\n        if (!leftIsSuper && !leftIsSub) {\n            return false;\n        }\n        const [superclass, subclass] = leftIsSuper ? [left, right] : [right, left];\n        // treat handle types as if they were 'inout' connections. Note that this\n        // guarantees that the handle's type will be preserved, and that the fact\n        // that the type comes from a handle rather than a connection will also\n        // be preserved.\n        const superDirection = superclass.direction || (superclass.connection ? superclass.connection.direction : 'inout');\n        const subDirection = subclass.direction || (subclass.connection ? subclass.connection.direction : 'inout');\n        if (superDirection === 'in') {\n            return true;\n        }\n        if (subDirection === 'out') {\n            return true;\n        }\n        return false;\n    }\n}\n//# sourceMappingURL=type-checker.js.map","/** @license\n * Copyright (c) 2018 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../../platform/assert-web.js';\nimport { Type } from './type.js';\nimport { handleFor } from './handle.js';\nexport class Reference {\n    constructor(data, type, context) {\n        this.entity = null;\n        this.storageProxy = null;\n        this.handle = null;\n        this.id = data.id;\n        this.storageKey = data.storageKey;\n        this.context = context;\n        assert(type.isReference);\n        this.type = type;\n    }\n    async ensureStorageProxy() {\n        if (this.storageProxy == null) {\n            this.storageProxy = await this.context.getStorageProxy(this.storageKey, this.type.referenceReferredType);\n            this.handle = handleFor(this.storageProxy);\n            if (this.storageKey) {\n                assert(this.storageKey === this.storageProxy.storageKey);\n            }\n            else {\n                this.storageKey = this.storageProxy.storageKey;\n            }\n        }\n    }\n    async dereference() {\n        assert(this.context, \"Must have context to dereference\");\n        if (this.entity) {\n            return this.entity;\n        }\n        await this.ensureStorageProxy();\n        this.entity = await this.handle.get(this.id);\n        return this.entity;\n    }\n    dataClone() {\n        return { storageKey: this.storageKey, id: this.id };\n    }\n}\nvar ReferenceMode;\n(function (ReferenceMode) {\n    ReferenceMode[ReferenceMode[\"Unstored\"] = 0] = \"Unstored\";\n    ReferenceMode[ReferenceMode[\"Stored\"] = 1] = \"Stored\";\n})(ReferenceMode || (ReferenceMode = {}));\nexport function newClientReference(context) {\n    return class extends Reference {\n        constructor(entity) {\n            // TODO(shans): start carrying storageKey information around on Entity objects\n            super({ id: entity.id, storageKey: null }, Type.newReference(entity.constructor.type), context);\n            this.mode = ReferenceMode.Unstored;\n            this.entity = entity;\n            this.stored = new Promise(async (resolve, reject) => {\n                await this.storeReference(entity);\n                resolve();\n            });\n        }\n        async storeReference(entity) {\n            await this.ensureStorageProxy();\n            await this.handle.store(entity);\n            this.mode = ReferenceMode.Stored;\n        }\n        async dereference() {\n            if (this.mode === ReferenceMode.Unstored) {\n                return null;\n            }\n            return super.dereference();\n        }\n        isIdentified() {\n            return this.entity.isIdentified();\n        }\n    };\n}\n//# sourceMappingURL=reference.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../../platform/assert-web.js';\nimport { Type } from './type.js';\nimport { TypeChecker } from './recipe/type-checker.js';\nimport { Entity } from './entity.js';\nimport { Reference } from './reference.js';\nexport class Schema {\n    constructor(model) {\n        const legacy = [];\n        // TODO: remove this (remnants of normative/optional)\n        if (model.sections) {\n            legacy.push('sections');\n            assert(!model.fields);\n            model.fields = {};\n            for (const section of model.sections) {\n                Object.assign(model.fields, section.fields);\n            }\n            delete model.sections;\n        }\n        if (model.name) {\n            legacy.push('name');\n            model.names = [model.name];\n            delete model.name;\n        }\n        if (model.parents) {\n            legacy.push('parents');\n            for (const parent of model.parents) {\n                const parentSchema = new Schema(parent);\n                model.names.push(...parent.names);\n                Object.assign(model.fields, parent.fields);\n            }\n            model.names = [...new Set(model.names)];\n        }\n        if (legacy.length > 0) {\n            console.warn(`Schema ${model.names[0] || '*'} was serialized with legacy format (${legacy.join(', ')})`, new Error());\n        }\n        assert(model.fields);\n        this._model = model;\n        this.description = {};\n        if (model.description) {\n            model.description.description.forEach(desc => this.description[desc.name] = desc.pattern || desc.patterns[0]);\n        }\n    }\n    toLiteral() {\n        const fields = {};\n        const updateField = field => {\n            if (field.kind === 'schema-reference') {\n                const schema = field.schema;\n                return { kind: 'schema-reference', schema: { kind: schema.kind, model: schema.model.toLiteral() } };\n            }\n            else if (field.kind === 'schema-collection') {\n                return { kind: 'schema-collection', schema: updateField(field.schema) };\n            }\n            else {\n                return field;\n            }\n        };\n        for (const key of Object.keys(this._model.fields)) {\n            fields[key] = updateField(this._model.fields[key]);\n        }\n        return { names: this._model.names, fields, description: this.description };\n    }\n    static fromLiteral(data) {\n        const fields = {};\n        const updateField = field => {\n            if (field.kind === 'schema-reference') {\n                const schema = field.schema;\n                return { kind: 'schema-reference', schema: { kind: schema.kind, model: Type.fromLiteral(schema.model) } };\n            }\n            else if (field.kind === 'schema-collection') {\n                return { kind: 'schema-collection', schema: updateField(field.schema) };\n            }\n            else {\n                return field;\n            }\n        };\n        for (const key of Object.keys(data.fields)) {\n            fields[key] = updateField(data.fields[key]);\n        }\n        const result = new Schema({ names: data.names, fields });\n        result.description = data.description || {};\n        return result;\n    }\n    get fields() {\n        return this._model.fields;\n    }\n    get names() {\n        return this._model.names;\n    }\n    // TODO: This should only be an ident used in manifest parsing.\n    get name() {\n        return this.names[0];\n    }\n    static typesEqual(fieldType1, fieldType2) {\n        // TODO: structural check instead of stringification.\n        return Schema._typeString(fieldType1) === Schema._typeString(fieldType2);\n    }\n    static _typeString(type) {\n        if (typeof (type) !== 'object') {\n            assert(typeof type === 'string');\n            return type;\n        }\n        switch (type.kind) {\n            case 'schema-union':\n                return `(${type.types.join(' or ')})`;\n            case 'schema-tuple':\n                return `(${type.types.join(', ')})`;\n            case 'schema-reference':\n                return `Reference<${Schema._typeString(type.schema)}>`;\n            case 'type-name':\n            case 'schema-inline':\n                return type.model.entitySchema.toInlineSchemaString();\n            case 'schema-collection':\n                return `[${Schema._typeString(type.schema)}]`;\n            default:\n                throw new Error(`Unknown type kind ${type.kind} in schema ${this.name}`);\n        }\n    }\n    static union(schema1, schema2) {\n        const names = [...new Set([...schema1.names, ...schema2.names])];\n        const fields = {};\n        for (const [field, type] of [...Object.entries(schema1.fields), ...Object.entries(schema2.fields)]) {\n            if (fields[field]) {\n                if (!Schema.typesEqual(fields[field], type)) {\n                    return null;\n                }\n            }\n            else {\n                fields[field] = type;\n            }\n        }\n        return new Schema({\n            names,\n            fields,\n        });\n    }\n    static intersect(schema1, schema2) {\n        const names = [...schema1.names].filter(name => schema2.names.includes(name));\n        const fields = {};\n        for (const [field, type] of Object.entries(schema1.fields)) {\n            const otherType = schema2.fields[field];\n            if (otherType && Schema.typesEqual(type, otherType)) {\n                fields[field] = type;\n            }\n        }\n        return new Schema({\n            names,\n            fields,\n        });\n    }\n    equals(otherSchema) {\n        return this === otherSchema || (this.name === otherSchema.name\n            // TODO: Check equality without calling contains.\n            && this.isMoreSpecificThan(otherSchema)\n            && otherSchema.isMoreSpecificThan(this));\n    }\n    isMoreSpecificThan(otherSchema) {\n        const names = new Set(this.names);\n        for (const name of otherSchema.names) {\n            if (!names.has(name)) {\n                return false;\n            }\n        }\n        const fields = {};\n        for (const [name, type] of Object.entries(this.fields)) {\n            fields[name] = type;\n        }\n        for (const [name, type] of Object.entries(otherSchema.fields)) {\n            if (fields[name] == undefined) {\n                return false;\n            }\n            if (!Schema.typesEqual(fields[name], type)) {\n                return false;\n            }\n        }\n        return true;\n    }\n    get type() {\n        return Type.newEntity(this);\n    }\n    entityClass(context = null) {\n        const schema = this;\n        const className = this.name;\n        const classJunk = ['toJSON', 'prototype', 'toString', 'inspect'];\n        const convertToJsType = fieldType => {\n            switch (fieldType) {\n                case 'Text':\n                    return 'string';\n                case 'URL':\n                    return 'string';\n                case 'Number':\n                    return 'number';\n                case 'Boolean':\n                    return 'boolean';\n                case 'Object':\n                    return 'object';\n                default:\n                    throw new Error(`Unknown field type ${fieldType} in schema ${className}`);\n            }\n        };\n        const fieldTypes = this.fields;\n        const validateFieldAndTypes = (op, name, value) => _validateFieldAndTypes(op, name, fieldTypes[name], value);\n        const _validateFieldAndTypes = (op, name, fieldType, value) => {\n            if (fieldType === undefined) {\n                throw new Error(`Can't ${op} field ${name}; not in schema ${className}`);\n            }\n            if (value === undefined || value === null) {\n                return;\n            }\n            if (typeof (fieldType) !== 'object') {\n                // Primitive fields.\n                if (typeof (value) !== convertToJsType(fieldType)) {\n                    throw new TypeError(`Type mismatch ${op}ting field ${name} (type ${fieldType}); ` +\n                        `value '${value}' is type ${typeof (value)}`);\n                }\n                return;\n            }\n            switch (fieldType.kind) {\n                case 'schema-union':\n                    // Value must be a primitive that matches one of the union types.\n                    for (const innerType of fieldType.types) {\n                        if (typeof (value) === convertToJsType(innerType)) {\n                            return;\n                        }\n                    }\n                    throw new TypeError(`Type mismatch ${op}ting field ${name} (union [${fieldType.types}]); ` +\n                        `value '${value}' is type ${typeof (value)}`);\n                case 'schema-tuple':\n                    // Value must be an array whose contents match each of the tuple types.\n                    if (!Array.isArray(value)) {\n                        throw new TypeError(`Cannot ${op} tuple ${name} with non-array value '${value}'`);\n                    }\n                    if (value.length !== fieldType.types.length) {\n                        throw new TypeError(`Length mismatch ${op}ting tuple ${name} ` +\n                            `[${fieldType.types}] with value '${value}'`);\n                    }\n                    fieldType.types.map((innerType, i) => {\n                        if (value[i] !== undefined && value[i] !== null &&\n                            typeof (value[i]) !== convertToJsType(innerType)) {\n                            throw new TypeError(`Type mismatch ${op}ting field ${name} (tuple [${fieldType.types}]); ` +\n                                `value '${value}' has type ${typeof (value[i])} at index ${i}`);\n                        }\n                    });\n                    break;\n                case 'schema-reference':\n                    if (!(value instanceof Reference)) {\n                        throw new TypeError(`Cannot ${op} reference ${name} with non-reference '${value}'`);\n                    }\n                    if (!TypeChecker.compareTypes({ type: value.type }, { type: Type.newReference(fieldType.schema.model) })) {\n                        throw new TypeError(`Cannot ${op} reference ${name} with value '${value}' of mismatched type`);\n                    }\n                    break;\n                case 'schema-collection':\n                    // WTF?! value instanceof Set is returning false sometimes here because the Set in\n                    // this environment (a native code constructor) isn't equal to the Set that the value\n                    // has been constructed with (another native code constructor)...\n                    if (value.constructor.name !== 'Set') {\n                        throw new TypeError(`Cannot ${op} collection ${name} with non-Set '${value}'`);\n                    }\n                    for (const element of value) {\n                        _validateFieldAndTypes(op, name, fieldType.schema, element);\n                    }\n                    break;\n                default:\n                    throw new Error(`Unknown kind ${fieldType.kind} in schema ${className}`);\n            }\n        };\n        const clazz = class extends Entity {\n            constructor(data, userIDComponent) {\n                super(userIDComponent);\n                this.rawData = new Proxy({}, {\n                    get: (target, name) => {\n                        if (classJunk.includes(name) || name.constructor === Symbol) {\n                            return undefined;\n                        }\n                        const value = target[name];\n                        validateFieldAndTypes('get', name, value);\n                        return value;\n                    },\n                    set: (target, name, value) => {\n                        validateFieldAndTypes('set', name, value);\n                        target[name] = value;\n                        return true;\n                    }\n                });\n                assert(data, `can't construct entity with null data`);\n                // TODO: figure out how to do this only on wire-created entities.\n                const sanitizedData = this.sanitizeData(data);\n                for (const [name, value] of Object.entries(sanitizedData)) {\n                    this.rawData[name] = value;\n                }\n            }\n            sanitizeData(data) {\n                const sanitizedData = {};\n                for (const [name, value] of Object.entries(data)) {\n                    sanitizedData[name] = this.sanitizeEntry(fieldTypes[name], value, name);\n                }\n                return sanitizedData;\n            }\n            sanitizeEntry(type, value, name) {\n                if (!type) {\n                    // If there isn't a field type for this, the proxy will pick up\n                    // that fact and report a meaningful error.\n                    return value;\n                }\n                if (type.kind === 'schema-reference' && value) {\n                    if (value instanceof Reference) {\n                        // Setting value as Reference (Particle side). This will enforce that the type provided for\n                        // the handle matches the type of the reference.\n                        return value;\n                    }\n                    else if (value.id && value.storageKey) {\n                        // Setting value from raw data (Channel side).\n                        // TODO(shans): This can't enforce type safety here as there isn't any type data available.\n                        // Maybe this is OK because there's type checking on the other side of the channel?\n                        return new Reference(value, Type.newReference(type.schema.model), context);\n                    }\n                    else {\n                        throw new TypeError(`Cannot set reference ${name} with non-reference '${value}'`);\n                    }\n                }\n                else if (type.kind === 'schema-collection' && value) {\n                    // WTF?! value instanceof Set is returning false sometimes here because the Set in\n                    // this environment (a native code constructor) isn't equal to the Set that the value\n                    // has been constructed with (another native code constructor)...\n                    if (value.constructor.name === 'Set') {\n                        return value;\n                    }\n                    else if (value.length && value instanceof Object) {\n                        return new Set(value.map(v => this.sanitizeEntry(type.schema, v, name)));\n                    }\n                    else {\n                        throw new TypeError(`Cannot set collection ${name} with non-collection '${value}'`);\n                    }\n                }\n                else {\n                    return value;\n                }\n            }\n            dataClone() {\n                const clone = {};\n                for (const name of Object.keys(schema.fields)) {\n                    if (this.rawData[name] !== undefined) {\n                        if (fieldTypes[name] && fieldTypes[name].kind === 'schema-reference') {\n                            clone[name] = this.rawData[name].dataClone();\n                        }\n                        else if (fieldTypes[name] && fieldTypes[name].kind === 'schema-collection') {\n                            clone[name] = [...this.rawData[name]].map(a => a.dataClone());\n                        }\n                        else {\n                            clone[name] = this.rawData[name];\n                        }\n                    }\n                }\n                return clone;\n            }\n            static get type() {\n                // TODO: should the entity's key just be its type?\n                // Should it just be called type in that case?\n                return Type.newEntity(this.key.schema);\n            }\n            static get key() {\n                return {\n                    tag: 'entity',\n                    schema,\n                };\n            }\n        };\n        Object.defineProperty(clazz, 'type', { value: this.type });\n        Object.defineProperty(clazz, 'name', { value: this.name });\n        // TODO: add query / getter functions for user properties\n        for (const name of Object.keys(this.fields)) {\n            Object.defineProperty(clazz.prototype, name, {\n                get() {\n                    return this.rawData[name];\n                },\n                set(v) {\n                    this.rawData[name] = v;\n                }\n            });\n        }\n        return clazz;\n    }\n    toInlineSchemaString(options) {\n        const names = (this.names || ['*']).join(' ');\n        const fields = Object.entries(this.fields).map(([name, type]) => `${Schema._typeString(type)} ${name}`).join(', ');\n        return `${names} {${fields.length > 0 && options && options.hideFields ? '...' : fields}}`;\n    }\n    toManifestString() {\n        const results = [];\n        results.push(`schema ${this.names.join(' ')}`);\n        results.push(...Object.entries(this.fields).map(([name, type]) => `  ${Schema._typeString(type)} ${name}`));\n        if (Object.keys(this.description).length > 0) {\n            results.push(`  description \\`${this.description.pattern}\\``);\n            for (const name of Object.keys(this.description)) {\n                if (name !== 'pattern') {\n                    results.push(`    ${name} \\`${this.description[name]}\\``);\n                }\n            }\n        }\n        return results.join('\\n');\n    }\n}\n//# sourceMappingURL=schema.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { assert } from '../../platform/assert-web.js';\n// ShapeHandle {name, direction, type}\n// Slot {name, direction, isRequired, isSet}\nfunction _fromLiteral(member) {\n    if (!!member && typeof member === 'object') {\n        return Type.fromLiteral(member);\n    }\n    return member;\n}\nfunction _toLiteral(member) {\n    if (!!member && member.toLiteral) {\n        return member.toLiteral();\n    }\n    return member;\n}\nconst handleFields = ['type', 'name', 'direction'];\nconst slotFields = ['name', 'direction', 'isRequired', 'isSet'];\nexport class Shape {\n    constructor(name, handles, slots) {\n        assert(name);\n        assert(handles !== undefined);\n        assert(slots !== undefined);\n        this.name = name;\n        this.handles = handles;\n        this.slots = slots;\n        this.typeVars = [];\n        for (const handle of handles) {\n            for (const field of handleFields) {\n                if (Shape.isTypeVar(handle[field])) {\n                    this.typeVars.push({ object: handle, field });\n                }\n            }\n        }\n        for (const slot of slots) {\n            for (const field of slotFields) {\n                if (Shape.isTypeVar(slot[field])) {\n                    this.typeVars.push({ object: slot, field });\n                }\n            }\n        }\n    }\n    toPrettyString() {\n        return 'SHAAAAPE';\n    }\n    mergeTypeVariablesByName(variableMap) {\n        this.typeVars.map(({ object, field }) => object[field] = object[field].mergeTypeVariablesByName(variableMap));\n    }\n    get canReadSubset() {\n        return this._cloneAndUpdate(typeVar => typeVar.canReadSubset);\n    }\n    get canWriteSuperset() {\n        return this._cloneAndUpdate(typeVar => typeVar.canWriteSuperset);\n    }\n    isMoreSpecificThan(other) {\n        if (this.handles.length !== other.handles.length ||\n            this.slots.length !== other.slots.length) {\n            return false;\n        }\n        // TODO: should probably confirm that handles and slots actually match.\n        for (let i = 0; i < this.typeVars.length; i++) {\n            const thisTypeVar = this.typeVars[i];\n            const otherTypeVar = other.typeVars[i];\n            if (!thisTypeVar.object[thisTypeVar.field].isMoreSpecificThan(otherTypeVar.object[otherTypeVar.field])) {\n                return false;\n            }\n        }\n        return true;\n    }\n    _applyExistenceTypeTest(test) {\n        for (const typeRef of this.typeVars) {\n            if (test(typeRef.object[typeRef.field])) {\n                return true;\n            }\n        }\n        return false;\n    }\n    _handlesToManifestString() {\n        return this.handles\n            .map(handle => {\n            const type = handle.type.resolvedType();\n            return `  ${handle.direction ? handle.direction + ' ' : ''}${type.toString()} ${handle.name ? handle.name : '*'}`;\n        }).join('\\n');\n    }\n    _slotsToManifestString() {\n        // TODO deal with isRequired\n        return this.slots\n            .map(slot => `  ${slot.direction} ${slot.isSet ? 'set of ' : ''}${slot.name ? slot.name + ' ' : ''}`)\n            .join('\\n');\n    }\n    // TODO: Include name as a property of the shape and normalize this to just\n    // toString().\n    toString() {\n        return `shape ${this.name}\n${this._handlesToManifestString()}\n${this._slotsToManifestString()}\n`;\n    }\n    static fromLiteral(data) {\n        const handles = data.handles.map(handle => ({ type: _fromLiteral(handle.type), name: _fromLiteral(handle.name), direction: _fromLiteral(handle.direction) }));\n        const slots = data.slots.map(slot => ({ name: _fromLiteral(slot.name), direction: _fromLiteral(slot.direction), isRequired: _fromLiteral(slot.isRequired), isSet: _fromLiteral(slot.isSet) }));\n        return new Shape(data.name, handles, slots);\n    }\n    toLiteral() {\n        const handles = this.handles.map(handle => ({ type: _toLiteral(handle.type), name: _toLiteral(handle.name), direction: _toLiteral(handle.direction) }));\n        const slots = this.slots.map(slot => ({ name: _toLiteral(slot.name), direction: _toLiteral(slot.direction), isRequired: _toLiteral(slot.isRequired), isSet: _toLiteral(slot.isSet) }));\n        return { name: this.name, handles, slots };\n    }\n    clone(variableMap) {\n        const handles = this.handles.map(({ name, direction, type }) => ({ name, direction, type: type ? type.clone(variableMap) : undefined }));\n        const slots = this.slots.map(({ name, direction, isRequired, isSet }) => ({ name, direction, isRequired, isSet }));\n        return new Shape(this.name, handles, slots);\n    }\n    cloneWithResolutions(variableMap) {\n        return this._cloneWithResolutions(variableMap);\n    }\n    _cloneWithResolutions(variableMap) {\n        const handles = this.handles.map(({ name, direction, type }) => ({ name, direction, type: type ? type._cloneWithResolutions(variableMap) : undefined }));\n        const slots = this.slots.map(({ name, direction, isRequired, isSet }) => ({ name, direction, isRequired, isSet }));\n        return new Shape(this.name, handles, slots);\n    }\n    canEnsureResolved() {\n        for (const typeVar of this.typeVars) {\n            if (!typeVar.object[typeVar.field].canEnsureResolved()) {\n                return false;\n            }\n        }\n        return true;\n    }\n    maybeEnsureResolved() {\n        for (const typeVar of this.typeVars) {\n            let variable = typeVar.object[typeVar.field];\n            variable = variable.clone(new Map());\n            if (!variable.maybeEnsureResolved())\n                return false;\n        }\n        for (const typeVar of this.typeVars) {\n            typeVar.object[typeVar.field].maybeEnsureResolved();\n        }\n        return true;\n    }\n    tryMergeTypeVariablesWith(other) {\n        // Type variable enabled slot matching will Just Work when we\n        // unify slots and handles.\n        if (!this._equalItems(other.slots, this.slots, this._equalSlot)) {\n            return null;\n        }\n        if (other.handles.length !== this.handles.length) {\n            return null;\n        }\n        const handles = new Set(this.handles);\n        const otherHandles = new Set(other.handles);\n        const handleMap = new Map();\n        let sizeCheck = handles.size;\n        while (handles.size > 0) {\n            const handleMatches = [...handles.values()].map(handle => ({ handle, match: [...otherHandles.values()].filter(otherHandle => this._equalHandle(handle, otherHandle)) }));\n            for (const handleMatch of handleMatches) {\n                // no match!\n                if (handleMatch.match.length === 0) {\n                    return null;\n                }\n                if (handleMatch.match.length === 1) {\n                    handleMap.set(handleMatch.handle, handleMatch.match[0]);\n                    otherHandles.delete(handleMatch.match[0]);\n                    handles.delete(handleMatch.handle);\n                }\n            }\n            // no progress!\n            if (handles.size === sizeCheck) {\n                return null;\n            }\n            sizeCheck = handles.size;\n        }\n        const handleList = [];\n        for (const handle of this.handles) {\n            const otherHandle = handleMap.get(handle);\n            let resultType;\n            if (handle.type.hasVariable || otherHandle.type.hasVariable) {\n                resultType = TypeChecker._tryMergeTypeVariable(handle.type, otherHandle.type);\n                if (!resultType) {\n                    return null;\n                }\n            }\n            else {\n                resultType = handle.type || otherHandle.type;\n            }\n            handleList.push({ name: handle.name || otherHandle.name, direction: handle.direction || otherHandle.direction, type: resultType });\n        }\n        const slots = this.slots.map(({ name, direction, isRequired, isSet }) => ({ name, direction, isRequired, isSet }));\n        return new Shape(this.name, handleList, slots);\n    }\n    resolvedType() {\n        return this._cloneAndUpdate(typeVar => typeVar.resolvedType());\n    }\n    equals(other) {\n        if (this.handles.length !== other.handles.length) {\n            return false;\n        }\n        // TODO: this isn't quite right as it doesn't deal with duplicates properly\n        if (!this._equalItems(other.handles, this.handles, this._equalHandle)) {\n            return false;\n        }\n        if (!this._equalItems(other.slots, this.slots, this._equalSlot)) {\n            return false;\n        }\n        return true;\n    }\n    _equalHandle(handle, otherHandle) {\n        return handle.name === otherHandle.name && handle.direction === otherHandle.direction && handle.type.equals(otherHandle.type);\n    }\n    _equalSlot(slot, otherSlot) {\n        return slot.name === otherSlot.name && slot.direction === otherSlot.direction && slot.isRequired === otherSlot.isRequired && slot.isSet === otherSlot.isSet;\n    }\n    _equalItems(otherItems, items, compareItem) {\n        for (const otherItem of otherItems) {\n            let exists = false;\n            for (const item of items) {\n                if (compareItem(item, otherItem)) {\n                    exists = true;\n                    break;\n                }\n            }\n            if (!exists) {\n                return false;\n            }\n        }\n        return true;\n    }\n    _cloneAndUpdate(update) {\n        const copy = this.clone(new Map());\n        copy.typeVars.forEach(typeVar => Shape._updateTypeVar(typeVar, update));\n        return copy;\n    }\n    static _updateTypeVar(typeVar, update) {\n        typeVar.object[typeVar.field] = update(typeVar.object[typeVar.field]);\n    }\n    static isTypeVar(reference) {\n        return (reference instanceof Type) && reference.hasProperty(r => r.isVariable);\n    }\n    static mustMatch(reference) {\n        return !(reference == undefined || Shape.isTypeVar(reference));\n    }\n    static handlesMatch(shapeHandle, particleHandle) {\n        if (Shape.mustMatch(shapeHandle.name) &&\n            shapeHandle.name !== particleHandle.name) {\n            return false;\n        }\n        // TODO: direction subsetting?\n        if (Shape.mustMatch(shapeHandle.direction) &&\n            shapeHandle.direction !== particleHandle.direction) {\n            return false;\n        }\n        if (shapeHandle.type == undefined) {\n            return true;\n        }\n        if (shapeHandle.type.isVariableReference) {\n            return false;\n        }\n        const [left, right] = Type.unwrapPair(shapeHandle.type, particleHandle.type);\n        if (left.isVariable) {\n            return [{ var: left, value: right, direction: shapeHandle.direction }];\n        }\n        else {\n            return left.equals(right);\n        }\n    }\n    static slotsMatch(shapeSlot, particleSlot) {\n        if (Shape.mustMatch(shapeSlot.name) &&\n            shapeSlot.name !== particleSlot.name) {\n            return false;\n        }\n        if (Shape.mustMatch(shapeSlot.direction) &&\n            shapeSlot.direction !== particleSlot.direction) {\n            return false;\n        }\n        if (Shape.mustMatch(shapeSlot.isRequired) &&\n            shapeSlot.isRequired !== particleSlot.isRequired) {\n            return false;\n        }\n        if (Shape.mustMatch(shapeSlot.isSet) &&\n            shapeSlot.isSet !== particleSlot.isSet) {\n            return false;\n        }\n        return true;\n    }\n    particleMatches(particleSpec) {\n        const shape = this.cloneWithResolutions(new Map());\n        return shape.restrictType(particleSpec) !== false;\n    }\n    restrictType(particleSpec) {\n        return this._restrictThis(particleSpec);\n    }\n    _restrictThis(particleSpec) {\n        const handleMatches = this.handles.map(handle => particleSpec.connections.map(connection => ({ match: connection, result: Shape.handlesMatch(handle, connection) }))\n            .filter(a => a.result !== false));\n        const particleSlots = [];\n        particleSpec.slots.forEach(consumedSlot => {\n            particleSlots.push({ name: consumedSlot.name, direction: 'consume', isRequired: consumedSlot.isRequired, isSet: consumedSlot.isSet });\n            consumedSlot.providedSlots.forEach(providedSlot => {\n                particleSlots.push({ name: providedSlot.name, direction: 'provide', isRequired: false, isSet: providedSlot.isSet });\n            });\n        });\n        let slotMatches = this.slots.map(slot => particleSlots.filter(particleSlot => Shape.slotsMatch(slot, particleSlot)));\n        slotMatches = slotMatches.map(matchList => matchList.map(slot => ({ match: slot, result: true })));\n        const exclusions = [];\n        // TODO: this probably doesn't deal with multiple match options.\n        function choose(list, exclusions) {\n            if (list.length === 0) {\n                return [];\n            }\n            const thisLevel = list.pop();\n            for (const connection of thisLevel) {\n                if (exclusions.includes(connection.match)) {\n                    continue;\n                }\n                const newExclusions = exclusions.slice();\n                newExclusions.push(connection.match);\n                const constraints = choose(list, newExclusions);\n                if (constraints !== false) {\n                    return connection.result.length ? constraints.concat(connection.result) : constraints;\n                }\n            }\n            return false;\n        }\n        const handleOptions = choose(handleMatches, []);\n        const slotOptions = choose(slotMatches, []);\n        if (handleOptions === false || slotOptions === false) {\n            return false;\n        }\n        for (const constraint of handleOptions) {\n            if (!constraint.var.variable.resolution) {\n                constraint.var.variable.resolution = constraint.value;\n            }\n            else if (constraint.var.variable.resolution.isVariable) {\n                // TODO(shans): revisit how this should be done,\n                // consider reusing tryMergeTypeVariablesWith(other).\n                if (!TypeChecker.processTypeList(constraint.var, [{\n                        type: constraint.value, direction: constraint.direction\n                    }]))\n                    return false;\n            }\n            else {\n                if (!constraint.var.variable.resolution.equals(constraint.value))\n                    return false;\n            }\n        }\n        return this;\n    }\n}\nimport { Type } from './type.js';\nimport { TypeChecker } from './recipe/type-checker.js';\n//# sourceMappingURL=shape.js.map","// @license\n// Copyright (c) 2017 Google Inc. All rights reserved.\n// This code may only be used under the BSD style license found at\n// http://polymer.github.io/LICENSE.txt\n// Code distributed by Google as part of this project is also\n// subject to an additional IP rights grant found at\n// http://polymer.github.io/PATENTS.txt\nimport { assert } from '../../../platform/assert-web.js';\nexport class CrdtCollectionModel {\n    constructor(model = undefined) {\n        // id => {value, Set[keys]}\n        this.items = new Map();\n        if (model) {\n            for (let { id, value, keys } of model) {\n                if (!keys) {\n                    keys = [];\n                }\n                this.items.set(id, { value, keys: new Set(keys) });\n            }\n        }\n    }\n    /**\n     * Adds membership, `keys`, of `value` indexed by `id` to this collection.\n     * Returns whether the change is effective (`id` is new to the collection,\n     * or `value` is different to the value previously stored).\n     */\n    add(id, value, keys) {\n        // Ensure that keys is actually an array, not a single string.\n        // TODO(shans): remove this when all callers are implemented in typeScript.\n        assert(keys.length > 0 && typeof keys === 'object', 'add requires a list of keys');\n        let item = this.items.get(id);\n        let effective = false;\n        if (!item) {\n            item = { value, keys: new Set(keys) };\n            this.items.set(id, item);\n            effective = true;\n        }\n        else {\n            let newKeys = false;\n            for (const key of keys) {\n                if (!item.keys.has(key)) {\n                    newKeys = true;\n                }\n                item.keys.add(key);\n            }\n            if (!this._equals(item.value, value)) {\n                assert(newKeys, 'cannot add without new keys');\n                item.value = value;\n                effective = true;\n            }\n        }\n        return effective;\n    }\n    _equals(value1, value2) {\n        if (Boolean(value1) !== Boolean(value2)) {\n            return false;\n        }\n        if (!value1) {\n            return true;\n        }\n        const type1 = typeof (value1);\n        if (type1 !== typeof (value2)) {\n            return false;\n        }\n        if (type1 === 'object') {\n            const keys = Object.keys(value1);\n            if (keys.length !== Object.keys(value2).length) {\n                return false;\n            }\n            return keys.every(key => this._equals(value1[key], value2[key]));\n        }\n        return JSON.stringify(value1) === JSON.stringify(value2);\n    }\n    /**\n     * Removes the membership, `keys`, of the value indexed by `id` from this collection.\n     * Returns whether the change is effective (the value is no longer present\n     * in the collection because all of the keys have been removed).\n     */\n    remove(id, keys) {\n        const item = this.items.get(id);\n        if (!item) {\n            return false;\n        }\n        for (const key of keys) {\n            item.keys.delete(key);\n        }\n        const effective = item.keys.size === 0;\n        if (effective) {\n            this.items.delete(id);\n        }\n        return effective;\n    }\n    // [{id, value, keys: []}]\n    toLiteral() {\n        const result = [];\n        for (const [id, { value, keys }] of this.items.entries()) {\n            result.push({ id, value, keys: [...keys] });\n        }\n        return result;\n    }\n    toList() {\n        return [...this.items.values()].map(item => item.value);\n    }\n    has(id) {\n        return this.items.has(id);\n    }\n    getKeys(id) {\n        const item = this.items.get(id);\n        return item ? [...item.keys] : [];\n    }\n    getValue(id) {\n        const item = this.items.get(id);\n        return item ? item.value : null;\n    }\n    get size() {\n        return this.items.size;\n    }\n}\n//# sourceMappingURL=crdt-collection-model.js.map","// @license\n// Copyright (c) 2017 Google Inc. All rights reserved.\n// This code may only be used under the BSD style license found at\n// http://polymer.github.io/LICENSE.txt\n// Code distributed by Google as part of this project is also\n// subject to an additional IP rights grant found at\n// http://polymer.github.io/PATENTS.txt\n// tslint:disable-next-line: variable-name\nexport const Symbols = { identifier: Symbol('id') };\n//# sourceMappingURL=symbols.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\nimport { Type } from './type.js';\nexport class TupleFields {\n    constructor(fieldList) {\n        this.fieldList = fieldList;\n    }\n    static fromLiteral(literal) {\n        return new TupleFields(literal.map(a => Type.fromLiteral(a)));\n    }\n    toLiteral() {\n        return this.fieldList.map(a => a.toLiteral());\n    }\n    clone() {\n        return new TupleFields(this.fieldList.map(a => a.clone({})));\n    }\n    equals(other) {\n        if (this.fieldList.length !== other.fieldList.length) {\n            return false;\n        }\n        for (let i = 0; i < this.fieldList.length; i++) {\n            if (!this.fieldList[i].equals(other.fieldList[i])) {\n                return false;\n            }\n        }\n        return true;\n    }\n}\n//# sourceMappingURL=tuple-fields.js.map","// @license\n// Copyright (c) 2017 Google Inc. All rights reserved.\n// This code may only be used under the BSD style license found at\n// http://polymer.github.io/LICENSE.txt\n// Code distributed by Google as part of this project is also\n// subject to an additional IP rights grant found at\n// http://polymer.github.io/PATENTS.txt\nimport { Type } from './type.js';\nimport { assert } from '../../platform/assert-web.js';\nimport { Schema } from './schema.js';\nexport class TypeVariable {\n    constructor(name, canWriteSuperset, canReadSubset) {\n        this.name = name;\n        this._canWriteSuperset = canWriteSuperset;\n        this._canReadSubset = canReadSubset;\n        this._resolution = null;\n    }\n    /**\n     * Merge both the read subset (upper bound) and write superset (lower bound) constraints\n     * of two variables together. Use this when two separate type variables need to resolve\n     * to the same value.\n     */\n    maybeMergeConstraints(variable) {\n        if (!this.maybeMergeCanReadSubset(variable.canReadSubset)) {\n            return false;\n        }\n        return this.maybeMergeCanWriteSuperset(variable.canWriteSuperset);\n    }\n    /**\n     * Merge a type variable's read subset (upper bound) constraints into this variable.\n     * This is used to accumulate read constraints when resolving a handle's type.\n     */\n    maybeMergeCanReadSubset(constraint) {\n        if (constraint == null) {\n            return true;\n        }\n        if (this.canReadSubset == null) {\n            this.canReadSubset = constraint;\n            return true;\n        }\n        if (this.canReadSubset.isSlot && constraint.isSlot) {\n            // TODO: formFactor compatibility, etc.\n            return true;\n        }\n        const mergedSchema = Schema.intersect(this.canReadSubset.entitySchema, constraint.entitySchema);\n        if (!mergedSchema) {\n            return false;\n        }\n        this.canReadSubset = Type.newEntity(mergedSchema);\n        return true;\n    }\n    /**\n     * merge a type variable's write superset (lower bound) constraints into this variable.\n     * This is used to accumulate write constraints when resolving a handle's type.\n     */\n    maybeMergeCanWriteSuperset(constraint) {\n        if (constraint == null) {\n            return true;\n        }\n        if (this.canWriteSuperset == null) {\n            this.canWriteSuperset = constraint;\n            return true;\n        }\n        if (this.canWriteSuperset.isSlot && constraint.isSlot) {\n            // TODO: formFactor compatibility, etc.\n            return true;\n        }\n        const mergedSchema = Schema.union(this.canWriteSuperset.entitySchema, constraint.entitySchema);\n        if (!mergedSchema) {\n            return false;\n        }\n        this.canWriteSuperset = Type.newEntity(mergedSchema);\n        return true;\n    }\n    isSatisfiedBy(type) {\n        const constraint = this._canWriteSuperset;\n        if (!constraint) {\n            return true;\n        }\n        if (!constraint.isEntity || !type.isEntity) {\n            throw new Error(`constraint checking not implemented for ${this} and ${type}`);\n        }\n        return type.entitySchema.isMoreSpecificThan(constraint.entitySchema);\n    }\n    get resolution() {\n        if (this._resolution) {\n            return this._resolution.resolvedType();\n        }\n        return null;\n    }\n    set resolution(value) {\n        assert(!this._resolution);\n        const elementType = value.resolvedType().getContainedType();\n        if (elementType !== null && elementType.isVariable) {\n            assert(elementType.variable !== this, 'variable cannot resolve to collection of itself');\n        }\n        let probe = value;\n        while (probe) {\n            if (!probe.isVariable) {\n                break;\n            }\n            if (probe.variable === this) {\n                return;\n            }\n            probe = probe.variable.resolution;\n        }\n        this._resolution = value;\n        this._canWriteSuperset = null;\n        this._canReadSubset = null;\n    }\n    get canWriteSuperset() {\n        if (this._resolution) {\n            assert(!this._canWriteSuperset);\n            if (this._resolution.isVariable) {\n                return this._resolution.variable.canWriteSuperset;\n            }\n            return null;\n        }\n        return this._canWriteSuperset;\n    }\n    set canWriteSuperset(value) {\n        assert(!this._resolution);\n        this._canWriteSuperset = value;\n    }\n    get canReadSubset() {\n        if (this._resolution) {\n            assert(!this._canReadSubset);\n            if (this._resolution.isVariable) {\n                return this._resolution.variable.canReadSubset;\n            }\n            return null;\n        }\n        return this._canReadSubset;\n    }\n    set canReadSubset(value) {\n        assert(!this._resolution);\n        this._canReadSubset = value;\n    }\n    get hasConstraint() {\n        return this._canReadSubset !== null || this._canWriteSuperset !== null;\n    }\n    canEnsureResolved() {\n        if (this._resolution) {\n            return this._resolution.canEnsureResolved();\n        }\n        if (this._canWriteSuperset || this._canReadSubset) {\n            return true;\n        }\n        return false;\n    }\n    maybeEnsureResolved() {\n        if (this._resolution) {\n            return this._resolution.maybeEnsureResolved();\n        }\n        if (this._canWriteSuperset) {\n            this.resolution = this._canWriteSuperset;\n            return true;\n        }\n        if (this._canReadSubset) {\n            this.resolution = this._canReadSubset;\n            return true;\n        }\n        return false;\n    }\n    toLiteral() {\n        assert(this.resolution == null);\n        return this.toLiteralIgnoringResolutions();\n    }\n    toLiteralIgnoringResolutions() {\n        return {\n            name: this.name,\n            canWriteSuperset: this._canWriteSuperset && this._canWriteSuperset.toLiteral(),\n            canReadSubset: this._canReadSubset && this._canReadSubset.toLiteral()\n        };\n    }\n    static fromLiteral(data) {\n        return new TypeVariable(data.name, data.canWriteSuperset ? Type.fromLiteral(data.canWriteSuperset) : null, data.canReadSubset ? Type.fromLiteral(data.canReadSubset) : null);\n    }\n    isResolved() {\n        return (this._resolution && this._resolution.isResolved());\n    }\n}\n//# sourceMappingURL=type-variable.js.map","// @license\n// Copyright (c) 2017 Google Inc. All rights reserved.\n// This code may only be used under the BSD style license found at\n// http://polymer.github.io/LICENSE.txt\n// Code distributed by Google as part of this project is also\n// subject to an additional IP rights grant found at\n// http://polymer.github.io/PATENTS.txt\nimport { assert } from '../../platform/assert-web.js';\nfunction addType(name, arg) {\n    const lowerName = name[0].toLowerCase() + name.substring(1);\n    const upperArg = arg ? arg[0].toUpperCase() + arg.substring(1) : '';\n    Object.defineProperty(Type.prototype, `${lowerName}${upperArg}`, {\n        get() {\n            if (!this[`is${name}`]) {\n                assert(this[`is${name}`], `{${this.tag}, ${this.data}} is not of type ${name}`);\n            }\n            return this.data;\n        }\n    });\n    Object.defineProperty(Type.prototype, `is${name}`, {\n        get() {\n            return this.tag === name;\n        }\n    });\n}\nexport class Type {\n    constructor(tag, data) {\n        assert(typeof tag === 'string');\n        assert(data);\n        if (tag === 'Entity') {\n            assert(data instanceof Schema);\n        }\n        if (tag === 'Collection' || tag === 'BigCollection') {\n            if (!(data instanceof Type) && data.tag && data.data) {\n                data = new Type(data.tag, data.data);\n            }\n        }\n        if (tag === 'Variable') {\n            if (!(data instanceof TypeVariable)) {\n                // type constraints (\"~a with EntityName\") should be considered minimum requirements\n                // for the type, so are fed in as 'canWriteSuperset' (i.e. low-watermark) constraints.\n                data = new TypeVariable(data.name, data.constraint, null);\n            }\n        }\n        this.tag = tag;\n        this.data = data;\n    }\n    static newEntity(entity) {\n        return new Type('Entity', entity);\n    }\n    static newVariable(variable) {\n        return new Type('Variable', variable);\n    }\n    static newCollection(collection) {\n        return new Type('Collection', collection);\n    }\n    static newBigCollection(bigCollection) {\n        return new Type('BigCollection', bigCollection);\n    }\n    static newRelation(relation) {\n        return new Type('Relation', relation);\n    }\n    static newInterface(iface) {\n        return new Type('Interface', iface);\n    }\n    static newSlot(slot) {\n        return new Type('Slot', slot);\n    }\n    static newReference(reference) {\n        return new Type('Reference', reference);\n    }\n    // Provided only to get a Type object for SyntheticStorage; do not use otherwise.\n    static newSynthesized() {\n        return new Type('Synthesized', 1);\n    }\n    mergeTypeVariablesByName(variableMap) {\n        if (this.isVariable) {\n            const name = this.variable.name;\n            let variable = variableMap.get(name);\n            if (!variable) {\n                variable = this;\n                variableMap.set(name, this);\n            }\n            else {\n                if (variable.variable.hasConstraint || this.variable.hasConstraint) {\n                    const mergedConstraint = variable.variable.maybeMergeConstraints(this.variable);\n                    if (!mergedConstraint) {\n                        throw new Error('could not merge type variables');\n                    }\n                }\n            }\n            return variable;\n        }\n        if (this.isCollection) {\n            const primitiveType = this.collectionType;\n            const result = primitiveType.mergeTypeVariablesByName(variableMap);\n            return (result === primitiveType) ? this : result.collectionOf();\n        }\n        if (this.isBigCollection) {\n            const primitiveType = this.bigCollectionType;\n            const result = primitiveType.mergeTypeVariablesByName(variableMap);\n            return (result === primitiveType) ? this : result.bigCollectionOf();\n        }\n        if (this.isInterface) {\n            const shape = this.interfaceShape.clone(new Map());\n            shape.mergeTypeVariablesByName(variableMap);\n            // TODO: only build a new type when a variable is modified\n            return Type.newInterface(shape);\n        }\n        return this;\n    }\n    static unwrapPair(type1, type2) {\n        assert(type1 instanceof Type);\n        assert(type2 instanceof Type);\n        if (type1.isCollection && type2.isCollection) {\n            return Type.unwrapPair(type1.collectionType, type2.collectionType);\n        }\n        if (type1.isBigCollection && type2.isBigCollection) {\n            return Type.unwrapPair(type1.bigCollectionType, type2.bigCollectionType);\n        }\n        if (type1.isReference && type2.isReference) {\n            return Type.unwrapPair(type1.referenceReferredType, type2.referenceReferredType);\n        }\n        return [type1, type2];\n    }\n    // TODO: update call sites to use the type checker instead (since they will\n    // have additional information about direction etc.)\n    equals(type) {\n        return TypeChecker.compareTypes({ type: this }, { type });\n    }\n    _applyExistenceTypeTest(test) {\n        if (this.isCollection) {\n            return this.collectionType._applyExistenceTypeTest(test);\n        }\n        if (this.isBigCollection) {\n            return this.bigCollectionType._applyExistenceTypeTest(test);\n        }\n        if (this.isInterface) {\n            return this.interfaceShape._applyExistenceTypeTest(test);\n        }\n        return test(this);\n    }\n    get hasVariable() {\n        return this._applyExistenceTypeTest(type => type.isVariable);\n    }\n    get hasUnresolvedVariable() {\n        return this._applyExistenceTypeTest(type => type.isVariable && !type.variable.isResolved());\n    }\n    get hasVariableReference() {\n        return this._applyExistenceTypeTest(type => type.isVariableReference);\n    }\n    // TODO: remove this in favor of a renamed collectionType\n    primitiveType() {\n        return this.collectionType;\n    }\n    getContainedType() {\n        if (this.isCollection) {\n            return this.collectionType;\n        }\n        if (this.isBigCollection) {\n            return this.bigCollectionType;\n        }\n        if (this.isReference) {\n            return this.referenceReferredType;\n        }\n        return null;\n    }\n    isTypeContainer() {\n        return this.isCollection || this.isBigCollection || this.isReference;\n    }\n    collectionOf() {\n        return Type.newCollection(this);\n    }\n    bigCollectionOf() {\n        return Type.newBigCollection(this);\n    }\n    resolvedType() {\n        if (this.isCollection) {\n            const primitiveType = this.collectionType;\n            const resolvedPrimitiveType = primitiveType.resolvedType();\n            return (primitiveType !== resolvedPrimitiveType) ? resolvedPrimitiveType.collectionOf() : this;\n        }\n        if (this.isBigCollection) {\n            const primitiveType = this.bigCollectionType;\n            const resolvedPrimitiveType = primitiveType.resolvedType();\n            return (primitiveType !== resolvedPrimitiveType) ? resolvedPrimitiveType.bigCollectionOf() : this;\n        }\n        if (this.isReference) {\n            const primitiveType = this.referenceReferredType;\n            const resolvedPrimitiveType = primitiveType.resolvedType();\n            return (primitiveType !== resolvedPrimitiveType) ? Type.newReference(resolvedPrimitiveType) : this;\n        }\n        if (this.isVariable) {\n            const resolution = this.variable.resolution;\n            if (resolution) {\n                return resolution;\n            }\n        }\n        if (this.isInterface) {\n            return Type.newInterface(this.interfaceShape.resolvedType());\n        }\n        return this;\n    }\n    isResolved() {\n        // TODO: one of these should not exist.\n        return !this.hasUnresolvedVariable;\n    }\n    canEnsureResolved() {\n        if (this.isResolved()) {\n            return true;\n        }\n        if (this.isInterface) {\n            return this.interfaceShape.canEnsureResolved();\n        }\n        if (this.isVariable) {\n            return this.variable.canEnsureResolved();\n        }\n        if (this.isCollection) {\n            return this.collectionType.canEnsureResolved();\n        }\n        if (this.isBigCollection) {\n            return this.bigCollectionType.canEnsureResolved();\n        }\n        if (this.isReference) {\n            return this.referenceReferredType.canEnsureResolved();\n        }\n        return true;\n    }\n    maybeEnsureResolved() {\n        if (this.isInterface) {\n            return this.interfaceShape.maybeEnsureResolved();\n        }\n        if (this.isVariable) {\n            return this.variable.maybeEnsureResolved();\n        }\n        if (this.isCollection) {\n            return this.collectionType.maybeEnsureResolved();\n        }\n        if (this.isBigCollection) {\n            return this.bigCollectionType.maybeEnsureResolved();\n        }\n        if (this.isReference) {\n            return this.referenceReferredType.maybeEnsureResolved();\n        }\n        return true;\n    }\n    get canWriteSuperset() {\n        if (this.isVariable) {\n            return this.variable.canWriteSuperset;\n        }\n        if (this.isEntity || this.isSlot) {\n            return this;\n        }\n        if (this.isInterface) {\n            return Type.newInterface(this.interfaceShape.canWriteSuperset);\n        }\n        throw new Error(`canWriteSuperset not implemented for ${this}`);\n    }\n    get canReadSubset() {\n        if (this.isVariable) {\n            return this.variable.canReadSubset;\n        }\n        if (this.isEntity || this.isSlot) {\n            return this;\n        }\n        if (this.isInterface) {\n            return Type.newInterface(this.interfaceShape.canReadSubset);\n        }\n        if (this.isReference) {\n            return this.referenceReferredType.canReadSubset;\n        }\n        throw new Error(`canReadSubset not implemented for ${this}`);\n    }\n    isMoreSpecificThan(type) {\n        if (this.tag !== type.tag) {\n            return false;\n        }\n        if (this.isEntity) {\n            return this.entitySchema.isMoreSpecificThan(type.entitySchema);\n        }\n        if (this.isInterface) {\n            return this.interfaceShape.isMoreSpecificThan(type.interfaceShape);\n        }\n        if (this.isSlot) {\n            // TODO: formFactor checking, etc.\n            return true;\n        }\n        throw new Error(`contains not implemented for ${this}`);\n    }\n    static _canMergeCanReadSubset(type1, type2) {\n        if (type1.canReadSubset && type2.canReadSubset) {\n            if (type1.canReadSubset.tag !== type2.canReadSubset.tag) {\n                return false;\n            }\n            if (type1.canReadSubset.isEntity) {\n                return Schema.intersect(type1.canReadSubset.entitySchema, type2.canReadSubset.entitySchema) !== null;\n            }\n            throw new Error(`_canMergeCanReadSubset not implemented for types tagged with ${type1.canReadSubset.tag}`);\n        }\n        return true;\n    }\n    static _canMergeCanWriteSuperset(type1, type2) {\n        if (type1.canWriteSuperset && type2.canWriteSuperset) {\n            if (type1.canWriteSuperset.tag !== type2.canWriteSuperset.tag) {\n                return false;\n            }\n            if (type1.canWriteSuperset.isEntity) {\n                return Schema.union(type1.canWriteSuperset.entitySchema, type2.canWriteSuperset.entitySchema) !== null;\n            }\n        }\n        return true;\n    }\n    /** Tests whether two types' constraints are compatible with each other. */\n    static canMergeConstraints(type1, type2) {\n        return Type._canMergeCanReadSubset(type1, type2) && Type._canMergeCanWriteSuperset(type1, type2);\n    }\n    /**\n     * Clone a type object.\n     * When cloning multiple types, variables that were associated with the same name\n     * before cloning should still be associated after cloning. To maintain this\n     * property, create a Map() and pass it into all clone calls in the group.\n     */\n    clone(variableMap) {\n        const type = this.resolvedType();\n        if (type.isVariable) {\n            if (variableMap.has(type.variable)) {\n                return new Type('Variable', variableMap.get(type.variable));\n            }\n            else {\n                const newTypeVariable = TypeVariable.fromLiteral(type.variable.toLiteral());\n                variableMap.set(type.variable, newTypeVariable);\n                return new Type('Variable', newTypeVariable);\n            }\n        }\n        if (type.data.clone) {\n            return new Type(type.tag, type.data.clone(variableMap));\n        }\n        return Type.fromLiteral(type.toLiteral());\n    }\n    /**\n     * Clone a type object, maintaining resolution information.\n     * This function SHOULD NOT BE USED at the type level. In order for type variable\n     * information to be maintained correctly, an entire context root needs to be\n     * cloned.\n     */\n    _cloneWithResolutions(variableMap) {\n        if (this.isVariable) {\n            if (variableMap.has(this.variable)) {\n                return new Type('Variable', variableMap.get(this.variable));\n            }\n            else {\n                const newTypeVariable = TypeVariable.fromLiteral(this.variable.toLiteralIgnoringResolutions());\n                if (this.variable.resolution) {\n                    newTypeVariable.resolution = this.variable.resolution._cloneWithResolutions(variableMap);\n                }\n                if (this.variable._canReadSubset) {\n                    newTypeVariable.canReadSubset = this.variable.canReadSubset._cloneWithResolutions(variableMap);\n                }\n                if (this.variable._canWriteSuperset) {\n                    newTypeVariable.canWriteSuperset = this.variable.canWriteSuperset._cloneWithResolutions(variableMap);\n                }\n                variableMap.set(this.variable, newTypeVariable);\n                return new Type('Variable', newTypeVariable);\n            }\n        }\n        if (this.data instanceof Shape || this.data instanceof Type) {\n            return new Type(this.tag, this.data._cloneWithResolutions(variableMap));\n        }\n        return Type.fromLiteral(this.toLiteral());\n    }\n    toLiteral() {\n        if (this.isVariable && this.variable.resolution) {\n            return this.variable.resolution.toLiteral();\n        }\n        if (this.data instanceof Type || this.data instanceof Shape || this.data instanceof Schema ||\n            this.data instanceof TypeVariable) {\n            return { tag: this.tag, data: this.data.toLiteral() };\n        }\n        return this;\n    }\n    static _deliteralizer(tag) {\n        switch (tag) {\n            case 'Interface':\n                return Shape.fromLiteral;\n            case 'Entity':\n                return Schema.fromLiteral;\n            case 'Collection':\n            case 'BigCollection':\n                return Type.fromLiteral;\n            case 'Tuple':\n                return TupleFields.fromLiteral;\n            case 'Variable':\n                return TypeVariable.fromLiteral;\n            case 'Reference':\n                return Type.fromLiteral;\n            default:\n                return a => a;\n        }\n    }\n    static fromLiteral(literal) {\n        if (literal.tag === 'SetView') {\n            // TODO: SetView is deprecated, remove when possible.\n            literal.tag = 'Collection';\n        }\n        return new Type(literal.tag, Type._deliteralizer(literal.tag)(literal.data));\n    }\n    // TODO: is this the same as _applyExistenceTypeTest\n    hasProperty(property) {\n        if (property(this)) {\n            return true;\n        }\n        if (this.isCollection) {\n            return this.collectionType.hasProperty(property);\n        }\n        if (this.isBigCollection) {\n            return this.bigCollectionType.hasProperty(property);\n        }\n        return false;\n    }\n    toString(options = undefined) {\n        if (this.isCollection) {\n            return `[${this.collectionType.toString(options)}]`;\n        }\n        if (this.isBigCollection) {\n            return `BigCollection<${this.bigCollectionType.toString(options)}>`;\n        }\n        if (this.isEntity) {\n            return this.entitySchema.toInlineSchemaString(options);\n        }\n        if (this.isInterface) {\n            return this.interfaceShape.name;\n        }\n        if (this.isVariable) {\n            return `~${this.variable.name}`;\n        }\n        if (this.isSlot) {\n            const fields = [];\n            for (const key of Object.keys(this.data)) {\n                if (this.data[key] !== undefined) {\n                    fields.push(`${key}:${this.data[key]}`);\n                }\n            }\n            let fieldsString = '';\n            if (fields.length !== 0) {\n                fieldsString = ` {${fields.join(', ')}}`;\n            }\n            return `Slot${fieldsString}`;\n        }\n        if (this.isReference) {\n            return 'Reference<' + this.referenceReferredType.toString() + '>';\n        }\n        throw new Error(`Add support to serializing type: ${JSON.stringify(this)}`);\n    }\n    getEntitySchema() {\n        if (this.isCollection) {\n            return this.collectionType.getEntitySchema();\n        }\n        if (this.isBigCollection) {\n            return this.bigCollectionType.getEntitySchema();\n        }\n        if (this.isEntity) {\n            return this.entitySchema;\n        }\n        if (this.isVariable) {\n            if (this.variable.isResolved()) {\n                return this.resolvedType().getEntitySchema();\n            }\n        }\n    }\n    toPrettyString() {\n        // Try extract the description from schema spec.\n        const entitySchema = this.getEntitySchema();\n        if (entitySchema) {\n            if (this.isTypeContainer() && entitySchema.description.plural) {\n                return entitySchema.description.plural;\n            }\n            if (this.isEntity && entitySchema.description.pattern) {\n                return entitySchema.description.pattern;\n            }\n        }\n        if (this.isRelation) {\n            return JSON.stringify(this.data);\n        }\n        if (this.isCollection) {\n            return `${this.collectionType.toPrettyString()} List`;\n        }\n        if (this.isBigCollection) {\n            return `Collection of ${this.bigCollectionType.toPrettyString()}`;\n        }\n        if (this.isVariable) {\n            return this.variable.isResolved() ? this.resolvedType().toPrettyString() : `[~${this.variable.name}]`;\n        }\n        if (this.isSlot) {\n            const fields = [];\n            for (const key of Object.keys(this.data)) {\n                if (this.data[key] !== undefined) {\n                    fields.push(`${key}:${this.data[key]}`);\n                }\n            }\n            let fieldsString = '';\n            if (fields.length !== 0) {\n                fieldsString = ` {${fields.join(', ')}}`;\n            }\n            return `Slot${fieldsString}`;\n        }\n        if (this.isEntity) {\n            // Spit MyTypeFOO to My Type FOO\n            if (this.entitySchema.name) {\n                return this.entitySchema.name.replace(/([^A-Z])([A-Z])/g, '$1 $2').replace(/([A-Z][^A-Z])/g, ' $1').replace(/[\\s]+/g, ' ').trim();\n            }\n            return JSON.stringify(this.entitySchema.toLiteral());\n        }\n        if (this.isInterface) {\n            return this.interfaceShape.toPrettyString();\n        }\n    }\n}\naddType('Entity', 'schema');\naddType('Variable');\naddType('Collection', 'type');\naddType('BigCollection', 'type');\naddType('Relation', 'entities');\naddType('Interface', 'shape');\naddType('Slot');\naddType('Reference', 'referredType');\n// Special case for SyntheticStorage, not a real Type in the usual sense.\naddType('Synthesized');\nimport { Shape } from './shape.js';\nimport { Schema } from './schema.js';\nimport { TypeVariable } from './type-variable.js';\nimport { TupleFields } from './tuple-fields.js';\nimport { TypeChecker } from './recipe/type-checker.js';\n//# sourceMappingURL=type.js.map","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n\nconst nob = () => Object.create(null);\n\nconst debounce = (key, action, delay) => {\n  if (key) {\n    clearTimeout(key);\n  }\n  if (action && delay) {\n    return setTimeout(action, delay);\n  }\n};\n\nconst XenStateMixin = Base => class extends Base {\n  constructor() {\n    super();\n    this._pendingProps = nob();\n    this._props = this._getInitialProps() || nob();\n    this._lastProps = nob();\n    this._state = this._getInitialState() || nob();\n    this._lastState = nob();\n  }\n  _getInitialProps() {\n  }\n  _getInitialState() {\n  }\n  _getProperty(name) {\n    return this._pendingProps[name] || this._props[name];\n  }\n  _setProperty(name, value) {\n    // dirty checking opportunity\n    if (this._validator || this._wouldChangeProp(name, value)) {\n      this._pendingProps[name] = value;\n      this._invalidateProps();\n    }\n  }\n  _wouldChangeValue(map, name, value) {\n    // TODO(sjmiles): fundamental dirty-checking issue here. Can be overridden to change\n    // behavior, but the default implementation will use strict reference checking.\n    // To modify structured values one must create a new Object with the new values.\n    // See `_setImmutableState`.\n    return (map[name] !== value);\n    // TODO(sjmiles): an example of dirty-checking that instead simply punts on structured data\n    //return (typeof value === 'object') || (map[name] !== value);\n  }\n  _wouldChangeProp(name, value) {\n    return this._wouldChangeValue(this._props, name, value);\n  }\n  _wouldChangeState(name, value) {\n    return this._wouldChangeValue(this._state, name, value);\n  }\n  _setProps(props) {\n    // TODO(sjmiles): should be a replace instead of a merge?\n    Object.assign(this._pendingProps, props);\n    this._invalidateProps();\n  }\n  _invalidateProps() {\n    this._propsInvalid = true;\n    this._invalidate();\n  }\n  _setImmutableState(name, value) {\n    if (typeof name === 'object') {\n      console.warn('Xen:: _setImmutableState takes name and value args for a single property, dictionaries not supported.');\n      value = Object.values(name)[0];\n      name = Object.names(name)[0];\n    }\n    if (typeof value === 'object') {\n      value = Object.assign(Object.create(null), value);\n    }\n    this._state[name] = value;\n    this._invalidate();\n  }\n  _setState(object) {\n    let dirty = false;\n    const state = this._state;\n    for (const property in object) {\n      const value = object[property];\n      if (this._wouldChangeState(property, value)) {\n        dirty = true;\n        state[property] = value;\n      }\n    }\n    if (dirty) {\n      this._invalidate();\n      return true;\n    }\n  }\n  // TODO(sjmiles): deprecated\n  _setIfDirty(object) {\n    return this._setState(object);\n  }\n  _async(fn) {\n    return Promise.resolve().then(fn.bind(this));\n    //return setTimeout(fn.bind(this), 10);\n  }\n  _invalidate() {\n    if (!this._validator) {\n      this._validator = this._async(this._validate);\n    }\n  }\n  _getStateArgs() {\n    return [this._props, this._state, this._lastProps, this._lastState];\n  }\n  _validate() {\n    const stateArgs = this._getStateArgs();\n    // try..catch to ensure we nullify `validator` before return\n    try {\n      // TODO(sjmiles): should be a replace instead of a merge\n      Object.assign(this._props, this._pendingProps);\n      if (this._propsInvalid) {\n        // TODO(sjmiles): should/can have different timing from rendering?\n        this._willReceiveProps(...stateArgs);\n        this._propsInvalid = false;\n      }\n      if (this._shouldUpdate(...stateArgs)) {\n        // TODO(sjmiles): consider throttling update to rAF\n        this._ensureMount();\n        this._doUpdate(...stateArgs);\n      }\n    } catch (x) {\n      console.error(x);\n    }\n    // nullify validator _after_ methods so state changes don't reschedule validation\n    this._validator = null;\n    // save the old props and state\n    this._lastProps = Object.assign(nob(), this._props);\n    this._lastState = Object.assign(nob(), this._state);\n  }\n  _doUpdate(...stateArgs) {\n    this._update(...stateArgs);\n    this._didUpdate(...stateArgs);\n  }\n  _ensureMount() {\n  }\n  _willReceiveProps() {\n  }\n  _shouldUpdate() {\n    return true;\n  }\n  _update() {\n  }\n  _didUpdate() {\n  }\n  _debounce(key, func, delay) {\n    key = `_debounce_${key}`;\n    this._state[key] = debounce(this._state[key], func, delay != null ? delay : 16);\n  }\n};\n\nexport {XenStateMixin, nob, debounce};\n","/**\n * @license\n * Copyright (c) 2017 Google Inc. All rights reserved.\n * This code may only be used under the BSD style license found at\n * http://polymer.github.io/LICENSE.txt\n * Code distributed by Google as part of this project is also\n * subject to an additional IP rights grant found at\n * http://polymer.github.io/PATENTS.txt\n */\n\nimport {Loader} from '../../runtime/ts-build/loader.js';\nimport {Particle} from '../../runtime/particle.js';\nimport {DomParticle} from '../../runtime/dom-particle.js';\nimport {MultiplexerDomParticle} from '../../runtime/multiplexer-dom-particle.js';\nimport {TransformationDomParticle} from '../../runtime/transformation-dom-particle.js';\n\nconst logFactory = (preamble, color, log='log') => console[log].bind(console, `%c${preamble} [Particle]`, `background: ${color}; color: white; padding: 1px 6px 2px 7px; border-radius: 4px;`);\nconst html = (strings, ...values) => (strings[0] + values.map((v, i) => v + strings[i + 1]).join('')).trim();\n\nconst dumbCache = {};\n\nexport class BrowserLoader extends Loader {\n  constructor(urlMap) {\n    super();\n    this._urlMap = urlMap;\n  }\n  _loadURL(url) {\n    const resolved = this._resolve(url);\n    // use URL to normalize the path for deduping\n    const cacheKey = new URL(resolved, document.URL).href;\n    // console.log(`browser-loader::_loadURL`);\n    // console.log(`    ${url}`);\n    // console.log(`    ${resolved}`);\n    // console.log(`    ${cacheKey}`);\n    const resource = dumbCache[cacheKey];\n    return resource || (dumbCache[cacheKey] = super._loadURL(resolved));\n  }\n  loadResource(name) {\n    // subclass impl differentiates paths and URLs,\n    // for browser env we can feed both kinds into _loadURL\n    return this._loadURL(name);\n  }\n  _resolve(path) {\n    //return new URL(path, this._base).href;\n    let url = this._urlMap[path];\n    if (!url && path) {\n      // TODO(sjmiles): inefficient!\n      const macro = Object.keys(this._urlMap).sort((a, b) => b.length - a.length).find(k => path.slice(0, k.length) == k);\n      if (macro) {\n        url = this._urlMap[macro] + path.slice(macro.length);\n      }\n    }\n    url = url || path;\n    //console.log(`browser-loader: resolve(${path}) = ${url}`);\n    return url;\n  }\n  requireParticle(fileName) {\n    const path = this._resolve(fileName);\n    //console.log(`requireParticle [${path}]`);\n    // inject path to this particle into the UrlMap,\n    // allows \"foo.js\" particle to invoke `importScripts(resolver('foo/othermodule.js'))`\n    this.mapParticleUrl(path);\n    const result = [];\n    self.defineParticle = function(particleWrapper) {\n      result.push(particleWrapper);\n    };\n    importScripts(path);\n    delete self.defineParticle;\n    const logger = logFactory(fileName.split('/').pop(), '#1faa00');\n    return this.unwrapParticle(result[0], logger);\n  }\n  mapParticleUrl(path) {\n    const parts = path.split('/');\n    const suffix = parts.pop();\n    const folder = parts.join('/');\n    const name = suffix.split('.').shift();\n    this._urlMap[name] = folder;\n  }\n  unwrapParticle(particleWrapper, log) {\n    // TODO(sjmiles): regarding `resolver`:\n    //  _resolve method allows particles to request remapping of assets paths\n    //  for use in DOM\n    const resolver = this._resolve.bind(this);\n    // TODO(sjmiles): hack to plumb `fetch` into Particle space under node\n    const _fetch = BrowserLoader.fetch || fetch;\n    return particleWrapper({\n      Particle,\n      DomParticle,\n      MultiplexerDomParticle,\n      SimpleParticle: DomParticle,\n      TransformationDomParticle,\n      resolver,\n      log,\n      html,\n      _fetch\n    });\n  }\n}\n","// @license\n// Copyright (c) 2017 Google Inc. All rights reserved.\n// This code may only be used under the BSD style license found at\n// http://polymer.github.io/LICENSE.txt\n// Code distributed by Google as part of this project is also\n// subject to an additional IP rights grant found at\n// http://polymer.github.io/PATENTS.txt\n\nimport {ParticleExecutionContext} from '../../runtime/particle-execution-context.js';\nimport {BrowserLoader} from './browser-loader.js';\n\nconst log = console.log.bind(console, `%cworker-entry`, `background: #12005e; color: white; padding: 1px 6px 2px 7px; border-radius: 6px;`);\n\nself.onmessage = function(e) {\n  self.onmessage = null;\n  const {id, base} = e.data;\n  //log('starting worker', id);\n  new ParticleExecutionContext(e.ports[0], id, new BrowserLoader(base));\n};\n","/*\n  Copyright 2015 Google Inc. All Rights Reserved.\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n      http://www.apache.org/licenses/LICENSE-2.0\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n*/\n\nconst events = [];\nlet pid;\nlet now;\nif (typeof document == 'object') {\n  pid = 42;\n  now = function() {\n    return performance.now() * 1000;\n  };\n} else {\n  pid = process.pid;\n  now = function() {\n    const t = process.hrtime();\n    return t[0] * 1000000 + t[1] / 1000;\n  };\n}\n\nlet flowId = 0;\n\nfunction parseInfo(info) {\n  if (!info) {\n    return {};\n  }\n  if (typeof info == 'function') {\n    return parseInfo(info());\n  }\n  if (info.toTraceInfo) {\n    return parseInfo(info.toTraceInfo());\n  }\n  return info;\n}\n\nconst streamingCallbacks = [];\nfunction pushEvent(event) {\n    event.pid = pid;\n    event.tid = 0;\n    if (!event.args) {\n      delete event.args;\n    }\n    if (!event.ov) {\n      delete event.ov;\n    }\n    if (!event.cat) {\n      event.cat = '';\n    }\n    // Only keep events in memory if we're not streaming them.\n    if (streamingCallbacks.length === 0) events.push(event);\n    Promise.resolve().then(() => {\n      for (const {callback, predicate} of streamingCallbacks) {\n          if (!predicate || predicate(event)) callback(event);\n      }\n    });\n}\n\nconst module = {exports: {}};\nexport const Tracing = module.exports;\nmodule.exports.enabled = false;\nmodule.exports.enable = function() {\n  module.exports.enabled = true;\n  init();\n};\n\n// TODO: Add back support for options.\n//module.exports.options = options;\n//var enabled = Boolean(options.traceFile);\n\nfunction init() {\n  const result = {\n    wait: async function(v) {\n      return v;\n    },\n    start: function() {\n      return this;\n    },\n    end: function() {\n      return this;\n    },\n    step: function() {\n      return this;\n    },\n    addArgs: function() {\n    },\n    endWith: async function(v) {\n      return v;\n    },\n  };\n  module.exports.wrap = function(info, fn) {\n    return fn;\n  };\n  module.exports.start = function(info, fn) {\n    return result;\n  };\n  module.exports.flow = function(info, fn) {\n    return result;\n  };\n\n  if (!module.exports.enabled) {\n    return;\n  }\n\n  module.exports.wrap = function(info, fn) {\n    return function(...args) {\n      const t = module.exports.start(info);\n      try {\n        return fn(...args);\n      } finally {\n        t.end();\n      }\n    };\n  };\n\n  function startSyncTrace(info) {\n    info = parseInfo(info);\n    let args = info.args;\n    const begin = now();\n    return {\n      addArgs: function(extraArgs) {\n        args = Object.assign(args || {}, extraArgs);\n      },\n      end: function(endInfo = {}, flow) {\n        endInfo = parseInfo(endInfo);\n        if (endInfo.args) {\n          args = Object.assign(args || {}, endInfo.args);\n        }\n        endInfo = Object.assign({}, info, endInfo);\n        this.endTs = now();\n        pushEvent({\n          ph: 'X',\n          ts: begin,\n          dur: this.endTs - begin,\n          cat: endInfo.cat,\n          name: endInfo.name,\n          ov: endInfo.overview,\n          args: args,\n          // Arcs Devtools Specific:\n          flowId: flow && flow.id(),\n          seq: endInfo.sequence\n        });\n      },\n      beginTs: begin\n    };\n  }\n  module.exports.start = function(info) {\n    let trace = startSyncTrace(info);\n    let flow;\n    const baseInfo = {cat: info.cat, name: info.name + ' (async)', overview: info.overview, sequence: info.sequence};\n    return {\n      async wait(v, info) {\n        const flowExisted = !!flow;\n        if (!flowExisted) {\n          flow = module.exports.flow(baseInfo);\n        }\n        trace.end(info, flow);\n        if (flowExisted) {\n          flow.step(Object.assign({ts: trace.beginTs}, baseInfo));\n        } else {\n          flow.start({ts: trace.endTs});\n        }\n        trace = null;\n        try {\n          return await v;\n        } finally {\n          trace = startSyncTrace(baseInfo);\n        }\n      },\n      addArgs(extraArgs) {\n        trace.addArgs(extraArgs);\n      },\n      end(endInfo) {\n        trace.end(endInfo, flow);\n        if (flow) {\n          flow.end({ts: trace.beginTs});\n        }\n      },\n      async endWith(v, endInfo) {\n        if (Promise.resolve(v) === v) { // If v is a promise.\n          v = this.wait(v);\n          try {\n            return await v;\n          } finally {\n            this.end(endInfo);\n          }\n        } else { // If v is not a promise.\n          this.end(endInfo);\n          return v;\n        }\n      }\n    };\n  };\n  module.exports.flow = function(info) {\n    info = parseInfo(info);\n    const id = flowId++;\n    let started = false;\n    return {\n      start: function(startInfo) {\n        const ts = (startInfo && startInfo.ts) || now();\n        started = true;\n        pushEvent({\n          ph: 's',\n          ts,\n          cat: info.cat,\n          name: info.name,\n          ov: info.overview,\n          args: info.args,\n          id: id,\n          seq: info.sequence\n        });\n        return this;\n      },\n      end: function(endInfo) {\n        if (!started) return;\n        const ts = (endInfo && endInfo.ts) || now();\n        endInfo = parseInfo(endInfo);\n        pushEvent({\n          ph: 'f',\n          bp: 'e', // binding point is enclosing slice.\n          ts,\n          cat: info.cat,\n          name: info.name,\n          ov: info.overview,\n          args: endInfo && endInfo.args,\n          id: id,\n          seq: info.sequence\n        });\n        return this;\n      },\n      step: function(stepInfo) {\n        if (!started) return;\n        const ts = (stepInfo && stepInfo.ts) || now();\n        stepInfo = parseInfo(stepInfo);\n        pushEvent({\n          ph: 't',\n          ts,\n          cat: info.cat,\n          name: info.name,\n          ov: info.overview,\n          args: stepInfo && stepInfo.args,\n          id: id,\n          seq: info.sequence\n        });\n        return this;\n      },\n      id: () => id\n    };\n  };\n  module.exports.save = function() {\n    return {traceEvents: events};\n  };\n  module.exports.download = function() {\n    const a = document.createElement('a');\n    a.download = 'trace.json';\n    a.href = 'data:text/plain;base64,' + btoa(JSON.stringify(module.exports.save()));\n    a.click();\n  };\n  module.exports.now = now;\n  module.exports.stream = function(callback, predicate) {\n    // Once we start streaming we no longer keep events in memory.\n    events.length = 0;\n    streamingCallbacks.push({callback, predicate});\n  };\n  module.exports.__clearForTests = function() {\n    events.length = 0;\n    streamingCallbacks.length = 0;\n  };\n}\n\ninit();\n"],"sourceRoot":""}